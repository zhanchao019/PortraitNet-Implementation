{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.nn import DataParallel\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from easydict import EasyDict as edict\n",
    "from yaml import load,FullLoader\n",
    "\n",
    "import sys\n",
    "sys.path.append('../data/')\n",
    "sys.path.append('../util/')\n",
    "sys.path.append('../model/')\n",
    "\n",
    "import datasets\n",
    "from datasets import Human\n",
    "from data_aug import Normalize_Img, Anti_Normalize_Img\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcIOU(img, mask):\n",
    "    sum1 = img + mask\n",
    "    sum1[sum1>0] = 1\n",
    "    sum2 = img + mask\n",
    "    sum2[sum2<2] = 0\n",
    "    sum2[sum2>=2] = 1\n",
    "    if np.sum(sum1) == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 1.0*np.sum(sum2)/np.sum(sum1)\n",
    "\n",
    "def test(dataLoader, netmodel, exp_args):\n",
    "    # switch to eval mode\n",
    "    netmodel.eval()\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    iou = 0\n",
    "    for i, (input_ori, input, edge, mask) in enumerate(dataLoader):  \n",
    "        input_ori_var = Variable(input_ori.cuda())\n",
    "        input_var = Variable(input.cuda())\n",
    "        edge_var = Variable(edge.cuda())\n",
    "        mask_var = Variable(mask.cuda())\n",
    "        \n",
    "        # compute output: loss part1\n",
    "        if exp_args.addEdge == True:\n",
    "            output_mask, output_edge = netmodel(input_ori_var)\n",
    "        else:\n",
    "            output_mask = netmodel(input_ori_var)\n",
    "            \n",
    "        prob = softmax(output_mask)[0,1,:,:]\n",
    "        pred = prob.data.cpu().numpy()\n",
    "        pred[pred>0.5] = 1\n",
    "        pred[pred<=0.5] = 0\n",
    "        iou += calcIOU(pred, mask_var[0].data.cpu().numpy())\n",
    "        \n",
    "    print (len(dataLoader))\n",
    "    return iou/len(dataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish load config file ...\n"
     ]
    }
   ],
   "source": [
    "# load model-1 or model-2: trained with two auxiliary losses (without prior channel)\n",
    "config_path = '../config/model_mobilenetv2_with_two_auxiliary_losses.yaml'\n",
    "\n",
    "# load model-3: trained with prior channel \n",
    "# config_path = '../config/model_mobilenetv2_with_prior_channel.yaml'\n",
    "\n",
    "with open(config_path,'rb') as f:\n",
    "    cont = f.read()\n",
    "cf = load(cont,FullLoader)\n",
    "\n",
    "print ('finish load config file ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========> loading data <===========\n",
      "datasetlist:  ['EG1800']\n",
      "289\n",
      "289\n",
      "finish load dataset ...\n",
      "===========> loading model <===========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhanchao/github/cv_assignment3/myTest/../model/model_mobilenetv2_seg_small.py:257: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MobileNetV2:\n\tMissing key(s) in state_dict: \"edge.weight\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 64\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(bestModelFile):\n\u001b[1;32m     63\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(bestModelFile)\n\u001b[0;32m---> 64\u001b[0m     \u001b[43mnetmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstate_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminLoss: \u001b[39m\u001b[38;5;124m\"\u001b[39m, checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminLoss\u001b[39m\u001b[38;5;124m'\u001b[39m], checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=> loaded checkpoint \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (epoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(bestModelFile, checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "File \u001b[0;32m~/anaconda3/envs/portraitnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1482\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1477\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   1478\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1479\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1481\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 1482\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1483\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1484\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MobileNetV2:\n\tMissing key(s) in state_dict: \"edge.weight\". "
     ]
    }
   ],
   "source": [
    "print ('===========> loading data <===========')\n",
    "exp_args = edict()    \n",
    "exp_args.istrain = False\n",
    "exp_args.task = cf['task']\n",
    "exp_args.datasetlist = cf['datasetlist'] # ['EG1800', ATR', 'MscocoBackground', 'supervisely_face_easy']\n",
    "print (\"datasetlist: \", exp_args.datasetlist)\n",
    "\n",
    "exp_args.model_root = cf['model_root'] \n",
    "exp_args.data_root = cf['data_root']\n",
    "exp_args.file_root = cf['file_root']\n",
    "\n",
    "# the height of input images, default=224\n",
    "exp_args.input_height = cf['input_height']\n",
    "# the width of input images, default=224\n",
    "exp_args.input_width = cf['input_width']\n",
    "\n",
    "# if exp_args.video=True, add prior channel for input images, default=False\n",
    "exp_args.video = cf['video']\n",
    "# the probability to set empty prior channel, default=0.5\n",
    "exp_args.prior_prob = cf['prior_prob']\n",
    "\n",
    "# whether to add boundary auxiliary loss, default=False\n",
    "exp_args.addEdge = cf['addEdge']\n",
    "# whether to add consistency constraint loss, default=False\n",
    "exp_args.stability = cf['stability']\n",
    "\n",
    "# input normalization parameters\n",
    "exp_args.padding_color = cf['padding_color']\n",
    "exp_args.img_scale = cf['img_scale']\n",
    "# BGR order, image mean, default=[103.94, 116.78, 123.68]\n",
    "exp_args.img_mean = cf['img_mean']\n",
    "# BGR order, image val, default=[1/0.017, 1/0.017, 1/0.017]\n",
    "exp_args.img_val = cf['img_val'] \n",
    "\n",
    "# if exp_args.useUpsample==True, use nn.Upsample in decoder, else use nn.ConvTranspose2d\n",
    "exp_args.useUpsample = cf['useUpsample'] \n",
    "# if exp_args.useDeconvGroup==True, set groups=input_channel in nn.ConvTranspose2d\n",
    "exp_args.useDeconvGroup = cf['useDeconvGroup'] \n",
    "\n",
    "exp_args.init = False\n",
    "exp_args.resume = True\n",
    "\n",
    "dataset_test = Human(exp_args)\n",
    "print (len(dataset_test))\n",
    "dataLoader_test = torch.utils.data.DataLoader(dataset_test, batch_size=1, shuffle=False, num_workers=1)\n",
    "print (len(dataLoader_test))\n",
    "print (\"finish load dataset ...\")\n",
    "\n",
    "print ('===========> loading model <===========')\n",
    "import model_mobilenetv2_seg_small as modellib\n",
    "netmodel = modellib.MobileNetV2(n_class=2, \n",
    "                                useUpsample=exp_args.useUpsample, \n",
    "                                useDeconvGroup=exp_args.useDeconvGroup, \n",
    "                                addEdge=exp_args.addEdge, \n",
    "                                channelRatio=1.0, \n",
    "                                minChannel=16, \n",
    "                                weightInit=True,\n",
    "                                video=exp_args.video).cuda()\n",
    "\n",
    "if exp_args.resume:\n",
    "    bestModelFile = os.path.join(exp_args.model_root, 'model_best.pth.tar')\n",
    "    if os.path.isfile(bestModelFile):\n",
    "        checkpoint = torch.load(bestModelFile)\n",
    "        netmodel.load_state_dict(checkpoint['state_dict'],strict=False)\n",
    "        print (\"minLoss: \", checkpoint['minLoss'], checkpoint['epoch'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\".format(bestModelFile, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(bestModelFile))\n",
    "netmodel = netmodel.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhanchao/github/cv_assignment3/myTest/../model/model_mobilenetv2_seg_small.py:257: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['edge.weight'], unexpected_keys=[])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestModelFile = os.path.join(exp_args.model_root, 'model_best.pth.tar')\n",
    "checkpoint = torch.load(bestModelFile)\n",
    "import model_mobilenetv2_seg_small as modellib\n",
    "netmodel = modellib.MobileNetV2(n_class=2, \n",
    "                                useUpsample=exp_args.useUpsample, \n",
    "                                useDeconvGroup=exp_args.useDeconvGroup, \n",
    "                                addEdge=exp_args.addEdge, \n",
    "                                channelRatio=1.0, \n",
    "                                minChannel=16, \n",
    "                                weightInit=True,\n",
    "                                video=exp_args.video).cuda()\n",
    "netmodel.load_state_dict(checkpoint['state_dict'],strict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "('mean iou: ', 0.93428609883957936)\n"
     ]
    }
   ],
   "source": [
    "acc = test(dataLoader_test, netmodel, exp_args)\n",
    "print (\"mean iou: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('portraitnet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "0207daf77e3a18e9e5029fea4cb3644a59b3a2aeb17af1b33263e7e0717de6c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
