{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.nn import DataParallel\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from easydict import EasyDict as edict\n",
    "from yaml import load\n",
    "\n",
    "import sys\n",
    "sys.path.append('../data/')\n",
    "sys.path.append('../util/')\n",
    "sys.path.append('../model/')\n",
    "\n",
    "import datasets\n",
    "from datasets import Human\n",
    "from data_aug import Normalize_Img, Anti_Normalize_Img\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcIOU(img, mask):\n",
    "    sum1 = img + mask\n",
    "    sum1[sum1>0] = 1\n",
    "    sum2 = img + mask\n",
    "    sum2[sum2<2] = 0\n",
    "    sum2[sum2>=2] = 1\n",
    "    if np.sum(sum1) == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 1.0*np.sum(sum2)/np.sum(sum1)\n",
    "\n",
    "def test(dataLoader, netmodel, exp_args):\n",
    "    # switch to eval mode\n",
    "    netmodel.eval()\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    iou = 0\n",
    "    for i, (input_ori, input, edge, mask) in enumerate(dataLoader):  \n",
    "        input_ori_var = Variable(input_ori.cuda())\n",
    "        input_var = Variable(input.cuda())\n",
    "        edge_var = Variable(edge.cuda())\n",
    "        mask_var = Variable(mask.cuda())\n",
    "        \n",
    "        # compute output: loss part1\n",
    "        if exp_args.addEdge == True:\n",
    "            output_mask, output_edge = netmodel(input_ori_var)\n",
    "        else:\n",
    "            output_mask = netmodel(input_ori_var)\n",
    "            \n",
    "        prob = softmax(output_mask)[0,1,:,:]\n",
    "        pred = prob.data.cpu().numpy()\n",
    "        pred[pred>0.5] = 1\n",
    "        pred[pred<=0.5] = 0\n",
    "        iou += calcIOU(pred, mask_var[0].data.cpu().numpy())\n",
    "        \n",
    "    print len(dataLoader)\n",
    "    return iou/len(dataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish load config file ...\n"
     ]
    }
   ],
   "source": [
    "# load model-1 or model-2: trained with two auxiliary losses (without prior channel)\n",
    "config_path = '../config/model_mobilenetv2_with_two_auxiliary_losses.yaml'\n",
    "\n",
    "# load model-3: trained with prior channel \n",
    "# config_path = '../config/model_mobilenetv2_with_prior_channel.yaml'\n",
    "\n",
    "with open(config_path,'rb') as f:\n",
    "    cont = f.read()\n",
    "cf = load(cont)\n",
    "\n",
    "print ('finish load config file ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========> loading data <===========\n",
      "('datasetlist: ', ['supervisely_face_easy'])\n",
      "400\n",
      "400\n",
      "finish load dataset ...\n",
      "===========> loading model <===========\n",
      "('minLoss: ', 0.06571390116042064, 1698)\n",
      "=> loaded checkpoint '/home/dongx12/PortraitNet/myexp/mobilenetv2_supervise_portrait/both_224_without_group/model_best.pth.tar' (epoch 1698)\n"
     ]
    }
   ],
   "source": [
    "print ('===========> loading data <===========')\n",
    "exp_args = edict()    \n",
    "exp_args.istrain = False\n",
    "exp_args.task = cf['task']\n",
    "exp_args.datasetlist = cf['datasetlist'] # ['EG1800', ATR', 'MscocoBackground', 'supervisely_face_easy']\n",
    "print (\"datasetlist: \", exp_args.datasetlist)\n",
    "\n",
    "exp_args.model_root = cf['model_root'] \n",
    "exp_args.data_root = cf['data_root']\n",
    "exp_args.file_root = cf['file_root']\n",
    "\n",
    "# the height of input images, default=224\n",
    "exp_args.input_height = cf['input_height']\n",
    "# the width of input images, default=224\n",
    "exp_args.input_width = cf['input_width']\n",
    "\n",
    "# if exp_args.video=True, add prior channel for input images, default=False\n",
    "exp_args.video = cf['video']\n",
    "# the probability to set empty prior channel, default=0.5\n",
    "exp_args.prior_prob = cf['prior_prob']\n",
    "\n",
    "# whether to add boundary auxiliary loss, default=False\n",
    "exp_args.addEdge = cf['addEdge']\n",
    "# whether to add consistency constraint loss, default=False\n",
    "exp_args.stability = cf['stability']\n",
    "\n",
    "# input normalization parameters\n",
    "exp_args.padding_color = cf['padding_color']\n",
    "exp_args.img_scale = cf['img_scale']\n",
    "# BGR order, image mean, default=[103.94, 116.78, 123.68]\n",
    "exp_args.img_mean = cf['img_mean']\n",
    "# BGR order, image val, default=[1/0.017, 1/0.017, 1/0.017]\n",
    "exp_args.img_val = cf['img_val'] \n",
    "\n",
    "# if exp_args.useUpsample==True, use nn.Upsample in decoder, else use nn.ConvTranspose2d\n",
    "exp_args.useUpsample = cf['useUpsample'] \n",
    "# if exp_args.useDeconvGroup==True, set groups=input_channel in nn.ConvTranspose2d\n",
    "exp_args.useDeconvGroup = cf['useDeconvGroup'] \n",
    "\n",
    "exp_args.init = False\n",
    "exp_args.resume = True\n",
    "\n",
    "dataset_test = Human(exp_args)\n",
    "print len(dataset_test)\n",
    "dataLoader_test = torch.utils.data.DataLoader(dataset_test, batch_size=1, shuffle=False, num_workers=1)\n",
    "print len(dataLoader_test)\n",
    "print (\"finish load dataset ...\")\n",
    "\n",
    "print ('===========> loading model <===========')\n",
    "import model_mobilenetv2_seg_small as modellib\n",
    "netmodel = modellib.MobileNetV2(n_class=2, \n",
    "                                useUpsample=exp_args.useUpsample, \n",
    "                                useDeconvGroup=exp_args.useDeconvGroup, \n",
    "                                addEdge=exp_args.addEdge, \n",
    "                                channelRatio=1.0, \n",
    "                                minChannel=16, \n",
    "                                weightInit=True,\n",
    "                                video=exp_args.video).cuda()\n",
    "\n",
    "if exp_args.resume:\n",
    "    bestModelFile = os.path.join(exp_args.model_root, 'model_best.pth.tar')\n",
    "    if os.path.isfile(bestModelFile):\n",
    "        checkpoint = torch.load(bestModelFile)\n",
    "        netmodel.load_state_dict(checkpoint['state_dict'])\n",
    "        print (\"minLoss: \", checkpoint['minLoss'], checkpoint['epoch'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\".format(bestModelFile, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(bestModelFile))\n",
    "netmodel = netmodel.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "('mean iou: ', 0.93428609883957936)\n"
     ]
    }
   ],
   "source": [
    "acc = test(dataLoader_test, netmodel, exp_args)\n",
    "print (\"mean iou: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
