2022-12-04 02:03:19.257608: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-04 02:03:19.408047: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2022-12-04 02:03:20.020774: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/zhanchao/anaconda3/envs/portraitnet/lib/python3.8/site-packages/cv2/../../lib64:/usr/local/cuda-11.1/lib64
2022-12-04 02:03:20.020852: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/zhanchao/anaconda3/envs/portraitnet/lib/python3.8/site-packages/cv2/../../lib64:/usr/local/cuda-11.1/lib64
2022-12-04 02:03:20.020864: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2022-12-04 02:03:20.624202: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/zhanchao/anaconda3/envs/portraitnet/lib/python3.8/site-packages/cv2/../../lib64:/usr/local/cuda-11.1/lib64
2022-12-04 02:03:20.624249: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2022-12-04 02:03:20.624555: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
===========> loading config <============
config path:  /home/zhanchao/github/cv_assignment3/config/model_mobilenetv2_without_auxiliary_losses.yaml
b"data_root: /data/zhanchao/ #\xe9\x9c\x80\xe8\xa6\x81\xe8\xbf\x9b\xe8\xa1\x8c\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84dataset root\xe5\x9c\xb0\xe5\x9d\x80\nfile_root: /home/zhanchao/github/cv_assignment3/data/select_data/\nmodel_root: /home/zhanchao/github/cv_assignment3/myexp/mobilenetv2_eg1800/single_224_single_gpu/\n\nistrain: True\ntask: 'seg'\ndatasetlist: ['EG1800'] # 'support: [EG1800, supervisely_face_easy, ATR, MscocoBackground]'\n# datasetlist: ['supervisely_face_easy'] # 'support: [EG1800, supervisely_face_easy, ATR, MscocoBackground]'\n\ninput_height: 224 # the height of input images\ninput_width: 224 # the width of input images\n\nvideo: False # if exp_args.video=True, add prior channel for input images\nprior_prob: 0.5 # the probability to set empty prior channel\n\naddEdge: False # whether to add boundary auxiliary loss \nedgeRatio: 0.1 # the weight of boundary auxiliary loss\nstability: False # whether to add consistency constraint loss\nuse_kl: True # whether to use KL loss in consistency constraint loss\ntemperature: 1 # temperature in consistency constraint loss\nalpha: 2 # the weight of consistency constraint loss\n\n# input normalization parameters\npadding_color: 128\nimg_scale: 1\nimg_mean: [103.94, 116.78, 123.68] # BGR order, image mean\nimg_val: [0.017, 0.017, 0.017] # BGR order, image val\n\ninit: False # whether to use pretian model to init portraitnet\nresume: False # whether to continue training\n\nuseUpsample: False # if exp_args.useUpsample==True, use nn.Upsample in decoder, else use nn.ConvTranspose2d\nuseDeconvGroup: False # if exp_args.useDeconvGroup==True, set groups=input_channel in nn.ConvTranspose2d\n\n\n"
===========> loading data <===========
image number in training:  1447
image number in testing:  289
finish load dataset ...
===========> loading model <===========
finish load PortraitNet ...
===========>   training    <===========
/home/zhanchao/github/cv_assignment3/myTrain/../model/model_mobilenetv2_seg_small.py:257: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.
  nn.init.kaiming_normal(m.weight.data)
Epoch: [0][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 2.5648 (2.5648)	
1.0 0.031329554
===========>   testing    <===========
Epoch: [0][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.7043 (0.7043)	
0.95358574 0.043366313
Epoch: [0][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.6860 (0.7553)	
0.9818133 0.008676421
Epoch: [0][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.7158 (0.7346)	
0.98528683 0.010403257
loss:  0.782947436967445 10000
===========>   training    <===========
Epoch: [1][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.7457 (0.7457)	
0.9990833 0.010671055
===========>   testing    <===========
Epoch: [1][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.6983 (0.6983)	
0.91892046 0.1720114
Epoch: [1][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.7130 (0.7232)	
0.97383016 0.07643604
Epoch: [1][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.7059 (0.7203)	
0.95979387 0.076083295
loss:  0.6624680097976561 0.782947436967445
===========>   training    <===========
Epoch: [2][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.7221 (0.7221)	
0.92309487 0.054260004
===========>   testing    <===========
Epoch: [2][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.6964 (0.6964)	
0.88169247 0.13668251
Epoch: [2][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.7133 (0.7058)	
0.93287855 0.13749595
Epoch: [2][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.7048 (0.7045)	
0.9169081 0.136426
loss:  0.632447416887487 0.6624680097976561
===========>   training    <===========
Epoch: [3][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.6997 (0.6997)	
0.9098147 0.11557147
===========>   testing    <===========
Epoch: [3][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.6945 (0.6945)	
0.8570023 0.15355484
Epoch: [3][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.7253 (0.6874)	
0.9222561 0.15881373
Epoch: [3][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.7019 (0.6880)	
0.91872615 0.1582533
loss:  0.5996383814064787 0.632447416887487
===========>   training    <===========
Epoch: [4][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.6828 (0.6828)	
0.9057214 0.11437181
===========>   testing    <===========
Epoch: [4][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.6918 (0.6918)	
0.8786165 0.118474185
Epoch: [4][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.7674 (0.6770)	
0.94501084 0.121324725
Epoch: [4][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.7118 (0.6818)	
0.9269122 0.11974918
loss:  0.540536252310402 0.5996383814064787
===========>   training    <===========
Epoch: [5][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.6665 (0.6665)	
0.8768673 0.20983362
===========>   testing    <===========
Epoch: [5][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.6548 (0.6548)	
0.88284904 0.21418446
Epoch: [5][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.6699 (0.6462)	
0.9465457 0.13551843
Epoch: [5][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.6637 (0.6438)	
0.934575 0.2081535
loss:  0.5823749034124674 0.540536252310402
===========>   training    <===========
Epoch: [6][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.6292 (0.6292)	
0.9634352 0.09344636
===========>   testing    <===========
Epoch: [6][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.4841 (0.4841)	
0.9794932 0.092236415
Epoch: [6][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.6152 (0.5423)	
0.9870271 0.07577905
Epoch: [6][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.5189 (0.5383)	
0.98504966 0.09300324
loss:  0.42332954765751674 0.540536252310402
===========>   training    <===========
Epoch: [7][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.4922 (0.4922)	
0.99648535 0.0360704
===========>   testing    <===========
Epoch: [7][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.4511 (0.4511)	
0.98149866 0.012721505
Epoch: [7][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.6100 (0.4585)	
0.9960742 0.013058163
Epoch: [7][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.4110 (0.4588)	
0.99009097 0.012722181
loss:  0.3446083778706871 0.42332954765751674
===========>   training    <===========
Epoch: [8][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.4285 (0.4285)	
0.99832004 0.008800217
===========>   testing    <===========
Epoch: [8][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.4521 (0.4521)	
0.9752989 0.011132125
Epoch: [8][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.5199 (0.4096)	
0.9922341 0.0120542105
Epoch: [8][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.4280 (0.4120)	
0.9796826 0.01066403
loss:  0.3324046091375962 0.3446083778706871
===========>   training    <===========
Epoch: [9][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.4239 (0.4239)	
0.96717495 0.009172019
===========>   testing    <===========
Epoch: [9][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.4033 (0.4033)	
0.98199916 0.006133791
Epoch: [9][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.5301 (0.3807)	
0.9952728 0.006291479
Epoch: [9][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.4430 (0.3884)	
0.9837013 0.0059846425
loss:  0.3233385412673587 0.3324046091375962
===========>   training    <===========
Epoch: [10][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3823 (0.3823)	
0.9999403 0.012022125
===========>   testing    <===========
Epoch: [10][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2981 (0.2981)	
0.9913127 0.012655771
Epoch: [10][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.5344 (0.3627)	
0.9913112 0.01303215
Epoch: [10][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3815 (0.3688)	
0.98002934 0.01177957
loss:  0.26336896188121406 0.3233385412673587
===========>   training    <===========
Epoch: [11][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3583 (0.3583)	
0.99942136 0.010609755
===========>   testing    <===========
Epoch: [11][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3839 (0.3839)	
0.99208987 0.0060208756
Epoch: [11][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.5200 (0.3567)	
0.9800704 0.00677727
Epoch: [11][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3134 (0.3601)	
0.9896331 0.006530758
loss:  0.26887354713516054 0.26336896188121406
===========>   training    <===========
Epoch: [12][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3398 (0.3398)	
0.99999726 0.009407483
===========>   testing    <===========
Epoch: [12][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.4289 (0.4289)	
0.9900449 0.0054014106
Epoch: [12][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.5133 (0.3454)	
0.9794214 0.005459461
Epoch: [12][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3429 (0.3457)	
0.98924667 0.005516605
loss:  0.26420218937956674 0.26336896188121406
===========>   training    <===========
Epoch: [13][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3409 (0.3409)	
0.9998018 0.0077896155
===========>   testing    <===========
Epoch: [13][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3609 (0.3609)	
0.98372275 0.0065425555
Epoch: [13][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.4732 (0.3254)	
0.96645176 0.006575278
Epoch: [13][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3426 (0.3276)	
0.983113 0.0065025073
loss:  0.25218804900249703 0.26336896188121406
===========>   training    <===========
Epoch: [14][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3629 (0.3629)	
0.9962585 0.006478109
===========>   testing    <===========
Epoch: [14][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.4054 (0.4054)	
0.9936587 0.0051890532
Epoch: [14][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.5315 (0.3185)	
0.97803694 0.005224664
Epoch: [14][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2746 (0.3167)	
0.9934145 0.00508048
loss:  0.24869376556251044 0.25218804900249703
===========>   training    <===========
Epoch: [15][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3223 (0.3223)	
0.9998816 0.0049617747
===========>   testing    <===========
Epoch: [15][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2573 (0.2573)	
0.99886763 0.004587401
Epoch: [15][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.6477 (0.2963)	
0.99797946 0.0046599642
Epoch: [15][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2876 (0.2990)	
0.99690384 0.004607831
loss:  0.23018176621127262 0.24869376556251044
===========>   training    <===========
Epoch: [16][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3816 (0.3816)	
0.9994925 0.0035143478
===========>   testing    <===========
Epoch: [16][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2995 (0.2995)	
0.9963813 0.004771516
Epoch: [16][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.5625 (0.3144)	
0.9849156 0.0048182677
Epoch: [16][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3188 (0.3178)	
0.99548197 0.004801618
loss:  0.23626903327753057 0.23018176621127262
===========>   training    <===========
Epoch: [17][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3396 (0.3396)	
0.9960057 0.0044067376
===========>   testing    <===========
Epoch: [17][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3097 (0.3097)	
0.99457103 0.0040178006
Epoch: [17][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.5997 (0.3078)	
0.9927025 0.004109967
Epoch: [17][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2436 (0.3100)	
0.9943474 0.004025295
loss:  0.23318839226245636 0.23018176621127262
===========>   training    <===========
Epoch: [18][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2841 (0.2841)	
0.9981377 0.0035392176
===========>   testing    <===========
Epoch: [18][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2987 (0.2987)	
0.99806756 0.003680967
Epoch: [18][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.6827 (0.3212)	
0.9963504 0.0036899208
Epoch: [18][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2569 (0.3234)	
0.99734664 0.00365839
loss:  0.23436624121317484 0.23018176621127262
===========>   training    <===========
Epoch: [19][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3069 (0.3069)	
0.9993912 0.003586585
===========>   testing    <===========
Epoch: [19][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3794 (0.3794)	
0.9953343 0.00310841
Epoch: [19][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.5320 (0.2881)	
0.99069935 0.0031428493
Epoch: [19][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3122 (0.2866)	
0.9928 0.0030723948
loss:  0.21948815220314488 0.23018176621127262
===========>   training    <===========
Epoch: [20][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2864 (0.2864)	
0.997488 0.0035416824
===========>   testing    <===========
Epoch: [20][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2336 (0.2336)	
0.99744606 0.0024334395
Epoch: [20][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.5928 (0.2730)	
0.9922477 0.0024728845
Epoch: [20][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2417 (0.2745)	
0.99215454 0.0024217432
loss:  0.2062015328154373 0.21948815220314488
===========>   training    <===========
Epoch: [21][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2883 (0.2883)	
0.9999695 0.002189299
===========>   testing    <===========
Epoch: [21][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2697 (0.2697)	
0.9908121 0.0020413091
Epoch: [21][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.5249 (0.2710)	
0.9901417 0.002045138
Epoch: [21][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2562 (0.2689)	
0.98869705 0.0020160144
loss:  0.20878569323115215 0.2062015328154373
===========>   training    <===========
Epoch: [22][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2701 (0.2701)	
0.999759 0.0018756408
===========>   testing    <===========
Epoch: [22][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2422 (0.2422)	
0.99728 0.0021215533
Epoch: [22][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.5957 (0.2613)	
0.9918635 0.0021974612
Epoch: [22][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2343 (0.2601)	
0.99649966 0.0021290113
loss:  0.2006662917728006 0.2062015328154373
===========>   training    <===========
Epoch: [23][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.3055 (0.3055)	
0.9999882 0.0020713343
===========>   testing    <===========
Epoch: [23][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.3349 (0.3349)	
0.9948102 0.0023633048
Epoch: [23][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.6431 (0.2661)	
0.9829107 0.0023668467
Epoch: [23][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2385 (0.2636)	
0.9946557 0.0023702565
loss:  0.20554378418565267 0.2006662917728006
===========>   training    <===========
Epoch: [24][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2793 (0.2793)	
0.99999976 0.001948024
===========>   testing    <===========
Epoch: [24][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.3107 (0.3107)	
0.99593383 0.001969714
Epoch: [24][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.5621 (0.2587)	
0.9843121 0.001974178
Epoch: [24][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2162 (0.2519)	
0.9951154 0.0019204115
loss:  0.19929327037754274 0.2006662917728006
===========>   training    <===========
Epoch: [25][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2684 (0.2684)	
0.9980817 0.0016410992
===========>   testing    <===========
Epoch: [25][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2277 (0.2277)	
0.99935085 0.0014099315
Epoch: [25][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.7192 (0.2519)	
0.9990758 0.0014111242
Epoch: [25][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1962 (0.2465)	
0.99916995 0.001413964
loss:  0.18970747986553227 0.19929327037754274
===========>   training    <===========
Epoch: [26][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2820 (0.2820)	
0.9982153 0.0016256334
===========>   testing    <===========
Epoch: [26][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.3798 (0.3798)	
0.99708897 0.0018952776
Epoch: [26][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.4758 (0.2602)	
0.98487365 0.0018365749
Epoch: [26][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2604 (0.2484)	
0.99689925 0.0018344205
loss:  0.19810827116998087 0.18970747986553227
===========>   training    <===========
Epoch: [27][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2268 (0.2268)	
0.9995346 0.0020216792
===========>   testing    <===========
Epoch: [27][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2504 (0.2504)	
0.99939775 0.0020723687
Epoch: [27][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.5801 (0.2428)	
0.99057543 0.0021273892
Epoch: [27][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2053 (0.2386)	
0.9982395 0.0020708996
loss:  0.18830263568766492 0.18970747986553227
===========>   training    <===========
Epoch: [28][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2561 (0.2561)	
0.9998037 0.002124787
===========>   testing    <===========
Epoch: [28][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2447 (0.2447)	
0.9963516 0.0014055584
Epoch: [28][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.5669 (0.2463)	
0.98278284 0.0014069163
Epoch: [28][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2200 (0.2425)	
0.99633324 0.001402001
loss:  0.1909856858976272 0.18830263568766492
===========>   training    <===========
Epoch: [29][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2172 (0.2172)	
0.9998529 0.0016352268
===========>   testing    <===========
Epoch: [29][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2987 (0.2987)	
0.99927956 0.0012735656
Epoch: [29][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.6356 (0.2441)	
0.994409 0.0012862479
Epoch: [29][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1742 (0.2440)	
0.99910766 0.0012710061
loss:  0.19218157684823645 0.18830263568766492
===========>   training    <===========
Epoch: [30][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2455 (0.2455)	
0.99999297 0.0013029688
===========>   testing    <===========
Epoch: [30][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2390 (0.2390)	
0.99977607 0.0011078181
Epoch: [30][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.6784 (0.2283)	
0.9984723 0.0011485372
Epoch: [30][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1607 (0.2266)	
0.9998863 0.0011052976
loss:  0.1739878692795911 0.18830263568766492
===========>   training    <===========
Epoch: [31][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2328 (0.2328)	
0.99991214 0.001597424
===========>   testing    <===========
Epoch: [31][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2170 (0.2170)	
0.9991353 0.0015857554
Epoch: [31][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.6369 (0.2206)	
0.99507856 0.0016065418
Epoch: [31][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1988 (0.2165)	
0.9997334 0.0015969011
loss:  0.1654893807779254 0.1739878692795911
===========>   training    <===========
Epoch: [32][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2365 (0.2365)	
0.9999051 0.0021642202
===========>   testing    <===========
Epoch: [32][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2253 (0.2253)	
0.99954695 0.0014915542
Epoch: [32][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.5224 (0.2231)	
0.9954484 0.0014904396
Epoch: [32][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2317 (0.2146)	
0.99896383 0.00147639
loss:  0.16774557866755113 0.1654893807779254
===========>   training    <===========
Epoch: [33][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2183 (0.2183)	
0.9962708 0.0016518986
===========>   testing    <===========
Epoch: [33][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1919 (0.1919)	
0.99930453 0.001638654
Epoch: [33][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.5933 (0.2240)	
0.9909973 0.0016524091
Epoch: [33][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2043 (0.2219)	
0.9990964 0.0015928913
loss:  0.17085412708254333 0.1654893807779254
===========>   training    <===========
Epoch: [34][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2407 (0.2407)	
0.99658966 0.0023258475
===========>   testing    <===========
Epoch: [34][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2713 (0.2713)	
0.99914014 0.0011538062
Epoch: [34][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.4829 (0.2258)	
0.99336535 0.0011634368
Epoch: [34][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1571 (0.2221)	
0.99897516 0.0011509137
loss:  0.17354135502699775 0.1654893807779254
===========>   training    <===========
Epoch: [35][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2290 (0.2290)	
0.9982326 0.001366339
===========>   testing    <===========
Epoch: [35][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1828 (0.1828)	
0.99989414 0.0013173041
Epoch: [35][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.4692 (0.2051)	
0.9952809 0.0014019429
Epoch: [35][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1693 (0.2039)	
0.9997801 0.0012762551
loss:  0.15605768424351618 0.1654893807779254
===========>   training    <===========
Epoch: [36][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2298 (0.2298)	
0.9999474 0.0012369138
===========>   testing    <===========
Epoch: [36][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2584 (0.2584)	
0.9998615 0.0011703428
Epoch: [36][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.5994 (0.2284)	
0.9990753 0.0011854267
Epoch: [36][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1851 (0.2283)	
0.999876 0.0011708188
loss:  0.17778041431716518 0.15605768424351618
===========>   training    <===========
Epoch: [37][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2360 (0.2360)	
0.9998343 0.0010428984
===========>   testing    <===========
Epoch: [37][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1694 (0.1694)	
0.9999069 0.0012125613
Epoch: [37][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.6012 (0.2066)	
0.99722445 0.0012630774
Epoch: [37][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1782 (0.2061)	
0.9999267 0.0011556388
loss:  0.15871176238227214 0.15605768424351618
===========>   training    <===========
Epoch: [38][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2330 (0.2330)	
0.99998224 0.001138738
===========>   testing    <===========
Epoch: [38][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1790 (0.1790)	
0.9989832 0.0011019312
Epoch: [38][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.4725 (0.2145)	
0.990387 0.0010691065
Epoch: [38][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2274 (0.2130)	
0.99868006 0.001058086
loss:  0.1663980355501783 0.15605768424351618
===========>   training    <===========
Epoch: [39][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1996 (0.1996)	
0.9999987 0.0010368042
===========>   testing    <===========
Epoch: [39][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1994 (0.1994)	
0.99930716 0.0012283453
Epoch: [39][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.4802 (0.1946)	
0.9979481 0.0012632116
Epoch: [39][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1848 (0.1914)	
0.9982992 0.0012231453
loss:  0.14906649620733425 0.15605768424351618
===========>   training    <===========
Epoch: [40][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.2111 (0.2111)	
0.9999995 0.0011208823
===========>   testing    <===========
Epoch: [40][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1916 (0.1916)	
0.99992394 0.000866909
Epoch: [40][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.3302 (0.1948)	
0.9990866 0.0008682011
Epoch: [40][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1867 (0.1925)	
0.99995995 0.0008601578
loss:  0.1489070289804182 0.14906649620733425
===========>   training    <===========
Epoch: [41][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1989 (0.1989)	
0.99998236 0.0010589493
===========>   testing    <===========
Epoch: [41][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1923 (0.1923)	
0.99966204 0.00096603285
Epoch: [41][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.4812 (0.1908)	
0.996863 0.00097423745
Epoch: [41][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1579 (0.1877)	
0.99967694 0.0009599271
loss:  0.1473330443375509 0.1489070289804182
===========>   training    <===========
Epoch: [42][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1788 (0.1788)	
0.99999654 0.0013975046
===========>   testing    <===========
Epoch: [42][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1895 (0.1895)	
0.9996983 0.0008873572
Epoch: [42][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.3891 (0.1972)	
0.9993272 0.0011610321
Epoch: [42][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1702 (0.1936)	
0.9998229 0.0007897193
loss:  0.1564384773948635 0.1473330443375509
===========>   training    <===========
Epoch: [43][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1887 (0.1887)	
0.9999021 0.00082478346
===========>   testing    <===========
Epoch: [43][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1777 (0.1777)	
0.99996924 0.0010102142
Epoch: [43][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.3851 (0.1931)	
0.9993824 0.001104928
Epoch: [43][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1438 (0.1911)	
0.99999464 0.0009815098
loss:  0.14858940661585407 0.1473330443375509
===========>   training    <===========
Epoch: [44][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1894 (0.1894)	
0.9999999 0.0011051882
===========>   testing    <===========
Epoch: [44][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.2008 (0.2008)	
0.9993247 0.0009897253
Epoch: [44][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.3304 (0.1965)	
0.9852879 0.001009383
Epoch: [44][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1533 (0.1861)	
0.99977595 0.00096578914
loss:  0.1496233256162811 0.1473330443375509
===========>   training    <===========
Epoch: [45][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1794 (0.1794)	
0.9994266 0.0010329152
===========>   testing    <===========
Epoch: [45][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.2148 (0.2148)	
0.9999013 0.0008356371
Epoch: [45][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.2551 (0.1941)	
0.99888223 0.0008331278
Epoch: [45][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1664 (0.1951)	
0.9999187 0.00083047623
loss:  0.1531002256038535 0.1473330443375509
===========>   training    <===========
Epoch: [46][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1723 (0.1723)	
0.99999917 0.00077057735
===========>   testing    <===========
Epoch: [46][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1275 (0.1275)	
0.9998085 0.00068232924
Epoch: [46][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.3795 (0.1703)	
0.98049 0.0007237417
Epoch: [46][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1579 (0.1661)	
0.9999018 0.00066661526
loss:  0.12614744920386456 0.1473330443375509
===========>   training    <===========
Epoch: [47][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.2123 (0.2123)	
0.99999845 0.0005149453
===========>   testing    <===========
Epoch: [47][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.2463 (0.2463)	
0.99933285 0.0011621254
Epoch: [47][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.2032 (0.1981)	
0.9976139 0.0011733277
Epoch: [47][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.2131 (0.1910)	
0.9996227 0.0011669807
loss:  0.14986268974873118 0.12614744920386456
===========>   training    <===========
Epoch: [48][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.2385 (0.2385)	
1.0 0.0008085886
===========>   testing    <===========
Epoch: [48][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.2176 (0.2176)	
0.9999205 0.0011078538
Epoch: [48][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.2666 (0.1771)	
0.9998115 0.0011160423
Epoch: [48][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1864 (0.1728)	
0.99995065 0.0011183405
loss:  0.13344373293259593 0.12614744920386456
===========>   training    <===========
Epoch: [49][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1967 (0.1967)	
0.9999207 0.001027201
===========>   testing    <===========
Epoch: [49][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1277 (0.1277)	
0.9998605 0.0008560006
Epoch: [49][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1674 (0.1692)	
0.99920326 0.0008712349
Epoch: [49][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1949 (0.1672)	
0.9999403 0.0008713519
loss:  0.13064197078365802 0.12614744920386456
===========>   training    <===========
Epoch: [50][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1867 (0.1867)	
0.9999857 0.0007451388
===========>   testing    <===========
Epoch: [50][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1362 (0.1362)	
0.9998429 0.000543349
Epoch: [50][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.2308 (0.1559)	
0.99847275 0.00060166186
Epoch: [50][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1522 (0.1543)	
0.9999579 0.00054187037
loss:  0.12259550716476575 0.12614744920386456
===========>   training    <===========
Epoch: [51][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1857 (0.1857)	
0.99806136 0.0006060289
===========>   testing    <===========
Epoch: [51][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1360 (0.1360)	
0.9999753 0.000644974
Epoch: [51][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1522 (0.1683)	
0.99949145 0.0006895458
Epoch: [51][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1719 (0.1672)	
0.9999819 0.00062993
loss:  0.12784162733127857 0.12259550716476575
===========>   training    <===========
Epoch: [52][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1495 (0.1495)	
1.0 0.0006371937
===========>   testing    <===========
Epoch: [52][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1600 (0.1600)	
0.99974436 0.00063247344
Epoch: [52][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1835 (0.1762)	
0.9927313 0.0006348145
Epoch: [52][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1413 (0.1680)	
0.9998987 0.00063496974
loss:  0.13563862640960445 0.12259550716476575
===========>   training    <===========
Epoch: [53][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1743 (0.1743)	
0.9999739 0.00089170004
===========>   testing    <===========
Epoch: [53][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1452 (0.1452)	
0.99992704 0.00059338566
Epoch: [53][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.2803 (0.1625)	
0.9973127 0.00055850786
Epoch: [53][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1306 (0.1615)	
0.99997747 0.00048828445
loss:  0.12538562502377504 0.12259550716476575
===========>   training    <===========
Epoch: [54][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1808 (0.1808)	
1.0 0.0005247224
===========>   testing    <===========
Epoch: [54][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1459 (0.1459)	
0.9999498 0.0004169907
Epoch: [54][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.2774 (0.1535)	
0.9985202 0.0004197799
Epoch: [54][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1145 (0.1482)	
0.99999654 0.00042354508
loss:  0.11953672641590352 0.12259550716476575
===========>   training    <===========
Epoch: [55][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.2143 (0.2143)	
1.0 0.00031865507
===========>   testing    <===========
Epoch: [55][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1212 (0.1212)	
0.9998324 0.00055836147
Epoch: [55][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.2542 (0.1511)	
0.987398 0.0005883712
Epoch: [55][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1389 (0.1470)	
0.99996316 0.0005652553
loss:  0.1146815668878629 0.11953672641590352
===========>   training    <===========
Epoch: [56][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1609 (0.1609)	
0.9999896 0.0007291443
===========>   testing    <===========
Epoch: [56][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1709 (0.1709)	
0.99997854 0.0007966795
Epoch: [56][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.2435 (0.1558)	
0.99994373 0.0008003326
Epoch: [56][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1099 (0.1546)	
0.9999993 0.00077617134
loss:  0.1202153316199357 0.1146815668878629
===========>   training    <===========
Epoch: [57][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1765 (0.1765)	
0.99999917 0.00067306863
===========>   testing    <===========
Epoch: [57][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1565 (0.1565)	
0.99996734 0.0005425213
Epoch: [57][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1312 (0.1572)	
0.99787736 0.00056618406
Epoch: [57][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1255 (0.1532)	
0.99999726 0.00052659924
loss:  0.12278967641938454 0.1146815668878629
===========>   training    <===========
Epoch: [58][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1632 (0.1632)	
1.0 0.00089783414
===========>   testing    <===========
Epoch: [58][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1233 (0.1233)	
0.9999341 0.0005798673
Epoch: [58][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.2033 (0.1514)	
0.99888843 0.0005775831
Epoch: [58][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.0969 (0.1487)	
0.9999994 0.0005580027
loss:  0.11640490721037078 0.1146815668878629
===========>   training    <===========
Epoch: [59][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1668 (0.1668)	
0.99999726 0.00056765234
===========>   testing    <===========
Epoch: [59][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1476 (0.1476)	
0.99994814 0.00043008162
Epoch: [59][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1719 (0.1501)	
0.9991215 0.00042891514
Epoch: [59][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1469 (0.1483)	
0.9999746 0.00042057817
loss:  0.11782069564797892 0.1146815668878629
===========>   training    <===========
Epoch: [60][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1641 (0.1641)	
1.0 0.00058335974
===========>   testing    <===========
Epoch: [60][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1427 (0.1427)	
0.99991155 0.0005222111
Epoch: [60][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.2095 (0.1463)	
0.9998522 0.0005151498
Epoch: [60][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1208 (0.1445)	
0.99995005 0.0005148312
loss:  0.11299207528620958 0.1146815668878629
===========>   training    <===========
Epoch: [61][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1734 (0.1734)	
0.9999994 0.00040765744
===========>   testing    <===========
Epoch: [61][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.0962 (0.0962)	
0.9999982 0.00045966593
Epoch: [61][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1784 (0.1420)	
0.99996734 0.00053919916
Epoch: [61][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1395 (0.1387)	
1.0 0.00042934783
loss:  0.1096873501826674 0.11299207528620958
===========>   training    <===========
Epoch: [62][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1586 (0.1586)	
0.9999999 0.0004451522
===========>   testing    <===========
Epoch: [62][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1099 (0.1099)	
0.9999877 0.0004347859
Epoch: [62][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.4736 (0.1732)	
0.9999994 0.00042007337
Epoch: [62][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1486 (0.1786)	
0.9999999 0.00041253766
loss:  0.13746501581739812 0.1096873501826674
===========>   training    <===========
Epoch: [63][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1524 (0.1524)	
0.9999155 0.00035974433
===========>   testing    <===========
Epoch: [63][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1060 (0.1060)	
0.99999595 0.0004955993
Epoch: [63][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.2223 (0.1427)	
0.99999464 0.00061779236
Epoch: [63][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1393 (0.1399)	
0.9999999 0.0005054351
loss:  0.10683138962385552 0.1096873501826674
===========>   training    <===========
Epoch: [64][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1827 (0.1827)	
0.99995065 0.0003932193
===========>   testing    <===========
Epoch: [64][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1340 (0.1340)	
0.9999727 0.0004052476
Epoch: [64][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.2486 (0.1370)	
0.9999697 0.0004643197
Epoch: [64][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1101 (0.1332)	
0.9999862 0.00041371916
loss:  0.10411405945019614 0.10683138962385552
===========>   training    <===========
Epoch: [65][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1586 (0.1586)	
0.99998236 0.00038818413
===========>   testing    <===========
Epoch: [65][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.0897 (0.0897)	
0.99996734 0.00041573803
Epoch: [65][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.3305 (0.1335)	
0.9999889 0.00043784705
Epoch: [65][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1043 (0.1333)	
0.99999774 0.00043650143
loss:  0.10132064833536136 0.10411405945019614
===========>   training    <===========
Epoch: [66][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1387 (0.1387)	
0.99999976 0.00048288933
===========>   testing    <===========
Epoch: [66][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1289 (0.1289)	
0.9999783 0.0005277626
Epoch: [66][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.2514 (0.1441)	
0.9999871 0.00049258885
Epoch: [66][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1141 (0.1389)	
0.9999999 0.00043618132
loss:  0.10683627627635672 0.10132064833536136
===========>   training    <===========
Epoch: [67][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1494 (0.1494)	
0.99999475 0.00037822739
===========>   testing    <===========
Epoch: [67][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1263 (0.1263)	
0.99994814 0.00039235622
Epoch: [67][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1910 (0.1523)	
0.99993765 0.00044838333
Epoch: [67][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1433 (0.1429)	
0.9999976 0.00038033878
loss:  0.11504800504147517 0.10132064833536136
===========>   training    <===========
Epoch: [68][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1358 (0.1358)	
0.9999565 0.00070417504
===========>   testing    <===========
Epoch: [68][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1051 (0.1051)	
0.99984837 0.0003714458
Epoch: [68][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.2236 (0.1331)	
0.9995925 0.00038413034
Epoch: [68][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1143 (0.1285)	
0.9999876 0.0003588425
loss:  0.10116817718808269 0.10132064833536136
===========>   training    <===========
Epoch: [69][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1400 (0.1400)	
0.9999726 0.00052394177
===========>   testing    <===========
Epoch: [69][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.2031 (0.2031)	
0.99997985 0.0003865871
Epoch: [69][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1572 (0.1387)	
0.9999869 0.00039916742
Epoch: [69][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1280 (0.1340)	
1.0 0.00038707003
loss:  0.10631237112378134 0.10116817718808269
===========>   training    <===========
Epoch: [70][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1475 (0.1475)	
0.99999976 0.00041015312
===========>   testing    <===========
Epoch: [70][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1224 (0.1224)	
0.99993443 0.00032384408
Epoch: [70][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1714 (0.1346)	
0.9997708 0.0003558402
Epoch: [70][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1363 (0.1290)	
0.999987 0.0003149174
loss:  0.10246788148984154 0.10116817718808269
===========>   training    <===========
Epoch: [71][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1146 (0.1146)	
0.99999976 0.000233906
===========>   testing    <===========
Epoch: [71][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1344 (0.1344)	
0.9999702 0.00030873987
Epoch: [71][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.2032 (0.1378)	
0.9998223 0.00031150435
Epoch: [71][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1507 (0.1353)	
0.9999999 0.00030450616
loss:  0.10480920683195383 0.10116817718808269
===========>   training    <===========
Epoch: [72][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1460 (0.1460)	
0.9999999 0.00028816846
===========>   testing    <===========
Epoch: [72][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1616 (0.1616)	
0.9999963 0.00038116323
Epoch: [72][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1672 (0.1451)	
0.9999995 0.0003861698
Epoch: [72][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1745 (0.1365)	
1.0 0.00038047714
loss:  0.1033761246373236 0.10116817718808269
===========>   training    <===========
Epoch: [73][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1328 (0.1328)	
0.9999802 0.00034879372
===========>   testing    <===========
Epoch: [73][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1541 (0.1541)	
0.9999503 0.0002833199
Epoch: [73][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1987 (0.1310)	
0.999509 0.00029391146
Epoch: [73][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1617 (0.1282)	
0.9999924 0.00029290526
loss:  0.09817288727409579 0.10116817718808269
===========>   training    <===========
Epoch: [74][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1268 (0.1268)	
0.99999666 0.00031894504
===========>   testing    <===========
Epoch: [74][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1200 (0.1200)	
0.9996525 0.00024115623
Epoch: [74][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1100 (0.1464)	
0.99936444 0.00026569827
Epoch: [74][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1450 (0.1370)	
0.9997943 0.00025269456
loss:  0.10917595329806695 0.09817288727409579
===========>   training    <===========
Epoch: [75][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1449 (0.1449)	
1.0 0.00016578234
===========>   testing    <===========
Epoch: [75][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1071 (0.1071)	
0.9999989 0.00027309786
Epoch: [75][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.2036 (0.1402)	
0.9999858 0.00029640892
Epoch: [75][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1816 (0.1340)	
0.9999999 0.0002520151
loss:  0.10340543147031378 0.09817288727409579
===========>   training    <===========
Epoch: [76][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1268 (0.1268)	
0.9999994 0.00023629978
===========>   testing    <===========
Epoch: [76][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1433 (0.1433)	
0.99996257 0.00021285893
Epoch: [76][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1556 (0.1224)	
0.9996958 0.00022168487
Epoch: [76][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.0949 (0.1204)	
0.9999956 0.00021910442
loss:  0.09826250126277114 0.09817288727409579
===========>   training    <===========
Epoch: [77][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1345 (0.1345)	
0.99999976 0.0002038143
===========>   testing    <===========
Epoch: [77][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.0894 (0.0894)	
0.99997747 0.00025747195
Epoch: [77][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1176 (0.1221)	
0.99981314 0.00022397496
Epoch: [77][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1524 (0.1199)	
0.9999999 0.00015858041
loss:  0.09236369192518012 0.09817288727409579
===========>   training    <===========
Epoch: [78][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1266 (0.1266)	
0.9999989 0.0002417548
===========>   testing    <===========
Epoch: [78][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1166 (0.1166)	
0.99995923 0.0001762391
Epoch: [78][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1476 (0.1440)	
0.9999689 0.0001776096
Epoch: [78][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1819 (0.1394)	
0.99999976 0.00014429961
loss:  0.10803242212745545 0.09236369192518012
===========>   training    <===========
Epoch: [79][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1558 (0.1558)	
0.9999875 0.00015933142
===========>   testing    <===========
Epoch: [79][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1218 (0.1218)	
0.9999932 0.00012892311
Epoch: [79][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1754 (0.1472)	
0.9999976 0.00015066953
Epoch: [79][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1490 (0.1467)	
1.0 0.00013644867
loss:  0.11124729854776172 0.09236369192518012
===========>   training    <===========
Epoch: [80][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1146 (0.1146)	
0.9999999 0.00013355546
===========>   testing    <===========
Epoch: [80][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1413 (0.1413)	
0.9999716 0.00013515119
Epoch: [80][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1135 (0.1217)	
0.9998878 0.00016190634
Epoch: [80][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1288 (0.1187)	
0.9999995 0.00015091986
loss:  0.09373205121532346 0.09236369192518012
===========>   training    <===========
Epoch: [81][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1270 (0.1270)	
0.9999993 0.00015319136
===========>   testing    <===========
Epoch: [81][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1511 (0.1511)	
0.9999393 0.00020256353
Epoch: [81][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1499 (0.1212)	
0.9999064 0.00023429528
Epoch: [81][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1440 (0.1179)	
0.99999976 0.00020559848
loss:  0.0927192121211804 0.09236369192518012
===========>   training    <===========
Epoch: [82][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1844 (0.1844)	
0.9999796 0.00020321315
===========>   testing    <===========
Epoch: [82][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1746 (0.1746)	
0.9999994 0.00046509536
Epoch: [82][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1998 (0.1380)	
0.9999999 0.00042940793
Epoch: [82][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1424 (0.1331)	
1.0 0.00035960617
loss:  0.10336090732643355 0.09236369192518012
===========>   training    <===========
Epoch: [83][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1455 (0.1455)	
1.0 0.00035412237
===========>   testing    <===========
Epoch: [83][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1309 (0.1309)	
0.99992085 0.00023457289
Epoch: [83][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1759 (0.1280)	
0.9999542 0.00021952868
Epoch: [83][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1037 (0.1234)	
0.9999999 0.00021059511
loss:  0.09731555912306777 0.09236369192518012
===========>   training    <===========
Epoch: [84][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1505 (0.1505)	
1.0 0.0005986925
===========>   testing    <===========
Epoch: [84][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.3428 (0.3428)	
0.9999689 0.00022991805
Epoch: [84][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1276 (0.1259)	
0.99996686 0.00023159852
Epoch: [84][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1070 (0.1227)	
0.9999999 0.00015224774
loss:  0.09687928102458665 0.09236369192518012
===========>   training    <===========
Epoch: [85][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1473 (0.1473)	
0.99990225 0.0001451911
===========>   testing    <===========
Epoch: [85][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1071 (0.1071)	
0.9999988 0.000189847
Epoch: [85][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0582 (0.1382)	
0.9999964 0.00021097215
Epoch: [85][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1482 (0.1314)	
1.0 0.00016563681
loss:  0.10476324860204878 0.09236369192518012
===========>   training    <===========
Epoch: [86][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1296 (0.1296)	
0.9999975 0.0003931337
===========>   testing    <===========
Epoch: [86][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1234 (0.1234)	
0.9999821 0.00031304025
Epoch: [86][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0852 (0.1186)	
0.9999907 0.00029392968
Epoch: [86][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1061 (0.1165)	
1.0 0.00024721213
loss:  0.09285385859036632 0.09236369192518012
===========>   training    <===========
Epoch: [87][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1002 (0.1002)	
0.9999957 0.00026111837
===========>   testing    <===========
Epoch: [87][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1033 (0.1033)	
0.99990237 0.00018787998
Epoch: [87][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1035 (0.1189)	
0.999814 0.00020383492
Epoch: [87][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0796 (0.1141)	
1.0 0.0001830544
loss:  0.09154281255363128 0.09236369192518012
===========>   training    <===========
Epoch: [88][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1348 (0.1348)	
0.99998236 0.00012543185
===========>   testing    <===========
Epoch: [88][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1070 (0.1070)	
0.99998903 0.00014894566
Epoch: [88][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0684 (0.1171)	
0.9999999 0.00016898967
Epoch: [88][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1478 (0.1138)	
1.0 0.00014962911
loss:  0.08962494263230725 0.09154281255363128
===========>   training    <===========
Epoch: [89][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1322 (0.1322)	
1.0 0.00011696195
===========>   testing    <===========
Epoch: [89][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0717 (0.0717)	
0.9999716 0.00018744839
Epoch: [89][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.2549 (0.1121)	
0.9999827 0.00020014148
Epoch: [89][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0823 (0.1068)	
0.9999999 0.0001866405
loss:  0.08593954896438216 0.08962494263230725
===========>   training    <===========
Epoch: [90][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1183 (0.1183)	
0.9999999 0.00020085284
===========>   testing    <===========
Epoch: [90][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1431 (0.1431)	
0.9999778 0.00015662397
Epoch: [90][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1117 (0.1176)	
0.9999535 0.00015492784
Epoch: [90][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0945 (0.1135)	
1.0 0.00015672989
loss:  0.09154336092798954 0.08593954896438216
===========>   training    <===========
Epoch: [91][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1227 (0.1227)	
0.9999999 0.000108194
===========>   testing    <===========
Epoch: [91][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0876 (0.0876)	
0.99999297 0.00016343633
Epoch: [91][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0575 (0.1202)	
0.99999857 0.00022239132
Epoch: [91][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1340 (0.1162)	
1.0 0.00015045304
loss:  0.09085122996425554 0.08593954896438216
===========>   training    <===========
Epoch: [92][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1232 (0.1232)	
1.0 0.00018649621
===========>   testing    <===========
Epoch: [92][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1036 (0.1036)	
0.99992466 0.00013672728
Epoch: [92][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1034 (0.1135)	
0.99997604 0.00019848642
Epoch: [92][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0951 (0.1130)	
0.99999976 0.00014226219
loss:  0.09139556105333158 0.08593954896438216
===========>   training    <===========
Epoch: [93][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1419 (0.1419)	
0.9999999 6.762223e-05
===========>   testing    <===========
Epoch: [93][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1076 (0.1076)	
0.9999964 0.00014912701
Epoch: [93][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1863 (0.1167)	
0.99989533 0.0001396313
Epoch: [93][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1014 (0.1096)	
1.0 0.00011268246
loss:  0.08408638324479722 0.08593954896438216
===========>   training    <===========
Epoch: [94][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1112 (0.1112)	
0.99996316 0.000119922894
===========>   testing    <===========
Epoch: [94][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1206 (0.1206)	
0.99996996 0.00014798754
Epoch: [94][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0531 (0.1163)	
0.9999732 0.00015393755
Epoch: [94][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1094 (0.1112)	
0.99999964 0.00012420783
loss:  0.08781993501651308 0.08408638324479722
===========>   training    <===========
Epoch: [95][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1482 (0.1482)	
0.9999976 0.00017029389
===========>   testing    <===========
Epoch: [95][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1189 (0.1189)	
0.99973017 0.00011417975
Epoch: [95][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.2872 (0.1167)	
0.99999356 0.00011721539
Epoch: [95][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0851 (0.1119)	
0.9999994 0.00010584268
loss:  0.08938529371967441 0.08408638324479722
===========>   training    <===========
Epoch: [96][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1016 (0.1016)	
0.99999964 0.00016731402
===========>   testing    <===========
Epoch: [96][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0880 (0.0880)	
0.99998987 0.00021630303
Epoch: [96][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1601 (0.1190)	
0.99999905 0.00016855856
Epoch: [96][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1194 (0.1147)	
1.0 0.0001733148
loss:  0.09099205923885978 0.08408638324479722
===========>   training    <===========
Epoch: [97][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1381 (0.1381)	
0.99999654 0.0001324061
===========>   testing    <===========
Epoch: [97][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1081 (0.1081)	
0.9999788 0.00030921501
Epoch: [97][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1459 (0.1154)	
0.99999154 0.0002817664
Epoch: [97][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0788 (0.1086)	
0.9999995 0.00015140518
loss:  0.08981530496048629 0.08408638324479722
===========>   training    <===========
Epoch: [98][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1534 (0.1534)	
0.9999999 0.00010202843
===========>   testing    <===========
Epoch: [98][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1784 (0.1784)	
0.9999727 0.00027006763
Epoch: [98][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1043 (0.1444)	
0.99999166 0.000245538
Epoch: [98][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1303 (0.1418)	
0.99999905 0.00014915132
loss:  0.10450625662549462 0.08408638324479722
===========>   training    <===========
Epoch: [99][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1183 (0.1183)	
0.9999974 0.00019663246
===========>   testing    <===========
Epoch: [99][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.3801 (0.3801)	
0.9997781 0.00016777843
Epoch: [99][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.2008 (0.1469)	
0.99991393 0.0001626745
Epoch: [99][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1182 (0.1361)	
0.99999964 0.00014495316
loss:  0.1170017946370393 0.08408638324479722
===========>   training    <===========
Epoch: [100][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1202 (0.1202)	
0.9999999 0.00015917986
===========>   testing    <===========
Epoch: [100][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0957 (0.0957)	
0.99994624 0.00012216959
Epoch: [100][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1174 (0.1202)	
0.9999821 0.0001092144
Epoch: [100][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1454 (0.1191)	
0.99999976 0.00010741479
loss:  0.09368660333263101 0.08408638324479722
===========>   training    <===========
Epoch: [101][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0996 (0.0996)	
0.9999994 0.00010894147
===========>   testing    <===========
Epoch: [101][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0957 (0.0957)	
0.99999094 0.000107373315
Epoch: [101][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.2192 (0.1157)	
0.99999976 9.328362e-05
Epoch: [101][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0918 (0.1102)	
1.0 0.00010188484
loss:  0.0859523101821299 0.08408638324479722
===========>   training    <===========
Epoch: [102][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1110 (0.1110)	
0.9999999 0.00013515801
===========>   testing    <===========
Epoch: [102][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1221 (0.1221)	
0.99994683 9.200661e-05
Epoch: [102][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0834 (0.1017)	
0.99999666 8.5816166e-05
Epoch: [102][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0747 (0.0986)	
0.9999995 9.060415e-05
loss:  0.08105942804937183 0.08408638324479722
===========>   training    <===========
Epoch: [103][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0937 (0.0937)	
0.9999001 9.242633e-05
===========>   testing    <===========
Epoch: [103][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0705 (0.0705)	
0.9999286 0.0001021401
Epoch: [103][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.2004 (0.1229)	
0.9999858 0.00010032809
Epoch: [103][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1407 (0.1183)	
0.9999999 9.9555196e-05
loss:  0.09096572697066885 0.08105942804937183
===========>   training    <===========
Epoch: [104][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1275 (0.1275)	
0.99999857 0.00011548773
===========>   testing    <===========
Epoch: [104][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1263 (0.1263)	
0.99999845 0.00014311363
Epoch: [104][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1039 (0.1018)	
0.99999905 0.00013809992
Epoch: [104][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0864 (0.0976)	
1.0 0.00014972428
loss:  0.0775166223441014 0.08105942804937183
===========>   training    <===========
Epoch: [105][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1115 (0.1115)	
1.0 0.00010721678
===========>   testing    <===========
Epoch: [105][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1194 (0.1194)	
0.99999106 0.00019733398
Epoch: [105][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1135 (0.1117)	
0.9999999 0.00018861769
Epoch: [105][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1386 (0.1098)	
1.0 0.00016255496
loss:  0.08587639129552771 0.0775166223441014
===========>   training    <===========
Epoch: [106][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1288 (0.1288)	
0.99999297 0.00014282748
===========>   testing    <===========
Epoch: [106][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1581 (0.1581)	
0.99998903 0.00010689704
Epoch: [106][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1408 (0.1209)	
0.9999447 9.7027936e-05
Epoch: [106][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0827 (0.1128)	
0.9999999 9.397333e-05
loss:  0.0863033389985125 0.0775166223441014
===========>   training    <===========
Epoch: [107][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1041 (0.1041)	
0.99996877 9.7294025e-05
===========>   testing    <===========
Epoch: [107][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1088 (0.1088)	
0.9999794 0.00014908705
Epoch: [107][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0763 (0.1052)	
0.9999999 0.0001559749
Epoch: [107][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0847 (0.0988)	
1.0 0.000118484335
loss:  0.07792057732580637 0.0775166223441014
===========>   training    <===========
Epoch: [108][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0984 (0.0984)	
0.9999999 0.00010148564
===========>   testing    <===========
Epoch: [108][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1742 (0.1742)	
0.99999964 0.00014596399
Epoch: [108][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1491 (0.1244)	
1.0 0.00013215962
Epoch: [108][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0819 (0.1184)	
1.0 0.00012468488
loss:  0.09109847051290121 0.0775166223441014
===========>   training    <===========
Epoch: [109][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1054 (0.1054)	
1.0 0.0001792266
===========>   testing    <===========
Epoch: [109][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1024 (0.1024)	
0.9999131 9.040617e-05
Epoch: [109][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0602 (0.1105)	
0.99998367 8.371306e-05
Epoch: [109][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1436 (0.1069)	
0.99999857 8.010535e-05
loss:  0.08505858727238169 0.0775166223441014
===========>   training    <===========
Epoch: [110][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1042 (0.1042)	
1.0 7.1968476e-05
===========>   testing    <===========
Epoch: [110][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1056 (0.1056)	
0.9999765 0.00014318188
Epoch: [110][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0520 (0.1050)	
0.99999464 0.00014734083
Epoch: [110][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0983 (0.1004)	
0.9999999 0.00013652911
loss:  0.07865358435422587 0.0775166223441014
===========>   training    <===========
Epoch: [111][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1070 (0.1070)	
1.0 0.00022231396
===========>   testing    <===========
Epoch: [111][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1092 (0.1092)	
0.9999893 0.00015630634
Epoch: [111][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0810 (0.1025)	
0.9999887 0.00014885807
Epoch: [111][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0606 (0.0987)	
1.0 0.00013628083
loss:  0.07993789019661657 0.0775166223441014
===========>   training    <===========
Epoch: [112][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1449 (0.1449)	
0.9999962 0.00022400018
===========>   testing    <===========
Epoch: [112][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0919 (0.0919)	
0.99997175 0.00012023756
Epoch: [112][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1327 (0.1151)	
0.9999629 0.00012474183
Epoch: [112][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1009 (0.1183)	
0.9999981 0.000116567346
loss:  0.0910446750121836 0.0775166223441014
===========>   training    <===========
Epoch: [113][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0992 (0.0992)	
0.9999982 0.000109525914
===========>   testing    <===========
Epoch: [113][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1076 (0.1076)	
0.99999833 8.680639e-05
Epoch: [113][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1050 (0.1073)	
0.9999999 7.592228e-05
Epoch: [113][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1026 (0.1055)	
1.0 7.5187956e-05
loss:  0.08384064282662207 0.0775166223441014
===========>   training    <===========
Epoch: [114][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0848 (0.0848)	
0.99999714 0.00017281575
===========>   testing    <===========
Epoch: [114][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0920 (0.0920)	
0.99993825 8.170923e-05
Epoch: [114][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0901 (0.1119)	
0.99991524 6.6499226e-05
Epoch: [114][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0787 (0.1073)	
0.999998 6.895015e-05
loss:  0.08477714119434376 0.0775166223441014
===========>   training    <===========
Epoch: [115][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1269 (0.1269)	
1.0 7.111367e-05
===========>   testing    <===========
Epoch: [115][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0884 (0.0884)	
0.9999341 0.0002700092
Epoch: [115][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0772 (0.1208)	
0.99992394 0.0002005868
Epoch: [115][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1746 (0.1186)	
0.99999845 0.00013201278
loss:  0.09199102254865876 0.0775166223441014
===========>   training    <===========
Epoch: [116][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0910 (0.0910)	
0.99999845 0.00025871707
===========>   testing    <===========
Epoch: [116][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1527 (0.1527)	
0.9999995 0.00013961745
Epoch: [116][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1113 (0.1125)	
0.99999416 0.000110391375
Epoch: [116][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0889 (0.1102)	
1.0 9.6921314e-05
loss:  0.08387225994206782 0.0775166223441014
===========>   training    <===========
Epoch: [117][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1044 (0.1044)	
0.99999166 3.3120505e-05
===========>   testing    <===========
Epoch: [117][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1130 (0.1130)	
0.9998871 6.564323e-05
Epoch: [117][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0677 (0.1038)	
0.99978083 5.5558507e-05
Epoch: [117][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1332 (0.1018)	
0.99997735 5.6329493e-05
loss:  0.08132959913652926 0.0775166223441014
===========>   training    <===========
Epoch: [118][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1005 (0.1005)	
0.9999137 3.5371326e-05
===========>   testing    <===========
Epoch: [118][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1589 (0.1589)	
0.9999137 5.8817208e-05
Epoch: [118][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0521 (0.1107)	
0.9999808 5.3889155e-05
Epoch: [118][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0827 (0.1055)	
0.9999999 5.1721214e-05
loss:  0.08664029309536558 0.0775166223441014
===========>   training    <===========
Epoch: [119][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1077 (0.1077)	
0.9999695 6.8868e-05
===========>   testing    <===========
Epoch: [119][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1185 (0.1185)	
0.9999703 8.051147e-05
Epoch: [119][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0590 (0.0973)	
0.99995375 7.320142e-05
Epoch: [119][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1287 (0.0913)	
0.99999845 7.735989e-05
loss:  0.0713885324036655 0.0775166223441014
===========>   training    <===========
Epoch: [120][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1036 (0.1036)	
0.99999845 7.408669e-05
===========>   testing    <===========
Epoch: [120][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0863 (0.0863)	
0.99989927 7.0078095e-05
Epoch: [120][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0347 (0.1027)	
0.99991345 6.815268e-05
Epoch: [120][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1467 (0.1011)	
0.9999981 6.627335e-05
loss:  0.07833722793384268 0.0713885324036655
===========>   training    <===========
Epoch: [121][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0881 (0.0881)	
0.9999651 7.154137e-05
===========>   testing    <===========
Epoch: [121][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1019 (0.1019)	
0.9999275 7.178506e-05
Epoch: [121][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1160 (0.0928)	
0.9996307 6.117938e-05
Epoch: [121][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0765 (0.0905)	
0.9999906 6.147137e-05
loss:  0.07305525339644914 0.0713885324036655
===========>   training    <===========
Epoch: [122][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1133 (0.1133)	
0.9999831 4.2762596e-05
===========>   testing    <===========
Epoch: [122][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1260 (0.1260)	
0.9999684 5.195588e-05
Epoch: [122][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0340 (0.0901)	
0.99998033 4.9508173e-05
Epoch: [122][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0856 (0.0882)	
0.9999987 4.716735e-05
loss:  0.06988354770565353 0.0713885324036655
===========>   training    <===========
Epoch: [123][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0927 (0.0927)	
0.99998784 4.0519855e-05
===========>   testing    <===========
Epoch: [123][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0865 (0.0865)	
0.99995387 4.230781e-05
Epoch: [123][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1174 (0.0936)	
0.99990714 3.8122515e-05
Epoch: [123][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1021 (0.0878)	
0.999997 3.793032e-05
loss:  0.06933262342934254 0.06988354770565353
===========>   training    <===========
Epoch: [124][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0968 (0.0968)	
1.0 3.9535942e-05
===========>   testing    <===========
Epoch: [124][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0875 (0.0875)	
0.99999917 9.9973215e-05
Epoch: [124][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.2979 (0.1005)	
0.99998486 0.00010731887
Epoch: [124][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1055 (0.0940)	
1.0 5.3674878e-05
loss:  0.07623618858764969 0.06933262342934254
===========>   training    <===========
Epoch: [125][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1177 (0.1177)	
0.9999995 7.913246e-05
===========>   testing    <===========
Epoch: [125][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1464 (0.1464)	
0.99999774 5.7179903e-05
Epoch: [125][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1176 (0.1073)	
0.99998116 4.941633e-05
Epoch: [125][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1205 (0.0989)	
1.0 4.854879e-05
loss:  0.0761261555470083 0.06933262342934254
===========>   training    <===========
Epoch: [126][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1020 (0.1020)	
0.9999999 3.902653e-05
===========>   testing    <===========
Epoch: [126][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0928 (0.0928)	
0.9999894 0.00027182343
Epoch: [126][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0699 (0.1035)	
0.99993145 0.00012674925
Epoch: [126][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1363 (0.0983)	
1.0 6.610842e-05
loss:  0.07574373550773295 0.06933262342934254
===========>   training    <===========
Epoch: [127][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1159 (0.1159)	
0.99999976 7.352021e-05
===========>   testing    <===========
Epoch: [127][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0698 (0.0698)	
0.9999784 3.88999e-05
Epoch: [127][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0456 (0.0972)	
0.9999311 3.3481712e-05
Epoch: [127][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1377 (0.0909)	
0.9999995 3.1639833e-05
loss:  0.07240526382844459 0.06933262342934254
===========>   training    <===========
Epoch: [128][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0960 (0.0960)	
0.9999994 9.181082e-05
===========>   testing    <===========
Epoch: [128][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0981 (0.0981)	
0.9999666 5.256393e-05
Epoch: [128][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0656 (0.0972)	
0.9997843 4.5585588e-05
Epoch: [128][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1479 (0.0928)	
0.99999666 4.0806306e-05
loss:  0.07412490206516498 0.06933262342934254
===========>   training    <===========
Epoch: [129][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1098 (0.1098)	
0.9999964 3.3665172e-05
===========>   testing    <===========
Epoch: [129][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0989 (0.0989)	
0.99996614 4.0890405e-05
Epoch: [129][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0548 (0.0995)	
0.9999777 3.9227984e-05
Epoch: [129][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.2091 (0.0949)	
0.99999297 3.3012002e-05
loss:  0.07591814127314178 0.06933262342934254
===========>   training    <===========
Epoch: [130][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0903 (0.0903)	
0.99999285 3.0349345e-05
===========>   testing    <===========
Epoch: [130][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1102 (0.1102)	
0.9999615 5.8525315e-05
Epoch: [130][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1275 (0.1115)	
0.99998486 7.0341885e-05
Epoch: [130][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.2010 (0.1070)	
0.99999857 4.9074075e-05
loss:  0.08213404159593507 0.06933262342934254
===========>   training    <===========
Epoch: [131][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0933 (0.0933)	
0.99997246 4.2443913e-05
===========>   testing    <===========
Epoch: [131][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0765 (0.0765)	
0.9999858 2.728673e-05
Epoch: [131][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0672 (0.1013)	
0.9999896 2.3184628e-05
Epoch: [131][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.2057 (0.0945)	
0.9999999 2.1474318e-05
loss:  0.07268505649566048 0.06933262342934254
===========>   training    <===========
Epoch: [132][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0924 (0.0924)	
0.9999764 4.7409874e-05
===========>   testing    <===========
Epoch: [132][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1222 (0.1222)	
0.99995065 2.863805e-05
Epoch: [132][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.2332 (0.0983)	
0.99999225 2.6804946e-05
Epoch: [132][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1675 (0.0952)	
0.99999976 2.5529653e-05
loss:  0.07477822383395827 0.06933262342934254
===========>   training    <===========
Epoch: [133][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1007 (0.1007)	
0.9999862 0.000101383586
===========>   testing    <===========
Epoch: [133][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1088 (0.1088)	
0.99997175 0.00013664842
Epoch: [133][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0402 (0.0952)	
0.99994934 0.00014200942
Epoch: [133][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.2054 (0.0921)	
0.99999976 8.742577e-05
loss:  0.071931510481551 0.06933262342934254
===========>   training    <===========
Epoch: [134][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0954 (0.0954)	
0.99999964 4.6816556e-05
===========>   testing    <===========
Epoch: [134][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1409 (0.1409)	
0.99999666 0.00010743365
Epoch: [134][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0763 (0.1334)	
0.99999845 6.852519e-05
Epoch: [134][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.2123 (0.1262)	
1.0 4.7840924e-05
loss:  0.08818880866070533 0.06933262342934254
===========>   training    <===========
Epoch: [135][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1017 (0.1017)	
0.9999993 7.712375e-05
===========>   testing    <===========
Epoch: [135][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1017 (0.1017)	
0.9999832 9.442686e-05
Epoch: [135][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0990 (0.0981)	
0.9999901 7.404807e-05
Epoch: [135][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1336 (0.0913)	
0.9999995 7.030547e-05
loss:  0.07408915334088184 0.06933262342934254
===========>   training    <===========
Epoch: [136][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0914 (0.0914)	
1.0 7.79315e-05
===========>   testing    <===========
Epoch: [136][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0944 (0.0944)	
0.99990857 0.00010649537
Epoch: [136][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0550 (0.1029)	
0.9997564 9.8109325e-05
Epoch: [136][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.2933 (0.1006)	
0.999998 9.8218654e-05
loss:  0.07739925563586558 0.06933262342934254
===========>   training    <===========
Epoch: [137][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0916 (0.0916)	
1.0 0.00011867259
===========>   testing    <===========
Epoch: [137][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0915 (0.0915)	
0.99980146 7.935167e-05
Epoch: [137][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1068 (0.0983)	
0.99976474 7.289276e-05
Epoch: [137][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1330 (0.0919)	
0.9999974 7.1465736e-05
loss:  0.07160837370164674 0.06933262342934254
===========>   training    <===========
Epoch: [138][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0854 (0.0854)	
0.9999862 9.928946e-05
===========>   testing    <===========
Epoch: [138][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1231 (0.1231)	
0.9999919 0.00011087328
Epoch: [138][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0836 (0.0887)	
0.999972 8.89469e-05
Epoch: [138][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1119 (0.0878)	
1.0 5.945387e-05
loss:  0.06874023536561191 0.06933262342934254
===========>   training    <===========
Epoch: [139][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0915 (0.0915)	
0.99999464 7.244545e-05
===========>   testing    <===========
Epoch: [139][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1303 (0.1303)	
0.9999591 0.00011761409
Epoch: [139][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.3896 (0.1089)	
0.999972 9.845299e-05
Epoch: [139][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0969 (0.1037)	
1.0 8.578352e-05
loss:  0.08059134547223079 0.06874023536561191
===========>   training    <===========
Epoch: [140][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0770 (0.0770)	
0.99999964 0.00016868816
===========>   testing    <===========
Epoch: [140][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0797 (0.0797)	
0.999944 5.6427667e-05
Epoch: [140][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0527 (0.0889)	
0.9999646 6.1471546e-05
Epoch: [140][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1505 (0.0857)	
0.9999999 4.4720036e-05
loss:  0.06795400361536874 0.06874023536561191
===========>   training    <===========
Epoch: [141][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0772 (0.0772)	
0.9999938 3.131787e-05
===========>   testing    <===========
Epoch: [141][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1126 (0.1126)	
0.99999535 4.8222333e-05
Epoch: [141][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.2071 (0.0920)	
0.9999974 3.8346683e-05
Epoch: [141][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1181 (0.0889)	
1.0 3.02434e-05
loss:  0.06977939813882839 0.06795400361536874
===========>   training    <===========
Epoch: [142][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0931 (0.0931)	
0.99999976 2.8830273e-05
===========>   testing    <===========
Epoch: [142][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0794 (0.0794)	
0.99997807 8.006037e-05
Epoch: [142][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1162 (0.0863)	
0.99997675 3.9031445e-05
Epoch: [142][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1070 (0.0842)	
0.9999999 3.3687138e-05
loss:  0.06562329884536566 0.06795400361536874
===========>   training    <===========
Epoch: [143][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1021 (0.1021)	
0.99999964 2.6377835e-05
===========>   testing    <===========
Epoch: [143][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.2338 (0.2338)	
0.9999913 3.178342e-05
Epoch: [143][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0977 (0.0964)	
0.99997807 3.0552306e-05
Epoch: [143][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1038 (0.0940)	
1.0 3.0398618e-05
loss:  0.07376585890720133 0.06562329884536566
===========>   training    <===========
Epoch: [144][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0938 (0.0938)	
0.999985 8.69657e-05
===========>   testing    <===========
Epoch: [144][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1005 (0.1005)	
0.99992263 4.025925e-05
Epoch: [144][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0948 (0.0933)	
0.9999511 3.535598e-05
Epoch: [144][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1248 (0.0895)	
0.9999981 3.6274494e-05
loss:  0.06820693248799325 0.06562329884536566
===========>   training    <===========
Epoch: [145][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1208 (0.1208)	
0.99996865 3.712509e-05
===========>   testing    <===========
Epoch: [145][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1104 (0.1104)	
0.9999856 0.00011963382
Epoch: [145][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.2905 (0.0997)	
0.9999809 9.297963e-05
Epoch: [145][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1821 (0.0982)	
1.0 6.763571e-05
loss:  0.07533971127077832 0.06562329884536566
===========>   training    <===========
Epoch: [146][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0769 (0.0769)	
0.9999924 3.575005e-05
===========>   testing    <===========
Epoch: [146][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1181 (0.1181)	
0.99998426 3.1970983e-05
Epoch: [146][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0635 (0.0867)	
0.9999883 2.8676635e-05
Epoch: [146][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1940 (0.0844)	
0.9999999 2.818982e-05
loss:  0.06569541059456108 0.06562329884536566
===========>   training    <===========
Epoch: [147][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0979 (0.0979)	
0.99996793 7.1855815e-05
===========>   testing    <===========
Epoch: [147][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0870 (0.0870)	
0.9999937 3.755155e-05
Epoch: [147][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1457 (0.0911)	
0.9999722 4.1968935e-05
Epoch: [147][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1253 (0.0883)	
0.9999999 3.59566e-05
loss:  0.07140787319286956 0.06562329884536566
===========>   training    <===========
Epoch: [148][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0866 (0.0866)	
0.9999987 5.1878997e-05
===========>   testing    <===========
Epoch: [148][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0968 (0.0968)	
0.99999106 4.4866e-05
Epoch: [148][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0495 (0.1045)	
0.99995494 4.5854114e-05
Epoch: [148][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1782 (0.0958)	
0.99999917 5.7539495e-05
loss:  0.07372461605286496 0.06562329884536566
===========>   training    <===========
Epoch: [149][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0904 (0.0904)	
0.9999881 3.2811477e-05
===========>   testing    <===========
Epoch: [149][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1044 (0.1044)	
0.9999825 3.148116e-05
Epoch: [149][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0676 (0.0890)	
0.99988854 2.9318247e-05
Epoch: [149][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1105 (0.0851)	
0.9999993 2.8843557e-05
loss:  0.0683405519196103 0.06562329884536566
===========>   training    <===========
Epoch: [150][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0781 (0.0781)	
0.9999809 4.3642467e-05
===========>   testing    <===========
Epoch: [150][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0922 (0.0922)	
0.9999393 3.7510104e-05
Epoch: [150][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0394 (0.0961)	
0.99994075 3.7713333e-05
Epoch: [150][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1474 (0.0916)	
0.9999999 3.40255e-05
loss:  0.07243100574171013 0.06562329884536566
===========>   training    <===========
Epoch: [151][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1076 (0.1076)	
1.0 2.6684025e-05
===========>   testing    <===========
Epoch: [151][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0777 (0.0777)	
0.99998546 2.9984052e-05
Epoch: [151][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1178 (0.0939)	
0.9999918 2.9678631e-05
Epoch: [151][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1557 (0.0908)	
0.9999999 2.8900165e-05
loss:  0.07046596486247125 0.06562329884536566
===========>   training    <===========
Epoch: [152][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0845 (0.0845)	
0.99998367 2.8263172e-05
===========>   testing    <===========
Epoch: [152][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0756 (0.0756)	
0.9999862 3.6348112e-05
Epoch: [152][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1819 (0.0884)	
0.9999299 4.026927e-05
Epoch: [152][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1160 (0.0855)	
0.99999976 2.6935526e-05
loss:  0.06749254215284428 0.06562329884536566
===========>   training    <===========
Epoch: [153][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1074 (0.1074)	
0.99999976 2.4066343e-05
===========>   testing    <===========
Epoch: [153][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1588 (0.1588)	
1.0 5.593931e-05
Epoch: [153][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0839 (0.1083)	
0.99998546 4.4153814e-05
Epoch: [153][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1590 (0.1049)	
1.0 4.042001e-05
loss:  0.07722539369565706 0.06562329884536566
===========>   training    <===========
Epoch: [154][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0875 (0.0875)	
0.9999988 2.347351e-05
===========>   testing    <===========
Epoch: [154][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1375 (0.1375)	
0.9999974 9.789299e-05
Epoch: [154][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.3911 (0.0939)	
0.99999034 9.316475e-05
Epoch: [154][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1598 (0.0924)	
1.0 0.00011502327
loss:  0.06941316483480564 0.06562329884536566
===========>   training    <===========
Epoch: [155][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1011 (0.1011)	
0.99999833 2.8101806e-05
===========>   testing    <===========
Epoch: [155][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1311 (0.1311)	
0.9999869 3.6307643e-05
Epoch: [155][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1097 (0.1095)	
0.9999728 3.72797e-05
Epoch: [155][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.2253 (0.1080)	
1.0 2.8329092e-05
loss:  0.08167059096768448 0.06562329884536566
===========>   training    <===========
Epoch: [156][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0929 (0.0929)	
0.9999968 3.0163214e-05
===========>   testing    <===========
Epoch: [156][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1701 (0.1701)	
0.99997485 4.0892744e-05
Epoch: [156][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0375 (0.0999)	
0.9999913 3.2219734e-05
Epoch: [156][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.2331 (0.0940)	
0.99999976 3.2862266e-05
loss:  0.07313473563101602 0.06562329884536566
===========>   training    <===========
Epoch: [157][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0826 (0.0826)	
0.9999864 2.668871e-05
===========>   testing    <===========
Epoch: [157][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1216 (0.1216)	
0.9998853 2.908283e-05
Epoch: [157][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0295 (0.0900)	
0.99997413 2.9962242e-05
Epoch: [157][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1889 (0.0885)	
0.9999999 2.3411005e-05
loss:  0.07172995338532828 0.06562329884536566
===========>   training    <===========
Epoch: [158][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0921 (0.0921)	
0.9999999 5.668514e-05
===========>   testing    <===========
Epoch: [158][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.2152 (0.2152)	
0.99999726 3.870408e-05
Epoch: [158][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0474 (0.1043)	
0.9999815 3.483708e-05
Epoch: [158][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1374 (0.0997)	
1.0 3.3155302e-05
loss:  0.07457366427073597 0.06562329884536566
===========>   training    <===========
Epoch: [159][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0856 (0.0856)	
1.0 5.120347e-05
===========>   testing    <===========
Epoch: [159][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1939 (0.1939)	
0.9999021 0.00012172468
Epoch: [159][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0841 (0.0959)	
0.9999049 5.5009747e-05
Epoch: [159][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1335 (0.0917)	
0.99999774 5.8777845e-05
loss:  0.07100876855810723 0.06562329884536566
===========>   training    <===========
Epoch: [160][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1240 (0.1240)	
0.99997973 1.76487e-05
===========>   testing    <===========
Epoch: [160][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0618 (0.0618)	
0.9999765 2.2050386e-05
Epoch: [160][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0476 (0.0825)	
0.9999343 1.7494298e-05
Epoch: [160][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0923 (0.0786)	
0.9999999 1.7445067e-05
loss:  0.06365232106023266 0.06562329884536566
===========>   training    <===========
Epoch: [161][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0870 (0.0870)	
0.9999758 2.109083e-05
===========>   testing    <===========
Epoch: [161][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0923 (0.0923)	
0.99998236 3.6653975e-05
Epoch: [161][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0720 (0.0925)	
0.9999641 3.5369674e-05
Epoch: [161][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.2190 (0.0888)	
0.999995 3.6533304e-05
loss:  0.06645318865210936 0.06365232106023266
===========>   training    <===========
Epoch: [162][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0773 (0.0773)	
0.9999945 2.7822829e-05
===========>   testing    <===========
Epoch: [162][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0744 (0.0744)	
0.9999386 2.2270531e-05
Epoch: [162][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0933 (0.0881)	
0.99980384 2.1121727e-05
Epoch: [162][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1690 (0.0852)	
0.9999981 1.9899202e-05
loss:  0.06611284846229759 0.06365232106023266
===========>   training    <===========
Epoch: [163][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0834 (0.0834)	
0.99999106 2.0434481e-05
===========>   testing    <===========
Epoch: [163][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0988 (0.0988)	
1.0 2.3787192e-05
Epoch: [163][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0588 (0.0869)	
0.9999943 2.220409e-05
Epoch: [163][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1027 (0.0824)	
1.0 2.2074666e-05
loss:  0.06457217257305192 0.06365232106023266
===========>   training    <===========
Epoch: [164][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0828 (0.0828)	
0.9999999 2.5507967e-05
===========>   testing    <===========
Epoch: [164][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0631 (0.0631)	
0.9999602 1.9925505e-05
Epoch: [164][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0426 (0.0867)	
0.9998454 1.8733963e-05
Epoch: [164][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1077 (0.0833)	
0.9999993 1.9059213e-05
loss:  0.06563150150886343 0.06365232106023266
===========>   training    <===========
Epoch: [165][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0807 (0.0807)	
0.99999833 2.0378979e-05
===========>   testing    <===========
Epoch: [165][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1016 (0.1016)	
0.9999248 3.214549e-05
Epoch: [165][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0518 (0.0840)	
0.99988294 2.3537688e-05
Epoch: [165][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1492 (0.0780)	
0.9999995 2.3554347e-05
loss:  0.061169677250172416 0.06365232106023266
===========>   training    <===========
Epoch: [166][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0893 (0.0893)	
0.9999964 1.8989056e-05
===========>   testing    <===========
Epoch: [166][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0476 (0.0476)	
0.999982 8.199521e-05
Epoch: [166][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0312 (0.0979)	
0.999974 3.2183496e-05
Epoch: [166][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.2084 (0.0939)	
0.9999993 2.9386714e-05
loss:  0.0724395376183995 0.061169677250172416
===========>   training    <===========
Epoch: [167][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0897 (0.0897)	
0.99999714 2.144509e-05
===========>   testing    <===========
Epoch: [167][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1244 (0.1244)	
0.999998 2.3212324e-05
Epoch: [167][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1094 (0.1029)	
0.9999932 2.3135395e-05
Epoch: [167][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1812 (0.0935)	
1.0 2.2456352e-05
loss:  0.07024633215291254 0.061169677250172416
===========>   training    <===========
Epoch: [168][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0956 (0.0956)	
1.0 1.623842e-05
===========>   testing    <===========
Epoch: [168][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0846 (0.0846)	
0.9999596 3.174165e-05
Epoch: [168][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0400 (0.0857)	
0.9999826 2.9640643e-05
Epoch: [168][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1475 (0.0864)	
0.9999993 2.6344525e-05
loss:  0.06837609209305995 0.061169677250172416
===========>   training    <===========
Epoch: [169][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0841 (0.0841)	
0.9999927 5.2244697e-05
===========>   testing    <===========
Epoch: [169][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0543 (0.0543)	
0.9999622 3.983158e-05
Epoch: [169][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0369 (0.0828)	
0.99998176 2.3388979e-05
Epoch: [169][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1358 (0.0790)	
1.0 2.0305823e-05
loss:  0.06153028528216298 0.061169677250172416
===========>   training    <===========
Epoch: [170][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0989 (0.0989)	
0.9999989 1.7908389e-05
===========>   testing    <===========
Epoch: [170][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0627 (0.0627)	
0.9999932 2.8005335e-05
Epoch: [170][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0489 (0.0801)	
0.9999951 1.8126757e-05
Epoch: [170][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1181 (0.0771)	
1.0 1.656458e-05
loss:  0.06186054832509069 0.061169677250172416
===========>   training    <===========
Epoch: [171][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0972 (0.0972)	
0.9999614 1.6106125e-05
===========>   testing    <===========
Epoch: [171][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0959 (0.0959)	
0.99995625 4.6435238e-05
Epoch: [171][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0340 (0.0901)	
0.99998975 3.1166463e-05
Epoch: [171][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0885 (0.0849)	
0.9999999 2.430024e-05
loss:  0.06706801011844943 0.061169677250172416
===========>   training    <===========
Epoch: [172][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0947 (0.0947)	
0.9999976 2.2302858e-05
===========>   testing    <===========
Epoch: [172][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0800 (0.0800)	
0.99997854 3.2557822e-05
Epoch: [172][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0781 (0.0830)	
0.99997807 1.6965785e-05
Epoch: [172][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1426 (0.0804)	
1.0 1.5529065e-05
loss:  0.06213684794277763 0.061169677250172416
===========>   training    <===========
Epoch: [173][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0963 (0.0963)	
1.0 1.1846325e-05
===========>   testing    <===========
Epoch: [173][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0618 (0.0618)	
0.99997735 2.0138124e-05
Epoch: [173][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0397 (0.0868)	
0.9999807 1.7350661e-05
Epoch: [173][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.2367 (0.0857)	
1.0 1.5178356e-05
loss:  0.06703313994873084 0.061169677250172416
===========>   training    <===========
Epoch: [174][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0827 (0.0827)	
0.9999937 4.7072583e-05
===========>   testing    <===========
Epoch: [174][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1197 (0.1197)	
0.9999511 1.7289827e-05
Epoch: [174][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0761 (0.0955)	
0.99996185 1.22734755e-05
Epoch: [174][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1306 (0.0866)	
0.9999982 1.245393e-05
loss:  0.06656721314785596 0.061169677250172416
===========>   training    <===========
Epoch: [175][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0959 (0.0959)	
0.99997723 3.188047e-05
===========>   testing    <===========
Epoch: [175][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0455 (0.0455)	
0.9999645 2.138293e-05
Epoch: [175][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0509 (0.0891)	
0.9999211 1.6660268e-05
Epoch: [175][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1884 (0.0863)	
0.99998796 1.5027041e-05
loss:  0.06355377546520968 0.061169677250172416
===========>   training    <===========
Epoch: [176][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0917 (0.0917)	
0.9999534 1.2589644e-05
===========>   testing    <===========
Epoch: [176][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1069 (0.1069)	
0.9999602 1.29285745e-05
Epoch: [176][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0416 (0.0987)	
0.9999298 1.2824195e-05
Epoch: [176][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.2439 (0.0921)	
0.99999905 1.2291303e-05
loss:  0.07088230695567854 0.061169677250172416
===========>   training    <===========
Epoch: [177][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0800 (0.0800)	
0.9999999 2.5031268e-05
===========>   testing    <===========
Epoch: [177][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0787 (0.0787)	
0.9998104 1.3027053e-05
Epoch: [177][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0369 (0.0835)	
0.99995923 1.3490768e-05
Epoch: [177][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1012 (0.0814)	
0.99999833 1.2964626e-05
loss:  0.06419791915620121 0.061169677250172416
===========>   training    <===========
Epoch: [178][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1003 (0.1003)	
0.9999987 2.9926947e-05
===========>   testing    <===========
Epoch: [178][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1779 (0.1779)	
0.9999958 4.235843e-05
Epoch: [178][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.2868 (0.0896)	
0.99999166 2.2966788e-05
Epoch: [178][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0756 (0.0823)	
1.0 2.8179094e-05
loss:  0.06545596847255519 0.061169677250172416
===========>   training    <===========
Epoch: [179][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0942 (0.0942)	
1.0 1.36966155e-05
===========>   testing    <===========
Epoch: [179][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0874 (0.0874)	
0.99997914 1.7871058e-05
Epoch: [179][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0430 (0.0833)	
0.9999932 1.7460481e-05
Epoch: [179][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0872 (0.0794)	
0.9999999 1.7017543e-05
loss:  0.06219522337949057 0.061169677250172416
===========>   training    <===========
Epoch: [180][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0859 (0.0859)	
0.9999914 2.2656617e-05
===========>   testing    <===========
Epoch: [180][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0529 (0.0529)	
0.99999714 1.7712584e-05
Epoch: [180][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0372 (0.0762)	
0.99999154 1.6488582e-05
Epoch: [180][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1207 (0.0737)	
1.0 1.6231825e-05
loss:  0.0576035350622488 0.061169677250172416
===========>   training    <===========
Epoch: [181][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1111 (0.1111)	
0.9999957 3.3303484e-05
===========>   testing    <===========
Epoch: [181][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0821 (0.0821)	
0.99995995 3.3223983e-05
Epoch: [181][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0438 (0.0826)	
0.99999034 1.9368985e-05
Epoch: [181][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1658 (0.0759)	
0.99999976 1.6331553e-05
loss:  0.06031307013575271 0.0576035350622488
===========>   training    <===========
Epoch: [182][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0818 (0.0818)	
1.0 1.2060781e-05
===========>   testing    <===========
Epoch: [182][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0687 (0.0687)	
0.99993813 1.7348395e-05
Epoch: [182][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0417 (0.0784)	
0.9999732 1.2962475e-05
Epoch: [182][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1848 (0.0736)	
0.9999958 1.2834082e-05
loss:  0.05815162609998026 0.0576035350622488
===========>   training    <===========
Epoch: [183][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0729 (0.0729)	
0.9999747 2.6770122e-05
===========>   testing    <===========
Epoch: [183][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0753 (0.0753)	
0.9999974 7.3946314e-05
Epoch: [183][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0554 (0.0823)	
0.99987805 3.4891007e-05
Epoch: [183][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1185 (0.0776)	
0.9999995 3.239349e-05
loss:  0.062396069416814304 0.0576035350622488
===========>   training    <===========
Epoch: [184][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0741 (0.0741)	
0.99998987 2.2669068e-05
===========>   testing    <===========
Epoch: [184][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0515 (0.0515)	
0.99997306 4.3535674e-05
Epoch: [184][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0543 (0.0786)	
0.9999131 2.4335306e-05
Epoch: [184][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1288 (0.0754)	
0.99999714 1.9093088e-05
loss:  0.058945419498444895 0.0576035350622488
===========>   training    <===========
Epoch: [185][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0766 (0.0766)	
0.99999976 2.396132e-05
===========>   testing    <===========
Epoch: [185][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0979 (0.0979)	
0.9999534 1.2180671e-05
Epoch: [185][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0686 (0.0853)	
0.99987745 1.0535659e-05
Epoch: [185][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1908 (0.0832)	
0.99999833 1.022626e-05
loss:  0.06519374875604111 0.0576035350622488
===========>   training    <===========
Epoch: [186][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0925 (0.0925)	
0.9999677 1.096188e-05
===========>   testing    <===========
Epoch: [186][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0539 (0.0539)	
0.9999845 1.9563817e-05
Epoch: [186][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1919 (0.0840)	
0.9999229 1.0118076e-05
Epoch: [186][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1811 (0.0794)	
0.99999917 1.275448e-05
loss:  0.0629240037392148 0.0576035350622488
===========>   training    <===========
Epoch: [187][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0788 (0.0788)	
0.99999964 9.511923e-06
===========>   testing    <===========
Epoch: [187][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1102 (0.1102)	
0.9999422 8.6341915e-06
Epoch: [187][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0351 (0.0755)	
0.99990547 8.116183e-06
Epoch: [187][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0707 (0.0735)	
0.99999964 7.720257e-06
loss:  0.05819385946743438 0.0576035350622488
===========>   training    <===========
Epoch: [188][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0809 (0.0809)	
0.99999917 1.3796023e-05
===========>   testing    <===========
Epoch: [188][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0535 (0.0535)	
0.9999728 2.7696342e-05
Epoch: [188][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0361 (0.0770)	
0.99997425 1.9795198e-05
Epoch: [188][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1608 (0.0750)	
0.99999666 1.4822937e-05
loss:  0.05881115158870509 0.0576035350622488
===========>   training    <===========
Epoch: [189][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0794 (0.0794)	
0.99998295 1.8050927e-05
===========>   testing    <===========
Epoch: [189][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1923 (0.1923)	
0.99986315 1.3062744e-05
Epoch: [189][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0435 (0.0930)	
0.99997413 1.0189559e-05
Epoch: [189][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.3306 (0.0851)	
0.99999917 1.0983741e-05
loss:  0.06532613123932973 0.0576035350622488
===========>   training    <===========
Epoch: [190][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1048 (0.1048)	
0.9999907 1.4965559e-05
===========>   testing    <===========
Epoch: [190][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1187 (0.1187)	
0.9999745 2.0384558e-05
Epoch: [190][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0302 (0.0772)	
0.9999392 1.5099167e-05
Epoch: [190][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1163 (0.0742)	
0.9999994 1.3726024e-05
loss:  0.05867896350833468 0.0576035350622488
===========>   training    <===========
Epoch: [191][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0727 (0.0727)	
0.9999889 2.1721538e-05
===========>   testing    <===========
Epoch: [191][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1688 (0.1688)	
0.99994016 1.512596e-05
Epoch: [191][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0399 (0.0761)	
0.9999788 1.1456589e-05
Epoch: [191][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1131 (0.0734)	
1.0 1.1137401e-05
loss:  0.05741168014819398 0.0576035350622488
===========>   training    <===========
Epoch: [192][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1217 (0.1217)	
0.999995 1.1332214e-05
===========>   testing    <===========
Epoch: [192][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0751 (0.0751)	
0.999926 2.7297974e-05
Epoch: [192][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0722 (0.0834)	
0.9999739 1.8619208e-05
Epoch: [192][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1117 (0.0755)	
0.99999917 1.441058e-05
loss:  0.057706555324293696 0.05741168014819398
===========>   training    <===========
Epoch: [193][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0781 (0.0781)	
0.9999747 1.8438071e-05
===========>   testing    <===========
Epoch: [193][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0845 (0.0845)	
0.99998796 2.3043729e-05
Epoch: [193][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0419 (0.0780)	
0.99999166 1.6663813e-05
Epoch: [193][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.2039 (0.0758)	
1.0 1.4589961e-05
loss:  0.05902446793757765 0.05741168014819398
===========>   training    <===========
Epoch: [194][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0828 (0.0828)	
0.99999666 2.3880657e-05
===========>   testing    <===========
Epoch: [194][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0970 (0.0970)	
0.99998784 2.2827693e-05
Epoch: [194][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0922 (0.0836)	
0.99999 2.0271595e-05
Epoch: [194][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0779 (0.0774)	
1.0 1.7677605e-05
loss:  0.06034417941943282 0.05741168014819398
===========>   training    <===========
Epoch: [195][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0967 (0.0967)	
0.9999951 9.637319e-06
===========>   testing    <===========
Epoch: [195][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1072 (0.1072)	
0.999941 1.3418976e-05
Epoch: [195][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0375 (0.0783)	
0.99996805 1.070746e-05
Epoch: [195][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0744 (0.0739)	
1.0 9.873972e-06
loss:  0.05716217173313687 0.05741168014819398
===========>   training    <===========
Epoch: [196][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0699 (0.0699)	
0.9999566 2.0839554e-05
===========>   testing    <===========
Epoch: [196][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1296 (0.1296)	
0.9999324 1.1330971e-05
Epoch: [196][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0823 (0.0846)	
0.99996376 1.0723157e-05
Epoch: [196][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0776 (0.0778)	
0.9999995 1.0581263e-05
loss:  0.06019334562127765 0.05716217173313687
===========>   training    <===========
Epoch: [197][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0846 (0.0846)	
0.99999595 2.3886443e-05
===========>   testing    <===========
Epoch: [197][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1125 (0.1125)	
0.9998441 1.0028086e-05
Epoch: [197][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0446 (0.0786)	
0.99984515 1.0137036e-05
Epoch: [197][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0785 (0.0734)	
0.99999297 9.745768e-06
loss:  0.05590792820413315 0.05716217173313687
===========>   training    <===========
Epoch: [198][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0907 (0.0907)	
0.99998593 2.0019119e-05
===========>   testing    <===========
Epoch: [198][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.2265 (0.2265)	
0.9998648 8.830644e-06
Epoch: [198][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0329 (0.0956)	
0.9999416 9.208678e-06
Epoch: [198][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1686 (0.0915)	
0.99999285 8.896993e-06
loss:  0.0730123774307816 0.05590792820413315
===========>   training    <===========
Epoch: [199][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0937 (0.0937)	
1.0 8.430395e-06
===========>   testing    <===========
Epoch: [199][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0770 (0.0770)	
0.99997294 1.9041026e-05
Epoch: [199][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0347 (0.0785)	
0.9999695 1.5594958e-05
Epoch: [199][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1903 (0.0770)	
0.9999995 1.3791524e-05
loss:  0.060091604331671156 0.05590792820413315
===========>   training    <===========
Epoch: [200][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0884 (0.0884)	
1.0 1.0611842e-05
===========>   testing    <===========
Epoch: [200][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1475 (0.1475)	
0.9999453 1.1036028e-05
Epoch: [200][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0889 (0.1031)	
0.99990726 1.1624092e-05
Epoch: [200][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1485 (0.0939)	
0.99999833 1.1203e-05
loss:  0.07215303495640957 0.05590792820413315
===========>   training    <===========
Epoch: [201][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0922 (0.0922)	
0.9999901 1.2092949e-05
===========>   testing    <===========
Epoch: [201][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0887 (0.0887)	
0.9998869 1.25284905e-05
Epoch: [201][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0329 (0.0763)	
0.9999609 1.3143919e-05
Epoch: [201][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0957 (0.0761)	
0.9999845 1.2670128e-05
loss:  0.061089952093869915 0.05590792820413315
===========>   training    <===========
Epoch: [202][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0687 (0.0687)	
0.99997234 1.336758e-05
===========>   testing    <===========
Epoch: [202][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0616 (0.0616)	
0.9999776 1.9822759e-05
Epoch: [202][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0813 (0.0784)	
0.9999875 2.4745526e-05
Epoch: [202][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.2084 (0.0768)	
0.999998 1.9835808e-05
loss:  0.060225682187415974 0.05590792820413315
===========>   training    <===========
Epoch: [203][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0943 (0.0943)	
0.9999883 1.9816598e-05
===========>   testing    <===========
Epoch: [203][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1420 (0.1420)	
0.99995065 3.309525e-05
Epoch: [203][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0818 (0.0872)	
0.99994314 2.6979333e-05
Epoch: [203][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.2020 (0.0808)	
0.9999988 1.9367288e-05
loss:  0.06116324186040856 0.05590792820413315
===========>   training    <===========
Epoch: [204][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0914 (0.0914)	
0.9999888 1.5430027e-05
===========>   testing    <===========
Epoch: [204][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1015 (0.1015)	
0.99995387 1.9578842e-05
Epoch: [204][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0374 (0.0791)	
0.99993956 1.5789321e-05
Epoch: [204][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1651 (0.0766)	
0.9999995 1.2866435e-05
loss:  0.0568094798419867 0.05590792820413315
===========>   training    <===========
Epoch: [205][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0757 (0.0757)	
0.9999962 1.3006905e-05
===========>   testing    <===========
Epoch: [205][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0822 (0.0822)	
0.99996984 1.0978201e-05
Epoch: [205][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0477 (0.0838)	
0.9999968 9.999112e-06
Epoch: [205][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1141 (0.0788)	
1.0 9.689414e-06
loss:  0.05915137242565871 0.05590792820413315
===========>   training    <===========
Epoch: [206][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0990 (0.0990)	
0.9999999 1.4370453e-05
===========>   testing    <===========
Epoch: [206][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0729 (0.0729)	
0.99994445 1.4181514e-05
Epoch: [206][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0881 (0.0780)	
0.99994683 1.1714121e-05
Epoch: [206][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1351 (0.0726)	
0.9999999 1.2168804e-05
loss:  0.05707986763427875 0.05590792820413315
===========>   training    <===========
Epoch: [207][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0806 (0.0806)	
0.99999917 1.7471506e-05
===========>   testing    <===========
Epoch: [207][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0702 (0.0702)	
0.9998505 8.9990945e-06
Epoch: [207][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0422 (0.0774)	
0.99998426 9.048697e-06
Epoch: [207][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0814 (0.0738)	
0.99999654 8.967396e-06
loss:  0.05722368442624326 0.05590792820413315
===========>   training    <===========
Epoch: [208][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0936 (0.0936)	
0.9999833 1.0734248e-05
===========>   testing    <===========
Epoch: [208][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0607 (0.0607)	
0.99998224 2.0600168e-05
Epoch: [208][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0882 (0.0825)	
0.9999932 1.9443123e-05
Epoch: [208][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.2264 (0.0825)	
1.0 1.5071676e-05
loss:  0.06310056161478483 0.05590792820413315
===========>   training    <===========
Epoch: [209][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0680 (0.0680)	
0.9999869 3.2157783e-05
===========>   testing    <===========
Epoch: [209][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0547 (0.0547)	
0.99996865 1.9926722e-05
Epoch: [209][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1088 (0.0797)	
0.9999696 2.8100761e-05
Epoch: [209][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1503 (0.0770)	
0.99999976 1.8602488e-05
loss:  0.05728175087116105 0.05590792820413315
===========>   training    <===========
Epoch: [210][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0974 (0.0974)	
1.0 7.0860046e-06
===========>   testing    <===========
Epoch: [210][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1075 (0.1075)	
0.99996555 1.0026584e-05
Epoch: [210][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0551 (0.0840)	
0.99995494 1.063839e-05
Epoch: [210][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1960 (0.0797)	
0.99999905 9.945892e-06
loss:  0.06030608023865902 0.05590792820413315
===========>   training    <===========
Epoch: [211][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0708 (0.0708)	
0.9999958 1.952164e-05
===========>   testing    <===========
Epoch: [211][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1801 (0.1801)	
0.9999007 1.40493785e-05
Epoch: [211][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1410 (0.0839)	
0.99998784 1.2239555e-05
Epoch: [211][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0936 (0.0781)	
0.99999917 1.1603812e-05
loss:  0.062037932552421404 0.05590792820413315
===========>   training    <===========
Epoch: [212][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0959 (0.0959)	
0.99999607 9.68051e-06
===========>   testing    <===========
Epoch: [212][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1194 (0.1194)	
0.9999677 1.0589843e-05
Epoch: [212][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0418 (0.0802)	
0.9999317 1.0667722e-05
Epoch: [212][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1570 (0.0770)	
0.99999833 1.0046627e-05
loss:  0.06065385180071092 0.05590792820413315
===========>   training    <===========
Epoch: [213][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1066 (0.1066)	
0.99999523 7.725103e-06
===========>   testing    <===========
Epoch: [213][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0914 (0.0914)	
0.99993575 2.3982491e-05
Epoch: [213][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0479 (0.0798)	
0.999985 1.6201791e-05
Epoch: [213][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1259 (0.0751)	
0.9999995 1.01303385e-05
loss:  0.060308099891879574 0.05590792820413315
===========>   training    <===========
Epoch: [214][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0736 (0.0736)	
0.99999857 3.2628624e-05
===========>   testing    <===========
Epoch: [214][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0907 (0.0907)	
0.9999956 9.127853e-06
Epoch: [214][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.2144 (0.0862)	
0.99994016 9.255578e-06
Epoch: [214][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1568 (0.0806)	
1.0 8.817003e-06
loss:  0.06195968196554058 0.05590792820413315
===========>   training    <===========
Epoch: [215][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0781 (0.0781)	
0.9999993 7.786094e-06
===========>   testing    <===========
Epoch: [215][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0693 (0.0693)	
0.9999269 6.549207e-06
Epoch: [215][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0302 (0.0764)	
0.99989843 6.5994213e-06
Epoch: [215][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1511 (0.0740)	
0.99999535 6.625212e-06
loss:  0.05789791046505144 0.05590792820413315
===========>   training    <===========
Epoch: [216][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0798 (0.0798)	
0.99994314 1.7199724e-05
===========>   testing    <===========
Epoch: [216][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1023 (0.1023)	
0.9999589 1.7766282e-05
Epoch: [216][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0262 (0.0778)	
0.99995935 1.4691507e-05
Epoch: [216][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1352 (0.0731)	
0.9999995 9.960519e-06
loss:  0.05939208588628464 0.05590792820413315
===========>   training    <===========
Epoch: [217][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0801 (0.0801)	
0.9999713 1.32812875e-05
===========>   testing    <===========
Epoch: [217][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0485 (0.0485)	
0.9999844 1.6397304e-05
Epoch: [217][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0427 (0.0788)	
0.9999813 1.4210295e-05
Epoch: [217][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1774 (0.0776)	
0.9999999 1.5518273e-05
loss:  0.0612018144954769 0.05590792820413315
===========>   training    <===========
Epoch: [218][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0766 (0.0766)	
0.9999995 9.85998e-06
===========>   testing    <===========
Epoch: [218][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0585 (0.0585)	
0.999961 9.66362e-06
Epoch: [218][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0478 (0.0779)	
0.9995782 1.9913306e-05
Epoch: [218][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0925 (0.0743)	
0.9999994 1.17238205e-05
loss:  0.05729816420430511 0.05590792820413315
===========>   training    <===========
Epoch: [219][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0675 (0.0675)	
0.9999976 1.0674976e-05
===========>   testing    <===========
Epoch: [219][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0558 (0.0558)	
0.99997175 7.088749e-06
Epoch: [219][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1407 (0.0787)	
0.9999192 1.1248853e-05
Epoch: [219][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1993 (0.0775)	
0.99999976 7.936759e-06
loss:  0.058481642129329936 0.05590792820413315
===========>   training    <===========
Epoch: [220][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0838 (0.0838)	
0.9999839 2.6455904e-05
===========>   testing    <===========
Epoch: [220][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0526 (0.0526)	
0.999977 7.3397746e-06
Epoch: [220][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.5245 (0.0806)	
0.999936 9.416325e-06
Epoch: [220][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1526 (0.0756)	
0.99999976 7.696065e-06
loss:  0.0596343148886318 0.05590792820413315
===========>   training    <===========
Epoch: [221][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0867 (0.0867)	
0.9999999 6.8550685e-06
===========>   testing    <===========
Epoch: [221][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0586 (0.0586)	
0.99993896 8.23656e-06
Epoch: [221][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0553 (0.0728)	
0.99983644 9.24852e-06
Epoch: [221][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1550 (0.0712)	
0.99998736 7.1395375e-06
loss:  0.056940699490043656 0.05590792820413315
===========>   training    <===========
Epoch: [222][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0710 (0.0710)	
0.9999759 2.0358155e-05
===========>   testing    <===========
Epoch: [222][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0618 (0.0618)	
0.99996626 8.593692e-06
Epoch: [222][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0389 (0.0786)	
0.99996066 9.819788e-06
Epoch: [222][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1423 (0.0769)	
0.99999917 7.630359e-06
loss:  0.06009989496230028 0.05590792820413315
===========>   training    <===========
Epoch: [223][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0835 (0.0835)	
0.9999856 1.026229e-05
===========>   testing    <===========
Epoch: [223][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1594 (0.1594)	
0.9999316 1.0537699e-05
Epoch: [223][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0479 (0.0809)	
0.99994874 1.0011077e-05
Epoch: [223][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.2455 (0.0791)	
0.9999962 8.636636e-06
loss:  0.060090738863759596 0.05590792820413315
===========>   training    <===========
Epoch: [224][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0746 (0.0746)	
0.99998415 2.3409732e-05
===========>   testing    <===========
Epoch: [224][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1105 (0.1105)	
0.9999646 2.903237e-05
Epoch: [224][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0347 (0.0789)	
0.9999385 2.6308395e-05
Epoch: [224][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1099 (0.0759)	
0.99999976 2.0459263e-05
loss:  0.05972861962100773 0.05590792820413315
===========>   training    <===========
Epoch: [225][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0687 (0.0687)	
0.9999869 6.8587437e-06
===========>   testing    <===========
Epoch: [225][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0817 (0.0817)	
0.9999478 7.0232345e-06
Epoch: [225][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0256 (0.0741)	
0.99974805 7.582554e-06
Epoch: [225][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1358 (0.0720)	
0.9999982 5.924872e-06
loss:  0.05738506431409374 0.05590792820413315
===========>   training    <===========
Epoch: [226][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0699 (0.0699)	
0.9999993 7.331764e-06
===========>   testing    <===========
Epoch: [226][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0906 (0.0906)	
0.99998367 2.801009e-05
Epoch: [226][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0325 (0.0720)	
0.99983215 1.830122e-05
Epoch: [226][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1270 (0.0709)	
1.0 1.570121e-05
loss:  0.0552879416418075 0.05590792820413315
===========>   training    <===========
Epoch: [227][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0583 (0.0583)	
0.99998534 9.805134e-06
===========>   testing    <===========
Epoch: [227][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0960 (0.0960)	
0.99998057 1.3545403e-05
Epoch: [227][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1948 (0.0787)	
0.9996432 9.701564e-06
Epoch: [227][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0886 (0.0732)	
1.0 1.0609201e-05
loss:  0.05813851299194228 0.0552879416418075
===========>   training    <===========
Epoch: [228][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0798 (0.0798)	
0.9999907 1.0290976e-05
===========>   testing    <===========
Epoch: [228][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0563 (0.0563)	
0.99998987 1.1612326e-05
Epoch: [228][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0494 (0.0778)	
0.99996126 8.652629e-06
Epoch: [228][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1430 (0.0741)	
0.9999999 6.964647e-06
loss:  0.05642858150515784 0.0552879416418075
===========>   training    <===========
Epoch: [229][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0702 (0.0702)	
0.99996924 1.0940491e-05
===========>   testing    <===========
Epoch: [229][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0984 (0.0984)	
0.9999896 6.916865e-05
Epoch: [229][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.4384 (0.0959)	
0.99995923 7.422218e-05
Epoch: [229][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1151 (0.0894)	
1.0 2.2177299e-05
loss:  0.06815075661567138 0.0552879416418075
===========>   training    <===========
Epoch: [230][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0856 (0.0856)	
0.99999714 1.1229517e-05
===========>   testing    <===========
Epoch: [230][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0408 (0.0408)	
0.9999782 1.0736337e-05
Epoch: [230][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1397 (0.0809)	
0.99989474 9.931542e-06
Epoch: [230][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1941 (0.0772)	
0.99999976 9.297832e-06
loss:  0.05799930060783354 0.0552879416418075
===========>   training    <===========
Epoch: [231][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0830 (0.0830)	
0.9999709 7.976048e-06
===========>   testing    <===========
Epoch: [231][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1063 (0.1063)	
0.9998965 1.162795e-05
Epoch: [231][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.2991 (0.0870)	
0.99974185 1.1929402e-05
Epoch: [231][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1019 (0.0771)	
0.9999993 1.0638705e-05
loss:  0.060662128378831115 0.0552879416418075
===========>   training    <===========
Epoch: [232][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0640 (0.0640)	
0.9999815 4.173744e-05
===========>   testing    <===========
Epoch: [232][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0751 (0.0751)	
0.9999734 7.592265e-06
Epoch: [232][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1051 (0.0739)	
0.9999069 8.392308e-06
Epoch: [232][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1463 (0.0690)	
0.9999999 7.0116303e-06
loss:  0.055166730620432314 0.0552879416418075
===========>   training    <===========
Epoch: [233][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0918 (0.0918)	
0.99996614 9.007043e-06
===========>   testing    <===========
Epoch: [233][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0849 (0.0849)	
0.9999491 3.273406e-05
Epoch: [233][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0359 (0.0785)	
0.99983823 1.5312085e-05
Epoch: [233][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1516 (0.0730)	
0.9999981 1.9794366e-05
loss:  0.05598415764451692 0.055166730620432314
===========>   training    <===========
Epoch: [234][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0883 (0.0883)	
0.9999478 9.696689e-06
===========>   testing    <===========
Epoch: [234][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1009 (0.1009)	
0.99995124 1.3752518e-05
Epoch: [234][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0841 (0.0804)	
0.99989665 1.0514933e-05
Epoch: [234][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1185 (0.0740)	
0.99999785 1.4874552e-05
loss:  0.05635246070232347 0.055166730620432314
===========>   training    <===========
Epoch: [235][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0660 (0.0660)	
0.9999949 1.1700589e-05
===========>   testing    <===========
Epoch: [235][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1222 (0.1222)	
0.9999566 8.159652e-06
Epoch: [235][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0757 (0.0816)	
0.9998956 8.355963e-06
Epoch: [235][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1608 (0.0765)	
0.9999988 5.815492e-06
loss:  0.05939827452419133 0.055166730620432314
===========>   training    <===========
Epoch: [236][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0778 (0.0778)	
0.99999404 7.4780733e-06
===========>   testing    <===========
Epoch: [236][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0858 (0.0858)	
0.99994636 1.33359e-05
Epoch: [236][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0319 (0.0820)	
0.9998882 6.4482865e-06
Epoch: [236][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.2685 (0.0815)	
0.99999857 6.025474e-06
loss:  0.06151706611527186 0.055166730620432314
===========>   training    <===========
Epoch: [237][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0622 (0.0622)	
0.99998534 6.5756794e-06
===========>   testing    <===========
Epoch: [237][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1679 (0.1679)	
0.99995124 6.281019e-06
Epoch: [237][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0311 (0.0757)	
0.99991703 4.4947355e-06
Epoch: [237][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1138 (0.0722)	
0.9999989 4.3639907e-06
loss:  0.05630150455698646 0.055166730620432314
===========>   training    <===========
Epoch: [238][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0766 (0.0766)	
0.9999832 4.908076e-06
===========>   testing    <===========
Epoch: [238][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1062 (0.1062)	
0.9999753 6.4912245e-05
Epoch: [238][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0456 (0.0846)	
0.9999907 3.073993e-05
Epoch: [238][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.2690 (0.0834)	
0.9999999 1.4243756e-05
loss:  0.06267117217306739 0.055166730620432314
===========>   training    <===========
Epoch: [239][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0845 (0.0845)	
0.9999877 1.9509338e-05
===========>   testing    <===========
Epoch: [239][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0965 (0.0965)	
0.99998045 1.0781986e-05
Epoch: [239][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0521 (0.0798)	
0.9999726 1.1728204e-05
Epoch: [239][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1559 (0.0780)	
0.9999995 7.3251535e-06
loss:  0.06124681133021559 0.055166730620432314
===========>   training    <===========
Epoch: [240][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0802 (0.0802)	
0.9999931 7.5924677e-06
===========>   testing    <===========
Epoch: [240][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0636 (0.0636)	
0.99998844 1.9331932e-05
Epoch: [240][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0534 (0.0831)	
0.99995255 2.3822562e-05
Epoch: [240][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1882 (0.0797)	
1.0 1.7502358e-05
loss:  0.05915488143895142 0.055166730620432314
===========>   training    <===========
Epoch: [241][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0904 (0.0904)	
0.9999763 7.845439e-06
===========>   testing    <===========
Epoch: [241][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1121 (0.1121)	
0.99995196 9.538794e-06
Epoch: [241][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0361 (0.0727)	
0.9999051 7.583306e-06
Epoch: [241][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1779 (0.0707)	
0.9999982 7.5873068e-06
loss:  0.05577987562493425 0.055166730620432314
===========>   training    <===========
Epoch: [242][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0666 (0.0666)	
0.9999877 1.438116e-05
===========>   testing    <===========
Epoch: [242][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0850 (0.0850)	
0.99995077 5.464678e-06
Epoch: [242][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0807 (0.0768)	
0.99982977 5.550707e-06
Epoch: [242][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1148 (0.0704)	
0.9999968 5.1965317e-06
loss:  0.05634777379690081 0.055166730620432314
===========>   training    <===========
Epoch: [243][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0894 (0.0894)	
0.99999964 9.286107e-06
===========>   testing    <===========
Epoch: [243][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1311 (0.1311)	
0.99979883 9.920788e-06
Epoch: [243][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0884 (0.0845)	
0.99991846 8.063713e-06
Epoch: [243][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1845 (0.0795)	
0.9999988 9.132347e-06
loss:  0.0635763296512517 0.055166730620432314
===========>   training    <===========
Epoch: [244][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0938 (0.0938)	
0.9999895 1.9934e-05
===========>   testing    <===========
Epoch: [244][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0980 (0.0980)	
0.9999895 7.961981e-06
Epoch: [244][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0358 (0.0792)	
0.9999747 9.712515e-06
Epoch: [244][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1233 (0.0751)	
1.0 9.780833e-06
loss:  0.05729054562463931 0.055166730620432314
===========>   training    <===========
Epoch: [245][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0951 (0.0951)	
0.999997 1.0864e-05
===========>   testing    <===========
Epoch: [245][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0731 (0.0731)	
0.9999833 7.182843e-06
Epoch: [245][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0317 (0.0758)	
0.9999597 7.252929e-06
Epoch: [245][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0812 (0.0724)	
1.0 7.1863988e-06
loss:  0.05448101160869212 0.055166730620432314
===========>   training    <===========
Epoch: [246][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0744 (0.0744)	
0.9999989 9.39546e-06
===========>   testing    <===========
Epoch: [246][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1134 (0.1134)	
0.9999615 8.475198e-06
Epoch: [246][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0365 (0.0775)	
0.9999504 9.293886e-06
Epoch: [246][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0864 (0.0738)	
0.9999999 8.374623e-06
loss:  0.05919638882516276 0.05448101160869212
===========>   training    <===========
Epoch: [247][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0827 (0.0827)	
0.9999957 6.8606737e-06
===========>   testing    <===========
Epoch: [247][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1883 (0.1883)	
0.99998057 6.645746e-06
Epoch: [247][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1678 (0.0851)	
0.9999639 6.664558e-06
Epoch: [247][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0726 (0.0773)	
0.99999976 6.2085537e-06
loss:  0.06092145027244489 0.05448101160869212
===========>   training    <===========
Epoch: [248][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0722 (0.0722)	
0.9999994 5.7030325e-06
===========>   testing    <===========
Epoch: [248][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0847 (0.0847)	
0.9999869 1.6570015e-05
Epoch: [248][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0707 (0.0733)	
0.9999378 1.7428272e-05
Epoch: [248][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0916 (0.0700)	
0.99999917 1.8522298e-05
loss:  0.054803369423919834 0.05448101160869212
===========>   training    <===========
Epoch: [249][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0847 (0.0847)	
0.9999994 8.687638e-06
===========>   testing    <===========
Epoch: [249][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0524 (0.0524)	
0.9999697 6.2626564e-06
Epoch: [249][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0353 (0.0744)	
0.9997002 6.0552384e-06
Epoch: [249][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1600 (0.0723)	
0.99999857 5.7776533e-06
loss:  0.05598856192968671 0.05448101160869212
===========>   training    <===========
Epoch: [250][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0692 (0.0692)	
0.9999951 3.1160165e-05
===========>   testing    <===========
Epoch: [250][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0772 (0.0772)	
0.9999778 1.664807e-05
Epoch: [250][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0617 (0.0738)	
0.9999502 1.8827759e-05
Epoch: [250][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0862 (0.0708)	
1.0 1.1128727e-05
loss:  0.05617275082807538 0.05448101160869212
===========>   training    <===========
Epoch: [251][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0679 (0.0679)	
0.9999902 5.903755e-06
===========>   testing    <===========
Epoch: [251][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0631 (0.0631)	
0.9999753 3.6004123e-05
Epoch: [251][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0708 (0.0759)	
0.9999298 2.9003868e-05
Epoch: [251][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0893 (0.0722)	
0.9999999 1.9598325e-05
loss:  0.056826454893135536 0.05448101160869212
===========>   training    <===========
Epoch: [252][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0714 (0.0714)	
0.99999535 6.7851697e-06
===========>   testing    <===========
Epoch: [252][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0834 (0.0834)	
0.999969 5.1049237e-06
Epoch: [252][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0668 (0.0777)	
0.99993837 5.1321476e-06
Epoch: [252][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1202 (0.0716)	
0.99999976 4.858173e-06
loss:  0.05516896586500675 0.05448101160869212
===========>   training    <===========
Epoch: [253][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0623 (0.0623)	
0.99999106 8.463421e-06
===========>   testing    <===========
Epoch: [253][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0952 (0.0952)	
0.99998844 6.6789826e-06
Epoch: [253][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0429 (0.0794)	
0.9999459 5.987074e-06
Epoch: [253][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1630 (0.0722)	
0.9999999 5.2877517e-06
loss:  0.05533408096426229 0.05448101160869212
===========>   training    <===========
Epoch: [254][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0723 (0.0723)	
0.9999945 5.3968374e-06
===========>   testing    <===========
Epoch: [254][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1590 (0.1590)	
0.999974 1.2329059e-05
Epoch: [254][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.2294 (0.0878)	
0.9999664 1.35852615e-05
Epoch: [254][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.3056 (0.0784)	
0.9999976 6.915814e-06
loss:  0.060977112737596983 0.05448101160869212
===========>   training    <===========
Epoch: [255][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0887 (0.0887)	
0.9999813 2.1540935e-05
===========>   testing    <===========
Epoch: [255][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0685 (0.0685)	
0.99997973 5.7734283e-06
Epoch: [255][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0330 (0.0771)	
0.9999039 5.2319274e-06
Epoch: [255][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1874 (0.0720)	
0.99999726 4.7721064e-06
loss:  0.05499477969314581 0.05448101160869212
===========>   training    <===========
Epoch: [256][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0631 (0.0631)	
0.9999908 8.39929e-06
===========>   testing    <===========
Epoch: [256][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1495 (0.1495)	
0.9999678 5.986149e-06
Epoch: [256][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0311 (0.0832)	
0.99990714 5.3415574e-06
Epoch: [256][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1985 (0.0769)	
0.9999906 4.835625e-06
loss:  0.05900894643951682 0.05448101160869212
===========>   training    <===========
Epoch: [257][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0831 (0.0831)	
0.9999758 6.93901e-06
===========>   testing    <===========
Epoch: [257][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0811 (0.0811)	
0.9999932 8.763093e-06
Epoch: [257][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0321 (0.0755)	
0.99999166 8.129934e-06
Epoch: [257][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1608 (0.0706)	
1.0 6.9689263e-06
loss:  0.054119175423343324 0.05448101160869212
===========>   training    <===========
Epoch: [258][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0553 (0.0553)	
0.99998033 2.7560123e-05
===========>   testing    <===========
Epoch: [258][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1560 (0.1560)	
0.9999974 1.5984231e-05
Epoch: [258][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0347 (0.0758)	
0.9999504 1.1871905e-05
Epoch: [258][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1656 (0.0732)	
1.0 1.33673375e-05
loss:  0.05627435565890038 0.054119175423343324
===========>   training    <===========
Epoch: [259][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0609 (0.0609)	
0.9999641 3.9439565e-06
===========>   testing    <===========
Epoch: [259][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1063 (0.1063)	
0.99999523 1.5079296e-05
Epoch: [259][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0279 (0.0763)	
0.99999607 1.1210417e-05
Epoch: [259][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1569 (0.0733)	
1.0 8.890996e-06
loss:  0.056060009401071476 0.054119175423343324
===========>   training    <===========
Epoch: [260][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0713 (0.0713)	
0.99999976 1.7158256e-05
===========>   testing    <===========
Epoch: [260][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1118 (0.1118)	
0.9999707 8.495534e-06
Epoch: [260][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0356 (0.0829)	
0.99994314 6.9261773e-06
Epoch: [260][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1632 (0.0774)	
0.99999905 6.7942738e-06
loss:  0.059752812907847064 0.054119175423343324
===========>   training    <===========
Epoch: [261][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0766 (0.0766)	
0.99997497 3.821176e-05
===========>   testing    <===========
Epoch: [261][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0661 (0.0661)	
0.9999783 8.518185e-06
Epoch: [261][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0500 (0.0772)	
0.9999794 7.905546e-06
Epoch: [261][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1828 (0.0750)	
1.0 7.4277236e-06
loss:  0.05829029485000381 0.054119175423343324
===========>   training    <===========
Epoch: [262][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0599 (0.0599)	
0.99999905 1.2257439e-05
===========>   testing    <===========
Epoch: [262][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0752 (0.0752)	
0.9999441 8.7303615e-06
Epoch: [262][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0813 (0.0702)	
0.9998211 7.791264e-06
Epoch: [262][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1352 (0.0679)	
0.9999974 7.769004e-06
loss:  0.05407986559785816 0.054119175423343324
===========>   training    <===========
Epoch: [263][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0621 (0.0621)	
0.99999607 1.0058371e-05
===========>   testing    <===========
Epoch: [263][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0865 (0.0865)	
0.99998593 1.859119e-05
Epoch: [263][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0403 (0.0790)	
0.99996805 1.7086086e-05
Epoch: [263][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1606 (0.0762)	
0.9999999 2.008197e-05
loss:  0.05880596351351863 0.05407986559785816
===========>   training    <===========
Epoch: [264][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0598 (0.0598)	
0.9999771 1.6774113e-05
===========>   testing    <===========
Epoch: [264][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0999 (0.0999)	
0.99996316 1.2250416e-05
Epoch: [264][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0340 (0.0710)	
0.99985445 9.338319e-06
Epoch: [264][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0971 (0.0677)	
0.99999714 8.811053e-06
loss:  0.054709022101499194 0.05407986559785816
===========>   training    <===========
Epoch: [265][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0743 (0.0743)	
0.9999944 9.83288e-06
===========>   testing    <===========
Epoch: [265][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0924 (0.0924)	
0.9999914 7.2240805e-06
Epoch: [265][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0287 (0.0796)	
0.9999738 5.8023293e-06
Epoch: [265][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0703 (0.0756)	
0.99999976 6.015886e-06
loss:  0.05750838779560874 0.05407986559785816
===========>   training    <===========
Epoch: [266][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0862 (0.0862)	
0.9999963 1.1386508e-05
===========>   testing    <===========
Epoch: [266][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0534 (0.0534)	
0.9999368 1.6078193e-05
Epoch: [266][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0287 (0.0770)	
0.9998072 6.1106216e-06
Epoch: [266][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1447 (0.0732)	
0.99999714 6.049778e-06
loss:  0.056747832874589066 0.05407986559785816
===========>   training    <===========
Epoch: [267][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0589 (0.0589)	
0.9999831 1.8737821e-05
===========>   testing    <===========
Epoch: [267][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1340 (0.1340)	
0.99996686 4.557987e-06
Epoch: [267][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0419 (0.0841)	
0.999936 5.039502e-06
Epoch: [267][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.2027 (0.0811)	
0.9999987 4.487874e-06
loss:  0.06405880707420908 0.05407986559785816
===========>   training    <===========
Epoch: [268][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0792 (0.0792)	
0.9999912 1.518322e-05
===========>   testing    <===========
Epoch: [268][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0685 (0.0685)	
0.9999738 1.874195e-05
Epoch: [268][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0332 (0.0718)	
0.9998957 2.3375489e-05
Epoch: [268][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1753 (0.0713)	
0.99999964 1.0437424e-05
loss:  0.057089749302450365 0.05407986559785816
===========>   training    <===========
Epoch: [269][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0632 (0.0632)	
0.99998736 1.08071345e-05
===========>   testing    <===========
Epoch: [269][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0548 (0.0548)	
0.9999895 1.0089209e-05
Epoch: [269][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0310 (0.0833)	
0.99998415 9.9362505e-06
Epoch: [269][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1231 (0.0781)	
0.9999995 1.102532e-05
loss:  0.055054629275308464 0.05407986559785816
===========>   training    <===========
Epoch: [270][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0639 (0.0639)	
0.99999917 6.365539e-06
===========>   testing    <===========
Epoch: [270][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0634 (0.0634)	
0.99996424 2.1581052e-05
Epoch: [270][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0379 (0.0774)	
0.99972004 2.3524513e-05
Epoch: [270][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1440 (0.0752)	
0.9999964 1.2886157e-05
loss:  0.05901370429867536 0.05407986559785816
===========>   training    <===========
Epoch: [271][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0705 (0.0705)	
0.9999856 6.8097843e-06
===========>   testing    <===========
Epoch: [271][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0536 (0.0536)	
0.99998665 7.77305e-06
Epoch: [271][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0350 (0.0733)	
0.9999571 7.4743803e-06
Epoch: [271][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.2447 (0.0731)	
0.99999917 7.78432e-06
loss:  0.056237038901956415 0.05407986559785816
===========>   training    <===========
Epoch: [272][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0641 (0.0641)	
0.99998915 5.5217324e-06
===========>   testing    <===========
Epoch: [272][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0652 (0.0652)	
0.9999856 1.0167854e-05
Epoch: [272][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0697 (0.0770)	
0.999966 8.155466e-06
Epoch: [272][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1997 (0.0728)	
0.9999999 8.708826e-06
loss:  0.05800169181751147 0.05407986559785816
===========>   training    <===========
Epoch: [273][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0705 (0.0705)	
0.9999869 8.1084245e-06
===========>   testing    <===========
Epoch: [273][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0821 (0.0821)	
0.9999813 2.6993052e-05
Epoch: [273][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0477 (0.0799)	
0.9999932 1.4827872e-05
Epoch: [273][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1291 (0.0739)	
0.9999995 1.4406432e-05
loss:  0.05932154140178314 0.05407986559785816
===========>   training    <===========
Epoch: [274][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0546 (0.0546)	
0.99999917 8.742526e-06
===========>   testing    <===========
Epoch: [274][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0563 (0.0563)	
0.9999894 2.8273631e-05
Epoch: [274][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0307 (0.0699)	
0.99998283 1.677544e-05
Epoch: [274][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1222 (0.0682)	
0.99999976 2.048187e-05
loss:  0.054294875367751905 0.05407986559785816
===========>   training    <===========
Epoch: [275][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0658 (0.0658)	
0.9999919 1.1728003e-05
===========>   testing    <===========
Epoch: [275][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0920 (0.0920)	
0.99998164 7.030291e-06
Epoch: [275][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0455 (0.0750)	
0.9999629 6.873496e-06
Epoch: [275][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0988 (0.0710)	
0.99999964 6.186225e-06
loss:  0.057162155302328044 0.05407986559785816
===========>   training    <===========
Epoch: [276][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0661 (0.0661)	
0.99998796 1.45090935e-05
===========>   testing    <===========
Epoch: [276][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0726 (0.0726)	
0.9999912 9.576174e-06
Epoch: [276][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0317 (0.0752)	
0.9999746 1.1038459e-05
Epoch: [276][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1677 (0.0716)	
0.9999999 8.06162e-06
loss:  0.05603691481753592 0.05407986559785816
===========>   training    <===========
Epoch: [277][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0730 (0.0730)	
0.9999819 1.4770726e-05
===========>   testing    <===========
Epoch: [277][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1005 (0.1005)	
0.99999464 9.375448e-06
Epoch: [277][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0780 (0.0872)	
0.9999832 9.076103e-06
Epoch: [277][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1779 (0.0788)	
0.9999999 8.997722e-06
loss:  0.061023164485277004 0.05407986559785816
===========>   training    <===========
Epoch: [278][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0615 (0.0615)	
0.99997854 1.0792282e-05
===========>   testing    <===========
Epoch: [278][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1288 (0.1288)	
0.9999759 1.1137731e-05
Epoch: [278][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1176 (0.0749)	
0.9999764 8.419435e-06
Epoch: [278][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.2098 (0.0712)	
0.99999917 9.441638e-06
loss:  0.056876614132372216 0.05407986559785816
===========>   training    <===========
Epoch: [279][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0736 (0.0736)	
0.99999976 5.6999656e-06
===========>   testing    <===========
Epoch: [279][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0790 (0.0790)	
0.9999924 8.0360915e-06
Epoch: [279][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0303 (0.0702)	
0.99996924 7.336492e-06
Epoch: [279][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1418 (0.0687)	
1.0 7.479528e-06
loss:  0.05451198093774201 0.05407986559785816
===========>   training    <===========
Epoch: [280][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0662 (0.0662)	
0.9999994 5.819198e-06
===========>   testing    <===========
Epoch: [280][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1028 (0.1028)	
0.999959 7.7224e-06
Epoch: [280][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0794 (0.0782)	
0.999938 7.161646e-06
Epoch: [280][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1974 (0.0740)	
0.9999982 6.654809e-06
loss:  0.060126110538445965 0.05407986559785816
===========>   training    <===========
Epoch: [281][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0718 (0.0718)	
0.9999665 5.4071716e-06
===========>   testing    <===========
Epoch: [281][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1106 (0.1106)	
0.9999794 1.4326597e-05
Epoch: [281][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0360 (0.0779)	
0.9999844 1.051411e-05
Epoch: [281][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1942 (0.0778)	
0.9999999 1.4122536e-05
loss:  0.05769622546265851 0.05407986559785816
===========>   training    <===========
Epoch: [282][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0751 (0.0751)	
0.9999987 8.7379585e-06
===========>   testing    <===========
Epoch: [282][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0795 (0.0795)	
0.9999751 1.7044535e-05
Epoch: [282][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0341 (0.0725)	
0.99998486 1.7534838e-05
Epoch: [282][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1788 (0.0713)	
0.9999981 1.6212085e-05
loss:  0.05418069596095321 0.05407986559785816
===========>   training    <===========
Epoch: [283][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0697 (0.0697)	
0.9999875 1.2125953e-05
===========>   testing    <===========
Epoch: [283][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0702 (0.0702)	
0.9999757 1.5270623e-05
Epoch: [283][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0264 (0.0747)	
0.9999589 1.7017039e-05
Epoch: [283][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1246 (0.0708)	
0.99999857 1.5207812e-05
loss:  0.05542377149971023 0.05407986559785816
===========>   training    <===========
Epoch: [284][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0725 (0.0725)	
0.9999988 3.909997e-06
===========>   testing    <===========
Epoch: [284][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1476 (0.1476)	
0.9999653 1.116768e-05
Epoch: [284][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0425 (0.0739)	
0.9998889 8.595118e-06
Epoch: [284][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0789 (0.0692)	
0.99999964 6.9946595e-06
loss:  0.05476774312429589 0.05407986559785816
===========>   training    <===========
Epoch: [285][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0685 (0.0685)	
0.99999857 4.871126e-06
===========>   testing    <===========
Epoch: [285][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0522 (0.0522)	
0.99997854 9.406013e-06
Epoch: [285][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0293 (0.0722)	
0.99997616 7.1453e-06
Epoch: [285][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.2624 (0.0726)	
0.9999962 8.658549e-06
loss:  0.05525636346377316 0.05407986559785816
===========>   training    <===========
Epoch: [286][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0735 (0.0735)	
0.999997 8.460468e-06
===========>   testing    <===========
Epoch: [286][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1406 (0.1406)	
0.99995124 1.8377457e-05
Epoch: [286][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0661 (0.0702)	
0.99998665 8.69257e-06
Epoch: [286][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1277 (0.0714)	
0.99999154 8.885046e-06
loss:  0.055856233877388806 0.05407986559785816
===========>   training    <===========
Epoch: [287][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0664 (0.0664)	
0.9999894 9.126939e-06
===========>   testing    <===========
Epoch: [287][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0834 (0.0834)	
0.9999751 1.0883517e-05
Epoch: [287][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0740 (0.0717)	
0.99994826 9.209917e-06
Epoch: [287][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1730 (0.0706)	
0.99999905 8.598914e-06
loss:  0.05353498685988367 0.05407986559785816
===========>   training    <===========
Epoch: [288][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0743 (0.0743)	
0.9999844 1.6214419e-05
===========>   testing    <===========
Epoch: [288][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1625 (0.1625)	
0.9999521 7.2057655e-06
Epoch: [288][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0399 (0.0693)	
0.9999764 6.966089e-06
Epoch: [288][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1039 (0.0685)	
0.9999988 6.9515086e-06
loss:  0.05207945460419072 0.05353498685988367
===========>   training    <===========
Epoch: [289][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0850 (0.0850)	
0.9999833 3.8296617e-05
===========>   testing    <===========
Epoch: [289][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0863 (0.0863)	
0.99998 2.0528785e-05
Epoch: [289][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0360 (0.0725)	
0.99998784 1.6651706e-05
Epoch: [289][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1533 (0.0704)	
0.9999989 1.2155581e-05
loss:  0.05333439010294472 0.05207945460419072
===========>   training    <===========
Epoch: [290][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0667 (0.0667)	
0.9999918 5.763702e-06
===========>   testing    <===========
Epoch: [290][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0855 (0.0855)	
0.9999577 3.4482095e-05
Epoch: [290][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0851 (0.0702)	
0.99995387 2.1347376e-05
Epoch: [290][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1153 (0.0662)	
0.99999416 1.3427297e-05
loss:  0.05141317198492845 0.05207945460419072
===========>   training    <===========
Epoch: [291][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0598 (0.0598)	
0.99998856 6.5182567e-06
===========>   testing    <===========
Epoch: [291][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0898 (0.0898)	
0.9999646 5.783215e-06
Epoch: [291][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0473 (0.0715)	
0.99994445 6.0610796e-06
Epoch: [291][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1078 (0.0673)	
0.99999917 6.4152555e-06
loss:  0.05319717954971348 0.05141317198492845
===========>   training    <===========
Epoch: [292][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0709 (0.0709)	
0.9999956 8.687109e-06
===========>   testing    <===========
Epoch: [292][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0614 (0.0614)	
0.9999713 4.574434e-06
Epoch: [292][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0707 (0.0712)	
0.9999535 5.1691695e-06
Epoch: [292][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1319 (0.0693)	
0.99999785 5.0957606e-06
loss:  0.05481470506598396 0.05141317198492845
===========>   training    <===========
Epoch: [293][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0844 (0.0844)	
0.9999801 1.1059459e-05
===========>   testing    <===========
Epoch: [293][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1379 (0.1379)	
0.99997044 5.8467895e-06
Epoch: [293][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0551 (0.0782)	
0.9999825 6.511981e-06
Epoch: [293][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0961 (0.0735)	
0.9999995 5.9524764e-06
loss:  0.05607157222141479 0.05141317198492845
===========>   training    <===========
Epoch: [294][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0697 (0.0697)	
0.9999856 3.0267463e-05
===========>   testing    <===========
Epoch: [294][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1116 (0.1116)	
0.9999949 7.7713385e-06
Epoch: [294][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0503 (0.0874)	
0.99999404 8.239457e-06
Epoch: [294][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1083 (0.0834)	
1.0 9.747636e-06
loss:  0.05985758576627265 0.05141317198492845
===========>   training    <===========
Epoch: [295][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0820 (0.0820)	
0.9999976 5.3604595e-06
===========>   testing    <===========
Epoch: [295][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1112 (0.1112)	
0.9999753 7.3836813e-06
Epoch: [295][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1090 (0.0759)	
0.9999851 8.830542e-06
Epoch: [295][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1148 (0.0738)	
0.9999993 8.707546e-06
loss:  0.05762220345765545 0.05141317198492845
===========>   training    <===========
Epoch: [296][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0778 (0.0778)	
0.9999932 4.8717393e-06
===========>   testing    <===========
Epoch: [296][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1762 (0.1762)	
0.9999498 7.276416e-06
Epoch: [296][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0976 (0.0729)	
0.9999728 6.8471572e-06
Epoch: [296][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0940 (0.0722)	
0.99999857 6.5221616e-06
loss:  0.056358019898890666 0.05141317198492845
===========>   training    <===========
Epoch: [297][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0726 (0.0726)	
0.99996865 7.800818e-06
===========>   testing    <===========
Epoch: [297][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0811 (0.0811)	
0.9999683 9.190219e-06
Epoch: [297][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0329 (0.0710)	
0.9999299 8.07591e-06
Epoch: [297][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0793 (0.0688)	
0.9999962 8.543501e-06
loss:  0.055209790891626365 0.05141317198492845
===========>   training    <===========
Epoch: [298][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0600 (0.0600)	
0.9999739 1.2798504e-05
===========>   testing    <===========
Epoch: [298][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1051 (0.1051)	
0.99999785 1.1867718e-05
Epoch: [298][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0445 (0.0679)	
0.9999889 1.23457185e-05
Epoch: [298][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.2045 (0.0680)	
1.0 1.1828783e-05
loss:  0.0523106810064109 0.05141317198492845
===========>   training    <===========
Epoch: [299][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0846 (0.0846)	
0.99999154 9.365688e-06
===========>   testing    <===========
Epoch: [299][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0985 (0.0985)	
0.99999034 1.0219942e-05
Epoch: [299][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0327 (0.0719)	
0.9999813 8.924822e-06
Epoch: [299][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1597 (0.0727)	
0.99999964 8.413278e-06
loss:  0.05469794107233339 0.05141317198492845
===========>   training    <===========
Epoch: [300][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0648 (0.0648)	
0.99998796 2.9949446e-05
===========>   testing    <===========
Epoch: [300][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0448 (0.0448)	
0.99996936 2.5166648e-05
Epoch: [300][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0311 (0.0755)	
0.99996054 2.5261459e-05
Epoch: [300][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1931 (0.0738)	
0.9999969 1.4410649e-05
loss:  0.05671507326413061 0.05141317198492845
===========>   training    <===========
Epoch: [301][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0652 (0.0652)	
0.9999851 3.168993e-05
===========>   testing    <===========
Epoch: [301][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0632 (0.0632)	
0.9999541 1.5426025e-05
Epoch: [301][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0414 (0.0703)	
0.9999205 1.1042913e-05
Epoch: [301][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1673 (0.0677)	
0.99998724 1.18648995e-05
loss:  0.0524614343637847 0.05141317198492845
===========>   training    <===========
Epoch: [302][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0553 (0.0553)	
0.9999901 8.601465e-06
===========>   testing    <===========
Epoch: [302][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1116 (0.1116)	
0.99999475 1.47364235e-05
Epoch: [302][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0398 (0.0701)	
0.99999154 1.5900854e-05
Epoch: [302][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0757 (0.0658)	
1.0 1.3344424e-05
loss:  0.051229722433199676 0.05141317198492845
===========>   training    <===========
Epoch: [303][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0545 (0.0545)	
0.99999416 1.3201215e-05
===========>   testing    <===========
Epoch: [303][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0843 (0.0843)	
0.9999831 9.9855415e-06
Epoch: [303][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0373 (0.0824)	
0.99998605 1.09242055e-05
Epoch: [303][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1742 (0.0789)	
0.9999995 8.534616e-06
loss:  0.059580814591190356 0.051229722433199676
===========>   training    <===========
Epoch: [304][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0694 (0.0694)	
0.9999912 1.0811309e-05
===========>   testing    <===========
Epoch: [304][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0839 (0.0839)	
0.9999902 1.1978547e-05
Epoch: [304][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0347 (0.0853)	
0.9999733 1.5021466e-05
Epoch: [304][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1243 (0.0787)	
0.9999995 1.0631433e-05
loss:  0.05894835069159776 0.051229722433199676
===========>   training    <===========
Epoch: [305][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0672 (0.0672)	
0.99998665 6.020523e-06
===========>   testing    <===========
Epoch: [305][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0849 (0.0849)	
0.9999875 9.927688e-06
Epoch: [305][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0228 (0.0721)	
0.99998665 9.3111685e-06
Epoch: [305][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.2373 (0.0718)	
0.9999988 1.010212e-05
loss:  0.05384301031388539 0.051229722433199676
===========>   training    <===========
Epoch: [306][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0768 (0.0768)	
0.9999826 8.656112e-06
===========>   testing    <===========
Epoch: [306][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0792 (0.0792)	
0.99994314 7.934761e-06
Epoch: [306][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0413 (0.0795)	
0.9986864 7.6583465e-06
Epoch: [306][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1214 (0.0718)	
0.9999684 7.3785714e-06
loss:  0.054674094822704467 0.051229722433199676
===========>   training    <===========
Epoch: [307][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0678 (0.0678)	
0.99998915 3.076486e-05
===========>   testing    <===========
Epoch: [307][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0976 (0.0976)	
0.9999881 7.039053e-06
Epoch: [307][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0280 (0.0771)	
0.99996567 7.3647216e-06
Epoch: [307][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1822 (0.0752)	
0.9999989 7.074857e-06
loss:  0.056893455729874365 0.051229722433199676
===========>   training    <===========
Epoch: [308][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0669 (0.0669)	
0.99998796 1.7095832e-05
===========>   testing    <===========
Epoch: [308][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0731 (0.0731)	
0.99997306 1.3610238e-05
Epoch: [308][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0251 (0.0686)	
0.9999702 1.9927462e-05
Epoch: [308][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1518 (0.0694)	
0.99999726 1.2849071e-05
loss:  0.053551448033051785 0.051229722433199676
===========>   training    <===========
Epoch: [309][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0755 (0.0755)	
0.9999683 5.732489e-06
===========>   testing    <===========
Epoch: [309][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1613 (0.1613)	
0.99997973 7.109513e-06
Epoch: [309][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0400 (0.0737)	
0.9999536 6.9995244e-06
Epoch: [309][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0919 (0.0684)	
0.99999905 6.869381e-06
loss:  0.05518532916484642 0.051229722433199676
===========>   training    <===========
Epoch: [310][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0782 (0.0782)	
0.99999964 6.466348e-06
===========>   testing    <===========
Epoch: [310][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1237 (0.1237)	
0.99998903 1.0132203e-05
Epoch: [310][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0365 (0.0722)	
0.9999838 1.0949029e-05
Epoch: [310][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1662 (0.0695)	
0.9999994 8.807508e-06
loss:  0.05247486889909381 0.051229722433199676
===========>   training    <===========
Epoch: [311][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0594 (0.0594)	
0.9999968 1.1159015e-05
===========>   testing    <===========
Epoch: [311][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1129 (0.1129)	
0.999982 1.69973e-05
Epoch: [311][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0366 (0.0688)	
0.9999789 1.0637041e-05
Epoch: [311][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.2308 (0.0702)	
0.999998 1.1351922e-05
loss:  0.053501860491765973 0.051229722433199676
===========>   training    <===========
Epoch: [312][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0720 (0.0720)	
0.999985 8.405347e-06
===========>   testing    <===========
Epoch: [312][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0968 (0.0968)	
0.99997807 3.472805e-05
Epoch: [312][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0600 (0.0760)	
0.9999771 1.6758011e-05
Epoch: [312][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1799 (0.0728)	
0.9999989 2.0540925e-05
loss:  0.05676330242853567 0.051229722433199676
===========>   training    <===========
Epoch: [313][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0565 (0.0565)	
0.9999831 1.1261337e-05
===========>   testing    <===========
Epoch: [313][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0850 (0.0850)	
0.9999627 8.42333e-06
Epoch: [313][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0445 (0.0723)	
0.9998357 8.899275e-06
Epoch: [313][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1723 (0.0715)	
0.99999714 8.11969e-06
loss:  0.056051887093489294 0.051229722433199676
===========>   training    <===========
Epoch: [314][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0604 (0.0604)	
0.9999747 7.775208e-06
===========>   testing    <===========
Epoch: [314][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1007 (0.1007)	
0.99999523 2.6107353e-05
Epoch: [314][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0979 (0.0764)	
0.9999707 2.974323e-05
Epoch: [314][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1873 (0.0730)	
1.0 1.9338164e-05
loss:  0.055368256234514246 0.051229722433199676
===========>   training    <===========
Epoch: [315][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0718 (0.0718)	
0.999992 5.977415e-06
===========>   testing    <===========
Epoch: [315][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0935 (0.0935)	
0.99998486 7.963622e-06
Epoch: [315][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0523 (0.0764)	
0.99997365 7.1274208e-06
Epoch: [315][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1519 (0.0727)	
0.99999964 6.1774876e-06
loss:  0.0545914309536345 0.051229722433199676
===========>   training    <===========
Epoch: [316][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0771 (0.0771)	
0.9999665 1.1091813e-05
===========>   testing    <===========
Epoch: [316][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1000 (0.1000)	
0.99998415 7.891888e-06
Epoch: [316][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0545 (0.0739)	
0.99996924 7.25897e-06
Epoch: [316][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1321 (0.0686)	
0.99999976 6.762456e-06
loss:  0.05412415291907757 0.051229722433199676
===========>   training    <===========
Epoch: [317][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0698 (0.0698)	
0.999997 5.9254767e-06
===========>   testing    <===========
Epoch: [317][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0840 (0.0840)	
0.999998 7.3744063e-06
Epoch: [317][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0352 (0.0882)	
0.9999883 6.93516e-06
Epoch: [317][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.2665 (0.0823)	
0.9999999 6.6208663e-06
loss:  0.05915512179963578 0.051229722433199676
===========>   training    <===========
Epoch: [318][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0669 (0.0669)	
0.9999896 3.879602e-06
===========>   testing    <===========
Epoch: [318][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0840 (0.0840)	
0.9999875 1.2382991e-05
Epoch: [318][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0566 (0.0716)	
0.9999802 9.831173e-06
Epoch: [318][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1826 (0.0704)	
0.99999976 9.6181e-06
loss:  0.05320210787037982 0.051229722433199676
===========>   training    <===========
Epoch: [319][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0570 (0.0570)	
0.99998724 9.841538e-06
===========>   testing    <===========
Epoch: [319][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1209 (0.1209)	
0.99997044 7.411316e-06
Epoch: [319][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0826 (0.0731)	
0.9999782 7.8801795e-06
Epoch: [319][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1797 (0.0703)	
0.9999964 8.195572e-06
loss:  0.05505910918847068 0.051229722433199676
===========>   training    <===========
Epoch: [320][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0615 (0.0615)	
0.99999475 1.026321e-05
===========>   testing    <===========
Epoch: [320][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0799 (0.0799)	
0.9999521 6.1100736e-06
Epoch: [320][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0275 (0.0730)	
0.999882 6.6592534e-06
Epoch: [320][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1987 (0.0692)	
0.9999869 6.2808454e-06
loss:  0.05289937347683793 0.051229722433199676
===========>   training    <===========
Epoch: [321][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0689 (0.0689)	
0.99998796 6.361473e-06
===========>   testing    <===========
Epoch: [321][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0942 (0.0942)	
0.99997485 5.3408035e-06
Epoch: [321][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0652 (0.0736)	
0.99997234 4.5309994e-06
Epoch: [321][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.2113 (0.0713)	
0.9999987 4.752301e-06
loss:  0.05418838906928969 0.051229722433199676
===========>   training    <===========
Epoch: [322][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0618 (0.0618)	
0.99998665 4.624703e-06
===========>   testing    <===========
Epoch: [322][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0594 (0.0594)	
0.99998116 6.9928324e-06
Epoch: [322][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1711 (0.0712)	
0.9999633 6.7319183e-06
Epoch: [322][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.2096 (0.0687)	
0.9999993 6.7750893e-06
loss:  0.05372202447105845 0.051229722433199676
===========>   training    <===========
Epoch: [323][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0615 (0.0615)	
0.9999987 5.66012e-06
===========>   testing    <===========
Epoch: [323][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0640 (0.0640)	
0.9999857 1.3612082e-05
Epoch: [323][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1200 (0.0702)	
0.9999827 1.6550099e-05
Epoch: [323][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1586 (0.0680)	
0.99999964 1.1920986e-05
loss:  0.05287521934457806 0.051229722433199676
===========>   training    <===========
Epoch: [324][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0630 (0.0630)	
0.99996877 3.7485322e-06
===========>   testing    <===========
Epoch: [324][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0929 (0.0929)	
0.9999856 6.643363e-06
Epoch: [324][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1025 (0.0728)	
0.9999918 6.924196e-06
Epoch: [324][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1861 (0.0701)	
0.9999999 6.541111e-06
loss:  0.0530774906928656 0.051229722433199676
===========>   training    <===========
Epoch: [325][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0605 (0.0605)	
0.9999963 3.966362e-06
===========>   testing    <===========
Epoch: [325][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1482 (0.1482)	
0.9999931 6.8618124e-06
Epoch: [325][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1746 (0.0746)	
0.9999716 6.685993e-06
Epoch: [325][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1309 (0.0688)	
0.99999964 7.2105227e-06
loss:  0.052686220109687376 0.051229722433199676
===========>   training    <===========
Epoch: [326][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0595 (0.0595)	
0.99999154 1.0245012e-05
===========>   testing    <===========
Epoch: [326][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1520 (0.1520)	
0.9999913 1.1230867e-05
Epoch: [326][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0492 (0.0761)	
0.9999764 9.530583e-06
Epoch: [326][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1891 (0.0743)	
0.99999976 1.1406483e-05
loss:  0.05659931163329546 0.051229722433199676
===========>   training    <===========
Epoch: [327][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0724 (0.0724)	
0.99996376 3.6901279e-06
===========>   testing    <===========
Epoch: [327][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0802 (0.0802)	
0.9999702 1.137162e-05
Epoch: [327][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0609 (0.0746)	
0.999944 1.2234257e-05
Epoch: [327][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1646 (0.0715)	
0.9999982 1.3236867e-05
loss:  0.053291978290867514 0.051229722433199676
===========>   training    <===========
Epoch: [328][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0557 (0.0557)	
0.9999782 8.205144e-06
===========>   testing    <===========
Epoch: [328][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0807 (0.0807)	
0.99999833 1.3497512e-05
Epoch: [328][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1091 (0.0802)	
0.99998534 1.55066e-05
Epoch: [328][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1921 (0.0736)	
1.0 8.5245065e-06
loss:  0.05568704570886018 0.051229722433199676
===========>   training    <===========
Epoch: [329][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0649 (0.0649)	
0.99997616 5.5974224e-06
===========>   testing    <===========
Epoch: [329][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1296 (0.1296)	
0.99999547 1.3969139e-05
Epoch: [329][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0656 (0.0810)	
0.9998636 1.1935935e-05
Epoch: [329][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1185 (0.0745)	
0.99999964 1.4400497e-05
loss:  0.05633971220655565 0.051229722433199676
===========>   training    <===========
Epoch: [330][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0732 (0.0732)	
0.99997425 5.335855e-06
===========>   testing    <===========
Epoch: [330][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0754 (0.0754)	
0.9999701 5.3173035e-06
Epoch: [330][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0382 (0.0790)	
0.99985194 6.0303487e-06
Epoch: [330][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.2509 (0.0782)	
0.9999989 6.142065e-06
loss:  0.05966352573858713 0.051229722433199676
===========>   training    <===========
Epoch: [331][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0548 (0.0548)	
0.9999931 5.028772e-06
===========>   testing    <===========
Epoch: [331][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0719 (0.0719)	
0.99997544 1.0326121e-05
Epoch: [331][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0631 (0.0708)	
0.99994683 1.7486876e-05
Epoch: [331][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1072 (0.0683)	
0.999998 1.348215e-05
loss:  0.05347094019214493 0.051229722433199676
===========>   training    <===========
Epoch: [332][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0772 (0.0772)	
0.9999747 8.981544e-06
===========>   testing    <===========
Epoch: [332][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0470 (0.0470)	
0.9999912 8.615036e-06
Epoch: [332][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0308 (0.0684)	
0.9999734 8.249931e-06
Epoch: [332][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1871 (0.0680)	
0.99999535 8.755025e-06
loss:  0.05061467925777818 0.051229722433199676
===========>   training    <===========
Epoch: [333][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0812 (0.0812)	
0.9999776 4.1662156e-06
===========>   testing    <===========
Epoch: [333][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0600 (0.0600)	
0.9999875 8.620147e-06
Epoch: [333][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0419 (0.0714)	
0.9999726 7.2867274e-06
Epoch: [333][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1338 (0.0673)	
0.9999975 8.34202e-06
loss:  0.05059275391182283 0.05061467925777818
===========>   training    <===========
Epoch: [334][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0786 (0.0786)	
0.9999857 4.819415e-06
===========>   testing    <===========
Epoch: [334][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0754 (0.0754)	
0.9999927 1.0839856e-05
Epoch: [334][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0535 (0.0716)	
0.9999677 1.0581212e-05
Epoch: [334][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0788 (0.0677)	
0.9999988 1.27113e-05
loss:  0.05185431994069645 0.05059275391182283
===========>   training    <===========
Epoch: [335][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0540 (0.0540)	
0.99999464 6.393183e-06
===========>   testing    <===========
Epoch: [335][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1309 (0.1309)	
0.9999845 7.4000295e-06
Epoch: [335][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0441 (0.0689)	
0.9999621 8.004808e-06
Epoch: [335][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0738 (0.0665)	
0.99999785 7.829451e-06
loss:  0.05227650577287646 0.05059275391182283
===========>   training    <===========
Epoch: [336][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0605 (0.0605)	
0.9999827 1.3327903e-05
===========>   testing    <===========
Epoch: [336][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1033 (0.1033)	
0.9999839 5.763372e-06
Epoch: [336][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0446 (0.0728)	
0.99997807 5.8008022e-06
Epoch: [336][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1556 (0.0705)	
0.9999939 5.9518006e-06
loss:  0.05409807834673108 0.05059275391182283
===========>   training    <===========
Epoch: [337][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0649 (0.0649)	
0.99999774 4.173167e-06
===========>   testing    <===========
Epoch: [337][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0975 (0.0975)	
0.9999876 4.878746e-06
Epoch: [337][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0397 (0.0715)	
0.9999771 5.085691e-06
Epoch: [337][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.2608 (0.0716)	
0.99999785 4.786939e-06
loss:  0.05421468322830225 0.05059275391182283
===========>   training    <===========
Epoch: [338][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0528 (0.0528)	
0.9999931 1.1173668e-05
===========>   testing    <===========
Epoch: [338][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1043 (0.1043)	
0.9999255 1.4756477e-05
Epoch: [338][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0677 (0.0887)	
0.9999709 8.894422e-06
Epoch: [338][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1191 (0.0822)	
0.9999864 1.2532148e-05
loss:  0.0617090459628693 0.05059275391182283
===========>   training    <===========
Epoch: [339][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0616 (0.0616)	
0.99999464 8.166003e-06
===========>   testing    <===========
Epoch: [339][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1249 (0.1249)	
0.99998116 8.639174e-06
Epoch: [339][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0349 (0.0743)	
0.9999654 6.9062185e-06
Epoch: [339][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1071 (0.0685)	
0.9999914 1.20372015e-05
loss:  0.053064520980861896 0.05059275391182283
===========>   training    <===========
Epoch: [340][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0573 (0.0573)	
0.99998295 8.350968e-06
===========>   testing    <===========
Epoch: [340][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1666 (0.1666)	
0.99998724 8.086769e-06
Epoch: [340][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1039 (0.0876)	
0.9999825 6.532041e-06
Epoch: [340][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0514 (0.0768)	
0.9999989 5.4848006e-06
loss:  0.06061679582422663 0.05059275391182283
===========>   training    <===========
Epoch: [341][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0576 (0.0576)	
0.99998224 5.3219806e-06
===========>   testing    <===========
Epoch: [341][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0473 (0.0473)	
0.9999932 2.1785081e-05
Epoch: [341][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0305 (0.0678)	
0.99997413 9.848523e-06
Epoch: [341][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1660 (0.0660)	
0.9999982 1.5761265e-05
loss:  0.05215490652399957 0.05059275391182283
===========>   training    <===========
Epoch: [342][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0760 (0.0760)	
0.9999877 6.054274e-06
===========>   testing    <===========
Epoch: [342][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0738 (0.0738)	
0.9999771 5.406027e-06
Epoch: [342][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0400 (0.0758)	
0.9999502 5.1374072e-06
Epoch: [342][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.2100 (0.0732)	
0.999998 4.9025416e-06
loss:  0.053469994915207875 0.05059275391182283
===========>   training    <===========
Epoch: [343][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0608 (0.0608)	
0.99991167 5.5480978e-06
===========>   testing    <===========
Epoch: [343][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1239 (0.1239)	
0.9999838 2.6728621e-05
Epoch: [343][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1142 (0.0824)	
0.99997497 2.9570681e-05
Epoch: [343][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0895 (0.0780)	
0.99999917 1.5015995e-05
loss:  0.05873432211906593 0.05059275391182283
===========>   training    <===========
Epoch: [344][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0598 (0.0598)	
0.99997926 3.894924e-06
===========>   testing    <===========
Epoch: [344][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0857 (0.0857)	
0.9999546 4.3699924e-06
Epoch: [344][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0695 (0.0664)	
0.9999511 4.342958e-06
Epoch: [344][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1034 (0.0652)	
0.9999939 4.202128e-06
loss:  0.05144484469097976 0.05059275391182283
===========>   training    <===========
Epoch: [345][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0657 (0.0657)	
0.9999757 6.1199703e-06
===========>   testing    <===========
Epoch: [345][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0999 (0.0999)	
0.9999826 4.1237413e-06
Epoch: [345][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0383 (0.0803)	
0.99998236 4.23873e-06
Epoch: [345][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1100 (0.0750)	
0.99999857 4.246434e-06
loss:  0.05496935864026031 0.05059275391182283
===========>   training    <===========
Epoch: [346][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0515 (0.0515)	
0.9999769 9.347138e-06
===========>   testing    <===========
Epoch: [346][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1441 (0.1441)	
0.99993885 8.317142e-06
Epoch: [346][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0350 (0.0800)	
0.9999757 6.7842448e-06
Epoch: [346][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0931 (0.0742)	
0.99999285 5.8485075e-06
loss:  0.05909933249951704 0.05059275391182283
===========>   training    <===========
Epoch: [347][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0834 (0.0834)	
0.999998 2.5565628e-06
===========>   testing    <===========
Epoch: [347][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0724 (0.0724)	
0.9999808 8.463567e-06
Epoch: [347][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0264 (0.0735)	
0.9999527 9.204701e-06
Epoch: [347][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1299 (0.0711)	
0.9999981 6.289975e-06
loss:  0.05720699705152654 0.05059275391182283
===========>   training    <===========
Epoch: [348][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0715 (0.0715)	
0.9999845 1.0110678e-05
===========>   testing    <===========
Epoch: [348][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0905 (0.0905)	
0.9999826 7.703864e-06
Epoch: [348][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0512 (0.0720)	
0.99997485 9.667806e-06
Epoch: [348][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.2297 (0.0715)	
0.99999356 7.026028e-06
loss:  0.05382320721562106 0.05059275391182283
===========>   training    <===========
Epoch: [349][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0633 (0.0633)	
0.9999968 4.8145644e-06
===========>   testing    <===========
Epoch: [349][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1203 (0.1203)	
0.99997234 5.611822e-06
Epoch: [349][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1896 (0.0739)	
0.9999691 5.7809875e-06
Epoch: [349][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1513 (0.0711)	
0.9999858 5.0933845e-06
loss:  0.0530142618780971 0.05059275391182283
===========>   training    <===========
Epoch: [350][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0696 (0.0696)	
0.9999887 5.89436e-06
===========>   testing    <===========
Epoch: [350][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1575 (0.1575)	
0.9999609 1.2084071e-05
Epoch: [350][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0589 (0.0801)	
0.99995255 9.90808e-06
Epoch: [350][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1564 (0.0745)	
0.99998856 1.196988e-05
loss:  0.05871029678807349 0.05059275391182283
===========>   training    <===========
Epoch: [351][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0729 (0.0729)	
0.9999813 5.853786e-06
===========>   testing    <===========
Epoch: [351][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0644 (0.0644)	
0.99998736 6.6940443e-06
Epoch: [351][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0279 (0.0693)	
0.9999862 5.4274906e-06
Epoch: [351][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0953 (0.0661)	
0.9999962 5.666028e-06
loss:  0.05196977796702962 0.05059275391182283
===========>   training    <===========
Epoch: [352][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0565 (0.0565)	
0.9999871 6.8231493e-06
===========>   testing    <===========
Epoch: [352][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1083 (0.1083)	
0.99998665 9.934289e-06
Epoch: [352][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.3274 (0.0729)	
0.99996567 7.955477e-06
Epoch: [352][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1269 (0.0693)	
0.99999666 7.779257e-06
loss:  0.05494777242056181 0.05059275391182283
===========>   training    <===========
Epoch: [353][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0572 (0.0572)	
0.99999285 6.830891e-06
===========>   testing    <===========
Epoch: [353][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1379 (0.1379)	
0.99997115 5.6388117e-06
Epoch: [353][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0361 (0.0733)	
0.9999591 6.00983e-06
Epoch: [353][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1263 (0.0695)	
0.99999 6.4792375e-06
loss:  0.05437789706413254 0.05059275391182283
===========>   training    <===========
Epoch: [354][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0626 (0.0626)	
0.9999869 3.4822344e-06
===========>   testing    <===========
Epoch: [354][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1810 (0.1810)	
0.9999714 4.642586e-06
Epoch: [354][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0296 (0.0758)	
0.99996173 4.8321263e-06
Epoch: [354][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1454 (0.0701)	
0.9999883 4.9037385e-06
loss:  0.054480860056927205 0.05059275391182283
===========>   training    <===========
Epoch: [355][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0634 (0.0634)	
0.99997604 3.454239e-06
===========>   testing    <===========
Epoch: [355][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1529 (0.1529)	
0.99998283 4.607134e-06
Epoch: [355][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0293 (0.0687)	
0.9999591 5.056399e-06
Epoch: [355][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1257 (0.0670)	
0.9999943 4.828344e-06
loss:  0.05267092294487585 0.05059275391182283
===========>   training    <===========
Epoch: [356][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0526 (0.0526)	
0.9999918 8.118452e-06
===========>   testing    <===========
Epoch: [356][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.3918 (0.3918)	
0.9999852 5.123306e-06
Epoch: [356][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0600 (0.0756)	
0.9999764 5.5117994e-06
Epoch: [356][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0691 (0.0714)	
0.999998 5.5099968e-06
loss:  0.056119492415882766 0.05059275391182283
===========>   training    <===========
Epoch: [357][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0704 (0.0704)	
0.999979 5.8607798e-06
===========>   testing    <===========
Epoch: [357][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1440 (0.1440)	
0.9999925 8.36814e-06
Epoch: [357][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0363 (0.0717)	
0.99996305 1.866477e-05
Epoch: [357][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1020 (0.0687)	
0.99999905 1.12556345e-05
loss:  0.052281070805977436 0.05059275391182283
===========>   training    <===========
Epoch: [358][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0856 (0.0856)	
0.99997973 2.446434e-06
===========>   testing    <===========
Epoch: [358][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0710 (0.0710)	
0.9999894 4.7849944e-06
Epoch: [358][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0615 (0.0694)	
0.9999732 4.860263e-06
Epoch: [358][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1165 (0.0667)	
0.99999905 5.0700783e-06
loss:  0.05334437798715763 0.05059275391182283
===========>   training    <===========
Epoch: [359][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0571 (0.0571)	
0.99999726 8.838564e-06
===========>   testing    <===========
Epoch: [359][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0924 (0.0924)	
0.9999809 5.9377976e-06
Epoch: [359][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0440 (0.0658)	
0.99996233 6.4561996e-06
Epoch: [359][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1334 (0.0627)	
0.99999535 6.2490067e-06
loss:  0.04910942404849328 0.05059275391182283
===========>   training    <===========
Epoch: [360][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0582 (0.0582)	
0.99997735 5.856399e-06
===========>   testing    <===========
Epoch: [360][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0684 (0.0684)	
0.99997556 6.0399143e-06
Epoch: [360][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0289 (0.0697)	
0.9999473 8.488108e-06
Epoch: [360][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1474 (0.0689)	
0.999987 6.625692e-06
loss:  0.052313498308602324 0.04910942404849328
===========>   training    <===========
Epoch: [361][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0479 (0.0479)	
0.999977 7.842767e-06
===========>   testing    <===========
Epoch: [361][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1513 (0.1513)	
0.99999166 6.237575e-06
Epoch: [361][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0280 (0.0718)	
0.9999795 6.3164534e-06
Epoch: [361][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1698 (0.0730)	
0.9999963 5.4053257e-06
loss:  0.052979883616973034 0.04910942404849328
===========>   training    <===========
Epoch: [362][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0685 (0.0685)	
0.9999975 4.1967296e-06
===========>   testing    <===========
Epoch: [362][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1628 (0.1628)	
0.9999871 4.0469176e-06
Epoch: [362][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0376 (0.0660)	
0.9999858 4.3189116e-06
Epoch: [362][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1235 (0.0646)	
0.9999919 4.179364e-06
loss:  0.05022874375415076 0.04910942404849328
===========>   training    <===========
Epoch: [363][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0658 (0.0658)	
0.9999913 5.2402715e-06
===========>   testing    <===========
Epoch: [363][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1919 (0.1919)	
0.9999908 8.392452e-06
Epoch: [363][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1438 (0.0680)	
0.99997854 8.585148e-06
Epoch: [363][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1235 (0.0647)	
0.99999654 1.0279902e-05
loss:  0.05201209666277773 0.04910942404849328
===========>   training    <===========
Epoch: [364][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0625 (0.0625)	
0.99999344 7.765804e-06
===========>   testing    <===========
Epoch: [364][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1002 (0.1002)	
0.9999833 7.7443265e-06
Epoch: [364][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0414 (0.0801)	
0.99996996 7.0905207e-06
Epoch: [364][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.2224 (0.0756)	
0.9999951 6.408102e-06
loss:  0.05346802466389955 0.04910942404849328
===========>   training    <===========
Epoch: [365][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0684 (0.0684)	
0.99999344 5.485496e-06
===========>   testing    <===========
Epoch: [365][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1742 (0.1742)	
0.9999901 4.5971406e-06
Epoch: [365][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1586 (0.0700)	
0.99994075 5.313765e-06
Epoch: [365][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.2236 (0.0669)	
0.9999958 4.9903088e-06
loss:  0.052745061315475406 0.04910942404849328
===========>   training    <===========
Epoch: [366][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0624 (0.0624)	
0.9999863 5.7258344e-06
===========>   testing    <===========
Epoch: [366][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1197 (0.1197)	
0.99999094 5.7623115e-06
Epoch: [366][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0337 (0.0686)	
0.99998164 7.843478e-06
Epoch: [366][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1075 (0.0640)	
0.99999297 6.3708344e-06
loss:  0.04923298441050472 0.04910942404849328
===========>   training    <===========
Epoch: [367][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0595 (0.0595)	
0.99999416 4.6865725e-06
===========>   testing    <===========
Epoch: [367][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0765 (0.0765)	
0.9999887 7.720669e-06
Epoch: [367][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0938 (0.0785)	
0.9999566 7.640036e-06
Epoch: [367][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1668 (0.0733)	
0.9999956 8.29971e-06
loss:  0.0533266592687166 0.04910942404849328
===========>   training    <===========
Epoch: [368][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0609 (0.0609)	
0.9999914 4.492207e-06
===========>   testing    <===========
Epoch: [368][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1276 (0.1276)	
0.99999285 5.4805546e-06
Epoch: [368][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0904 (0.0846)	
0.99997234 5.6427652e-06
Epoch: [368][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1252 (0.0768)	
0.9999974 5.385136e-06
loss:  0.057671215566380996 0.04910942404849328
===========>   training    <===========
Epoch: [369][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0733 (0.0733)	
0.9999933 6.4533924e-06
===========>   testing    <===========
Epoch: [369][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1489 (0.1489)	
0.9999882 5.2825603e-06
Epoch: [369][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0766 (0.0702)	
0.999979 6.370154e-06
Epoch: [369][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0916 (0.0679)	
0.9999981 5.301991e-06
loss:  0.05223759703813824 0.04910942404849328
===========>   training    <===========
Epoch: [370][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0531 (0.0531)	
0.99999034 7.7570185e-06
===========>   testing    <===========
Epoch: [370][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1187 (0.1187)	
0.9999881 6.9337316e-06
Epoch: [370][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0397 (0.0765)	
0.99997556 6.731032e-06
Epoch: [370][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1810 (0.0760)	
0.9999976 6.540899e-06
loss:  0.055391232485048625 0.04910942404849328
===========>   training    <===========
Epoch: [371][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0541 (0.0541)	
0.99999094 5.435887e-06
===========>   testing    <===========
Epoch: [371][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1281 (0.1281)	
0.9999865 7.2050098e-06
Epoch: [371][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0541 (0.0746)	
0.9999895 1.1201419e-05
Epoch: [371][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1084 (0.0714)	
0.9999988 7.039368e-06
loss:  0.052154748885056335 0.04910942404849328
===========>   training    <===========
Epoch: [372][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0500 (0.0500)	
0.9999927 1.00274165e-05
===========>   testing    <===========
Epoch: [372][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0668 (0.0668)	
0.99998236 2.9415291e-06
Epoch: [372][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0329 (0.0689)	
0.9999504 3.6590657e-06
Epoch: [372][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0853 (0.0663)	
0.99998665 3.2740913e-06
loss:  0.04976618144873246 0.04910942404849328
===========>   training    <===========
Epoch: [373][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0631 (0.0631)	
0.9999846 3.5272014e-06
===========>   testing    <===========
Epoch: [373][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1022 (0.1022)	
0.99998236 3.1272184e-06
Epoch: [373][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0337 (0.0688)	
0.99995744 3.4878612e-06
Epoch: [373][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0966 (0.0651)	
0.9999858 3.4146246e-06
loss:  0.050257919233932746 0.04910942404849328
===========>   training    <===========
Epoch: [374][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0658 (0.0658)	
0.99996793 5.3541035e-06
===========>   testing    <===========
Epoch: [374][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0901 (0.0901)	
0.9999827 4.641652e-06
Epoch: [374][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0267 (0.0763)	
0.9999715 8.244795e-06
Epoch: [374][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1598 (0.0729)	
0.99998426 6.9319326e-06
loss:  0.055380640259722336 0.04910942404849328
===========>   training    <===========
Epoch: [375][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0678 (0.0678)	
0.9999945 5.8788937e-06
===========>   testing    <===========
Epoch: [375][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1050 (0.1050)	
0.9999858 4.824713e-06
Epoch: [375][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0344 (0.0740)	
0.9999639 5.226307e-06
Epoch: [375][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1235 (0.0704)	
0.99998856 5.1215375e-06
loss:  0.05345128640036323 0.04910942404849328
===========>   training    <===========
Epoch: [376][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0686 (0.0686)	
0.99997747 7.465646e-06
===========>   testing    <===========
Epoch: [376][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0641 (0.0641)	
0.99998784 4.166208e-06
Epoch: [376][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0318 (0.0710)	
0.9999765 4.9476316e-06
Epoch: [376][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1172 (0.0683)	
0.99999344 5.0825347e-06
loss:  0.0508855400403615 0.04910942404849328
===========>   training    <===========
Epoch: [377][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0606 (0.0606)	
0.9999833 4.5794627e-06
===========>   testing    <===========
Epoch: [377][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1220 (0.1220)	
0.99998796 4.5405504e-06
Epoch: [377][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0321 (0.0769)	
0.9999697 4.99668e-06
Epoch: [377][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1092 (0.0723)	
0.9999964 4.7797585e-06
loss:  0.05419061995485053 0.04910942404849328
===========>   training    <===========
Epoch: [378][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0576 (0.0576)	
0.9999651 5.91748e-06
===========>   testing    <===========
Epoch: [378][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1452 (0.1452)	
0.9999763 5.2808878e-06
Epoch: [378][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0314 (0.0710)	
0.99993396 5.7485295e-06
Epoch: [378][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1015 (0.0689)	
0.99999547 5.4243606e-06
loss:  0.05299773441300826 0.04910942404849328
===========>   training    <===========
Epoch: [379][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0538 (0.0538)	
0.9999871 1.0222262e-05
===========>   testing    <===========
Epoch: [379][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0972 (0.0972)	
0.99997425 4.2260644e-06
Epoch: [379][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0307 (0.0661)	
0.99994683 4.4238404e-06
Epoch: [379][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0713 (0.0633)	
0.9999876 4.2696006e-06
loss:  0.048949829984169635 0.04910942404849328
===========>   training    <===========
Epoch: [380][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0579 (0.0579)	
0.999979 5.0392523e-06
===========>   testing    <===========
Epoch: [380][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0905 (0.0905)	
0.999979 5.560572e-06
Epoch: [380][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0262 (0.0678)	
0.999949 6.205109e-06
Epoch: [380][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0702 (0.0665)	
0.9999845 5.874814e-06
loss:  0.05251278153351746 0.048949829984169635
===========>   training    <===========
Epoch: [381][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0564 (0.0564)	
0.9999802 4.74658e-06
===========>   testing    <===========
Epoch: [381][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.1230 (0.1230)	
0.9999821 5.101123e-06
Epoch: [381][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0301 (0.0711)	
0.99996066 5.522596e-06
Epoch: [381][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.1175 (0.0665)	
0.9999993 5.389323e-06
loss:  0.05031768263842351 0.048949829984169635
===========>   training    <===========
Epoch: [382][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0696 (0.0696)	
0.9999994 6.8365607e-06
===========>   testing    <===========
Epoch: [382][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0877 (0.0877)	
0.9999876 9.659899e-06
Epoch: [382][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0354 (0.0696)	
0.99997985 1.2305026e-05
Epoch: [382][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0504 (0.0661)	
0.9999975 1.2928353e-05
loss:  0.05035690571707996 0.048949829984169635
===========>   training    <===========
Epoch: [383][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0712 (0.0712)	
0.99999726 3.1100012e-06
===========>   testing    <===========
Epoch: [383][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0741 (0.0741)	
0.99998534 9.84426e-06
Epoch: [383][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0351 (0.0706)	
0.99998236 1.1061644e-05
Epoch: [383][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.1029 (0.0648)	
0.9999964 1.02511785e-05
loss:  0.049401231312214855 0.048949829984169635
===========>   training    <===========
Epoch: [384][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0661 (0.0661)	
0.99998343 2.4679205e-06
===========>   testing    <===========
Epoch: [384][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0675 (0.0675)	
0.99999 6.66412e-06
Epoch: [384][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0279 (0.0771)	
0.9999825 8.053844e-06
Epoch: [384][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0569 (0.0685)	
0.99999714 6.992052e-06
loss:  0.049917542601614295 0.048949829984169635
===========>   training    <===========
Epoch: [385][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0649 (0.0649)	
0.99996185 5.0808626e-06
===========>   testing    <===========
Epoch: [385][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.1273 (0.1273)	
0.99998593 4.6495024e-06
Epoch: [385][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0385 (0.0695)	
0.9999577 5.232057e-06
Epoch: [385][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.1035 (0.0641)	
0.9999949 4.641263e-06
loss:  0.05027147666371712 0.048949829984169635
===========>   training    <===========
Epoch: [386][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0642 (0.0642)	
0.9999906 7.1609015e-06
===========>   testing    <===========
Epoch: [386][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0790 (0.0790)	
0.99996054 5.064908e-06
Epoch: [386][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0320 (0.0679)	
0.9998734 4.970531e-06
Epoch: [386][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0907 (0.0662)	
0.9999689 5.044767e-06
loss:  0.05186823226871262 0.048949829984169635
===========>   training    <===========
Epoch: [387][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0588 (0.0588)	
0.99997747 3.7901868e-06
===========>   testing    <===========
Epoch: [387][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0859 (0.0859)	
0.99999225 9.534874e-06
Epoch: [387][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0354 (0.0700)	
0.9999913 1.2163061e-05
Epoch: [387][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.1345 (0.0703)	
0.9999945 9.926504e-06
loss:  0.05235892472032755 0.048949829984169635
===========>   training    <===========
Epoch: [388][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0758 (0.0758)	
0.99998784 7.1174295e-06
===========>   testing    <===========
Epoch: [388][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0696 (0.0696)	
0.9999907 8.159574e-06
Epoch: [388][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.1307 (0.0798)	
0.9999678 9.375715e-06
Epoch: [388][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0602 (0.0726)	
0.99999917 8.720427e-06
loss:  0.055657275086787195 0.048949829984169635
===========>   training    <===========
Epoch: [389][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0624 (0.0624)	
0.9999683 8.782788e-06
===========>   testing    <===========
Epoch: [389][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.1186 (0.1186)	
0.99996173 7.699772e-06
Epoch: [389][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0712 (0.0778)	
0.99994767 9.751123e-06
Epoch: [389][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.1380 (0.0731)	
0.9999845 8.869249e-06
loss:  0.056155284664955674 0.048949829984169635
===========>   training    <===========
Epoch: [390][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0695 (0.0695)	
0.99998057 5.316984e-06
===========>   testing    <===========
Epoch: [390][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0634 (0.0634)	
0.9999831 6.984055e-06
Epoch: [390][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0896 (0.0683)	
0.9999559 8.54496e-06
Epoch: [390][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0453 (0.0644)	
0.9999944 7.0766046e-06
loss:  0.04915404297266168 0.048949829984169635
===========>   training    <===========
Epoch: [391][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0608 (0.0608)	
0.999987 1.0252664e-05
===========>   testing    <===========
Epoch: [391][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0863 (0.0863)	
0.99996793 6.34512e-06
Epoch: [391][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0447 (0.0661)	
0.9999596 7.1140635e-06
Epoch: [391][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.1009 (0.0639)	
0.9999912 5.984266e-06
loss:  0.04903993300117737 0.048949829984169635
===========>   training    <===========
Epoch: [392][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0509 (0.0509)	
0.9999821 2.8082597e-05
===========>   testing    <===========
Epoch: [392][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.1214 (0.1214)	
0.9999728 5.833912e-06
Epoch: [392][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.1758 (0.0698)	
0.999974 5.906554e-06
Epoch: [392][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0642 (0.0649)	
0.99999535 5.573516e-06
loss:  0.048330197045782786 0.048949829984169635
===========>   training    <===========
Epoch: [393][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0691 (0.0691)	
0.99999976 5.5185155e-06
===========>   testing    <===========
Epoch: [393][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0665 (0.0665)	
0.99998796 8.576261e-06
Epoch: [393][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0790 (0.0793)	
0.9999738 8.905412e-06
Epoch: [393][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0896 (0.0754)	
0.99999857 8.23279e-06
loss:  0.05401468292196587 0.048330197045782786
===========>   training    <===========
Epoch: [394][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0535 (0.0535)	
0.9999871 1.2411911e-05
===========>   testing    <===========
Epoch: [394][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0978 (0.0978)	
0.99997866 2.4544463e-05
Epoch: [394][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0580 (0.0730)	
0.99998 1.7534636e-05
Epoch: [394][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0760 (0.0667)	
0.99999774 1.2164824e-05
loss:  0.049163985581626046 0.048330197045782786
===========>   training    <===========
Epoch: [395][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0544 (0.0544)	
0.9999753 6.054621e-06
===========>   testing    <===========
Epoch: [395][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.1196 (0.1196)	
0.99998856 6.395171e-06
Epoch: [395][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0782 (0.0730)	
0.99996257 6.2501276e-06
Epoch: [395][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0634 (0.0681)	
0.99999595 6.082226e-06
loss:  0.05035973274364203 0.048330197045782786
===========>   training    <===========
Epoch: [396][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0573 (0.0573)	
0.9999887 8.468185e-06
===========>   testing    <===========
Epoch: [396][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.1158 (0.1158)	
0.99998236 6.237099e-06
Epoch: [396][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0540 (0.0665)	
0.99996257 6.6644247e-06
Epoch: [396][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0793 (0.0657)	
0.9999902 6.522137e-06
loss:  0.04997297765005526 0.048330197045782786
===========>   training    <===========
Epoch: [397][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0544 (0.0544)	
0.99998033 5.478297e-06
===========>   testing    <===========
Epoch: [397][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.1107 (0.1107)	
0.9999713 5.8630494e-06
Epoch: [397][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0525 (0.0647)	
0.9999304 6.0692814e-06
Epoch: [397][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.1459 (0.0633)	
0.99998546 4.9057594e-06
loss:  0.047843498863911926 0.048330197045782786
===========>   training    <===========
Epoch: [398][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0676 (0.0676)	
0.99998236 5.9634026e-06
===========>   testing    <===========
Epoch: [398][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.1249 (0.1249)	
0.99997556 6.913513e-06
Epoch: [398][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0384 (0.0692)	
0.9998852 7.1935574e-06
Epoch: [398][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0599 (0.0632)	
0.99998987 6.2579525e-06
loss:  0.047620325085372284 0.047843498863911926
===========>   training    <===========
Epoch: [399][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0722 (0.0722)	
0.9999883 1.3506126e-05
===========>   testing    <===========
Epoch: [399][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.1215 (0.1215)	
0.9999726 5.621142e-06
Epoch: [399][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0294 (0.0714)	
0.9999809 7.729591e-06
Epoch: [399][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.1340 (0.0674)	
0.9999962 5.2280816e-06
loss:  0.050136191497139104 0.047620325085372284
===========>   training    <===========
Epoch: [400][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0624 (0.0624)	
0.999985 7.777144e-06
===========>   testing    <===========
Epoch: [400][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0830 (0.0830)	
0.99998736 9.211234e-06
Epoch: [400][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0452 (0.0698)	
0.9999796 1.4639577e-05
Epoch: [400][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1420 (0.0690)	
0.9999988 9.011958e-06
loss:  0.05032639863852961 0.047620325085372284
===========>   training    <===========
Epoch: [401][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0601 (0.0601)	
0.999984 4.258324e-06
===========>   testing    <===========
Epoch: [401][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1444 (0.1444)	
0.9999831 5.8263167e-06
Epoch: [401][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1171 (0.0735)	
0.9999416 6.9180837e-06
Epoch: [401][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0938 (0.0685)	
0.99999917 5.495471e-06
loss:  0.05481278795949829 0.047620325085372284
===========>   training    <===========
Epoch: [402][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0507 (0.0507)	
0.99999595 5.394187e-06
===========>   testing    <===========
Epoch: [402][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0929 (0.0929)	
0.99997926 4.9857704e-06
Epoch: [402][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1229 (0.0682)	
0.9999672 6.1316778e-06
Epoch: [402][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1342 (0.0669)	
0.9999962 4.7860303e-06
loss:  0.0514414593433663 0.047620325085372284
===========>   training    <===========
Epoch: [403][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0585 (0.0585)	
0.99999046 3.1445309e-06
===========>   testing    <===========
Epoch: [403][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0469 (0.0469)	
0.9999856 9.51823e-06
Epoch: [403][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0288 (0.0733)	
0.9999778 1.0088854e-05
Epoch: [403][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.2028 (0.0701)	
0.99999833 7.654213e-06
loss:  0.050363765858160714 0.047620325085372284
===========>   training    <===========
Epoch: [404][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0836 (0.0836)	
0.9999857 3.0274193e-06
===========>   testing    <===========
Epoch: [404][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0657 (0.0657)	
0.9999776 1.3818488e-05
Epoch: [404][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0221 (0.0715)	
0.99994636 1.4565742e-05
Epoch: [404][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0990 (0.0651)	
0.9999881 7.747984e-06
loss:  0.049831243318884444 0.047620325085372284
===========>   training    <===========
Epoch: [405][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0628 (0.0628)	
0.99998164 6.1825212e-06
===========>   testing    <===========
Epoch: [405][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1061 (0.1061)	
0.9999809 7.4650625e-06
Epoch: [405][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0423 (0.0675)	
0.99992096 8.298032e-06
Epoch: [405][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1426 (0.0650)	
0.999982 6.32998e-06
loss:  0.0502627427730854 0.047620325085372284
===========>   training    <===========
Epoch: [406][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0493 (0.0493)	
0.9999888 7.847788e-06
===========>   testing    <===========
Epoch: [406][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1035 (0.1035)	
0.99998665 1.470927e-05
Epoch: [406][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0226 (0.0656)	
0.9999515 1.2003602e-05
Epoch: [406][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1146 (0.0635)	
0.99999034 1.0799768e-05
loss:  0.049083802823698286 0.047620325085372284
===========>   training    <===========
Epoch: [407][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0593 (0.0593)	
0.9999764 5.49184e-06
===========>   testing    <===========
Epoch: [407][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0965 (0.0965)	
0.99999416 8.449897e-06
Epoch: [407][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0259 (0.0781)	
0.99996495 8.7286635e-06
Epoch: [407][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.2806 (0.0734)	
0.9999987 7.0987808e-06
loss:  0.04968729872012112 0.047620325085372284
===========>   training    <===========
Epoch: [408][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0698 (0.0698)	
0.999979 6.478416e-06
===========>   testing    <===========
Epoch: [408][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1423 (0.1423)	
0.9999869 6.7775254e-06
Epoch: [408][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0406 (0.0748)	
0.9999696 7.517788e-06
Epoch: [408][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1275 (0.0689)	
0.99999046 6.1449305e-06
loss:  0.05220942940199835 0.047620325085372284
===========>   training    <===========
Epoch: [409][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0558 (0.0558)	
0.99996305 7.821973e-06
===========>   testing    <===========
Epoch: [409][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0774 (0.0774)	
0.9999771 8.407745e-06
Epoch: [409][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0454 (0.0704)	
0.9999713 7.685799e-06
Epoch: [409][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1455 (0.0655)	
0.99998605 6.418426e-06
loss:  0.047495832812192496 0.047620325085372284
===========>   training    <===========
Epoch: [410][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0541 (0.0541)	
0.99999046 5.6459407e-06
===========>   testing    <===========
Epoch: [410][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1002 (0.1002)	
0.9999808 6.0452853e-06
Epoch: [410][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0304 (0.0705)	
0.99997544 6.4777423e-06
Epoch: [410][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0685 (0.0664)	
0.9999881 6.357773e-06
loss:  0.0507741091808771 0.047495832812192496
===========>   training    <===========
Epoch: [411][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0899 (0.0899)	
0.999969 4.41079e-06
===========>   testing    <===========
Epoch: [411][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1144 (0.1144)	
0.9999778 4.7105314e-06
Epoch: [411][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0241 (0.0719)	
0.99998176 4.9761275e-06
Epoch: [411][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1190 (0.0660)	
0.99998903 4.3221708e-06
loss:  0.04847906425886539 0.047495832812192496
===========>   training    <===========
Epoch: [412][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0616 (0.0616)	
0.9999809 1.0448119e-05
===========>   testing    <===========
Epoch: [412][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0644 (0.0644)	
0.99998355 6.097698e-06
Epoch: [412][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0209 (0.0753)	
0.99998164 6.3058906e-06
Epoch: [412][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1998 (0.0710)	
0.9999919 5.7096663e-06
loss:  0.052251444429656235 0.047495832812192496
===========>   training    <===========
Epoch: [413][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0607 (0.0607)	
0.9999944 7.287881e-06
===========>   testing    <===========
Epoch: [413][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1333 (0.1333)	
0.9999895 6.44002e-06
Epoch: [413][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0367 (0.0716)	
0.99997425 8.176757e-06
Epoch: [413][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0622 (0.0648)	
0.99999285 6.188975e-06
loss:  0.04872797448404831 0.047495832812192496
===========>   training    <===========
Epoch: [414][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0565 (0.0565)	
0.99999094 5.8803516e-06
===========>   testing    <===========
Epoch: [414][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0631 (0.0631)	
0.99998975 5.8489422e-06
Epoch: [414][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0654 (0.0694)	
0.9999845 7.1697914e-06
Epoch: [414][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0641 (0.0637)	
0.99999857 5.6460594e-06
loss:  0.048478937032176095 0.047495832812192496
===========>   training    <===========
Epoch: [415][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0687 (0.0687)	
0.99997604 6.0084662e-06
===========>   testing    <===========
Epoch: [415][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0594 (0.0594)	
0.9999925 5.557095e-06
Epoch: [415][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0483 (0.0832)	
0.9999875 5.8861924e-06
Epoch: [415][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1333 (0.0725)	
0.9999994 5.4851876e-06
loss:  0.05102219630030491 0.047495832812192496
===========>   training    <===========
Epoch: [416][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0558 (0.0558)	
0.99998856 7.686884e-06
===========>   testing    <===========
Epoch: [416][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0511 (0.0511)	
0.999967 5.177236e-06
Epoch: [416][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0263 (0.0724)	
0.99997354 5.4488214e-06
Epoch: [416][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1118 (0.0661)	
0.9999863 5.2078035e-06
loss:  0.049145138568690294 0.047495832812192496
===========>   training    <===========
Epoch: [417][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0613 (0.0613)	
0.9999945 3.8967073e-06
===========>   testing    <===========
Epoch: [417][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0486 (0.0486)	
0.9999856 5.047332e-06
Epoch: [417][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0299 (0.0802)	
0.99997497 5.7314287e-06
Epoch: [417][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0959 (0.0708)	
0.9999883 5.6337535e-06
loss:  0.05047013417695101 0.047495832812192496
===========>   training    <===========
Epoch: [418][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0541 (0.0541)	
0.9999807 5.7155885e-06
===========>   testing    <===========
Epoch: [418][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0772 (0.0772)	
0.9999862 1.0046215e-05
Epoch: [418][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0684 (0.0735)	
0.9999577 7.798474e-06
Epoch: [418][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0715 (0.0652)	
0.9999852 6.107644e-06
loss:  0.04720467373107162 0.047495832812192496
===========>   training    <===========
Epoch: [419][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0618 (0.0618)	
0.9999887 4.189404e-06
===========>   testing    <===========
Epoch: [419][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0416 (0.0416)	
0.99998856 5.5156065e-06
Epoch: [419][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1705 (0.0780)	
0.9999404 6.6776324e-06
Epoch: [419][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0942 (0.0687)	
0.9999863 5.2919795e-06
loss:  0.049940261489041626 0.04720467373107162
===========>   training    <===========
Epoch: [420][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0548 (0.0548)	
0.9999949 7.631501e-06
===========>   testing    <===========
Epoch: [420][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0437 (0.0437)	
0.99998844 4.212585e-06
Epoch: [420][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.3631 (0.0725)	
0.9999615 5.88932e-06
Epoch: [420][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.1125 (0.0660)	
0.99999 4.393824e-06
loss:  0.050719791086370924 0.04720467373107162
===========>   training    <===========
Epoch: [421][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0543 (0.0543)	
0.999979 1.2764799e-05
===========>   testing    <===========
Epoch: [421][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0900 (0.0900)	
0.99998033 3.6646388e-06
Epoch: [421][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.3046 (0.0710)	
0.999943 4.768176e-06
Epoch: [421][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0806 (0.0655)	
0.99998534 3.675044e-06
loss:  0.05057158784702298 0.04720467373107162
===========>   training    <===========
Epoch: [422][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0528 (0.0528)	
0.99997985 4.213549e-06
===========>   testing    <===========
Epoch: [422][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0997 (0.0997)	
0.9999664 4.092045e-06
Epoch: [422][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0572 (0.0689)	
0.99995625 4.281405e-06
Epoch: [422][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0972 (0.0643)	
0.9999795 5.144663e-06
loss:  0.048684989110228005 0.04720467373107162
===========>   training    <===========
Epoch: [423][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0485 (0.0485)	
0.9999869 6.025072e-06
===========>   testing    <===========
Epoch: [423][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0413 (0.0413)	
0.99998784 9.5084315e-06
Epoch: [423][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0606 (0.0721)	
0.99995744 8.948875e-06
Epoch: [423][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.1782 (0.0676)	
0.9999906 7.7974555e-06
loss:  0.04938287198003688 0.04720467373107162
===========>   training    <===========
Epoch: [424][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0563 (0.0563)	
0.99998665 4.3190144e-06
===========>   testing    <===========
Epoch: [424][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0512 (0.0512)	
0.99998915 7.2507437e-06
Epoch: [424][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0262 (0.0706)	
0.99994445 7.2338016e-06
Epoch: [424][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0905 (0.0668)	
0.99998844 7.656243e-06
loss:  0.0488658780995489 0.04720467373107162
===========>   training    <===========
Epoch: [425][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0531 (0.0531)	
0.99998665 3.6518807e-06
===========>   testing    <===========
Epoch: [425][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0878 (0.0878)	
0.99999166 4.01165e-06
Epoch: [425][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0321 (0.0700)	
0.9999769 4.074098e-06
Epoch: [425][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0676 (0.0641)	
0.9999982 3.7067407e-06
loss:  0.047517116750971256 0.04720467373107162
===========>   training    <===========
Epoch: [426][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0598 (0.0598)	
0.9999895 2.3388668e-05
===========>   testing    <===========
Epoch: [426][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0895 (0.0895)	
0.9999877 5.376597e-06
Epoch: [426][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0315 (0.0727)	
0.99996495 5.9099966e-06
Epoch: [426][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.1379 (0.0674)	
0.99999094 4.7906974e-06
loss:  0.04792063584765838 0.04720467373107162
===========>   training    <===========
Epoch: [427][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0619 (0.0619)	
0.99998474 5.274516e-06
===========>   testing    <===========
Epoch: [427][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0401 (0.0401)	
0.9999924 7.2522375e-06
Epoch: [427][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0394 (0.0681)	
0.9999691 7.653191e-06
Epoch: [427][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.1314 (0.0636)	
0.99999595 6.8958198e-06
loss:  0.04641309969177421 0.04720467373107162
===========>   training    <===========
Epoch: [428][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0553 (0.0553)	
0.9999876 5.9038284e-06
===========>   testing    <===========
Epoch: [428][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0505 (0.0505)	
0.99999 5.971461e-06
Epoch: [428][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0349 (0.0673)	
0.99998796 6.1058677e-06
Epoch: [428][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0923 (0.0648)	
0.99999785 5.67775e-06
loss:  0.050164051123693376 0.04641309969177421
===========>   training    <===========
Epoch: [429][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0627 (0.0627)	
0.9999919 4.3492455e-06
===========>   testing    <===========
Epoch: [429][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0578 (0.0578)	
0.9999901 4.5584957e-06
Epoch: [429][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0300 (0.0694)	
0.9999927 4.5338174e-06
Epoch: [429][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0917 (0.0640)	
0.9999995 5.3080416e-06
loss:  0.04762433500573837 0.04641309969177421
===========>   training    <===========
Epoch: [430][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0508 (0.0508)	
0.9999962 7.3487117e-06
===========>   testing    <===========
Epoch: [430][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0708 (0.0708)	
0.9999877 4.8947445e-06
Epoch: [430][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0325 (0.0674)	
0.9999703 5.7059756e-06
Epoch: [430][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.1176 (0.0636)	
0.99999535 5.7714137e-06
loss:  0.04834132775998601 0.04641309969177421
===========>   training    <===========
Epoch: [431][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0536 (0.0536)	
0.999984 9.112711e-06
===========>   testing    <===========
Epoch: [431][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0581 (0.0581)	
0.99999225 3.4788818e-06
Epoch: [431][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0243 (0.0669)	
0.9999659 3.3703438e-06
Epoch: [431][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.1133 (0.0614)	
0.99999046 3.786509e-06
loss:  0.046199283231262434 0.04641309969177421
===========>   training    <===========
Epoch: [432][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0474 (0.0474)	
0.9999801 8.580319e-06
===========>   testing    <===========
Epoch: [432][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0521 (0.0521)	
0.9999927 3.7008665e-06
Epoch: [432][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0249 (0.0669)	
0.99996674 3.6732463e-06
Epoch: [432][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.1115 (0.0634)	
0.99998796 4.6147898e-06
loss:  0.04751860313170342 0.046199283231262434
===========>   training    <===========
Epoch: [433][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0734 (0.0734)	
0.9999976 5.546622e-06
===========>   testing    <===========
Epoch: [433][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0554 (0.0554)	
0.99997747 3.2717408e-06
Epoch: [433][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0279 (0.0695)	
0.9998654 3.317307e-06
Epoch: [433][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0801 (0.0645)	
0.99997973 3.7886473e-06
loss:  0.0487887876257066 0.046199283231262434
===========>   training    <===========
Epoch: [434][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0649 (0.0649)	
0.999985 2.4825013e-06
===========>   testing    <===========
Epoch: [434][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.1091 (0.1091)	
0.9999893 3.1370696e-06
Epoch: [434][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0277 (0.0702)	
0.9999794 3.097389e-06
Epoch: [434][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0961 (0.0650)	
0.99999285 3.6304314e-06
loss:  0.05080744100882817 0.046199283231262434
===========>   training    <===========
Epoch: [435][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0723 (0.0723)	
0.99999857 3.3840804e-06
===========>   testing    <===========
Epoch: [435][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0634 (0.0634)	
0.9999819 3.8261483e-06
Epoch: [435][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0357 (0.0659)	
0.999964 3.9804245e-06
Epoch: [435][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.2012 (0.0641)	
0.99999344 4.553994e-06
loss:  0.04797432945100699 0.046199283231262434
===========>   training    <===========
Epoch: [436][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0595 (0.0595)	
0.9999906 1.2042518e-05
===========>   testing    <===========
Epoch: [436][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0966 (0.0966)	
0.9999906 9.428339e-06
Epoch: [436][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0229 (0.0661)	
0.99995995 8.9426385e-06
Epoch: [436][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0941 (0.0623)	
0.9999976 1.0255168e-05
loss:  0.04802819400309921 0.046199283231262434
===========>   training    <===========
Epoch: [437][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0599 (0.0599)	
0.9999881 9.272197e-06
===========>   testing    <===========
Epoch: [437][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0662 (0.0662)	
0.9999869 3.4477591e-06
Epoch: [437][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0228 (0.0650)	
0.9999281 4.4849558e-06
Epoch: [437][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0804 (0.0640)	
0.9999927 5.330484e-06
loss:  0.04764979475834763 0.046199283231262434
===========>   training    <===========
Epoch: [438][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0593 (0.0593)	
0.9999778 3.6058982e-06
===========>   testing    <===========
Epoch: [438][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0520 (0.0520)	
0.99998677 6.133929e-06
Epoch: [438][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0302 (0.0666)	
0.99997616 6.4098313e-06
Epoch: [438][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.1365 (0.0639)	
0.9999958 9.713238e-06
loss:  0.04761135130187644 0.046199283231262434
===========>   training    <===========
Epoch: [439][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0615 (0.0615)	
0.99998546 5.784042e-06
===========>   testing    <===========
Epoch: [439][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0588 (0.0588)	
0.99998033 4.329584e-06
Epoch: [439][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0772 (0.0683)	
0.9999453 4.426453e-06
Epoch: [439][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0461 (0.0637)	
0.9999882 4.194469e-06
loss:  0.047398577775782935 0.046199283231262434
===========>   training    <===========
Epoch: [440][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0622 (0.0622)	
0.9999778 4.4439475e-06
===========>   testing    <===========
Epoch: [440][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0430 (0.0430)	
0.9999894 7.61205e-06
Epoch: [440][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.1071 (0.0690)	
0.9999796 8.028384e-06
Epoch: [440][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.1586 (0.0656)	
0.9999918 8.0987475e-06
loss:  0.04781475022006898 0.046199283231262434
===========>   training    <===========
Epoch: [441][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0536 (0.0536)	
0.9999964 1.1326488e-05
===========>   testing    <===========
Epoch: [441][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0821 (0.0821)	
0.9999678 4.3786695e-06
Epoch: [441][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.1369 (0.0705)	
0.99995553 4.564634e-06
Epoch: [441][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0603 (0.0663)	
0.9999707 4.422883e-06
loss:  0.04929718402076766 0.046199283231262434
===========>   training    <===========
Epoch: [442][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0560 (0.0560)	
0.99997807 7.1760846e-06
===========>   testing    <===========
Epoch: [442][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0518 (0.0518)	
0.9999788 9.206738e-06
Epoch: [442][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.1421 (0.0727)	
0.99995697 1.2337303e-05
Epoch: [442][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.1432 (0.0693)	
0.9999901 8.649115e-06
loss:  0.05091488826394086 0.046199283231262434
===========>   training    <===========
Epoch: [443][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0497 (0.0497)	
0.999974 3.961784e-06
===========>   testing    <===========
Epoch: [443][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0474 (0.0474)	
0.99998724 3.2101402e-06
Epoch: [443][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0278 (0.0688)	
0.9999702 3.9535635e-06
Epoch: [443][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0728 (0.0653)	
0.99999034 4.536975e-06
loss:  0.04731164214247008 0.046199283231262434
===========>   training    <===========
Epoch: [444][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0504 (0.0504)	
0.9999918 4.984477e-06
===========>   testing    <===========
Epoch: [444][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0698 (0.0698)	
0.999984 3.448726e-06
Epoch: [444][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0258 (0.0612)	
0.9999784 3.6641427e-06
Epoch: [444][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.1118 (0.0592)	
0.99998546 3.322043e-06
loss:  0.04500069424972275 0.046199283231262434
===========>   training    <===========
Epoch: [445][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0496 (0.0496)	
0.9999883 6.0312113e-06
===========>   testing    <===========
Epoch: [445][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0771 (0.0771)	
0.99997973 2.9439148e-06
Epoch: [445][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0203 (0.0679)	
0.99996614 3.135909e-06
Epoch: [445][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.2097 (0.0659)	
0.9999833 2.6410844e-06
loss:  0.0480211147164783 0.04500069424972275
===========>   training    <===========
Epoch: [446][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0539 (0.0539)	
0.9999671 2.6780895e-06
===========>   testing    <===========
Epoch: [446][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0517 (0.0517)	
0.9999856 7.72573e-06
Epoch: [446][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0199 (0.0667)	
0.9999728 8.552942e-06
Epoch: [446][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.1964 (0.0661)	
0.99998915 6.8700624e-06
loss:  0.04734976682113534 0.04500069424972275
===========>   training    <===========
Epoch: [447][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0556 (0.0556)	
0.99999213 7.385421e-06
===========>   testing    <===========
Epoch: [447][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0526 (0.0526)	
0.99998116 4.311035e-06
Epoch: [447][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0270 (0.0662)	
0.99997044 5.307161e-06
Epoch: [447][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.1337 (0.0644)	
0.9999883 4.4495705e-06
loss:  0.0469154450866176 0.04500069424972275
===========>   training    <===========
Epoch: [448][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0515 (0.0515)	
0.9999796 5.410886e-06
===========>   testing    <===========
Epoch: [448][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0455 (0.0455)	
0.9999827 8.60391e-06
Epoch: [448][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0250 (0.0679)	
0.9999658 8.952887e-06
Epoch: [448][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.1222 (0.0662)	
0.9999893 8.900463e-06
loss:  0.04746107302218505 0.04500069424972275
===========>   training    <===========
Epoch: [449][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0510 (0.0510)	
0.99997723 4.6356713e-06
===========>   testing    <===========
Epoch: [449][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0492 (0.0492)	
0.999979 1.1530905e-05
Epoch: [449][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0659 (0.0628)	
0.99996626 1.25432425e-05
Epoch: [449][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.1946 (0.0642)	
0.9999809 1.8678287e-05
loss:  0.0466958982933362 0.04500069424972275
===========>   training    <===========
Epoch: [450][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0437 (0.0437)	
0.9999751 4.6824666e-06
===========>   testing    <===========
Epoch: [450][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0757 (0.0757)	
0.99998486 7.703217e-06
Epoch: [450][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0302 (0.0706)	
0.9999844 8.661993e-06
Epoch: [450][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0783 (0.0665)	
0.9999918 9.2112605e-06
loss:  0.04837052402656339 0.04500069424972275
===========>   training    <===========
Epoch: [451][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0668 (0.0668)	
0.9999869 4.643804e-06
===========>   testing    <===========
Epoch: [451][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0465 (0.0465)	
0.9999896 5.706449e-06
Epoch: [451][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0266 (0.0698)	
0.99996877 6.3451016e-06
Epoch: [451][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0775 (0.0645)	
0.9999913 5.8281785e-06
loss:  0.046698990358743475 0.04500069424972275
===========>   training    <===========
Epoch: [452][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0612 (0.0612)	
0.99997246 6.731815e-06
===========>   testing    <===========
Epoch: [452][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0837 (0.0837)	
0.9999895 9.128281e-06
Epoch: [452][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0318 (0.0809)	
0.99997866 9.48284e-06
Epoch: [452][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.1741 (0.0738)	
0.99998903 1.0374449e-05
loss:  0.051198161740743764 0.04500069424972275
===========>   training    <===========
Epoch: [453][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0523 (0.0523)	
0.9999715 2.6057035e-06
===========>   testing    <===========
Epoch: [453][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0853 (0.0853)	
0.9999844 5.4373545e-06
Epoch: [453][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0318 (0.0677)	
0.99996877 5.589623e-06
Epoch: [453][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.1106 (0.0651)	
0.9999925 5.133851e-06
loss:  0.047210077859821786 0.04500069424972275
===========>   training    <===========
Epoch: [454][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0695 (0.0695)	
0.99997723 1.1697826e-06
===========>   testing    <===========
Epoch: [454][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0637 (0.0637)	
0.999984 5.2530404e-06
Epoch: [454][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0897 (0.0712)	
0.9999682 6.9338503e-06
Epoch: [454][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0680 (0.0658)	
0.9999914 5.3668277e-06
loss:  0.049354243597736436 0.04500069424972275
===========>   training    <===========
Epoch: [455][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0484 (0.0484)	
0.99998796 3.6474464e-06
===========>   testing    <===========
Epoch: [455][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0664 (0.0664)	
0.99999344 5.7712814e-06
Epoch: [455][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0571 (0.0630)	
0.9999857 7.112307e-06
Epoch: [455][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.1000 (0.0638)	
0.999997 6.409238e-06
loss:  0.04700557686772411 0.04500069424972275
===========>   training    <===========
Epoch: [456][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0609 (0.0609)	
0.9999845 4.7722974e-06
===========>   testing    <===========
Epoch: [456][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0542 (0.0542)	
0.99999046 4.0963396e-06
Epoch: [456][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0352 (0.0660)	
0.9999733 4.4839335e-06
Epoch: [456][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.2096 (0.0660)	
0.9999951 3.290396e-06
loss:  0.04774209008643171 0.04500069424972275
===========>   training    <===========
Epoch: [457][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0676 (0.0676)	
0.9999908 7.990529e-06
===========>   testing    <===========
Epoch: [457][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0756 (0.0756)	
0.9999808 6.149884e-06
Epoch: [457][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0437 (0.0692)	
0.9999635 5.4021666e-06
Epoch: [457][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0791 (0.0667)	
0.99998903 5.6942936e-06
loss:  0.051711563168867714 0.04500069424972275
===========>   training    <===========
Epoch: [458][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0458 (0.0458)	
0.99998105 2.4839057e-06
===========>   testing    <===========
Epoch: [458][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0500 (0.0500)	
0.9999912 3.530651e-06
Epoch: [458][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0763 (0.0626)	
0.9999715 3.551362e-06
Epoch: [458][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.1039 (0.0623)	
0.9999914 4.0278815e-06
loss:  0.04757064036511527 0.04500069424972275
===========>   training    <===========
Epoch: [459][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0443 (0.0443)	
0.99999034 4.696711e-06
===========>   testing    <===========
Epoch: [459][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0694 (0.0694)	
0.9999931 6.933467e-06
Epoch: [459][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0273 (0.0684)	
0.99997675 7.96742e-06
Epoch: [459][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.1099 (0.0657)	
0.99999785 7.1359163e-06
loss:  0.048480484552615555 0.04500069424972275
===========>   training    <===========
Epoch: [460][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0551 (0.0551)	
0.9999672 3.873259e-06
===========>   testing    <===========
Epoch: [460][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0641 (0.0641)	
0.9999901 6.9557127e-06
Epoch: [460][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0768 (0.0652)	
0.999977 7.922557e-06
Epoch: [460][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.1613 (0.0644)	
0.99999547 6.4262044e-06
loss:  0.04840268885231269 0.04500069424972275
===========>   training    <===========
Epoch: [461][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0480 (0.0480)	
0.9999826 5.579398e-06
===========>   testing    <===========
Epoch: [461][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0387 (0.0387)	
0.99998295 5.571741e-06
Epoch: [461][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0328 (0.0669)	
0.9999716 6.381111e-06
Epoch: [461][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.1316 (0.0655)	
0.9999858 5.72096e-06
loss:  0.04717078488050108 0.04500069424972275
===========>   training    <===========
Epoch: [462][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0507 (0.0507)	
0.99997413 4.758813e-06
===========>   testing    <===========
Epoch: [462][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0398 (0.0398)	
0.9999926 4.8287634e-06
Epoch: [462][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0405 (0.0623)	
0.9999677 5.164735e-06
Epoch: [462][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.1510 (0.0630)	
0.99998796 5.227703e-06
loss:  0.04670444051731382 0.04500069424972275
===========>   training    <===========
Epoch: [463][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0503 (0.0503)	
0.99998 5.7861944e-06
===========>   testing    <===========
Epoch: [463][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0679 (0.0679)	
0.99999404 9.484939e-06
Epoch: [463][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0491 (0.0648)	
0.99996984 7.3157216e-06
Epoch: [463][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0776 (0.0618)	
0.99999547 7.1460972e-06
loss:  0.047697557935963975 0.04500069424972275
===========>   training    <===========
Epoch: [464][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0491 (0.0491)	
0.9999815 7.2346984e-06
===========>   testing    <===========
Epoch: [464][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.1164 (0.1164)	
0.9999819 4.5557836e-06
Epoch: [464][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0320 (0.0658)	
0.9999579 4.8638703e-06
Epoch: [464][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0979 (0.0618)	
0.9999844 4.6315e-06
loss:  0.04587576797246895 0.04500069424972275
===========>   training    <===========
Epoch: [465][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0480 (0.0480)	
0.99999547 5.0458016e-06
===========>   testing    <===========
Epoch: [465][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0664 (0.0664)	
0.9999926 6.8024297e-06
Epoch: [465][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0699 (0.0646)	
0.9999765 7.5216676e-06
Epoch: [465][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0729 (0.0619)	
0.99999213 7.358958e-06
loss:  0.04634562350759919 0.04500069424972275
===========>   training    <===========
Epoch: [466][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0589 (0.0589)	
0.9999893 1.0678968e-05
===========>   testing    <===========
Epoch: [466][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0625 (0.0625)	
0.99998486 3.9019433e-06
Epoch: [466][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0243 (0.0658)	
0.99996066 4.746734e-06
Epoch: [466][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.1028 (0.0629)	
0.9999887 4.656949e-06
loss:  0.04605568059344656 0.04500069424972275
===========>   training    <===========
Epoch: [467][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0573 (0.0573)	
0.9999808 1.2063424e-06
===========>   testing    <===========
Epoch: [467][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.1128 (0.1128)	
0.99997807 6.5518493e-06
Epoch: [467][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0284 (0.0708)	
0.99993217 7.7205295e-06
Epoch: [467][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.1411 (0.0705)	
0.99998784 7.2069756e-06
loss:  0.05239526090171265 0.04500069424972275
===========>   training    <===========
Epoch: [468][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0474 (0.0474)	
0.99999213 3.2429164e-06
===========>   testing    <===========
Epoch: [468][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0636 (0.0636)	
0.99998784 4.4087838e-06
Epoch: [468][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.1493 (0.0736)	
0.9999522 4.7314443e-06
Epoch: [468][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.1065 (0.0693)	
0.999995 4.523763e-06
loss:  0.052229694776749325 0.04500069424972275
===========>   training    <===========
Epoch: [469][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0665 (0.0665)	
0.9999733 3.1284353e-06
===========>   testing    <===========
Epoch: [469][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0380 (0.0380)	
0.99999094 3.4683806e-06
Epoch: [469][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0627 (0.0666)	
0.9999522 3.4035836e-06
Epoch: [469][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.1037 (0.0651)	
0.99998724 3.5984951e-06
loss:  0.048839899911875095 0.04500069424972275
===========>   training    <===========
Epoch: [470][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0618 (0.0618)	
0.99998856 3.398916e-06
===========>   testing    <===========
Epoch: [470][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0578 (0.0578)	
0.9999932 5.858097e-06
Epoch: [470][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0559 (0.0680)	
0.99997103 8.518599e-06
Epoch: [470][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0926 (0.0643)	
0.99999034 7.2622524e-06
loss:  0.047856486029288936 0.04500069424972275
===========>   training    <===========
Epoch: [471][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0523 (0.0523)	
0.99997234 5.033705e-06
===========>   testing    <===========
Epoch: [471][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0451 (0.0451)	
0.9999877 3.4224524e-06
Epoch: [471][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0448 (0.0670)	
0.99994254 4.2719344e-06
Epoch: [471][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.1111 (0.0629)	
0.9999813 3.7172829e-06
loss:  0.04749902417024543 0.04500069424972275
===========>   training    <===========
Epoch: [472][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0597 (0.0597)	
0.99997485 2.6901457e-06
===========>   testing    <===========
Epoch: [472][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0640 (0.0640)	
0.9999877 9.780255e-06
Epoch: [472][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0424 (0.0697)	
0.9999726 1.2227154e-05
Epoch: [472][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.1323 (0.0657)	
0.9999912 7.490236e-06
loss:  0.04920798987124253 0.04500069424972275
===========>   training    <===========
Epoch: [473][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0475 (0.0475)	
0.9999795 9.414987e-06
===========>   testing    <===========
Epoch: [473][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.1162 (0.1162)	
0.9999875 5.877403e-06
Epoch: [473][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0316 (0.0671)	
0.99998593 5.856801e-06
Epoch: [473][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.1226 (0.0635)	
0.9999964 5.6820772e-06
loss:  0.0467060550753392 0.04500069424972275
===========>   training    <===========
Epoch: [474][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0516 (0.0516)	
0.9999782 2.2587942e-06
===========>   testing    <===========
Epoch: [474][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0403 (0.0403)	
0.99999416 1.0029062e-05
Epoch: [474][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0236 (0.0655)	
0.99998987 8.699718e-06
Epoch: [474][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0802 (0.0632)	
0.9999951 7.1901422e-06
loss:  0.047063284237255365 0.04500069424972275
===========>   training    <===========
Epoch: [475][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0552 (0.0552)	
0.99998724 7.6113242e-06
===========>   testing    <===========
Epoch: [475][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0424 (0.0424)	
0.99999034 6.56928e-06
Epoch: [475][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0221 (0.0701)	
0.99998665 5.530417e-06
Epoch: [475][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0926 (0.0668)	
0.99998903 6.5244144e-06
loss:  0.047801230948381734 0.04500069424972275
===========>   training    <===========
Epoch: [476][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0554 (0.0554)	
0.99998844 8.935817e-06
===========>   testing    <===========
Epoch: [476][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0543 (0.0543)	
0.9999931 1.5093696e-05
Epoch: [476][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0234 (0.0641)	
0.999984 1.0338407e-05
Epoch: [476][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0565 (0.0633)	
0.9999919 1.01273245e-05
loss:  0.04641551022614976 0.04500069424972275
===========>   training    <===========
Epoch: [477][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0594 (0.0594)	
0.99997926 9.604879e-07
===========>   testing    <===========
Epoch: [477][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0956 (0.0956)	
0.99998856 6.5594263e-06
Epoch: [477][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0235 (0.0683)	
0.99997795 6.947214e-06
Epoch: [477][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0894 (0.0636)	
0.99998975 7.1085565e-06
loss:  0.046085155200142114 0.04500069424972275
===========>   training    <===========
Epoch: [478][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0585 (0.0585)	
0.99998355 1.6318647e-05
===========>   testing    <===========
Epoch: [478][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.1034 (0.1034)	
0.99999154 7.3029582e-06
Epoch: [478][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0331 (0.0646)	
0.9999732 6.56034e-06
Epoch: [478][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.1461 (0.0636)	
0.9999908 7.3427013e-06
loss:  0.04620193880899737 0.04500069424972275
===========>   training    <===========
Epoch: [479][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0578 (0.0578)	
0.99998486 1.0316504e-05
===========>   testing    <===========
Epoch: [479][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0496 (0.0496)	
0.99998796 6.167869e-06
Epoch: [479][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0410 (0.0736)	
0.99998796 5.897852e-06
Epoch: [479][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0562 (0.0684)	
0.9999927 7.9307665e-06
loss:  0.05011801496949897 0.04500069424972275
===========>   training    <===========
Epoch: [480][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0552 (0.0552)	
0.9999747 5.441868e-06
===========>   testing    <===========
Epoch: [480][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0561 (0.0561)	
0.99999356 1.0676483e-05
Epoch: [480][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0285 (0.0676)	
0.99998415 1.3516241e-05
Epoch: [480][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0803 (0.0642)	
0.9999943 9.846626e-06
loss:  0.04714732878900185 0.04500069424972275
===========>   training    <===========
Epoch: [481][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0664 (0.0664)	
0.999967 4.8261118e-06
===========>   testing    <===========
Epoch: [481][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0511 (0.0511)	
0.99998057 5.06613e-06
Epoch: [481][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0355 (0.0673)	
0.99997056 5.2425107e-06
Epoch: [481][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0445 (0.0654)	
0.9999814 4.814583e-06
loss:  0.048424891591116404 0.04500069424972275
===========>   training    <===========
Epoch: [482][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0567 (0.0567)	
0.99997246 5.69286e-06
===========>   testing    <===========
Epoch: [482][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0610 (0.0610)	
0.9999857 9.14147e-06
Epoch: [482][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0399 (0.0678)	
0.9999739 1.198283e-05
Epoch: [482][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0793 (0.0678)	
0.99998033 8.443074e-06
loss:  0.04898098397137707 0.04500069424972275
===========>   training    <===========
Epoch: [483][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0536 (0.0536)	
0.9999857 4.5285974e-06
===========>   testing    <===========
Epoch: [483][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0636 (0.0636)	
0.99998283 6.8432532e-06
Epoch: [483][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0261 (0.0684)	
0.9999845 7.468652e-06
Epoch: [483][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.1533 (0.0661)	
0.9999881 5.5148803e-06
loss:  0.0486228601176798 0.04500069424972275
===========>   training    <===========
Epoch: [484][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0560 (0.0560)	
0.99998116 5.5930786e-06
===========>   testing    <===========
Epoch: [484][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0695 (0.0695)	
0.99998343 8.428239e-06
Epoch: [484][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0350 (0.0645)	
0.9999763 9.655928e-06
Epoch: [484][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.1122 (0.0640)	
0.99999094 7.3567053e-06
loss:  0.047918136473851125 0.04500069424972275
===========>   training    <===========
Epoch: [485][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0610 (0.0610)	
0.9999937 7.000252e-06
===========>   testing    <===========
Epoch: [485][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0619 (0.0619)	
0.99999094 7.002322e-06
Epoch: [485][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0668 (0.0665)	
0.99997973 7.71214e-06
Epoch: [485][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.1219 (0.0663)	
0.99998796 4.937705e-06
loss:  0.0479815797203208 0.04500069424972275
===========>   training    <===========
Epoch: [486][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0583 (0.0583)	
0.9999889 5.6357308e-06
===========>   testing    <===========
Epoch: [486][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0585 (0.0585)	
0.9999895 7.1783165e-06
Epoch: [486][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.1098 (0.0636)	
0.99998164 8.647465e-06
Epoch: [486][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0893 (0.0628)	
0.999982 6.897056e-06
loss:  0.04741560618411633 0.04500069424972275
===========>   training    <===========
Epoch: [487][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0435 (0.0435)	
0.9999746 9.861663e-06
===========>   testing    <===========
Epoch: [487][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0423 (0.0423)	
0.99999225 7.146779e-06
Epoch: [487][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0466 (0.0654)	
0.99998343 7.747038e-06
Epoch: [487][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.1592 (0.0647)	
0.99999595 6.520495e-06
loss:  0.04692582663072997 0.04500069424972275
===========>   training    <===========
Epoch: [488][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0596 (0.0596)	
0.99999 1.1940123e-05
===========>   testing    <===========
Epoch: [488][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0685 (0.0685)	
0.9999906 7.5813396e-06
Epoch: [488][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0413 (0.0678)	
0.9999825 6.651535e-06
Epoch: [488][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0998 (0.0644)	
0.9999844 7.157139e-06
loss:  0.047529049435605764 0.04500069424972275
===========>   training    <===========
Epoch: [489][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0495 (0.0495)	
0.9999715 5.6422214e-06
===========>   testing    <===========
Epoch: [489][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0421 (0.0421)	
0.9999877 1.248105e-05
Epoch: [489][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0528 (0.0676)	
0.99997854 1.0612612e-05
Epoch: [489][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0838 (0.0635)	
0.9999931 9.276822e-06
loss:  0.04666837575139415 0.04500069424972275
===========>   training    <===========
Epoch: [490][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0520 (0.0520)	
0.9999865 5.7451866e-06
===========>   testing    <===========
Epoch: [490][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0648 (0.0648)	
0.9999933 9.614698e-06
Epoch: [490][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0731 (0.0717)	
0.9999851 9.769609e-06
Epoch: [490][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0786 (0.0674)	
0.9999963 1.0570864e-05
loss:  0.04958319739685213 0.04500069424972275
===========>   training    <===========
Epoch: [491][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0542 (0.0542)	
0.9999683 3.895091e-06
===========>   testing    <===========
Epoch: [491][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0627 (0.0627)	
0.99999034 6.1817905e-06
Epoch: [491][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0313 (0.0635)	
0.999985 6.1530754e-06
Epoch: [491][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.1087 (0.0650)	
0.9999932 4.5867664e-06
loss:  0.046760564256360215 0.04500069424972275
===========>   training    <===========
Epoch: [492][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0459 (0.0459)	
0.9999933 4.231646e-06
===========>   testing    <===========
Epoch: [492][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0807 (0.0807)	
0.9999876 4.981208e-06
Epoch: [492][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0793 (0.0667)	
0.9999869 6.5829145e-06
Epoch: [492][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0956 (0.0633)	
0.9999933 4.5761444e-06
loss:  0.0485074328594477 0.04500069424972275
===========>   training    <===========
Epoch: [493][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0597 (0.0597)	
0.9999753 4.558287e-06
===========>   testing    <===========
Epoch: [493][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0468 (0.0468)	
0.99999046 8.730345e-06
Epoch: [493][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0304 (0.0662)	
0.9999759 8.932546e-06
Epoch: [493][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.1112 (0.0632)	
0.99999 8.729513e-06
loss:  0.04715121715929371 0.04500069424972275
===========>   training    <===========
Epoch: [494][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0601 (0.0601)	
0.99996233 4.46023e-06
===========>   testing    <===========
Epoch: [494][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0618 (0.0618)	
0.9999845 6.0801613e-06
Epoch: [494][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.1301 (0.0664)	
0.9999715 7.0869373e-06
Epoch: [494][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.1031 (0.0624)	
0.9999845 5.7010093e-06
loss:  0.046934472690519646 0.04500069424972275
===========>   training    <===========
Epoch: [495][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0464 (0.0464)	
0.99998 7.743802e-06
===========>   testing    <===========
Epoch: [495][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0432 (0.0432)	
0.9999881 8.208635e-06
Epoch: [495][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0419 (0.0673)	
0.9999746 9.079661e-06
Epoch: [495][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0961 (0.0644)	
0.99998474 9.205675e-06
loss:  0.04666438383856708 0.04500069424972275
===========>   training    <===========
Epoch: [496][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0676 (0.0676)	
0.9999871 7.676927e-06
===========>   testing    <===========
Epoch: [496][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0829 (0.0829)	
0.9999902 4.0317395e-06
Epoch: [496][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0371 (0.0629)	
0.9999814 5.627004e-06
Epoch: [496][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0683 (0.0610)	
0.9999902 4.0380005e-06
loss:  0.04518318011829747 0.04500069424972275
===========>   training    <===========
Epoch: [497][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0702 (0.0702)	
0.99998176 4.484438e-06
===========>   testing    <===========
Epoch: [497][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0398 (0.0398)	
0.99998784 4.6170835e-06
Epoch: [497][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0323 (0.0681)	
0.99998355 6.2684403e-06
Epoch: [497][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.1445 (0.0654)	
0.99998784 4.3285686e-06
loss:  0.047685292734232276 0.04500069424972275
===========>   training    <===========
Epoch: [498][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0644 (0.0644)	
0.9999809 1.1478747e-05
===========>   testing    <===========
Epoch: [498][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0516 (0.0516)	
0.9999887 3.0557467e-06
Epoch: [498][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0417 (0.0672)	
0.99998 3.949531e-06
Epoch: [498][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.1444 (0.0664)	
0.99998903 3.0564083e-06
loss:  0.04759534998789616 0.04500069424972275
===========>   training    <===========
Epoch: [499][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0582 (0.0582)	
0.99998784 6.0987445e-06
===========>   testing    <===========
Epoch: [499][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0402 (0.0402)	
0.9999801 3.7675338e-06
Epoch: [499][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0266 (0.0640)	
0.99995947 4.527829e-06
Epoch: [499][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0933 (0.0628)	
0.9999814 3.9811e-06
loss:  0.04714479386228432 0.04500069424972275
===========>   training    <===========
Epoch: [500][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0711 (0.0711)	
0.99997115 4.8762295e-06
===========>   testing    <===========
Epoch: [500][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0421 (0.0421)	
0.99999106 6.6479583e-06
Epoch: [500][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.1305 (0.0636)	
0.9999887 9.056277e-06
Epoch: [500][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.1163 (0.0609)	
0.9999852 6.9072526e-06
loss:  0.04502657516401598 0.04500069424972275
===========>   training    <===========
Epoch: [501][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0609 (0.0609)	
0.9999889 2.1558628e-05
===========>   testing    <===========
Epoch: [501][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0722 (0.0722)	
0.9999739 4.0223226e-06
Epoch: [501][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0471 (0.0708)	
0.99995315 3.718818e-06
Epoch: [501][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.1136 (0.0669)	
0.9999714 4.154856e-06
loss:  0.05092844131091567 0.04500069424972275
===========>   training    <===========
Epoch: [502][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0549 (0.0549)	
0.9999455 3.4849056e-06
===========>   testing    <===========
Epoch: [502][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0510 (0.0510)	
0.99998546 5.2317923e-06
Epoch: [502][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0248 (0.0699)	
0.99999094 5.790798e-06
Epoch: [502][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.2508 (0.0670)	
0.99998903 4.817586e-06
loss:  0.048832557174863456 0.04500069424972275
===========>   training    <===========
Epoch: [503][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0515 (0.0515)	
0.9999857 5.8403975e-06
===========>   testing    <===========
Epoch: [503][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0774 (0.0774)	
0.99998033 4.6526698e-06
Epoch: [503][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0672 (0.0683)	
0.99997437 4.751163e-06
Epoch: [503][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.1065 (0.0632)	
0.9999846 4.62735e-06
loss:  0.04774360338693251 0.04500069424972275
===========>   training    <===========
Epoch: [504][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0604 (0.0604)	
0.99999225 3.3895196e-06
===========>   testing    <===========
Epoch: [504][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0672 (0.0672)	
0.99998367 5.114431e-06
Epoch: [504][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0341 (0.0648)	
0.9999763 5.809023e-06
Epoch: [504][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.1173 (0.0612)	
0.9999918 4.4988524e-06
loss:  0.04660193999823592 0.04500069424972275
===========>   training    <===========
Epoch: [505][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0598 (0.0598)	
0.99997234 4.294777e-06
===========>   testing    <===========
Epoch: [505][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0961 (0.0961)	
0.99999297 7.2062194e-06
Epoch: [505][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0311 (0.0635)	
0.9999882 8.923656e-06
Epoch: [505][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.1005 (0.0607)	
0.9999919 6.216404e-06
loss:  0.046549050633458045 0.04500069424972275
===========>   training    <===========
Epoch: [506][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0518 (0.0518)	
0.9999869 5.2941045e-06
===========>   testing    <===========
Epoch: [506][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0874 (0.0874)	
0.9999851 3.51627e-06
Epoch: [506][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0271 (0.0685)	
0.99998 3.629379e-06
Epoch: [506][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0973 (0.0657)	
0.9999857 3.1304112e-06
loss:  0.04987981438413147 0.04500069424972275
===========>   training    <===========
Epoch: [507][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0534 (0.0534)	
0.99996984 3.7930183e-06
===========>   testing    <===========
Epoch: [507][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0559 (0.0559)	
0.9999856 4.4817743e-06
Epoch: [507][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0275 (0.0652)	
0.9999863 4.533476e-06
Epoch: [507][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0808 (0.0618)	
0.99999 3.6408953e-06
loss:  0.04657453142822143 0.04500069424972275
===========>   training    <===========
Epoch: [508][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0448 (0.0448)	
0.9999831 4.229629e-06
===========>   testing    <===========
Epoch: [508][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0460 (0.0460)	
0.9999815 3.76568e-06
Epoch: [508][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0265 (0.0654)	
0.99997246 4.885226e-06
Epoch: [508][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0929 (0.0634)	
0.99998856 3.580677e-06
loss:  0.04743333427334806 0.04500069424972275
===========>   training    <===========
Epoch: [509][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0593 (0.0593)	
0.99998236 3.2571245e-06
===========>   testing    <===========
Epoch: [509][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0612 (0.0612)	
0.99998426 3.830687e-06
Epoch: [509][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0232 (0.0614)	
0.9999783 4.7983744e-06
Epoch: [509][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.1152 (0.0589)	
0.99998546 3.153793e-06
loss:  0.04467018217743923 0.04500069424972275
===========>   training    <===========
Epoch: [510][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0586 (0.0586)	
0.9999716 6.737068e-06
===========>   testing    <===========
Epoch: [510][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0425 (0.0425)	
0.9999795 4.3942096e-06
Epoch: [510][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0290 (0.0625)	
0.9999783 5.7948973e-06
Epoch: [510][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.1116 (0.0603)	
0.9999813 3.9470606e-06
loss:  0.04389168359212403 0.04467018217743923
===========>   training    <===========
Epoch: [511][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0559 (0.0559)	
0.99998903 2.9011997e-06
===========>   testing    <===========
Epoch: [511][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0578 (0.0578)	
0.9999732 4.455634e-06
Epoch: [511][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0264 (0.0660)	
0.9999821 5.380398e-06
Epoch: [511][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.1558 (0.0663)	
0.9999809 4.755919e-06
loss:  0.04691344195050651 0.04389168359212403
===========>   training    <===========
Epoch: [512][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0685 (0.0685)	
0.99996495 1.8799504e-06
===========>   testing    <===========
Epoch: [512][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0504 (0.0504)	
0.99998474 6.3468806e-06
Epoch: [512][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0257 (0.0633)	
0.9999858 5.628437e-06
Epoch: [512][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.1050 (0.0633)	
0.9999852 6.0213492e-06
loss:  0.04544011131957737 0.04389168359212403
===========>   training    <===========
Epoch: [513][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0558 (0.0558)	
0.9999777 1.8428157e-06
===========>   testing    <===========
Epoch: [513][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0593 (0.0593)	
0.99998724 2.3881341e-06
Epoch: [513][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0297 (0.0670)	
0.99998116 4.1539165e-06
Epoch: [513][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0915 (0.0633)	
0.99998975 2.2831591e-06
loss:  0.04662406589331047 0.04389168359212403
===========>   training    <===========
Epoch: [514][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0505 (0.0505)	
0.9999914 3.7675086e-06
===========>   testing    <===========
Epoch: [514][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0390 (0.0390)	
0.9999758 2.9195824e-06
Epoch: [514][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0395 (0.0648)	
0.9999776 3.847855e-06
Epoch: [514][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.1272 (0.0649)	
0.9999826 2.9073262e-06
loss:  0.04648930562320197 0.04389168359212403
===========>   training    <===========
Epoch: [515][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0511 (0.0511)	
0.9999598 4.6269524e-06
===========>   testing    <===========
Epoch: [515][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0306 (0.0306)	
0.9999877 6.607274e-06
Epoch: [515][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0294 (0.0619)	
0.9999856 8.233049e-06
Epoch: [515][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0959 (0.0627)	
0.99998665 7.102634e-06
loss:  0.04529126519244242 0.04389168359212403
===========>   training    <===========
Epoch: [516][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0584 (0.0584)	
0.9999889 3.8165604e-06
===========>   testing    <===========
Epoch: [516][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0516 (0.0516)	
0.9999871 6.839417e-06
Epoch: [516][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0459 (0.0650)	
0.99998593 6.840656e-06
Epoch: [516][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.1254 (0.0668)	
0.9999844 7.3771707e-06
loss:  0.048384433873875365 0.04389168359212403
===========>   training    <===========
Epoch: [517][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0467 (0.0467)	
0.99999034 7.0285682e-06
===========>   testing    <===========
Epoch: [517][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0514 (0.0514)	
0.99997544 4.0321706e-06
Epoch: [517][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0382 (0.0626)	
0.99998057 4.855389e-06
Epoch: [517][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.1380 (0.0612)	
0.99998176 3.839102e-06
loss:  0.045552375838303294 0.04389168359212403
===========>   training    <===========
Epoch: [518][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0537 (0.0537)	
0.9999869 5.477759e-06
===========>   testing    <===========
Epoch: [518][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0466 (0.0466)	
0.99998486 4.6095292e-06
Epoch: [518][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0844 (0.0653)	
0.99997354 8.427878e-06
Epoch: [518][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.1194 (0.0616)	
0.999979 4.6255846e-06
loss:  0.04656290543073438 0.04389168359212403
===========>   training    <===========
Epoch: [519][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0549 (0.0549)	
0.9999919 3.8522394e-06
===========>   testing    <===========
Epoch: [519][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0687 (0.0687)	
0.99997485 3.5570224e-06
Epoch: [519][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0298 (0.0619)	
0.9999808 5.4544103e-06
Epoch: [519][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0779 (0.0596)	
0.9999809 3.3902274e-06
loss:  0.04534368871059946 0.04389168359212403
===========>   training    <===========
Epoch: [520][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0502 (0.0502)	
0.9999938 7.700205e-06
===========>   testing    <===========
Epoch: [520][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0480 (0.0480)	
0.9999871 5.9550543e-06
Epoch: [520][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0315 (0.0600)	
0.99999 6.236837e-06
Epoch: [520][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0685 (0.0596)	
0.9999887 4.4912135e-06
loss:  0.04462993481166222 0.04389168359212403
===========>   training    <===========
Epoch: [521][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0445 (0.0445)	
0.99998724 7.3402366e-06
===========>   testing    <===========
Epoch: [521][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0898 (0.0898)	
0.999987 5.2474275e-06
Epoch: [521][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0223 (0.0629)	
0.99998677 4.742883e-06
Epoch: [521][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0683 (0.0641)	
0.99998546 4.3917294e-06
loss:  0.047517576374095705 0.04389168359212403
===========>   training    <===========
Epoch: [522][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0411 (0.0411)	
0.99998 7.9822585e-06
===========>   testing    <===========
Epoch: [522][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0501 (0.0501)	
0.9999864 4.7092153e-06
Epoch: [522][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0251 (0.0680)	
0.9999919 5.1964726e-06
Epoch: [522][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0762 (0.0647)	
0.9999889 4.0837876e-06
loss:  0.04780218657055024 0.04389168359212403
===========>   training    <===========
Epoch: [523][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0375 (0.0375)	
0.99999034 1.8067657e-06
===========>   testing    <===========
Epoch: [523][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0361 (0.0361)	
0.99999154 1.14729355e-05
Epoch: [523][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0271 (0.0634)	
0.9999893 1.0466868e-05
Epoch: [523][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.1309 (0.0620)	
0.9999832 9.8018245e-06
loss:  0.0450595609697495 0.04389168359212403
===========>   training    <===========
Epoch: [524][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0514 (0.0514)	
0.9999937 7.066462e-06
===========>   testing    <===========
Epoch: [524][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0475 (0.0475)	
0.9999856 7.2593853e-06
Epoch: [524][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0255 (0.0672)	
0.9999856 7.500858e-06
Epoch: [524][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.1624 (0.0643)	
0.9999819 8.005846e-06
loss:  0.04713620761213355 0.04389168359212403
===========>   training    <===========
Epoch: [525][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0596 (0.0596)	
0.9999776 4.747865e-06
===========>   testing    <===========
Epoch: [525][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0356 (0.0356)	
0.9999865 1.0495216e-05
Epoch: [525][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0241 (0.0676)	
0.9999597 6.3883076e-06
Epoch: [525][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.1281 (0.0679)	
0.999987 1.0141687e-05
loss:  0.049386881323859155 0.04389168359212403
===========>   training    <===========
Epoch: [526][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0463 (0.0463)	
0.99998116 6.916659e-06
===========>   testing    <===========
Epoch: [526][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0440 (0.0440)	
0.9999777 7.336765e-06
Epoch: [526][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0273 (0.0658)	
0.9999831 8.150016e-06
Epoch: [526][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.1120 (0.0622)	
0.9999815 6.4113538e-06
loss:  0.04606704317092203 0.04389168359212403
===========>   training    <===========
Epoch: [527][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0421 (0.0421)	
0.9999819 1.8332541e-05
===========>   testing    <===========
Epoch: [527][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0454 (0.0454)	
0.9999895 2.933811e-06
Epoch: [527][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0234 (0.0642)	
0.9999808 4.5915845e-06
Epoch: [527][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0633 (0.0617)	
0.99998665 2.7521135e-06
loss:  0.047436991042116405 0.04389168359212403
===========>   training    <===========
Epoch: [528][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0468 (0.0468)	
0.99998605 3.827178e-06
===========>   testing    <===========
Epoch: [528][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0492 (0.0492)	
0.9999907 6.862768e-06
Epoch: [528][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0416 (0.0636)	
0.9999763 6.4723326e-06
Epoch: [528][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0751 (0.0619)	
0.99998355 5.8837963e-06
loss:  0.045984508273009594 0.04389168359212403
===========>   training    <===========
Epoch: [529][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0572 (0.0572)	
0.9999908 8.421451e-06
===========>   testing    <===========
Epoch: [529][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0342 (0.0342)	
0.9999919 3.8289813e-06
Epoch: [529][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0238 (0.0682)	
0.99997973 6.269696e-06
Epoch: [529][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.2572 (0.0678)	
0.9999871 3.2255512e-06
loss:  0.0482870570165469 0.04389168359212403
===========>   training    <===========
Epoch: [530][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0561 (0.0561)	
0.99998593 2.4766298e-06
===========>   testing    <===========
Epoch: [530][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0574 (0.0574)	
0.9999919 6.8732866e-06
Epoch: [530][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0523 (0.0636)	
0.9999815 6.6872176e-06
Epoch: [530][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.1311 (0.0611)	
0.9999869 4.9058717e-06
loss:  0.04704741009295943 0.04389168359212403
===========>   training    <===========
Epoch: [531][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0562 (0.0562)	
0.99999225 2.09846e-06
===========>   testing    <===========
Epoch: [531][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0438 (0.0438)	
0.99998903 7.307856e-06
Epoch: [531][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0310 (0.0638)	
0.9999733 7.2728153e-06
Epoch: [531][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.1459 (0.0636)	
0.99998355 5.0183326e-06
loss:  0.04572405468794449 0.04389168359212403
===========>   training    <===========
Epoch: [532][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0606 (0.0606)	
0.9999856 1.470195e-05
===========>   testing    <===========
Epoch: [532][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0409 (0.0409)	
0.99999106 7.61324e-06
Epoch: [532][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0269 (0.0639)	
0.9999895 5.7911184e-06
Epoch: [532][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.1880 (0.0625)	
0.9999856 6.979807e-06
loss:  0.045707939117734075 0.04389168359212403
===========>   training    <===========
Epoch: [533][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0517 (0.0517)	
0.99998784 4.0190253e-06
===========>   testing    <===========
Epoch: [533][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0546 (0.0546)	
0.9999918 1.0394571e-05
Epoch: [533][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0272 (0.0638)	
0.99998677 7.9983365e-06
Epoch: [533][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0978 (0.0620)	
0.99998593 7.209092e-06
loss:  0.04688411407069104 0.04389168359212403
===========>   training    <===========
Epoch: [534][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0505 (0.0505)	
0.9999889 4.1662433e-06
===========>   testing    <===========
Epoch: [534][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0437 (0.0437)	
0.9999844 3.4816035e-06
Epoch: [534][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0264 (0.0690)	
0.9999863 4.025554e-06
Epoch: [534][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.1961 (0.0657)	
0.99998474 3.2850157e-06
loss:  0.04697286308347315 0.04389168359212403
===========>   training    <===========
Epoch: [535][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0541 (0.0541)	
0.99999416 2.948171e-06
===========>   testing    <===========
Epoch: [535][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0421 (0.0421)	
0.9999778 4.0556997e-06
Epoch: [535][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0572 (0.0687)	
0.9999621 5.8147934e-06
Epoch: [535][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.1341 (0.0667)	
0.99997544 3.623562e-06
loss:  0.047605935758396556 0.04389168359212403
===========>   training    <===========
Epoch: [536][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0550 (0.0550)	
0.9999763 4.8972706e-06
===========>   testing    <===========
Epoch: [536][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.1856 (0.1856)	
0.9999682 9.8401215e-06
Epoch: [536][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0278 (0.0663)	
0.99996746 6.346457e-06
Epoch: [536][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0944 (0.0616)	
0.99998116 1.1526848e-05
loss:  0.04669452619511971 0.04389168359212403
===========>   training    <===========
Epoch: [537][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0619 (0.0619)	
0.99998033 5.899832e-06
===========>   testing    <===========
Epoch: [537][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.1844 (0.1844)	
0.99998987 6.668672e-06
Epoch: [537][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0203 (0.0658)	
0.99999213 5.7754055e-06
Epoch: [537][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.1477 (0.0642)	
0.99998736 8.227068e-06
loss:  0.04664730049830079 0.04389168359212403
===========>   training    <===========
Epoch: [538][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0529 (0.0529)	
0.99998 5.349582e-06
===========>   testing    <===========
Epoch: [538][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0398 (0.0398)	
0.9999831 4.1783596e-06
Epoch: [538][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0273 (0.0629)	
0.99997663 4.4255157e-06
Epoch: [538][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0712 (0.0622)	
0.9999763 3.5886733e-06
loss:  0.045707927838252393 0.04389168359212403
===========>   training    <===========
Epoch: [539][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0593 (0.0593)	
0.9999839 4.457483e-06
===========>   testing    <===========
Epoch: [539][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0392 (0.0392)	
0.99998987 6.5347135e-06
Epoch: [539][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0244 (0.0611)	
0.9999907 5.720485e-06
Epoch: [539][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.1359 (0.0621)	
0.99999213 6.252786e-06
loss:  0.045745421278639564 0.04389168359212403
===========>   training    <===========
Epoch: [540][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0551 (0.0551)	
0.99998856 3.4509533e-06
===========>   testing    <===========
Epoch: [540][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0362 (0.0362)	
0.99999046 6.4350843e-06
Epoch: [540][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0393 (0.0654)	
0.9999802 6.70772e-06
Epoch: [540][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0908 (0.0616)	
0.9999852 7.460266e-06
loss:  0.04614852084920751 0.04389168359212403
===========>   training    <===========
Epoch: [541][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0552 (0.0552)	
0.99999285 1.0240879e-05
===========>   testing    <===========
Epoch: [541][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0426 (0.0426)	
0.9999944 8.277514e-06
Epoch: [541][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0370 (0.0661)	
0.99999225 9.605845e-06
Epoch: [541][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.1097 (0.0642)	
0.99999666 6.8624013e-06
loss:  0.04522651704004621 0.04389168359212403
===========>   training    <===========
Epoch: [542][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0471 (0.0471)	
0.9999893 6.5891827e-06
===========>   testing    <===========
Epoch: [542][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0733 (0.0733)	
0.9999814 4.797862e-06
Epoch: [542][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0466 (0.0628)	
0.999972 5.922381e-06
Epoch: [542][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0555 (0.0618)	
0.9999813 5.69032e-06
loss:  0.04741449047419122 0.04389168359212403
===========>   training    <===========
Epoch: [543][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0517 (0.0517)	
0.99998164 8.326324e-06
===========>   testing    <===========
Epoch: [543][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0449 (0.0449)	
0.99998665 6.6757602e-06
Epoch: [543][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0297 (0.0619)	
0.9999918 8.415068e-06
Epoch: [543][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0892 (0.0601)	
0.9999927 1.1309163e-05
loss:  0.043855837726288094 0.04389168359212403
===========>   training    <===========
Epoch: [544][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0441 (0.0441)	
0.99999547 3.554835e-06
===========>   testing    <===========
Epoch: [544][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0394 (0.0394)	
0.999992 4.1033068e-06
Epoch: [544][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0330 (0.0653)	
0.9999876 4.0687746e-06
Epoch: [544][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.1042 (0.0657)	
0.99999475 4.036079e-06
loss:  0.04960579174535129 0.043855837726288094
===========>   training    <===========
Epoch: [545][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0538 (0.0538)	
0.9999895 2.585332e-06
===========>   testing    <===========
Epoch: [545][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0462 (0.0462)	
0.99998677 3.3109002e-06
Epoch: [545][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0342 (0.0622)	
0.9999802 3.7854982e-06
Epoch: [545][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.1719 (0.0610)	
0.9999844 3.1009477e-06
loss:  0.04583889812435715 0.043855837726288094
===========>   training    <===========
Epoch: [546][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0506 (0.0506)	
0.9999827 8.801739e-06
===========>   testing    <===========
Epoch: [546][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0430 (0.0430)	
0.99998856 4.0015166e-06
Epoch: [546][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0274 (0.0617)	
0.9999851 3.8552676e-06
Epoch: [546][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.1055 (0.0592)	
0.9999901 4.1364124e-06
loss:  0.04508728955472663 0.043855837726288094
===========>   training    <===========
Epoch: [547][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0461 (0.0461)	
0.9999856 5.352128e-06
===========>   testing    <===========
Epoch: [547][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0508 (0.0508)	
0.99999046 5.2963464e-06
Epoch: [547][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0234 (0.0640)	
0.9999907 7.5991034e-06
Epoch: [547][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.1069 (0.0620)	
0.99999094 7.194244e-06
loss:  0.0458278809001752 0.043855837726288094
===========>   training    <===========
Epoch: [548][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0407 (0.0407)	
0.9999881 8.00293e-06
===========>   testing    <===========
Epoch: [548][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0485 (0.0485)	
0.9999901 5.5637124e-06
Epoch: [548][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0323 (0.0620)	
0.9999907 7.250115e-06
Epoch: [548][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0747 (0.0598)	
0.9999902 5.1820275e-06
loss:  0.04576906226826771 0.043855837726288094
===========>   training    <===========
Epoch: [549][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0523 (0.0523)	
0.99999106 5.158941e-06
===========>   testing    <===========
Epoch: [549][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0454 (0.0454)	
0.9999863 6.268261e-06
Epoch: [549][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0344 (0.0666)	
0.9999844 6.5491568e-06
Epoch: [549][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0594 (0.0626)	
0.9999857 6.3586585e-06
loss:  0.04704378317791269 0.043855837726288094
===========>   training    <===========
Epoch: [550][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0533 (0.0533)	
0.99995637 4.1016287e-06
===========>   testing    <===========
Epoch: [550][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0512 (0.0512)	
0.99998915 4.629623e-06
Epoch: [550][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0224 (0.0631)	
0.9999893 6.009315e-06
Epoch: [550][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.1313 (0.0600)	
0.9999869 4.156592e-06
loss:  0.0461435847305417 0.043855837726288094
===========>   training    <===========
Epoch: [551][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0443 (0.0443)	
0.9999862 4.029979e-06
===========>   testing    <===========
Epoch: [551][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0363 (0.0363)	
0.9999933 5.4444117e-06
Epoch: [551][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0249 (0.0579)	
0.99998677 5.3863378e-06
Epoch: [551][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.1349 (0.0569)	
0.9999901 4.482809e-06
loss:  0.04469503646909434 0.043855837726288094
===========>   training    <===========
Epoch: [552][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0563 (0.0563)	
0.9999728 1.3595733e-05
===========>   testing    <===========
Epoch: [552][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0555 (0.0555)	
0.9999906 5.213643e-06
Epoch: [552][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0230 (0.0620)	
0.9999894 7.607333e-06
Epoch: [552][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0659 (0.0597)	
0.99998856 5.674269e-06
loss:  0.04596704631588677 0.043855837726288094
===========>   training    <===========
Epoch: [553][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0525 (0.0525)	
0.9999862 5.517921e-06
===========>   testing    <===========
Epoch: [553][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0738 (0.0738)	
0.99998856 4.3131818e-06
Epoch: [553][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0236 (0.0613)	
0.9999808 4.4361136e-06
Epoch: [553][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.1421 (0.0601)	
0.9999883 4.230504e-06
loss:  0.04570612017745046 0.043855837726288094
===========>   training    <===========
Epoch: [554][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0455 (0.0455)	
0.9999863 6.7435094e-06
===========>   testing    <===========
Epoch: [554][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0574 (0.0574)	
0.9999838 3.8055732e-06
Epoch: [554][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0380 (0.0641)	
0.9999939 3.6603815e-06
Epoch: [554][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.1167 (0.0612)	
0.9999877 4.326513e-06
loss:  0.04748662910226298 0.043855837726288094
===========>   training    <===========
Epoch: [555][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0486 (0.0486)	
0.99999297 5.0960666e-06
===========>   testing    <===========
Epoch: [555][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0502 (0.0502)	
0.9999825 4.239361e-06
Epoch: [555][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0374 (0.0617)	
0.99999046 5.146106e-06
Epoch: [555][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.1718 (0.0601)	
0.9999821 4.5411657e-06
loss:  0.04568838534120356 0.043855837726288094
===========>   training    <===========
Epoch: [556][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0554 (0.0554)	
0.9999894 4.2574834e-06
===========>   testing    <===========
Epoch: [556][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0340 (0.0340)	
0.99998355 4.182426e-06
Epoch: [556][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0300 (0.0602)	
0.9999889 6.118622e-06
Epoch: [556][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.1041 (0.0621)	
0.99998415 4.221585e-06
loss:  0.04694075804850073 0.043855837726288094
===========>   training    <===========
Epoch: [557][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0532 (0.0532)	
0.9999739 4.5721836e-06
===========>   testing    <===========
Epoch: [557][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0344 (0.0344)	
0.99998474 5.4502248e-06
Epoch: [557][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0551 (0.0620)	
0.999985 7.432939e-06
Epoch: [557][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.1466 (0.0624)	
0.9999838 4.7481103e-06
loss:  0.04655950511558926 0.043855837726288094
===========>   training    <===========
Epoch: [558][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0530 (0.0530)	
0.9999858 8.380598e-06
===========>   testing    <===========
Epoch: [558][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0489 (0.0489)	
0.99998987 1.5020636e-05
Epoch: [558][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0467 (0.0589)	
0.9999883 1.3111944e-05
Epoch: [558][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0669 (0.0647)	
0.9999887 8.482443e-06
loss:  0.04899130015193209 0.043855837726288094
===========>   training    <===========
Epoch: [559][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0489 (0.0489)	
0.99999475 1.0640684e-05
===========>   testing    <===========
Epoch: [559][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0439 (0.0439)	
0.99998605 4.278613e-06
Epoch: [559][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0476 (0.0609)	
0.99998546 6.032805e-06
Epoch: [559][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0669 (0.0585)	
0.9999825 4.553503e-06
loss:  0.04467730636183731 0.043855837726288094
===========>   training    <===========
Epoch: [560][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0506 (0.0506)	
0.9999777 5.4821126e-06
===========>   testing    <===========
Epoch: [560][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0520 (0.0520)	
0.9999877 6.2949075e-06
Epoch: [560][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0537 (0.0663)	
0.9999896 8.957499e-06
Epoch: [560][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0716 (0.0642)	
0.9999881 7.821584e-06
loss:  0.048646982895755864 0.043855837726288094
===========>   training    <===========
Epoch: [561][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0557 (0.0557)	
0.9999784 3.534987e-06
===========>   testing    <===========
Epoch: [561][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0591 (0.0591)	
0.999985 4.713304e-06
Epoch: [561][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0244 (0.0606)	
0.9999877 6.640957e-06
Epoch: [561][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.1601 (0.0606)	
0.9999889 5.0635413e-06
loss:  0.04541519732784782 0.043855837726288094
===========>   training    <===========
Epoch: [562][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0634 (0.0634)	
0.9999807 2.4421756e-06
===========>   testing    <===========
Epoch: [562][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0601 (0.0601)	
0.999987 4.306544e-06
Epoch: [562][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0232 (0.0631)	
0.9999908 6.4988103e-06
Epoch: [562][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.1001 (0.0599)	
0.99998724 4.5075535e-06
loss:  0.04624909148444567 0.043855837726288094
===========>   training    <===========
Epoch: [563][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0470 (0.0470)	
0.99998915 2.621106e-06
===========>   testing    <===========
Epoch: [563][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0834 (0.0834)	
0.9999857 5.327135e-06
Epoch: [563][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0455 (0.0627)	
0.99998724 5.9039858e-06
Epoch: [563][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0907 (0.0620)	
0.99998903 5.6415165e-06
loss:  0.04877888700829669 0.043855837726288094
===========>   training    <===========
Epoch: [564][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0449 (0.0449)	
0.99998367 5.235646e-06
===========>   testing    <===========
Epoch: [564][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0366 (0.0366)	
0.99998343 5.1807083e-06
Epoch: [564][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0255 (0.0613)	
0.9999807 5.5717887e-06
Epoch: [564][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.1808 (0.0622)	
0.9999882 4.8171496e-06
loss:  0.04826166289539624 0.043855837726288094
===========>   training    <===========
Epoch: [565][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0572 (0.0572)	
0.99998724 1.1908442e-05
===========>   testing    <===========
Epoch: [565][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0584 (0.0584)	
0.999987 5.83488e-06
Epoch: [565][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0280 (0.0614)	
0.9999877 7.257122e-06
Epoch: [565][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.1109 (0.0595)	
0.99998844 5.8453734e-06
loss:  0.04531323911346807 0.043855837726288094
===========>   training    <===========
Epoch: [566][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0434 (0.0434)	
0.9999857 6.2746367e-06
===========>   testing    <===========
Epoch: [566][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0597 (0.0597)	
0.99998665 4.80572e-06
Epoch: [566][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0356 (0.0635)	
0.99998677 5.4217226e-06
Epoch: [566][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.1923 (0.0617)	
0.99998486 4.8112643e-06
loss:  0.04561172215099785 0.043855837726288094
===========>   training    <===========
Epoch: [567][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0503 (0.0503)	
0.999984 4.217762e-06
===========>   testing    <===========
Epoch: [567][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0452 (0.0452)	
0.9999845 3.6097035e-06
Epoch: [567][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0375 (0.0605)	
0.9999807 3.6124723e-06
Epoch: [567][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.1185 (0.0582)	
0.9999875 3.5788335e-06
loss:  0.04399482892807194 0.043855837726288094
===========>   training    <===========
Epoch: [568][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0487 (0.0487)	
0.99998176 2.512169e-06
===========>   testing    <===========
Epoch: [568][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0483 (0.0483)	
0.99998415 4.055123e-06
Epoch: [568][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0274 (0.0614)	
0.9999887 4.9254254e-06
Epoch: [568][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0959 (0.0582)	
0.99998605 3.8906583e-06
loss:  0.04391226042335883 0.043855837726288094
===========>   training    <===========
Epoch: [569][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0490 (0.0490)	
0.9999777 2.031366e-06
===========>   testing    <===========
Epoch: [569][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0589 (0.0589)	
0.99998283 5.195219e-06
Epoch: [569][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0424 (0.0650)	
0.9999871 4.364665e-06
Epoch: [569][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0681 (0.0628)	
0.99998355 4.8465254e-06
loss:  0.04735080227140054 0.043855837726288094
===========>   training    <===========
Epoch: [570][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0439 (0.0439)	
0.9999938 3.6411384e-06
===========>   testing    <===========
Epoch: [570][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0448 (0.0448)	
0.9999908 6.433526e-06
Epoch: [570][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0319 (0.0622)	
0.99998677 6.3757216e-06
Epoch: [570][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0670 (0.0596)	
0.9999852 6.1149353e-06
loss:  0.044108396624900625 0.043855837726288094
===========>   training    <===========
Epoch: [571][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0640 (0.0640)	
0.99997973 8.723987e-06
===========>   testing    <===========
Epoch: [571][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0598 (0.0598)	
0.99998534 5.543106e-06
Epoch: [571][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0263 (0.0646)	
0.9999882 5.559226e-06
Epoch: [571][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.1122 (0.0628)	
0.99998164 5.17092e-06
loss:  0.04582084661901864 0.043855837726288094
===========>   training    <===========
Epoch: [572][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0447 (0.0447)	
0.99999166 7.885683e-06
===========>   testing    <===========
Epoch: [572][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0451 (0.0451)	
0.9999833 5.568203e-06
Epoch: [572][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0354 (0.0607)	
0.9999877 5.861545e-06
Epoch: [572][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.1425 (0.0617)	
0.99998045 5.3814706e-06
loss:  0.046003360709089614 0.043855837726288094
===========>   training    <===========
Epoch: [573][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0539 (0.0539)	
0.9999758 1.8361727e-05
===========>   testing    <===========
Epoch: [573][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0565 (0.0565)	
0.9999815 5.568219e-06
Epoch: [573][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0297 (0.0601)	
0.999985 6.1700634e-06
Epoch: [573][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.1048 (0.0588)	
0.99998236 5.2032015e-06
loss:  0.04424077990562547 0.043855837726288094
===========>   training    <===========
Epoch: [574][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0441 (0.0441)	
0.9999722 5.3722715e-06
===========>   testing    <===========
Epoch: [574][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0570 (0.0570)	
0.9999856 4.867666e-06
Epoch: [574][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0347 (0.0629)	
0.9999858 5.2293385e-06
Epoch: [574][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.1520 (0.0613)	
0.9999831 4.709723e-06
loss:  0.04539167765827001 0.043855837726288094
===========>   training    <===========
Epoch: [575][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0508 (0.0508)	
0.9999876 2.787695e-06
===========>   testing    <===========
Epoch: [575][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0478 (0.0478)	
0.99998796 4.5526567e-06
Epoch: [575][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0426 (0.0616)	
0.999985 4.408641e-06
Epoch: [575][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0949 (0.0598)	
0.99998343 4.2222373e-06
loss:  0.045023839865920845 0.043855837726288094
===========>   training    <===========
Epoch: [576][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0530 (0.0530)	
0.9999863 3.7682596e-06
===========>   testing    <===========
Epoch: [576][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0501 (0.0501)	
0.99997866 4.313914e-06
Epoch: [576][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0320 (0.0619)	
0.99997294 4.5504603e-06
Epoch: [576][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.1690 (0.0613)	
0.9999809 4.397438e-06
loss:  0.045169284774332796 0.043855837726288094
===========>   training    <===========
Epoch: [577][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0397 (0.0397)	
0.9999777 2.1672872e-06
===========>   testing    <===========
Epoch: [577][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0475 (0.0475)	
0.9999845 3.7149864e-06
Epoch: [577][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0338 (0.0639)	
0.99997497 3.6093836e-06
Epoch: [577][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0790 (0.0611)	
0.9999858 3.7492111e-06
loss:  0.04493875670822989 0.043855837726288094
===========>   training    <===========
Epoch: [578][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0436 (0.0436)	
0.9999825 2.982875e-06
===========>   testing    <===========
Epoch: [578][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0315 (0.0315)	
0.99998677 3.6190966e-06
Epoch: [578][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0239 (0.0615)	
0.9999876 4.8949546e-06
Epoch: [578][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.1573 (0.0615)	
0.9999851 3.5121775e-06
loss:  0.04437962074036694 0.043855837726288094
===========>   training    <===========
Epoch: [579][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0631 (0.0631)	
0.9999871 5.5030914e-06
===========>   testing    <===========
Epoch: [579][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0319 (0.0319)	
0.9999887 4.0158607e-06
Epoch: [579][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0284 (0.0594)	
0.9999906 5.3258645e-06
Epoch: [579][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.1614 (0.0591)	
0.9999852 3.9122456e-06
loss:  0.04360711475562651 0.043855837726288094
===========>   training    <===========
Epoch: [580][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0536 (0.0536)	
0.99997985 2.1075716e-06
===========>   testing    <===========
Epoch: [580][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0429 (0.0429)	
0.9999809 3.7786742e-06
Epoch: [580][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0254 (0.0604)	
0.9999802 4.541737e-06
Epoch: [580][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0909 (0.0587)	
0.99998033 3.7532395e-06
loss:  0.045624968504782704 0.04360711475562651
===========>   training    <===========
Epoch: [581][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0514 (0.0514)	
0.99998116 2.2297677e-06
===========>   testing    <===========
Epoch: [581][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0573 (0.0573)	
0.9999888 5.065618e-06
Epoch: [581][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0394 (0.0635)	
0.9999875 6.517076e-06
Epoch: [581][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0779 (0.0596)	
0.99998534 5.3198846e-06
loss:  0.044873749469721336 0.04360711475562651
===========>   training    <===========
Epoch: [582][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0483 (0.0483)	
0.9999802 2.5737354e-06
===========>   testing    <===========
Epoch: [582][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0345 (0.0345)	
0.9999863 4.792018e-06
Epoch: [582][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0306 (0.0611)	
0.99999106 5.7453676e-06
Epoch: [582][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0903 (0.0588)	
0.9999759 4.7646668e-06
loss:  0.044122194661080805 0.04360711475562651
===========>   training    <===========
Epoch: [583][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0511 (0.0511)	
0.99999225 4.1960657e-06
===========>   testing    <===========
Epoch: [583][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0496 (0.0496)	
0.9999875 4.738782e-06
Epoch: [583][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0281 (0.0583)	
0.99997973 5.1169336e-06
Epoch: [583][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0972 (0.0590)	
0.9999802 4.649161e-06
loss:  0.04402523663175428 0.04360711475562651
===========>   training    <===========
Epoch: [584][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0457 (0.0457)	
0.9999852 2.577233e-06
===========>   testing    <===========
Epoch: [584][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0580 (0.0580)	
0.9999778 4.721883e-06
Epoch: [584][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0306 (0.0607)	
0.99997556 5.008464e-06
Epoch: [584][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.1899 (0.0612)	
0.99997675 4.408557e-06
loss:  0.04620192756115227 0.04360711475562651
===========>   training    <===========
Epoch: [585][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0602 (0.0602)	
0.9999826 3.9063925e-06
===========>   testing    <===========
Epoch: [585][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0488 (0.0488)	
0.9999852 5.3600197e-06
Epoch: [585][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0263 (0.0668)	
0.99998176 4.91588e-06
Epoch: [585][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0905 (0.0637)	
0.9999747 5.278652e-06
loss:  0.04660113455413928 0.04360711475562651
===========>   training    <===========
Epoch: [586][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0561 (0.0561)	
0.99996746 5.4818456e-06
===========>   testing    <===========
Epoch: [586][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0415 (0.0415)	
0.99998224 7.2144217e-06
Epoch: [586][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0265 (0.0632)	
0.99998355 7.949091e-06
Epoch: [586][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0792 (0.0624)	
0.9999764 5.2002256e-06
loss:  0.04493696440522832 0.04360711475562651
===========>   training    <===========
Epoch: [587][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0585 (0.0585)	
0.99996984 2.6239322e-06
===========>   testing    <===========
Epoch: [587][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0325 (0.0325)	
0.99998236 5.9966164e-06
Epoch: [587][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0261 (0.0610)	
0.9999809 5.476652e-06
Epoch: [587][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0830 (0.0614)	
0.9999777 6.935669e-06
loss:  0.04443334898561224 0.04360711475562651
===========>   training    <===========
Epoch: [588][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0495 (0.0495)	
0.9999865 4.859503e-06
===========>   testing    <===========
Epoch: [588][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0355 (0.0355)	
0.99998176 6.4794226e-06
Epoch: [588][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0634 (0.0632)	
0.99998343 6.1000364e-06
Epoch: [588][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0677 (0.0621)	
0.9999777 5.492474e-06
loss:  0.046288353977897656 0.04360711475562651
===========>   training    <===========
Epoch: [589][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0554 (0.0554)	
0.99997544 5.837574e-06
===========>   testing    <===========
Epoch: [589][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0454 (0.0454)	
0.999985 5.7485076e-06
Epoch: [589][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0320 (0.0612)	
0.9999865 5.095984e-06
Epoch: [589][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.1091 (0.0628)	
0.9999788 5.903412e-06
loss:  0.04711007285802593 0.04360711475562651
===========>   training    <===========
Epoch: [590][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0631 (0.0631)	
0.9999889 1.4458197e-06
===========>   testing    <===========
Epoch: [590][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0401 (0.0401)	
0.99998033 7.672235e-06
Epoch: [590][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0228 (0.0682)	
0.99998474 9.504107e-06
Epoch: [590][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.1007 (0.0656)	
0.99998 6.7901806e-06
loss:  0.04855238213536217 0.04360711475562651
===========>   training    <===========
Epoch: [591][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0495 (0.0495)	
0.9999771 6.31546e-06
===========>   testing    <===========
Epoch: [591][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0389 (0.0389)	
0.99998665 9.699112e-06
Epoch: [591][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0393 (0.0631)	
0.9999889 7.0617457e-06
Epoch: [591][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0998 (0.0607)	
0.99998116 7.4347404e-06
loss:  0.04633442181752534 0.04360711475562651
===========>   training    <===========
Epoch: [592][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0554 (0.0554)	
0.99999094 9.668063e-06
===========>   testing    <===========
Epoch: [592][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0353 (0.0353)	
0.999974 6.0510188e-06
Epoch: [592][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0223 (0.0630)	
0.9999845 5.999299e-06
Epoch: [592][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0768 (0.0608)	
0.99996746 6.150283e-06
loss:  0.045664279979648836 0.04360711475562651
===========>   training    <===========
Epoch: [593][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0454 (0.0454)	
0.99998736 8.973008e-06
===========>   testing    <===========
Epoch: [593][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0435 (0.0435)	
0.99998426 4.1509784e-06
Epoch: [593][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0363 (0.0674)	
0.9999932 4.116311e-06
Epoch: [593][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0785 (0.0654)	
0.99997926 4.8168877e-06
loss:  0.047911373824360504 0.04360711475562651
===========>   training    <===========
Epoch: [594][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0511 (0.0511)	
0.9999784 3.3494712e-06
===========>   testing    <===========
Epoch: [594][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0359 (0.0359)	
0.9999851 4.5092474e-06
Epoch: [594][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0487 (0.0619)	
0.9999912 4.6673617e-06
Epoch: [594][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0797 (0.0609)	
0.9999825 4.7436247e-06
loss:  0.04576062350008492 0.04360711475562651
===========>   training    <===========
Epoch: [595][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0571 (0.0571)	
0.99998546 6.5316112e-06
===========>   testing    <===========
Epoch: [595][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0403 (0.0403)	
0.9999877 4.8180596e-06
Epoch: [595][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0342 (0.0674)	
0.99998736 4.902864e-06
Epoch: [595][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0872 (0.0644)	
0.99998176 4.6901e-06
loss:  0.0467680482712054 0.04360711475562651
===========>   training    <===========
Epoch: [596][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0529 (0.0529)	
0.9999703 3.901504e-06
===========>   testing    <===========
Epoch: [596][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0401 (0.0401)	
0.999979 4.838633e-06
Epoch: [596][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0345 (0.0643)	
0.9999907 5.097481e-06
Epoch: [596][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0884 (0.0619)	
0.9999734 5.379736e-06
loss:  0.04540285962180901 0.04360711475562651
===========>   training    <===========
Epoch: [597][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0607 (0.0607)	
0.9999877 1.7319153e-05
===========>   testing    <===========
Epoch: [597][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0428 (0.0428)	
0.99997914 8.7880335e-06
Epoch: [597][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0252 (0.0643)	
0.99998903 7.5566604e-06
Epoch: [597][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0925 (0.0621)	
0.9999627 7.076389e-06
loss:  0.04528450336506784 0.04360711475562651
===========>   training    <===========
Epoch: [598][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0522 (0.0522)	
0.9999833 4.913293e-06
===========>   testing    <===========
Epoch: [598][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0408 (0.0408)	
0.9999733 4.585074e-06
Epoch: [598][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0224 (0.0607)	
0.99998593 4.414927e-06
Epoch: [598][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0688 (0.0616)	
0.99995923 3.728502e-06
loss:  0.04505402144849613 0.04360711475562651
===========>   training    <===========
Epoch: [599][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0384 (0.0384)	
0.99999607 7.6329425e-06
===========>   testing    <===========
Epoch: [599][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0728 (0.0728)	
0.99998844 5.7698285e-06
Epoch: [599][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0263 (0.0642)	
0.9999896 6.7141073e-06
Epoch: [599][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0480 (0.0628)	
0.9999733 4.7869157e-06
loss:  0.04638803827224025 0.04360711475562651
===========>   training    <===========
Epoch: [600][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0573 (0.0573)	
0.99999094 7.0854924e-07
===========>   testing    <===========
Epoch: [600][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0482 (0.0482)	
0.9999846 4.862525e-06
Epoch: [600][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0244 (0.0602)	
0.99998486 5.7311336e-06
Epoch: [600][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0606 (0.0579)	
0.9999646 4.7808344e-06
loss:  0.043682706045276354 0.04360711475562651
===========>   training    <===========
Epoch: [601][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0584 (0.0584)	
0.99998474 5.2595674e-06
===========>   testing    <===========
Epoch: [601][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0557 (0.0557)	
0.9999924 6.5082068e-06
Epoch: [601][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0198 (0.0621)	
0.9999926 8.89734e-06
Epoch: [601][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0840 (0.0587)	
0.9999839 6.2857407e-06
loss:  0.04358056267270216 0.04360711475562651
===========>   training    <===========
Epoch: [602][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0406 (0.0406)	
0.99998915 1.2520298e-05
===========>   testing    <===========
Epoch: [602][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0514 (0.0514)	
0.9999888 1.1340138e-05
Epoch: [602][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0192 (0.0601)	
0.9999906 1.0673245e-05
Epoch: [602][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.1089 (0.0598)	
0.999982 1.0889695e-05
loss:  0.04364331778910613 0.04358056267270216
===========>   training    <===========
Epoch: [603][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0447 (0.0447)	
0.99998534 1.7712824e-06
===========>   testing    <===========
Epoch: [603][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0612 (0.0612)	
0.9999764 5.722346e-06
Epoch: [603][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0475 (0.0613)	
0.9999751 5.366362e-06
Epoch: [603][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.1258 (0.0594)	
0.99996245 5.4603593e-06
loss:  0.04383728006820553 0.04358056267270216
===========>   training    <===========
Epoch: [604][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0454 (0.0454)	
0.9999697 5.2099895e-06
===========>   testing    <===========
Epoch: [604][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0388 (0.0388)	
0.99998724 7.6033725e-06
Epoch: [604][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0382 (0.0687)	
0.99998593 7.831914e-06
Epoch: [604][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.1228 (0.0629)	
0.99998105 8.044955e-06
loss:  0.04676486727949203 0.04358056267270216
===========>   training    <===========
Epoch: [605][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0452 (0.0452)	
0.9999815 5.510333e-06
===========>   testing    <===========
Epoch: [605][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0300 (0.0300)	
0.99998474 4.6651503e-06
Epoch: [605][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0338 (0.0591)	
0.9999858 4.6035807e-06
Epoch: [605][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0844 (0.0591)	
0.99996936 4.7185977e-06
loss:  0.04418994484000183 0.04358056267270216
===========>   training    <===========
Epoch: [606][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0411 (0.0411)	
0.9999839 2.6753378e-06
===========>   testing    <===========
Epoch: [606][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0377 (0.0377)	
0.9999783 4.5324773e-06
Epoch: [606][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0255 (0.0612)	
0.99998724 4.602395e-06
Epoch: [606][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0590 (0.0604)	
0.9999759 4.454521e-06
loss:  0.04525899880563622 0.04358056267270216
===========>   training    <===========
Epoch: [607][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0466 (0.0466)	
0.99996686 2.7230637e-06
===========>   testing    <===========
Epoch: [607][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0468 (0.0468)	
0.9999815 5.0836206e-06
Epoch: [607][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0257 (0.0651)	
0.9999815 5.2081664e-06
Epoch: [607][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0863 (0.0630)	
0.99997795 4.807343e-06
loss:  0.046595944983707116 0.04358056267270216
===========>   training    <===========
Epoch: [608][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0443 (0.0443)	
0.9999709 1.2195641e-06
===========>   testing    <===========
Epoch: [608][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0365 (0.0365)	
0.9999739 5.0413378e-06
Epoch: [608][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0194 (0.0595)	
0.99998105 4.8324764e-06
Epoch: [608][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.1125 (0.0593)	
0.9999734 4.6472856e-06
loss:  0.04394717152953842 0.04358056267270216
===========>   training    <===========
Epoch: [609][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0444 (0.0444)	
0.9999839 5.6704066e-06
===========>   testing    <===========
Epoch: [609][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0422 (0.0422)	
0.99998546 3.673306e-06
Epoch: [609][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0240 (0.0640)	
0.99998665 3.8141986e-06
Epoch: [609][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0637 (0.0602)	
0.9999789 3.718421e-06
loss:  0.044747863033013924 0.04358056267270216
===========>   training    <===========
Epoch: [610][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0437 (0.0437)	
0.99998915 3.5244946e-06
===========>   testing    <===========
Epoch: [610][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0586 (0.0586)	
0.99997354 5.9829304e-06
Epoch: [610][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0295 (0.0614)	
0.9999808 5.864906e-06
Epoch: [610][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0974 (0.0603)	
0.99997556 6.086311e-06
loss:  0.04433961681922172 0.04358056267270216
===========>   training    <===========
Epoch: [611][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0474 (0.0474)	
0.9999865 8.926951e-06
===========>   testing    <===========
Epoch: [611][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0340 (0.0340)	
0.9999876 5.9233976e-06
Epoch: [611][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0224 (0.0615)	
0.99998736 7.458715e-06
Epoch: [611][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0867 (0.0598)	
0.9999858 5.497489e-06
loss:  0.04402867644138564 0.04358056267270216
===========>   training    <===========
Epoch: [612][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0508 (0.0508)	
0.9999887 2.523522e-06
===========>   testing    <===========
Epoch: [612][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0803 (0.0803)	
0.9999721 6.000226e-06
Epoch: [612][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0262 (0.0645)	
0.999985 6.151773e-06
Epoch: [612][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0799 (0.0660)	
0.99997747 6.0688417e-06
loss:  0.047795497098912176 0.04358056267270216
===========>   training    <===========
Epoch: [613][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0486 (0.0486)	
0.99997497 5.134037e-06
===========>   testing    <===========
Epoch: [613][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0518 (0.0518)	
0.99999094 1.1933566e-05
Epoch: [613][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0241 (0.0723)	
0.99998426 7.970391e-06
Epoch: [613][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0781 (0.0687)	
0.9999846 1.10165865e-05
loss:  0.04882391093686478 0.04358056267270216
===========>   training    <===========
Epoch: [614][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0460 (0.0460)	
0.9999864 1.2056054e-05
===========>   testing    <===========
Epoch: [614][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0549 (0.0549)	
0.99996793 2.9468638e-06
Epoch: [614][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0235 (0.0634)	
0.99998343 2.7404926e-06
Epoch: [614][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0959 (0.0624)	
0.99997413 3.6323086e-06
loss:  0.04710434122020801 0.04358056267270216
===========>   training    <===========
Epoch: [615][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0594 (0.0594)	
0.9999844 8.568087e-06
===========>   testing    <===========
Epoch: [615][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0412 (0.0412)	
0.999974 5.1057664e-06
Epoch: [615][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0219 (0.0609)	
0.9999896 5.231977e-06
Epoch: [615][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0579 (0.0592)	
0.99997723 5.0737785e-06
loss:  0.044258835045806744 0.04358056267270216
===========>   training    <===========
Epoch: [616][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0465 (0.0465)	
0.9999869 5.421816e-06
===========>   testing    <===========
Epoch: [616][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0433 (0.0433)	
0.99997056 5.6207186e-06
Epoch: [616][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0205 (0.0593)	
0.99998903 5.357582e-06
Epoch: [616][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0752 (0.0578)	
0.9999808 5.590178e-06
loss:  0.043584024109704744 0.04358056267270216
===========>   training    <===========
Epoch: [617][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0451 (0.0451)	
0.9999802 3.3161807e-06
===========>   testing    <===========
Epoch: [617][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0382 (0.0382)	
0.9999695 5.331226e-06
Epoch: [617][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0196 (0.0609)	
0.99998474 5.6121326e-06
Epoch: [617][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0772 (0.0590)	
0.9999776 5.030753e-06
loss:  0.044708483801767285 0.04358056267270216
===========>   training    <===========
Epoch: [618][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0454 (0.0454)	
0.9999852 4.7797494e-06
===========>   testing    <===========
Epoch: [618][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0502 (0.0502)	
0.99997234 5.2773835e-06
Epoch: [618][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0229 (0.0692)	
0.9999914 7.0423366e-06
Epoch: [618][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0856 (0.0644)	
0.999982 5.0045014e-06
loss:  0.046837948049611056 0.04358056267270216
===========>   training    <===========
Epoch: [619][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0586 (0.0586)	
0.9999888 6.268793e-06
===========>   testing    <===========
Epoch: [619][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0414 (0.0414)	
0.99998176 4.9325936e-06
Epoch: [619][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0258 (0.0644)	
0.9999912 4.867369e-06
Epoch: [619][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0643 (0.0630)	
0.9999857 4.639807e-06
loss:  0.045848469604492625 0.04358056267270216
===========>   training    <===========
Epoch: [620][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0472 (0.0472)	
0.99998534 9.564939e-06
===========>   testing    <===========
Epoch: [620][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0403 (0.0403)	
0.99998295 4.7092285e-06
Epoch: [620][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0202 (0.0645)	
0.9999901 4.4248914e-06
Epoch: [620][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0657 (0.0624)	
0.9999877 4.480475e-06
loss:  0.04529749607033562 0.04358056267270216
===========>   training    <===========
Epoch: [621][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0589 (0.0589)	
0.9999931 6.965305e-06
===========>   testing    <===========
Epoch: [621][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0420 (0.0420)	
0.99998546 4.0973555e-06
Epoch: [621][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0192 (0.0602)	
0.99999094 3.5069597e-06
Epoch: [621][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.1178 (0.0622)	
0.99998593 4.389083e-06
loss:  0.04522922707251498 0.04358056267270216
===========>   training    <===========
Epoch: [622][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0507 (0.0507)	
0.9999862 3.8243174e-06
===========>   testing    <===========
Epoch: [622][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0386 (0.0386)	
0.9999857 4.7397903e-06
Epoch: [622][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0210 (0.0603)	
0.9999951 4.9139207e-06
Epoch: [622][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.1497 (0.0612)	
0.999984 4.5087872e-06
loss:  0.04459688558238861 0.04358056267270216
===========>   training    <===========
Epoch: [623][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0430 (0.0430)	
0.99997973 3.2623316e-06
===========>   testing    <===========
Epoch: [623][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0357 (0.0357)	
0.9999851 4.954586e-06
Epoch: [623][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0229 (0.0620)	
0.9999938 6.385128e-06
Epoch: [623][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.1104 (0.0616)	
0.99997926 4.6540895e-06
loss:  0.04568982279285916 0.04358056267270216
===========>   training    <===========
Epoch: [624][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0434 (0.0434)	
0.99999475 6.2244185e-06
===========>   testing    <===========
Epoch: [624][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0297 (0.0297)	
0.99998116 6.6122598e-06
Epoch: [624][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0229 (0.0599)	
0.9999883 6.2991226e-06
Epoch: [624][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0954 (0.0610)	
0.99997866 6.594042e-06
loss:  0.04489059054272648 0.04358056267270216
===========>   training    <===========
Epoch: [625][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0529 (0.0529)	
0.9999949 5.369075e-06
===========>   testing    <===========
Epoch: [625][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0289 (0.0289)	
0.999984 4.8907177e-06
Epoch: [625][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0187 (0.0606)	
0.9999914 6.0152433e-06
Epoch: [625][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0886 (0.0621)	
0.99998164 4.874105e-06
loss:  0.045281629309440574 0.04358056267270216
===========>   training    <===========
Epoch: [626][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0491 (0.0491)	
0.9999769 4.4309554e-06
===========>   testing    <===========
Epoch: [626][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0339 (0.0339)	
0.99997616 7.3847236e-06
Epoch: [626][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0263 (0.0607)	
0.9999862 6.5882778e-06
Epoch: [626][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0497 (0.0606)	
0.99998283 7.419568e-06
loss:  0.045152913373659675 0.04358056267270216
===========>   training    <===========
Epoch: [627][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0478 (0.0478)	
0.99998426 4.569015e-06
===========>   testing    <===========
Epoch: [627][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0331 (0.0331)	
0.99998593 6.82699e-06
Epoch: [627][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0236 (0.0583)	
0.9999919 1.0588712e-05
Epoch: [627][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0894 (0.0605)	
0.9999839 6.4104975e-06
loss:  0.04473178424169444 0.04358056267270216
===========>   training    <===========
Epoch: [628][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0433 (0.0433)	
0.9999821 3.5270805e-06
===========>   testing    <===========
Epoch: [628][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0358 (0.0358)	
0.9999895 6.208477e-06
Epoch: [628][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0207 (0.0596)	
0.99999464 7.859195e-06
Epoch: [628][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.1080 (0.0600)	
0.9999889 6.3037683e-06
loss:  0.044831676303795254 0.04358056267270216
===========>   training    <===========
Epoch: [629][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0482 (0.0482)	
0.99999 6.455362e-06
===========>   testing    <===========
Epoch: [629][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0335 (0.0335)	
0.9999815 6.0221764e-06
Epoch: [629][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0178 (0.0591)	
0.99999 4.7747926e-06
Epoch: [629][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0580 (0.0590)	
0.999984 7.155037e-06
loss:  0.04434323675684104 0.04358056267270216
===========>   training    <===========
Epoch: [630][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0421 (0.0421)	
0.99998784 5.1081574e-06
===========>   testing    <===========
Epoch: [630][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0444 (0.0444)	
0.99998 6.2780787e-06
Epoch: [630][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0225 (0.0597)	
0.9999846 4.9191676e-06
Epoch: [630][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0622 (0.0603)	
0.99997723 9.090326e-06
loss:  0.04481021267340668 0.04358056267270216
===========>   training    <===========
Epoch: [631][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0587 (0.0587)	
0.99998486 1.8553463e-06
===========>   testing    <===========
Epoch: [631][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0437 (0.0437)	
0.9999833 7.9367965e-06
Epoch: [631][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0279 (0.0573)	
0.9999833 6.2653567e-06
Epoch: [631][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.1552 (0.0597)	
0.999984 8.5386555e-06
loss:  0.04446103325555251 0.04358056267270216
===========>   training    <===========
Epoch: [632][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0535 (0.0535)	
0.99998474 1.0935651e-05
===========>   testing    <===========
Epoch: [632][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0479 (0.0479)	
0.9999912 4.737833e-06
Epoch: [632][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0530 (0.0616)	
0.99999046 4.111686e-06
Epoch: [632][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0639 (0.0622)	
0.99998975 5.5091245e-06
loss:  0.046387553290305084 0.04358056267270216
===========>   training    <===========
Epoch: [633][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0459 (0.0459)	
0.99998224 3.7118627e-06
===========>   testing    <===========
Epoch: [633][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0406 (0.0406)	
0.9999851 4.3674468e-06
Epoch: [633][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0200 (0.0581)	
0.99998605 4.0106247e-06
Epoch: [633][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0883 (0.0600)	
0.99998593 4.041071e-06
loss:  0.042808586076306554 0.04358056267270216
===========>   training    <===========
Epoch: [634][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0401 (0.0401)	
0.9999865 2.5843612e-05
===========>   testing    <===========
Epoch: [634][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0471 (0.0471)	
0.99999046 5.641032e-06
Epoch: [634][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0215 (0.0592)	
0.99998844 5.69292e-06
Epoch: [634][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0859 (0.0625)	
0.99998724 7.476647e-06
loss:  0.04367149197449993 0.042808586076306554
===========>   training    <===========
Epoch: [635][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0440 (0.0440)	
0.9999889 6.7426026e-06
===========>   testing    <===========
Epoch: [635][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0350 (0.0350)	
0.99999 5.1852703e-06
Epoch: [635][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0228 (0.0615)	
0.99999225 4.3441178e-06
Epoch: [635][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.1274 (0.0643)	
0.9999893 5.2925748e-06
loss:  0.04481295141777053 0.042808586076306554
===========>   training    <===========
Epoch: [636][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0522 (0.0522)	
0.9999883 1.045382e-05
===========>   testing    <===========
Epoch: [636][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0469 (0.0469)	
0.99999094 4.6790924e-06
Epoch: [636][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0230 (0.0625)	
0.99999404 4.169872e-06
Epoch: [636][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.1059 (0.0632)	
0.99998903 4.449129e-06
loss:  0.04521437313414001 0.042808586076306554
===========>   training    <===========
Epoch: [637][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0515 (0.0515)	
0.9999939 8.461437e-06
===========>   testing    <===========
Epoch: [637][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0609 (0.0609)	
0.9999846 5.4958327e-06
Epoch: [637][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0203 (0.0628)	
0.9999933 5.900845e-06
Epoch: [637][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.1098 (0.0654)	
0.99998534 4.820298e-06
loss:  0.04569334779286838 0.042808586076306554
===========>   training    <===========
Epoch: [638][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0574 (0.0574)	
0.9999863 3.450486e-06
===========>   testing    <===========
Epoch: [638][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0584 (0.0584)	
0.9999919 4.6301484e-06
Epoch: [638][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0239 (0.0622)	
0.99998915 4.2649613e-06
Epoch: [638][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0469 (0.0627)	
0.9999882 4.689206e-06
loss:  0.045680461866213995 0.042808586076306554
===========>   training    <===========
Epoch: [639][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0401 (0.0401)	
0.9999883 7.332946e-06
===========>   testing    <===========
Epoch: [639][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0631 (0.0631)	
0.9999926 8.477841e-06
Epoch: [639][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0221 (0.0628)	
0.99999475 7.0641436e-06
Epoch: [639][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0868 (0.0632)	
0.99999166 6.706914e-06
loss:  0.04527580919861851 0.042808586076306554
===========>   training    <===========
Epoch: [640][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0533 (0.0533)	
0.9999894 4.4623616e-06
===========>   testing    <===========
Epoch: [640][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0537 (0.0537)	
0.9999888 3.7733803e-06
Epoch: [640][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0323 (0.0605)	
0.99999166 3.0559129e-06
Epoch: [640][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.1877 (0.0635)	
0.99998486 3.3583922e-06
loss:  0.046244187886304244 0.042808586076306554
===========>   training    <===========
Epoch: [641][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0467 (0.0467)	
0.99998915 3.8037408e-06
===========>   testing    <===========
Epoch: [641][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0373 (0.0373)	
0.9999877 4.921683e-06
Epoch: [641][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0291 (0.0611)	
0.9999927 4.804423e-06
Epoch: [641][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.1632 (0.0633)	
0.999985 5.4925317e-06
loss:  0.04515033647763966 0.042808586076306554
===========>   training    <===========
Epoch: [642][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0514 (0.0514)	
0.9999943 4.699422e-06
===========>   testing    <===========
Epoch: [642][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0443 (0.0443)	
0.99998844 5.1631146e-06
Epoch: [642][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0351 (0.0612)	
0.9999937 4.9001014e-06
Epoch: [642][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0811 (0.0611)	
0.999987 4.9016207e-06
loss:  0.04569581130048139 0.042808586076306554
===========>   training    <===========
Epoch: [643][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0539 (0.0539)	
0.99998844 3.5658873e-06
===========>   testing    <===========
Epoch: [643][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0366 (0.0366)	
0.9999919 6.4652754e-06
Epoch: [643][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0556 (0.0583)	
0.9999925 5.037652e-06
Epoch: [643][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.1052 (0.0609)	
0.99998844 4.7887015e-06
loss:  0.04364351512021547 0.042808586076306554
===========>   training    <===========
Epoch: [644][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0441 (0.0441)	
0.9999795 3.2194296e-06
===========>   testing    <===========
Epoch: [644][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0359 (0.0359)	
0.9999913 5.670915e-06
Epoch: [644][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0425 (0.0630)	
0.9999918 4.204822e-06
Epoch: [644][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.1285 (0.0612)	
0.99998987 4.841148e-06
loss:  0.044162336319301665 0.042808586076306554
===========>   training    <===========
Epoch: [645][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0601 (0.0601)	
0.9999901 3.018088e-06
===========>   testing    <===========
Epoch: [645][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0641 (0.0641)	
0.9999931 5.6125123e-06
Epoch: [645][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0452 (0.0648)	
0.9999894 4.993384e-06
Epoch: [645][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.1260 (0.0653)	
0.99998283 3.946643e-06
loss:  0.046353053223616825 0.042808586076306554
===========>   training    <===========
Epoch: [646][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0477 (0.0477)	
0.99999523 1.824356e-05
===========>   testing    <===========
Epoch: [646][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0366 (0.0366)	
0.9999914 3.6192312e-06
Epoch: [646][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0224 (0.0614)	
0.9999894 3.5390349e-06
Epoch: [646][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.1826 (0.0661)	
0.9999864 3.2545533e-06
loss:  0.045826917573607906 0.042808586076306554
===========>   training    <===========
Epoch: [647][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0497 (0.0497)	
0.9999864 2.3822336e-06
===========>   testing    <===========
Epoch: [647][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0316 (0.0316)	
0.9999887 5.471755e-06
Epoch: [647][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0219 (0.0610)	
0.99999464 4.449163e-06
Epoch: [647][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.1240 (0.0607)	
0.9999863 5.7717384e-06
loss:  0.044427193494837924 0.042808586076306554
===========>   training    <===========
Epoch: [648][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0413 (0.0413)	
0.99998736 3.538785e-06
===========>   testing    <===========
Epoch: [648][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0313 (0.0313)	
0.9999895 6.621005e-06
Epoch: [648][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0259 (0.0598)	
0.9999945 5.5579058e-06
Epoch: [648][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.1089 (0.0608)	
0.9999912 7.830324e-06
loss:  0.04368396804578889 0.042808586076306554
===========>   training    <===========
Epoch: [649][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0535 (0.0535)	
0.99997926 5.2836285e-06
===========>   testing    <===========
Epoch: [649][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0352 (0.0352)	
0.9999883 4.375935e-06
Epoch: [649][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0585 (0.0623)	
0.9999927 3.8552016e-06
Epoch: [649][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0834 (0.0608)	
0.9999906 3.6131166e-06
loss:  0.044943836697711514 0.042808586076306554
===========>   training    <===========
Epoch: [650][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0485 (0.0485)	
0.9999864 2.7906794e-06
===========>   testing    <===========
Epoch: [650][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0323 (0.0323)	
0.9999857 4.8516863e-06
Epoch: [650][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0330 (0.0654)	
0.99998975 4.342925e-06
Epoch: [650][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.1633 (0.0631)	
0.9999852 4.0925524e-06
loss:  0.04559821806544673 0.042808586076306554
===========>   training    <===========
Epoch: [651][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0487 (0.0487)	
0.99998915 4.941389e-06
===========>   testing    <===========
Epoch: [651][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0323 (0.0323)	
0.9999782 5.3448234e-06
Epoch: [651][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0408 (0.0611)	
0.9999925 4.580039e-06
Epoch: [651][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.1506 (0.0602)	
0.9999802 5.923217e-06
loss:  0.04480837838301466 0.042808586076306554
===========>   training    <===========
Epoch: [652][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0533 (0.0533)	
0.9999931 3.3777767e-06
===========>   testing    <===========
Epoch: [652][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0480 (0.0480)	
0.999967 4.5874312e-06
Epoch: [652][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0496 (0.0635)	
0.9999857 4.0069776e-06
Epoch: [652][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.1022 (0.0606)	
0.9999763 4.3218365e-06
loss:  0.04509965234696012 0.042808586076306554
===========>   training    <===========
Epoch: [653][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0390 (0.0390)	
0.99998975 3.8865564e-06
===========>   testing    <===========
Epoch: [653][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0330 (0.0330)	
0.99998677 8.286573e-06
Epoch: [653][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0297 (0.0653)	
0.9999839 8.136216e-06
Epoch: [653][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0742 (0.0636)	
0.999982 6.5931367e-06
loss:  0.04545004795834695 0.042808586076306554
===========>   training    <===========
Epoch: [654][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0476 (0.0476)	
0.99998176 4.1691887e-06
===========>   testing    <===========
Epoch: [654][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0440 (0.0440)	
0.9999821 9.652643e-06
Epoch: [654][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0282 (0.0619)	
0.9999882 5.6211634e-06
Epoch: [654][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0726 (0.0603)	
0.99998164 7.451093e-06
loss:  0.04462207133477458 0.042808586076306554
===========>   training    <===========
Epoch: [655][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0482 (0.0482)	
0.9999893 8.267219e-06
===========>   testing    <===========
Epoch: [655][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0389 (0.0389)	
0.9999844 6.4490246e-06
Epoch: [655][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0444 (0.0673)	
0.9999938 4.8814222e-06
Epoch: [655][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0881 (0.0641)	
0.999985 4.712113e-06
loss:  0.04562555076633945 0.042808586076306554
===========>   training    <===========
Epoch: [656][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0630 (0.0630)	
0.99999094 6.684616e-06
===========>   testing    <===========
Epoch: [656][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0643 (0.0643)	
0.99998975 7.951768e-06
Epoch: [656][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0296 (0.0786)	
0.9999912 8.037731e-06
Epoch: [656][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.1387 (0.0752)	
0.99998915 5.219762e-06
loss:  0.05212332387990026 0.042808586076306554
===========>   training    <===========
Epoch: [657][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0503 (0.0503)	
0.999987 3.803414e-06
===========>   testing    <===========
Epoch: [657][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0442 (0.0442)	
0.99998915 5.0203525e-06
Epoch: [657][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0335 (0.0641)	
0.9999895 6.371053e-06
Epoch: [657][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.2239 (0.0670)	
0.99998844 4.282867e-06
loss:  0.04656830200734485 0.042808586076306554
===========>   training    <===========
Epoch: [658][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0541 (0.0541)	
0.99999344 8.130926e-06
===========>   testing    <===========
Epoch: [658][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0392 (0.0392)	
0.99998903 6.627145e-06
Epoch: [658][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0320 (0.0643)	
0.99998367 6.529076e-06
Epoch: [658][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.1705 (0.0636)	
0.9999863 5.932873e-06
loss:  0.04441966558967292 0.042808586076306554
===========>   training    <===========
Epoch: [659][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0440 (0.0440)	
0.9999943 2.2032923e-06
===========>   testing    <===========
Epoch: [659][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0423 (0.0423)	
0.99998724 4.699489e-06
Epoch: [659][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0286 (0.0615)	
0.99998796 4.4552094e-06
Epoch: [659][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.1964 (0.0606)	
0.9999858 3.863748e-06
loss:  0.043063589417949966 0.042808586076306554
===========>   training    <===========
Epoch: [660][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0460 (0.0460)	
0.99999106 3.1333025e-06
===========>   testing    <===========
Epoch: [660][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0313 (0.0313)	
0.9999944 4.828685e-06
Epoch: [660][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0294 (0.0630)	
0.99999523 5.242281e-06
Epoch: [660][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.1824 (0.0633)	
0.99999297 4.379012e-06
loss:  0.04485449492553417 0.042808586076306554
===========>   training    <===========
Epoch: [661][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0392 (0.0392)	
0.9999715 2.8984398e-06
===========>   testing    <===========
Epoch: [661][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0398 (0.0398)	
0.9999846 3.979589e-06
Epoch: [661][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0263 (0.0653)	
0.99998784 3.5327696e-06
Epoch: [661][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0883 (0.0615)	
0.99998033 5.186803e-06
loss:  0.04531085231400511 0.042808586076306554
===========>   training    <===========
Epoch: [662][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0537 (0.0537)	
0.99998176 2.5584018e-06
===========>   testing    <===========
Epoch: [662][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0362 (0.0362)	
0.99998355 2.7289702e-06
Epoch: [662][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0456 (0.0612)	
0.99998534 2.7707163e-06
Epoch: [662][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.1403 (0.0604)	
0.9999695 3.3910649e-06
loss:  0.04418513061747542 0.042808586076306554
===========>   training    <===========
Epoch: [663][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0376 (0.0376)	
0.9999857 7.733964e-06
===========>   testing    <===========
Epoch: [663][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0336 (0.0336)	
0.9999869 5.7063726e-06
Epoch: [663][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0295 (0.0617)	
0.9999856 5.0249896e-06
Epoch: [663][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.1120 (0.0612)	
0.9999814 5.973215e-06
loss:  0.04419478780737729 0.042808586076306554
===========>   training    <===========
Epoch: [664][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0456 (0.0456)	
0.99998665 4.3717846e-06
===========>   testing    <===========
Epoch: [664][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0439 (0.0439)	
0.9999949 4.604494e-06
Epoch: [664][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0321 (0.0662)	
0.99997437 4.772002e-06
Epoch: [664][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0541 (0.0622)	
0.99998474 5.4637662e-06
loss:  0.04645081451518773 0.042808586076306554
===========>   training    <===========
Epoch: [665][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0394 (0.0394)	
0.99999166 4.6484693e-06
===========>   testing    <===========
Epoch: [665][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0387 (0.0387)	
0.99999166 5.1800116e-06
Epoch: [665][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0330 (0.0596)	
0.9999827 4.8689153e-06
Epoch: [665][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0665 (0.0599)	
0.9999858 5.1688244e-06
loss:  0.04378482268654471 0.042808586076306554
===========>   training    <===========
Epoch: [666][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0573 (0.0573)	
0.99998796 1.1733093e-05
===========>   testing    <===========
Epoch: [666][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0454 (0.0454)	
0.999987 4.440787e-06
Epoch: [666][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0322 (0.0589)	
0.99998343 4.5323995e-06
Epoch: [666][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0490 (0.0585)	
0.99998486 4.293147e-06
loss:  0.04417747865645216 0.042808586076306554
===========>   training    <===========
Epoch: [667][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0480 (0.0480)	
0.9999776 3.0396711e-06
===========>   testing    <===========
Epoch: [667][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0467 (0.0467)	
0.9999862 5.6269987e-06
Epoch: [667][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0389 (0.0637)	
0.99998295 5.6160998e-06
Epoch: [667][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.1077 (0.0623)	
0.9999808 4.8013453e-06
loss:  0.04577750439571571 0.042808586076306554
===========>   training    <===========
Epoch: [668][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0445 (0.0445)	
0.9999831 7.779441e-07
===========>   testing    <===========
Epoch: [668][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0365 (0.0365)	
0.99998736 7.4519457e-06
Epoch: [668][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0343 (0.0584)	
0.9999882 8.190727e-06
Epoch: [668][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.1358 (0.0564)	
0.99997854 5.498789e-06
loss:  0.042966984680888665 0.042808586076306554
===========>   training    <===========
Epoch: [669][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0554 (0.0554)	
0.9999666 4.2932497e-06
===========>   testing    <===========
Epoch: [669][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0584 (0.0584)	
0.99998367 1.0622636e-05
Epoch: [669][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0613 (0.0629)	
0.99998975 1.0115818e-05
Epoch: [669][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0722 (0.0606)	
0.9999858 7.3307515e-06
loss:  0.04557583331710624 0.042808586076306554
===========>   training    <===========
Epoch: [670][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0447 (0.0447)	
0.9999733 1.1048e-06
===========>   testing    <===========
Epoch: [670][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0549 (0.0549)	
0.9999852 6.9802923e-06
Epoch: [670][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0268 (0.0617)	
0.9999863 7.050945e-06
Epoch: [670][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.1384 (0.0627)	
0.99997985 6.1476794e-06
loss:  0.04552051612595953 0.042808586076306554
===========>   training    <===========
Epoch: [671][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0571 (0.0571)	
0.99998593 2.5962975e-06
===========>   testing    <===========
Epoch: [671][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0320 (0.0320)	
0.9999889 5.9351933e-06
Epoch: [671][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0323 (0.0593)	
0.99998784 5.9203308e-06
Epoch: [671][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0796 (0.0602)	
0.9999821 5.3036606e-06
loss:  0.04544373290171111 0.042808586076306554
===========>   training    <===========
Epoch: [672][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0529 (0.0529)	
0.9999747 3.3970628e-06
===========>   testing    <===========
Epoch: [672][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0602 (0.0602)	
0.99998534 6.1644114e-06
Epoch: [672][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0533 (0.0643)	
0.9999939 7.155378e-06
Epoch: [672][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0876 (0.0643)	
0.99998593 4.8691054e-06
loss:  0.0474364225156102 0.042808586076306554
===========>   training    <===========
Epoch: [673][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0537 (0.0537)	
0.9999739 1.8972952e-06
===========>   testing    <===========
Epoch: [673][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0705 (0.0705)	
0.9999913 7.2093676e-06
Epoch: [673][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0377 (0.0590)	
0.9999943 6.7342685e-06
Epoch: [673][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0676 (0.0605)	
0.99998784 5.5418373e-06
loss:  0.04565660951178008 0.042808586076306554
===========>   training    <===========
Epoch: [674][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0526 (0.0526)	
0.99998724 3.2145513e-06
===========>   testing    <===========
Epoch: [674][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0445 (0.0445)	
0.9999896 5.2096366e-06
Epoch: [674][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0273 (0.0620)	
0.99998844 5.886069e-06
Epoch: [674][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.1746 (0.0643)	
0.9999858 4.2305487e-06
loss:  0.045282752423495 0.042808586076306554
===========>   training    <===========
Epoch: [675][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0494 (0.0494)	
0.9999882 2.0865584e-06
===========>   testing    <===========
Epoch: [675][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0771 (0.0771)	
0.99998987 4.776218e-06
Epoch: [675][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0222 (0.0583)	
0.9999888 3.8392486e-06
Epoch: [675][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.1809 (0.0596)	
0.99998665 4.605258e-06
loss:  0.044157820596394504 0.042808586076306554
===========>   training    <===========
Epoch: [676][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0514 (0.0514)	
0.99999285 2.137817e-06
===========>   testing    <===========
Epoch: [676][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0873 (0.0873)	
0.99998283 3.8203293e-06
Epoch: [676][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0249 (0.0584)	
0.999992 3.190287e-06
Epoch: [676][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0905 (0.0590)	
0.999982 3.7775822e-06
loss:  0.04492561478025714 0.042808586076306554
===========>   training    <===========
Epoch: [677][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0470 (0.0470)	
0.9999907 1.823484e-06
===========>   testing    <===========
Epoch: [677][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0625 (0.0625)	
0.99998987 4.51194e-06
Epoch: [677][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0272 (0.0575)	
0.9999896 3.536417e-06
Epoch: [677][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.1514 (0.0596)	
0.9999894 4.463179e-06
loss:  0.044667156623672155 0.042808586076306554
===========>   training    <===========
Epoch: [678][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0520 (0.0520)	
0.9999883 1.8329462e-06
===========>   testing    <===========
Epoch: [678][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0454 (0.0454)	
0.99998224 4.729184e-06
Epoch: [678][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0243 (0.0566)	
0.9999794 3.9548227e-06
Epoch: [678][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.1148 (0.0592)	
0.99998486 5.0261688e-06
loss:  0.044733729894546936 0.042808586076306554
===========>   training    <===========
Epoch: [679][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0581 (0.0581)	
0.9999889 4.129176e-06
===========>   testing    <===========
Epoch: [679][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0490 (0.0490)	
0.99999225 4.2482484e-06
Epoch: [679][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0257 (0.0582)	
0.99999106 3.804568e-06
Epoch: [679][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.1138 (0.0569)	
0.99999154 4.5057955e-06
loss:  0.04378683849232767 0.042808586076306554
===========>   training    <===========
Epoch: [680][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0506 (0.0506)	
0.99999094 5.2424257e-06
===========>   testing    <===========
Epoch: [680][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0415 (0.0415)	
0.9999858 3.4744555e-06
Epoch: [680][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0292 (0.0572)	
0.99998474 4.0316627e-06
Epoch: [680][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0765 (0.0567)	
0.9999864 4.4188946e-06
loss:  0.04391651313369538 0.042808586076306554
===========>   training    <===========
Epoch: [681][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0463 (0.0463)	
0.9999926 8.30492e-06
===========>   testing    <===========
Epoch: [681][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0399 (0.0399)	
0.99998724 5.634162e-06
Epoch: [681][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0459 (0.0599)	
0.99997306 5.730221e-06
Epoch: [681][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.1134 (0.0579)	
0.99998593 5.8159912e-06
loss:  0.044434473409458164 0.042808586076306554
===========>   training    <===========
Epoch: [682][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0400 (0.0400)	
0.9999672 2.9733803e-06
===========>   testing    <===========
Epoch: [682][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0389 (0.0389)	
0.9999918 6.9118187e-06
Epoch: [682][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0362 (0.0592)	
0.9999881 8.936798e-06
Epoch: [682][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.1157 (0.0589)	
0.99998975 6.484986e-06
loss:  0.04442425783775905 0.042808586076306554
===========>   training    <===========
Epoch: [683][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0513 (0.0513)	
0.9999839 5.1340767e-06
===========>   testing    <===========
Epoch: [683][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0516 (0.0516)	
0.9999869 6.3496295e-06
Epoch: [683][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0824 (0.0573)	
0.999987 5.729505e-06
Epoch: [683][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.1596 (0.0587)	
0.9999832 5.2209175e-06
loss:  0.04466438613390633 0.042808586076306554
===========>   training    <===========
Epoch: [684][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0437 (0.0437)	
0.9999857 1.0714335e-05
===========>   testing    <===========
Epoch: [684][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0436 (0.0436)	
0.99998224 5.7866796e-06
Epoch: [684][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0662 (0.0575)	
0.9999851 5.9424315e-06
Epoch: [684][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.1110 (0.0582)	
0.9999813 5.175577e-06
loss:  0.043451262757734255 0.042808586076306554
===========>   training    <===========
Epoch: [685][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0434 (0.0434)	
0.99999166 4.472198e-06
===========>   testing    <===========
Epoch: [685][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0387 (0.0387)	
0.9999881 4.051907e-06
Epoch: [685][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0441 (0.0614)	
0.99998343 4.8530096e-06
Epoch: [685][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.1368 (0.0605)	
0.9999825 4.911321e-06
loss:  0.04383763326203949 0.042808586076306554
===========>   training    <===========
Epoch: [686][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0471 (0.0471)	
0.99998 2.841376e-06
===========>   testing    <===========
Epoch: [686][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0405 (0.0405)	
0.999987 4.7630906e-06
Epoch: [686][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0416 (0.0578)	
0.99998033 4.3271443e-06
Epoch: [686][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.1756 (0.0578)	
0.99997735 5.3122144e-06
loss:  0.043599709388322694 0.042808586076306554
===========>   training    <===========
Epoch: [687][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0451 (0.0451)	
0.9999887 2.9767282e-06
===========>   testing    <===========
Epoch: [687][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0329 (0.0329)	
0.9999901 4.439652e-06
Epoch: [687][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0460 (0.0632)	
0.99998105 3.8733365e-06
Epoch: [687][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.1213 (0.0588)	
0.99998367 4.2214e-06
loss:  0.04416572453582668 0.042808586076306554
===========>   training    <===========
Epoch: [688][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0383 (0.0383)	
0.9999912 1.4131226e-05
===========>   testing    <===========
Epoch: [688][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0370 (0.0370)	
0.99998975 3.2078296e-06
Epoch: [688][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0653 (0.0571)	
0.9999875 2.9231956e-06
Epoch: [688][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.1745 (0.0585)	
0.99998295 3.2348298e-06
loss:  0.043599970629014106 0.042808586076306554
===========>   training    <===========
Epoch: [689][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0512 (0.0512)	
0.999987 3.702388e-06
===========>   testing    <===========
Epoch: [689][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0330 (0.0330)	
0.99999404 5.203668e-06
Epoch: [689][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0305 (0.0581)	
0.99999464 6.1168366e-06
Epoch: [689][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.1849 (0.0601)	
0.9999918 4.472151e-06
loss:  0.043495990485307945 0.042808586076306554
===========>   training    <===========
Epoch: [690][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0415 (0.0415)	
0.9999927 3.628611e-06
===========>   testing    <===========
Epoch: [690][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0479 (0.0479)	
0.9999894 5.1116713e-06
Epoch: [690][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0257 (0.0601)	
0.99999547 5.69639e-06
Epoch: [690][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.1256 (0.0598)	
0.9999869 4.9356668e-06
loss:  0.04317102673543238 0.042808586076306554
===========>   training    <===========
Epoch: [691][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0474 (0.0474)	
0.9999807 2.5128375e-06
===========>   testing    <===========
Epoch: [691][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0518 (0.0518)	
0.999985 4.4378103e-06
Epoch: [691][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0374 (0.0600)	
0.9999932 4.4659546e-06
Epoch: [691][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.1559 (0.0583)	
0.99998283 3.9973474e-06
loss:  0.043418752984204056 0.042808586076306554
===========>   training    <===========
Epoch: [692][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0432 (0.0432)	
0.9999908 8.6467235e-06
===========>   testing    <===========
Epoch: [692][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0455 (0.0455)	
0.999984 4.927516e-06
Epoch: [692][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0504 (0.0622)	
0.9999896 4.7892313e-06
Epoch: [692][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.1241 (0.0607)	
0.9999815 4.7060594e-06
loss:  0.04286728618170288 0.042808586076306554
===========>   training    <===========
Epoch: [693][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0444 (0.0444)	
0.99998355 9.498054e-06
===========>   testing    <===========
Epoch: [693][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0296 (0.0296)	
0.9999738 3.6691852e-06
Epoch: [693][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0387 (0.0597)	
0.999982 3.3559686e-06
Epoch: [693][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.2236 (0.0607)	
0.99997747 3.0419503e-06
loss:  0.04356616854150486 0.042808586076306554
===========>   training    <===========
Epoch: [694][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0499 (0.0499)	
0.9999815 6.0243938e-06
===========>   testing    <===========
Epoch: [694][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0361 (0.0361)	
0.9999888 6.4924616e-06
Epoch: [694][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0395 (0.0603)	
0.99999595 6.1447836e-06
Epoch: [694][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.1138 (0.0593)	
0.9999919 6.2389554e-06
loss:  0.04327969803464693 0.042808586076306554
===========>   training    <===========
Epoch: [695][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0479 (0.0479)	
0.9999833 3.823464e-06
===========>   testing    <===========
Epoch: [695][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0326 (0.0326)	
0.99998355 6.4499773e-06
Epoch: [695][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0605 (0.0595)	
0.99999213 6.0745742e-06
Epoch: [695][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0865 (0.0574)	
0.99998665 6.6044454e-06
loss:  0.04320346599631997 0.042808586076306554
===========>   training    <===========
Epoch: [696][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0490 (0.0490)	
0.9999937 1.465293e-05
===========>   testing    <===========
Epoch: [696][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0483 (0.0483)	
0.9999815 5.1178467e-06
Epoch: [696][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0719 (0.0603)	
0.9999889 4.5138854e-06
Epoch: [696][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0961 (0.0581)	
0.99998033 5.255756e-06
loss:  0.042687158922881996 0.042808586076306554
===========>   training    <===========
Epoch: [697][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0425 (0.0425)	
0.99999213 2.9657763e-06
===========>   testing    <===========
Epoch: [697][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0426 (0.0426)	
0.99998665 4.749392e-06
Epoch: [697][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0369 (0.0606)	
0.99998784 4.5348124e-06
Epoch: [697][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.1253 (0.0590)	
0.99998176 4.4788776e-06
loss:  0.04346666248740816 0.042687158922881996
===========>   training    <===========
Epoch: [698][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0621 (0.0621)	
0.9999896 2.4749204e-06
===========>   testing    <===========
Epoch: [698][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0411 (0.0411)	
0.9999846 5.0359326e-06
Epoch: [698][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0390 (0.0618)	
0.9999887 5.786277e-06
Epoch: [698][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.1667 (0.0611)	
0.99998486 4.5377888e-06
loss:  0.0443869602680661 0.042687158922881996
===========>   training    <===========
Epoch: [699][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0463 (0.0463)	
0.9999938 1.0411748e-06
===========>   testing    <===========
Epoch: [699][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0346 (0.0346)	
0.9999918 4.2105e-06
Epoch: [699][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0258 (0.0579)	
0.9999925 5.1817756e-06
Epoch: [699][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.1679 (0.0579)	
0.9999883 4.565095e-06
loss:  0.04234528818377192 0.042687158922881996
===========>   training    <===========
Epoch: [700][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0524 (0.0524)	
0.99998057 9.335772e-06
===========>   testing    <===========
Epoch: [700][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0434 (0.0434)	
0.9999902 4.5830366e-06
Epoch: [700][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0315 (0.0580)	
0.9999951 4.0303635e-06
Epoch: [700][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.1445 (0.0585)	
0.9999887 5.306255e-06
loss:  0.042560630820008494 0.04234528818377192
===========>   training    <===========
Epoch: [701][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0419 (0.0419)	
0.9999838 1.8961339e-06
===========>   testing    <===========
Epoch: [701][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0374 (0.0374)	
0.9999876 5.0905583e-06
Epoch: [701][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0254 (0.0597)	
0.9999933 3.8180274e-06
Epoch: [701][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.1672 (0.0595)	
0.999987 4.807696e-06
loss:  0.04315960363233784 0.04234528818377192
===========>   training    <===========
Epoch: [702][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0465 (0.0465)	
0.99998546 2.936641e-06
===========>   testing    <===========
Epoch: [702][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0356 (0.0356)	
0.9999901 3.752724e-06
Epoch: [702][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0315 (0.0606)	
0.9999945 2.8174259e-06
Epoch: [702][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0974 (0.0606)	
0.99998903 4.28187e-06
loss:  0.043015644866526204 0.04234528818377192
===========>   training    <===========
Epoch: [703][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0407 (0.0407)	
0.9999857 1.8793911e-06
===========>   testing    <===========
Epoch: [703][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0354 (0.0354)	
0.99998796 3.953993e-06
Epoch: [703][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0459 (0.0600)	
0.99999213 3.5375538e-06
Epoch: [703][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.1092 (0.0619)	
0.9999857 5.418859e-06
loss:  0.04388366869511395 0.04234528818377192
===========>   training    <===========
Epoch: [704][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0502 (0.0502)	
0.9999809 2.5878553e-06
===========>   testing    <===========
Epoch: [704][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0729 (0.0729)	
0.99999034 4.003658e-06
Epoch: [704][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0280 (0.0590)	
0.99999046 3.574675e-06
Epoch: [704][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0927 (0.0600)	
0.999987 4.709651e-06
loss:  0.04388841843918079 0.04234528818377192
===========>   training    <===========
Epoch: [705][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0473 (0.0473)	
0.9999819 2.969127e-06
===========>   testing    <===========
Epoch: [705][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0508 (0.0508)	
0.99998903 4.1386224e-06
Epoch: [705][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0300 (0.0610)	
0.99998057 3.4704353e-06
Epoch: [705][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0997 (0.0590)	
0.99998343 4.2147503e-06
loss:  0.044463125283522364 0.04234528818377192
===========>   training    <===========
Epoch: [706][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0382 (0.0382)	
0.9999882 2.9098671e-06
===========>   testing    <===========
Epoch: [706][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0365 (0.0365)	
0.99998784 5.45645e-06
Epoch: [706][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0249 (0.0600)	
0.99998355 5.255265e-06
Epoch: [706][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.2106 (0.0604)	
0.9999831 3.8665567e-06
loss:  0.04452849574780726 0.04234528818377192
===========>   training    <===========
Epoch: [707][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0423 (0.0423)	
0.99999046 4.3213754e-06
===========>   testing    <===========
Epoch: [707][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0304 (0.0304)	
0.9999901 4.783849e-06
Epoch: [707][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0230 (0.0600)	
0.9999943 5.5926203e-06
Epoch: [707][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0685 (0.0590)	
0.9999858 4.70597e-06
loss:  0.04283043625540228 0.04234528818377192
===========>   training    <===========
Epoch: [708][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0475 (0.0475)	
0.9999931 3.6181266e-06
===========>   testing    <===========
Epoch: [708][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0283 (0.0283)	
0.9999912 4.5926267e-06
Epoch: [708][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0312 (0.0602)	
0.9999933 4.3232717e-06
Epoch: [708][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.1693 (0.0621)	
0.99998736 4.509858e-06
loss:  0.04535918029846331 0.04234528818377192
===========>   training    <===========
Epoch: [709][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0510 (0.0510)	
0.999979 4.537434e-06
===========>   testing    <===========
Epoch: [709][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0431 (0.0431)	
0.9999926 5.8843625e-06
Epoch: [709][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0288 (0.0602)	
0.9999939 6.9317152e-06
Epoch: [709][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0716 (0.0610)	
0.9999869 6.1822266e-06
loss:  0.04411339552191773 0.04234528818377192
===========>   training    <===========
Epoch: [710][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0461 (0.0461)	
0.9999888 3.1680179e-06
===========>   testing    <===========
Epoch: [710][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0415 (0.0415)	
0.9999919 5.4434513e-06
Epoch: [710][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0371 (0.0626)	
0.99999404 6.827745e-06
Epoch: [710][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.1096 (0.0608)	
0.9999906 5.659143e-06
loss:  0.04434534393530787 0.04234528818377192
===========>   training    <===========
Epoch: [711][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0389 (0.0389)	
0.9999925 2.408678e-05
===========>   testing    <===========
Epoch: [711][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0450 (0.0450)	
0.999987 4.1080916e-06
Epoch: [711][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0240 (0.0565)	
0.9999906 3.5436483e-06
Epoch: [711][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0913 (0.0569)	
0.9999845 4.0043224e-06
loss:  0.042771228146539775 0.04234528818377192
===========>   training    <===========
Epoch: [712][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0381 (0.0381)	
0.9999914 2.6632104e-06
===========>   testing    <===========
Epoch: [712][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0455 (0.0455)	
0.9999912 3.4523623e-06
Epoch: [712][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0270 (0.0601)	
0.99999475 3.3766944e-06
Epoch: [712][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.1259 (0.0582)	
0.9999896 4.1597045e-06
loss:  0.04406527764913892 0.04234528818377192
===========>   training    <===========
Epoch: [713][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0455 (0.0455)	
0.9999895 2.3015095e-06
===========>   testing    <===========
Epoch: [713][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0346 (0.0346)	
0.9999851 4.0474115e-06
Epoch: [713][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0245 (0.0577)	
0.9999906 3.861799e-06
Epoch: [713][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.1191 (0.0575)	
0.99997556 4.6270497e-06
loss:  0.04209465628609743 0.04234528818377192
===========>   training    <===========
Epoch: [714][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0501 (0.0501)	
0.99999285 2.0092666e-06
===========>   testing    <===========
Epoch: [714][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0391 (0.0391)	
0.99998534 3.6508115e-06
Epoch: [714][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0334 (0.0597)	
0.9999924 3.3069557e-06
Epoch: [714][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.1358 (0.0598)	
0.9999856 4.030971e-06
loss:  0.04357272982394633 0.04209465628609743
===========>   training    <===========
Epoch: [715][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0485 (0.0485)	
0.9999809 2.2784584e-06
===========>   testing    <===========
Epoch: [715][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0330 (0.0330)	
0.9999882 3.8377184e-06
Epoch: [715][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0358 (0.0583)	
0.99998844 3.6018837e-06
Epoch: [715][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.1029 (0.0557)	
0.99998224 4.4987837e-06
loss:  0.04173826637396694 0.04209465628609743
===========>   training    <===========
Epoch: [716][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0447 (0.0447)	
0.99999225 3.0621063e-06
===========>   testing    <===========
Epoch: [716][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0513 (0.0513)	
0.999987 6.0763064e-06
Epoch: [716][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0355 (0.0591)	
0.9999908 5.6826516e-06
Epoch: [716][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.1303 (0.0577)	
0.99998665 5.599344e-06
loss:  0.04305921058539597 0.04173826637396694
===========>   training    <===========
Epoch: [717][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0545 (0.0545)	
0.99998665 7.3739e-06
===========>   testing    <===========
Epoch: [717][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0481 (0.0481)	
0.9999863 4.4532976e-06
Epoch: [717][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0282 (0.0599)	
0.99999344 4.756177e-06
Epoch: [717][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0687 (0.0575)	
0.9999832 2.632605e-06
loss:  0.042882765316381355 0.04173826637396694
===========>   training    <===========
Epoch: [718][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0671 (0.0671)	
0.9999937 4.8508537e-06
===========>   testing    <===========
Epoch: [718][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0386 (0.0386)	
0.99998903 2.7359201e-06
Epoch: [718][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0359 (0.0596)	
0.9999919 2.663449e-06
Epoch: [718][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0694 (0.0579)	
0.9999851 2.3533391e-06
loss:  0.04258373253502079 0.04173826637396694
===========>   training    <===========
Epoch: [719][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0520 (0.0520)	
0.999984 2.248431e-06
===========>   testing    <===========
Epoch: [719][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0556 (0.0556)	
0.9999933 4.798594e-06
Epoch: [719][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0288 (0.0651)	
0.99999356 5.6183067e-06
Epoch: [719][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0694 (0.0611)	
0.9999863 4.724712e-06
loss:  0.044331054338586307 0.04173826637396694
===========>   training    <===========
Epoch: [720][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0421 (0.0421)	
0.9999871 3.2046557e-06
===========>   testing    <===========
Epoch: [720][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0368 (0.0368)	
0.9999919 4.0918576e-06
Epoch: [720][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0327 (0.0597)	
0.9999914 4.4954986e-06
Epoch: [720][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0993 (0.0573)	
0.99998367 4.016014e-06
loss:  0.04152018537295421 0.04173826637396694
===========>   training    <===========
Epoch: [721][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0423 (0.0423)	
0.9999826 4.5120605e-06
===========>   testing    <===========
Epoch: [721][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0449 (0.0449)	
0.99999213 3.8733106e-06
Epoch: [721][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0404 (0.0607)	
0.99999404 4.570396e-06
Epoch: [721][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.1347 (0.0602)	
0.9999877 3.8038315e-06
loss:  0.04423430021968078 0.04152018537295421
===========>   training    <===========
Epoch: [722][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0487 (0.0487)	
0.9999957 7.093022e-06
===========>   testing    <===========
Epoch: [722][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0442 (0.0442)	
0.9999887 5.4216143e-06
Epoch: [722][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0280 (0.0630)	
0.9999945 5.5300798e-06
Epoch: [722][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0950 (0.0615)	
0.9999858 5.29519e-06
loss:  0.044155380116220444 0.04152018537295421
===========>   training    <===========
Epoch: [723][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0446 (0.0446)	
0.9999827 3.0171727e-06
===========>   testing    <===========
Epoch: [723][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0329 (0.0329)	
0.99999595 4.885459e-06
Epoch: [723][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0303 (0.0593)	
0.99999595 4.910122e-06
Epoch: [723][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0771 (0.0584)	
0.99999106 4.9527625e-06
loss:  0.04278215830438936 0.04152018537295421
===========>   training    <===========
Epoch: [724][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0459 (0.0459)	
0.99998224 3.3440072e-06
===========>   testing    <===========
Epoch: [724][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0497 (0.0497)	
0.99999464 4.5389224e-06
Epoch: [724][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0295 (0.0589)	
0.9999931 5.406687e-06
Epoch: [724][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0657 (0.0591)	
0.99999 5.5483783e-06
loss:  0.042957167765407256 0.04152018537295421
===========>   training    <===========
Epoch: [725][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0453 (0.0453)	
0.9999882 6.866879e-06
===========>   testing    <===========
Epoch: [725][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0497 (0.0497)	
0.9999926 2.9070823e-06
Epoch: [725][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0353 (0.0595)	
0.9999924 3.2479306e-06
Epoch: [725][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0790 (0.0599)	
0.99998415 3.5285002e-06
loss:  0.04340863194629485 0.04152018537295421
===========>   training    <===========
Epoch: [726][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0419 (0.0419)	
0.9999933 1.3010027e-06
===========>   testing    <===========
Epoch: [726][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0565 (0.0565)	
0.99999213 4.000944e-06
Epoch: [726][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0308 (0.0616)	
0.9999919 4.398486e-06
Epoch: [726][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.1024 (0.0608)	
0.9999862 4.489569e-06
loss:  0.04295954315675732 0.04152018537295421
===========>   training    <===========
Epoch: [727][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0522 (0.0522)	
0.99998915 2.649356e-06
===========>   testing    <===========
Epoch: [727][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0676 (0.0676)	
0.99998987 3.4417508e-06
Epoch: [727][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0356 (0.0624)	
0.99999034 4.5368974e-06
Epoch: [727][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0598 (0.0596)	
0.99997604 3.5462313e-06
loss:  0.04402321242507434 0.04152018537295421
===========>   training    <===========
Epoch: [728][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0565 (0.0565)	
0.99998367 2.0281102e-06
===========>   testing    <===========
Epoch: [728][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0450 (0.0450)	
0.99999106 4.6939576e-06
Epoch: [728][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0439 (0.0616)	
0.99999416 5.783215e-06
Epoch: [728][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.1771 (0.0614)	
0.9999852 4.85689e-06
loss:  0.04384532837003108 0.04152018537295421
===========>   training    <===========
Epoch: [729][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0465 (0.0465)	
0.99999154 5.6580043e-06
===========>   testing    <===========
Epoch: [729][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0579 (0.0579)	
0.9999914 4.3721307e-06
Epoch: [729][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0338 (0.0599)	
0.9999882 5.2888813e-06
Epoch: [729][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0683 (0.0599)	
0.999984 5.7166185e-06
loss:  0.0441895047774592 0.04152018537295421
===========>   training    <===========
Epoch: [730][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0383 (0.0383)	
0.9999845 3.1535556e-06
===========>   testing    <===========
Epoch: [730][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.1288 (0.1288)	
0.9999913 3.5324126e-06
Epoch: [730][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0310 (0.0651)	
0.9999895 3.1785644e-06
Epoch: [730][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.1112 (0.0635)	
0.99998116 3.5316577e-06
loss:  0.046900511840185954 0.04152018537295421
===========>   training    <===========
Epoch: [731][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0476 (0.0476)	
0.99998724 2.6123691e-06
===========>   testing    <===========
Epoch: [731][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0750 (0.0750)	
0.99999297 5.3708163e-06
Epoch: [731][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0378 (0.0695)	
0.9999924 6.045066e-06
Epoch: [731][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0823 (0.0677)	
0.99998343 5.3942645e-06
loss:  0.04593698543286728 0.04152018537295421
===========>   training    <===========
Epoch: [732][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0535 (0.0535)	
0.9999889 7.4725704e-06
===========>   testing    <===========
Epoch: [732][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0770 (0.0770)	
0.9999937 3.8732364e-06
Epoch: [732][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0502 (0.0611)	
0.99999416 3.986358e-06
Epoch: [732][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.1421 (0.0613)	
0.9999881 3.6558147e-06
loss:  0.04454090495280194 0.04152018537295421
===========>   training    <===========
Epoch: [733][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0451 (0.0451)	
0.99999046 7.674218e-06
===========>   testing    <===========
Epoch: [733][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0532 (0.0532)	
0.9999937 4.45628e-06
Epoch: [733][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0477 (0.0606)	
0.9999951 4.4175677e-06
Epoch: [733][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.1139 (0.0596)	
0.9999851 3.974325e-06
loss:  0.04395332072947511 0.04152018537295421
===========>   training    <===========
Epoch: [734][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0430 (0.0430)	
0.99999094 4.485178e-06
===========>   testing    <===========
Epoch: [734][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0444 (0.0444)	
0.99999166 5.02406e-06
Epoch: [734][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0283 (0.0604)	
0.9999951 3.856709e-06
Epoch: [734][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.1600 (0.0613)	
0.9999863 5.0879858e-06
loss:  0.043748113241212416 0.04152018537295421
===========>   training    <===========
Epoch: [735][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0523 (0.0523)	
0.9999895 3.7153266e-06
===========>   testing    <===========
Epoch: [735][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0494 (0.0494)	
0.9999862 3.7841485e-06
Epoch: [735][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0284 (0.0609)	
0.99999416 4.150915e-06
Epoch: [735][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.1009 (0.0597)	
0.99998116 4.9692794e-06
loss:  0.04327528208354159 0.04152018537295421
===========>   training    <===========
Epoch: [736][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0495 (0.0495)	
0.99999607 5.1478237e-06
===========>   testing    <===========
Epoch: [736][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0531 (0.0531)	
0.99999154 4.143835e-06
Epoch: [736][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0300 (0.0650)	
0.99999297 3.093646e-06
Epoch: [736][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.1542 (0.0632)	
0.99998236 4.1635662e-06
loss:  0.04455297147186821 0.04152018537295421
===========>   training    <===========
Epoch: [737][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0334 (0.0334)	
0.9999833 1.105209e-05
===========>   testing    <===========
Epoch: [737][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0401 (0.0401)	
0.9999938 5.9203253e-06
Epoch: [737][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0326 (0.0609)	
0.9999949 4.7947333e-06
Epoch: [737][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.1403 (0.0597)	
0.9999889 5.202219e-06
loss:  0.04272316503268192 0.04152018537295421
===========>   training    <===========
Epoch: [738][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0464 (0.0464)	
0.99999535 4.059527e-06
===========>   testing    <===========
Epoch: [738][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0348 (0.0348)	
0.99998844 4.8798347e-06
Epoch: [738][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0316 (0.0573)	
0.99999166 5.3054605e-06
Epoch: [738][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.1173 (0.0583)	
0.999985 5.2090604e-06
loss:  0.04190751511069879 0.04152018537295421
===========>   training    <===========
Epoch: [739][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0379 (0.0379)	
0.9999862 2.631174e-06
===========>   testing    <===========
Epoch: [739][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0584 (0.0584)	
0.99999404 3.6810736e-06
Epoch: [739][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0241 (0.0588)	
0.99999154 3.4244829e-06
Epoch: [739][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.1489 (0.0601)	
0.9999858 4.4960602e-06
loss:  0.04422830571866043 0.04152018537295421
===========>   training    <===========
Epoch: [740][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0431 (0.0431)	
0.99998856 1.172623e-06
===========>   testing    <===========
Epoch: [740][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0642 (0.0642)	
0.9999937 3.7545644e-06
Epoch: [740][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0343 (0.0580)	
0.9999882 3.4425743e-06
Epoch: [740][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.1076 (0.0576)	
0.99998474 4.5920137e-06
loss:  0.043331577062187154 0.04152018537295421
===========>   training    <===========
Epoch: [741][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0445 (0.0445)	
0.99997544 3.7974087e-06
===========>   testing    <===========
Epoch: [741][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0458 (0.0458)	
0.9999902 3.2216406e-06
Epoch: [741][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0376 (0.0590)	
0.99999046 3.4919383e-06
Epoch: [741][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.1444 (0.0599)	
0.99998057 3.521686e-06
loss:  0.043642329840475225 0.04152018537295421
===========>   training    <===========
Epoch: [742][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0440 (0.0440)	
0.99999154 4.1276485e-06
===========>   testing    <===========
Epoch: [742][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0671 (0.0671)	
0.9999937 5.9792856e-06
Epoch: [742][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0314 (0.0634)	
0.99999285 5.19088e-06
Epoch: [742][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.1817 (0.0625)	
0.9999863 6.5448303e-06
loss:  0.04512796582248524 0.04152018537295421
===========>   training    <===========
Epoch: [743][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0469 (0.0469)	
0.99999356 2.286508e-06
===========>   testing    <===========
Epoch: [743][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0527 (0.0527)	
0.99998987 4.649352e-06
Epoch: [743][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0333 (0.0594)	
0.9999914 4.188561e-06
Epoch: [743][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.1424 (0.0577)	
0.9999839 6.265691e-06
loss:  0.04175171362178398 0.04152018537295421
===========>   training    <===========
Epoch: [744][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0493 (0.0493)	
0.9999894 7.287353e-06
===========>   testing    <===========
Epoch: [744][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0824 (0.0824)	
0.99998486 3.6489146e-06
Epoch: [744][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0246 (0.0586)	
0.99998784 3.4308018e-06
Epoch: [744][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0401 (0.0568)	
0.9999801 5.1535417e-06
loss:  0.043144484808457784 0.04152018537295421
===========>   training    <===========
Epoch: [745][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0421 (0.0421)	
0.9999912 3.864146e-06
===========>   testing    <===========
Epoch: [745][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0570 (0.0570)	
0.999982 3.4502425e-06
Epoch: [745][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0230 (0.0610)	
0.99998665 3.410316e-06
Epoch: [745][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.1304 (0.0595)	
0.999977 4.408658e-06
loss:  0.04342150832494274 0.04152018537295421
===========>   training    <===========
Epoch: [746][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0481 (0.0481)	
0.9999778 2.9696537e-06
===========>   testing    <===========
Epoch: [746][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0426 (0.0426)	
0.9999906 5.168578e-06
Epoch: [746][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.1036 (0.0587)	
0.9999864 4.3911687e-06
Epoch: [746][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0806 (0.0581)	
0.99998415 5.8228616e-06
loss:  0.04208656808069289 0.04152018537295421
===========>   training    <===========
Epoch: [747][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0485 (0.0485)	
0.99999297 4.6449513e-06
===========>   testing    <===========
Epoch: [747][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0371 (0.0371)	
0.99998856 3.8333733e-06
Epoch: [747][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0283 (0.0600)	
0.9999875 3.5291966e-06
Epoch: [747][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.1144 (0.0584)	
0.9999832 4.388405e-06
loss:  0.042266857065125785 0.04152018537295421
===========>   training    <===========
Epoch: [748][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0412 (0.0412)	
0.9999839 2.1280896e-06
===========>   testing    <===========
Epoch: [748][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0938 (0.0938)	
0.99998844 3.8131661e-06
Epoch: [748][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0315 (0.0612)	
0.99998796 4.3764694e-06
Epoch: [748][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0592 (0.0592)	
0.9999888 5.2051923e-06
loss:  0.04393418671817251 0.04152018537295421
===========>   training    <===========
Epoch: [749][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0513 (0.0513)	
0.9999691 1.9188365e-06
===========>   testing    <===========
Epoch: [749][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0477 (0.0477)	
0.9999882 4.075042e-06
Epoch: [749][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0261 (0.0620)	
0.99999106 4.2895545e-06
Epoch: [749][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0626 (0.0604)	
0.99998426 5.410938e-06
loss:  0.043584244246024806 0.04152018537295421
===========>   training    <===========
Epoch: [750][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0483 (0.0483)	
0.9999908 2.008669e-06
===========>   testing    <===========
Epoch: [750][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0614 (0.0614)	
0.9999908 4.444863e-06
Epoch: [750][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0386 (0.0608)	
0.99999285 4.982595e-06
Epoch: [750][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0865 (0.0621)	
0.9999902 5.3707754e-06
loss:  0.044989852386849494 0.04152018537295421
===========>   training    <===========
Epoch: [751][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0421 (0.0421)	
0.9999925 5.528208e-06
===========>   testing    <===========
Epoch: [751][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0413 (0.0413)	
0.9999833 5.7953507e-06
Epoch: [751][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0263 (0.0585)	
0.9999896 7.5957337e-06
Epoch: [751][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.1352 (0.0596)	
0.9999838 6.9157486e-06
loss:  0.04453102712422441 0.04152018537295421
===========>   training    <===========
Epoch: [752][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0415 (0.0415)	
0.99998033 1.8709969e-06
===========>   testing    <===========
Epoch: [752][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0395 (0.0395)	
0.99998045 3.4081438e-06
Epoch: [752][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0388 (0.0588)	
0.9999914 4.665533e-06
Epoch: [752][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.1287 (0.0574)	
0.9999796 3.1705083e-06
loss:  0.04260630009127697 0.04152018537295421
===========>   training    <===========
Epoch: [753][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0383 (0.0383)	
0.9999851 4.3792206e-06
===========>   testing    <===========
Epoch: [753][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0312 (0.0312)	
0.9999851 3.891675e-06
Epoch: [753][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0217 (0.0578)	
0.99998975 4.283414e-06
Epoch: [753][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.1181 (0.0576)	
0.9999846 5.255235e-06
loss:  0.04209986388369247 0.04152018537295421
===========>   training    <===========
Epoch: [754][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0544 (0.0544)	
0.9999751 2.6575244e-06
===========>   testing    <===========
Epoch: [754][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0657 (0.0657)	
0.999985 2.7336928e-06
Epoch: [754][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0325 (0.0584)	
0.9999914 3.5801784e-06
Epoch: [754][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.1341 (0.0581)	
0.99998605 3.69888e-06
loss:  0.04271814096400339 0.04152018537295421
===========>   training    <===========
Epoch: [755][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0455 (0.0455)	
0.99998677 2.8420454e-06
===========>   testing    <===========
Epoch: [755][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0502 (0.0502)	
0.9999802 3.8880653e-06
Epoch: [755][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0244 (0.0589)	
0.99998546 5.8349356e-06
Epoch: [755][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.1073 (0.0592)	
0.99998474 5.696852e-06
loss:  0.043738320798168084 0.04152018537295421
===========>   training    <===========
Epoch: [756][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0440 (0.0440)	
0.99998915 3.544047e-06
===========>   testing    <===========
Epoch: [756][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0518 (0.0518)	
0.99998844 5.593367e-06
Epoch: [756][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0363 (0.0582)	
0.999995 5.3041053e-06
Epoch: [756][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.1441 (0.0579)	
0.9999865 4.622317e-06
loss:  0.043169151979031706 0.04152018537295421
===========>   training    <===========
Epoch: [757][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0483 (0.0483)	
0.9999912 5.600455e-06
===========>   testing    <===========
Epoch: [757][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0529 (0.0529)	
0.99998546 3.6829626e-06
Epoch: [757][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0223 (0.0565)	
0.9999937 3.8379235e-06
Epoch: [757][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0922 (0.0585)	
0.9999887 3.7564691e-06
loss:  0.043614286555267445 0.04152018537295421
===========>   training    <===========
Epoch: [758][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0387 (0.0387)	
0.9999765 3.9311703e-06
===========>   testing    <===========
Epoch: [758][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0473 (0.0473)	
0.99998343 3.909374e-06
Epoch: [758][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0245 (0.0607)	
0.9999889 3.744284e-06
Epoch: [758][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0634 (0.0606)	
0.9999783 4.6478885e-06
loss:  0.043444998820675096 0.04152018537295421
===========>   training    <===========
Epoch: [759][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0510 (0.0510)	
0.99997544 2.0403572e-06
===========>   testing    <===========
Epoch: [759][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0316 (0.0316)	
0.99998844 3.6275658e-06
Epoch: [759][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0347 (0.0583)	
0.9999907 4.6305504e-06
Epoch: [759][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.1230 (0.0593)	
0.9999858 4.326538e-06
loss:  0.043305461413848945 0.04152018537295421
===========>   training    <===========
Epoch: [760][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0495 (0.0495)	
0.99998534 3.1332395e-06
===========>   testing    <===========
Epoch: [760][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0545 (0.0545)	
0.9999914 5.3873955e-06
Epoch: [760][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0258 (0.0570)	
0.9999939 6.906442e-06
Epoch: [760][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.1266 (0.0571)	
0.9999875 7.5933076e-06
loss:  0.04058399317020689 0.04152018537295421
===========>   training    <===========
Epoch: [761][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0427 (0.0427)	
0.9999927 4.408397e-06
===========>   testing    <===========
Epoch: [761][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0449 (0.0449)	
0.99998987 3.958989e-06
Epoch: [761][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0261 (0.0590)	
0.99999094 4.058114e-06
Epoch: [761][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0553 (0.0583)	
0.9999839 4.5363868e-06
loss:  0.04108225788604658 0.04058399317020689
===========>   training    <===========
Epoch: [762][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0379 (0.0379)	
0.9999924 4.253356e-06
===========>   testing    <===========
Epoch: [762][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0570 (0.0570)	
0.99998534 4.238415e-06
Epoch: [762][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0381 (0.0580)	
0.99999094 4.128932e-06
Epoch: [762][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.1549 (0.0583)	
0.9999845 4.366547e-06
loss:  0.04160719682540559 0.04058399317020689
===========>   training    <===========
Epoch: [763][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0379 (0.0379)	
0.999987 4.2985307e-06
===========>   testing    <===========
Epoch: [763][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0400 (0.0400)	
0.9999827 3.364653e-06
Epoch: [763][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0282 (0.0630)	
0.9999908 3.3746117e-06
Epoch: [763][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.1158 (0.0616)	
0.99997854 3.0976137e-06
loss:  0.04408335641394667 0.04058399317020689
===========>   training    <===========
Epoch: [764][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0505 (0.0505)	
0.9999864 2.4036349e-06
===========>   testing    <===========
Epoch: [764][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0518 (0.0518)	
0.9999801 3.116031e-06
Epoch: [764][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0304 (0.0606)	
0.9999896 3.3740678e-06
Epoch: [764][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0917 (0.0587)	
0.99997854 3.6256429e-06
loss:  0.04213672400268886 0.04058399317020689
===========>   training    <===========
Epoch: [765][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0503 (0.0503)	
0.99997294 2.3823447e-06
===========>   testing    <===========
Epoch: [765][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0393 (0.0393)	
0.9999807 3.5792157e-06
Epoch: [765][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0327 (0.0590)	
0.9999906 4.0574405e-06
Epoch: [765][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0773 (0.0577)	
0.99998176 4.4823814e-06
loss:  0.04100947376027908 0.04058399317020689
===========>   training    <===========
Epoch: [766][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0416 (0.0416)	
0.9999887 5.918784e-06
===========>   testing    <===========
Epoch: [766][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0450 (0.0450)	
0.99998474 3.4868535e-06
Epoch: [766][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0312 (0.0631)	
0.9999925 4.0298332e-06
Epoch: [766][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0948 (0.0635)	
0.999984 4.157912e-06
loss:  0.042475922517496656 0.04058399317020689
===========>   training    <===========
Epoch: [767][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0450 (0.0450)	
0.9999883 5.3193776e-06
===========>   testing    <===========
Epoch: [767][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0379 (0.0379)	
0.9999902 3.2453174e-06
Epoch: [767][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0300 (0.0594)	
0.99999344 3.2196567e-06
Epoch: [767][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.1211 (0.0604)	
0.9999894 3.7607956e-06
loss:  0.04122372761943571 0.04058399317020689
===========>   training    <===========
Epoch: [768][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0364 (0.0364)	
0.99999464 3.4670973e-06
===========>   testing    <===========
Epoch: [768][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0551 (0.0551)	
0.99999094 2.633333e-06
Epoch: [768][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0343 (0.0591)	
0.9999912 2.7007825e-06
Epoch: [768][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0912 (0.0604)	
0.9999896 3.037037e-06
loss:  0.042315250885254674 0.04058399317020689
===========>   training    <===========
Epoch: [769][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0421 (0.0421)	
0.9999907 5.8640335e-06
===========>   testing    <===========
Epoch: [769][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0452 (0.0452)	
0.9999893 3.1387037e-06
Epoch: [769][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0293 (0.0586)	
0.99999046 3.2281177e-06
Epoch: [769][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0733 (0.0587)	
0.99998665 3.7135235e-06
loss:  0.042676489379881444 0.04058399317020689
===========>   training    <===========
Epoch: [770][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0505 (0.0505)	
0.9999856 1.9299137e-06
===========>   testing    <===========
Epoch: [770][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0414 (0.0414)	
0.999982 3.0761528e-06
Epoch: [770][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0326 (0.0576)	
0.99999094 3.2524126e-06
Epoch: [770][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0827 (0.0576)	
0.9999795 3.748339e-06
loss:  0.04207134190318995 0.04058399317020689
===========>   training    <===========
Epoch: [771][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0465 (0.0465)	
0.9999906 3.9625925e-06
===========>   testing    <===========
Epoch: [771][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0446 (0.0446)	
0.999987 3.6502963e-06
Epoch: [771][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0286 (0.0581)	
0.9999871 3.3260055e-06
Epoch: [771][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.1159 (0.0579)	
0.99998343 4.0896025e-06
loss:  0.04205792823293064 0.04058399317020689
===========>   training    <===========
Epoch: [772][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0473 (0.0473)	
0.99999154 2.7290587e-06
===========>   testing    <===========
Epoch: [772][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0412 (0.0412)	
0.99998987 3.6411384e-06
Epoch: [772][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0334 (0.0582)	
0.99999106 3.3705783e-06
Epoch: [772][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0735 (0.0580)	
0.99998546 4.0222003e-06
loss:  0.04263029172583299 0.04058399317020689
===========>   training    <===========
Epoch: [773][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0440 (0.0440)	
0.9999858 4.3903055e-06
===========>   testing    <===========
Epoch: [773][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0483 (0.0483)	
0.99998903 3.7976877e-06
Epoch: [773][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0317 (0.0590)	
0.9999927 3.141039e-06
Epoch: [773][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0867 (0.0580)	
0.9999863 4.1966896e-06
loss:  0.04266970635314726 0.04058399317020689
===========>   training    <===========
Epoch: [774][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0502 (0.0502)	
0.99998724 1.9523202e-06
===========>   testing    <===========
Epoch: [774][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0435 (0.0435)	
0.99997926 4.0451464e-06
Epoch: [774][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0269 (0.0573)	
0.9999927 3.5308767e-06
Epoch: [774][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0785 (0.0571)	
0.9999788 4.9613427e-06
loss:  0.041572216398468975 0.04058399317020689
===========>   training    <===========
Epoch: [775][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0410 (0.0410)	
0.9999857 2.833307e-06
===========>   testing    <===========
Epoch: [775][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0555 (0.0555)	
0.9999852 4.0017876e-06
Epoch: [775][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0344 (0.0582)	
0.9999931 3.8331464e-06
Epoch: [775][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0959 (0.0574)	
0.9999871 4.3123387e-06
loss:  0.041788054060198476 0.04058399317020689
===========>   training    <===========
Epoch: [776][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0427 (0.0427)	
0.9999926 6.703027e-06
===========>   testing    <===========
Epoch: [776][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0363 (0.0363)	
0.99997413 3.104081e-06
Epoch: [776][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0411 (0.0579)	
0.99999297 2.976135e-06
Epoch: [776][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.1302 (0.0565)	
0.99997365 3.1371474e-06
loss:  0.04192007323108571 0.04058399317020689
===========>   training    <===========
Epoch: [777][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0407 (0.0407)	
0.99998105 2.9131768e-06
===========>   testing    <===========
Epoch: [777][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0405 (0.0405)	
0.9999825 3.6423748e-06
Epoch: [777][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0352 (0.0569)	
0.99998724 3.5813396e-06
Epoch: [777][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.1276 (0.0559)	
0.99997747 4.7897975e-06
loss:  0.04065922394788701 0.04058399317020689
===========>   training    <===========
Epoch: [778][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0495 (0.0495)	
0.9999788 2.5730335e-06
===========>   testing    <===========
Epoch: [778][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0342 (0.0342)	
0.9999801 3.0997737e-06
Epoch: [778][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0303 (0.0570)	
0.99998856 2.8854663e-06
Epoch: [778][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.1354 (0.0559)	
0.9999721 3.4946202e-06
loss:  0.04087372821989488 0.04058399317020689
===========>   training    <===========
Epoch: [779][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0378 (0.0378)	
0.99998 3.308904e-07
===========>   testing    <===========
Epoch: [779][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0411 (0.0411)	
0.9999888 4.9346545e-06
Epoch: [779][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0258 (0.0590)	
0.9999926 4.8855522e-06
Epoch: [779][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0848 (0.0572)	
0.999984 6.8629247e-06
loss:  0.04168929184296366 0.04058399317020689
===========>   training    <===========
Epoch: [780][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0481 (0.0481)	
0.9999862 3.3171927e-06
===========>   testing    <===========
Epoch: [780][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0329 (0.0329)	
0.9999907 4.000006e-06
Epoch: [780][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0241 (0.0600)	
0.99999034 4.3273344e-06
Epoch: [780][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.1989 (0.0599)	
0.99998677 4.888554e-06
loss:  0.04251721763446059 0.04058399317020689
===========>   training    <===========
Epoch: [781][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0455 (0.0455)	
0.99998343 4.543955e-06
===========>   testing    <===========
Epoch: [781][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0385 (0.0385)	
0.99998295 3.481637e-06
Epoch: [781][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0280 (0.0555)	
0.99998784 3.1590366e-06
Epoch: [781][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.1454 (0.0562)	
0.99997854 3.7265825e-06
loss:  0.04178121470182106 0.04058399317020689
===========>   training    <===========
Epoch: [782][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0396 (0.0396)	
0.99998903 5.5117885e-06
===========>   testing    <===========
Epoch: [782][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0383 (0.0383)	
0.999987 4.160229e-06
Epoch: [782][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0304 (0.0586)	
0.99999213 3.8940066e-06
Epoch: [782][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.1134 (0.0583)	
0.99998295 3.647749e-06
loss:  0.042996630835810845 0.04058399317020689
===========>   training    <===========
Epoch: [783][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0376 (0.0376)	
0.99998295 4.9086702e-06
===========>   testing    <===========
Epoch: [783][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0453 (0.0453)	
0.99998856 3.1891218e-06
Epoch: [783][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0278 (0.0589)	
0.9999887 2.8180655e-06
Epoch: [783][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.1072 (0.0584)	
0.9999826 2.9374896e-06
loss:  0.041518132005120334 0.04058399317020689
===========>   training    <===========
Epoch: [784][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0398 (0.0398)	
0.9999821 3.7445445e-06
===========>   testing    <===========
Epoch: [784][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0321 (0.0321)	
0.9999908 4.744281e-06
Epoch: [784][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0265 (0.0569)	
0.9999918 4.86426e-06
Epoch: [784][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0921 (0.0572)	
0.99999034 5.5157006e-06
loss:  0.039959689509458274 0.04058399317020689
===========>   training    <===========
Epoch: [785][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0444 (0.0444)	
0.99998355 2.1320936e-06
===========>   testing    <===========
Epoch: [785][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0428 (0.0428)	
0.9999896 3.8939434e-06
Epoch: [785][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0250 (0.0561)	
0.9999869 3.9739575e-06
Epoch: [785][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.1132 (0.0572)	
0.99998426 3.76992e-06
loss:  0.040477288961429436 0.039959689509458274
===========>   training    <===========
Epoch: [786][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0385 (0.0385)	
0.9999902 4.709979e-06
===========>   testing    <===========
Epoch: [786][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0436 (0.0436)	
0.9999877 2.924428e-06
Epoch: [786][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0283 (0.0553)	
0.9999831 3.107828e-06
Epoch: [786][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0682 (0.0566)	
0.9999752 2.9890543e-06
loss:  0.040628309387705785 0.039959689509458274
===========>   training    <===========
Epoch: [787][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0544 (0.0544)	
0.9999846 2.4341814e-06
===========>   testing    <===========
Epoch: [787][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0430 (0.0430)	
0.9999887 3.944833e-06
Epoch: [787][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0261 (0.0571)	
0.99998784 3.84234e-06
Epoch: [787][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.1340 (0.0587)	
0.9999857 3.7022396e-06
loss:  0.04121988357951423 0.039959689509458274
===========>   training    <===========
Epoch: [788][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0453 (0.0453)	
0.99998045 4.081409e-06
===========>   testing    <===========
Epoch: [788][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0423 (0.0423)	
0.9999889 3.7328357e-06
Epoch: [788][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0244 (0.0584)	
0.99999213 3.7605269e-06
Epoch: [788][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0717 (0.0586)	
0.9999869 3.3123245e-06
loss:  0.04246422419552642 0.039959689509458274
===========>   training    <===========
Epoch: [789][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0498 (0.0498)	
0.9999814 1.8979177e-06
===========>   testing    <===========
Epoch: [789][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0309 (0.0309)	
0.9999871 3.331777e-06
Epoch: [789][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0289 (0.0584)	
0.99998856 3.3289439e-06
Epoch: [789][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0746 (0.0587)	
0.9999858 3.1677885e-06
loss:  0.04179076681375027 0.039959689509458274
===========>   training    <===========
Epoch: [790][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0454 (0.0454)	
0.99997854 1.6592755e-06
===========>   testing    <===========
Epoch: [790][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0357 (0.0357)	
0.9999888 2.841273e-06
Epoch: [790][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0336 (0.0591)	
0.99998903 2.5423515e-06
Epoch: [790][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0884 (0.0599)	
0.9999863 3.181109e-06
loss:  0.0414709513154482 0.039959689509458274
===========>   training    <===========
Epoch: [791][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0410 (0.0410)	
0.99998665 1.6811321e-06
===========>   testing    <===========
Epoch: [791][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0455 (0.0455)	
0.9999827 3.4092136e-06
Epoch: [791][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0283 (0.0620)	
0.9999876 2.865724e-06
Epoch: [791][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0606 (0.0602)	
0.99997985 3.4909863e-06
loss:  0.042917227253975176 0.039959689509458274
===========>   training    <===========
Epoch: [792][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0418 (0.0418)	
0.99999166 1.7810456e-05
===========>   testing    <===========
Epoch: [792][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0305 (0.0305)	
0.9999889 3.8795947e-06
Epoch: [792][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0398 (0.0564)	
0.9999901 3.2503847e-06
Epoch: [792][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.1041 (0.0581)	
0.99998677 2.9868572e-06
loss:  0.04190100963727206 0.039959689509458274
===========>   training    <===========
Epoch: [793][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0526 (0.0526)	
0.9999962 8.7022966e-07
===========>   testing    <===========
Epoch: [793][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0400 (0.0400)	
0.9999876 4.9787095e-06
Epoch: [793][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0566 (0.0626)	
0.999987 5.427579e-06
Epoch: [793][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0459 (0.0595)	
0.99999 4.047489e-06
loss:  0.04238736812778454 0.039959689509458274
===========>   training    <===========
Epoch: [794][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0526 (0.0526)	
0.9999858 1.9330007e-06
===========>   testing    <===========
Epoch: [794][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0380 (0.0380)	
0.9999852 5.651339e-06
Epoch: [794][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.1005 (0.0685)	
0.999979 4.771042e-06
Epoch: [794][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0885 (0.0657)	
0.99998534 5.615141e-06
loss:  0.046037281337165115 0.039959689509458274
===========>   training    <===========
Epoch: [795][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0467 (0.0467)	
0.99998665 4.6225596e-06
===========>   testing    <===========
Epoch: [795][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0386 (0.0386)	
0.9999827 4.852584e-06
Epoch: [795][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0811 (0.0589)	
0.9999695 3.7327857e-06
Epoch: [795][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0740 (0.0597)	
0.9999815 4.678677e-06
loss:  0.04338840045029135 0.039959689509458274
===========>   training    <===========
Epoch: [796][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0396 (0.0396)	
0.99998903 7.100941e-06
===========>   testing    <===========
Epoch: [796][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0339 (0.0339)	
0.9999852 3.4545587e-06
Epoch: [796][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0665 (0.0589)	
0.99996233 3.01683e-06
Epoch: [796][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0558 (0.0591)	
0.9999778 3.355546e-06
loss:  0.042677667633181815 0.039959689509458274
===========>   training    <===========
Epoch: [797][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0471 (0.0471)	
0.99997795 2.1814374e-06
===========>   testing    <===========
Epoch: [797][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0312 (0.0312)	
0.9999901 3.5800624e-06
Epoch: [797][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0325 (0.0563)	
0.9999789 3.205909e-06
Epoch: [797][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.1196 (0.0583)	
0.9999844 3.1581724e-06
loss:  0.041111613417075143 0.039959689509458274
===========>   training    <===========
Epoch: [798][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0389 (0.0389)	
0.9999932 3.6842205e-06
===========>   testing    <===========
Epoch: [798][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0524 (0.0524)	
0.99999034 2.9824653e-06
Epoch: [798][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0429 (0.0617)	
0.99997723 2.819216e-06
Epoch: [798][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0601 (0.0611)	
0.99997556 2.5823454e-06
loss:  0.04267341574167183 0.039959689509458274
===========>   training    <===========
Epoch: [799][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0454 (0.0454)	
0.99998105 3.4787759e-06
===========>   testing    <===========
Epoch: [799][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0439 (0.0439)	
0.99999 4.274074e-06
Epoch: [799][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0313 (0.0584)	
0.9999877 4.1203607e-06
Epoch: [799][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0963 (0.0592)	
0.9999838 4.02276e-06
loss:  0.04167001750299726 0.039959689509458274
===========>   training    <===========
Epoch: [800][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0452 (0.0452)	
0.99999285 4.3785653e-06
===========>   testing    <===========
Epoch: [800][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0365 (0.0365)	
0.9999883 4.4680974e-06
Epoch: [800][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0330 (0.0590)	
0.99998903 3.9311967e-06
Epoch: [800][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0803 (0.0591)	
0.99998665 4.780488e-06
loss:  0.04152462647857624 0.039959689509458274
===========>   training    <===========
Epoch: [801][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0443 (0.0443)	
0.9999902 2.667262e-06
===========>   testing    <===========
Epoch: [801][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0377 (0.0377)	
0.999984 3.856628e-06
Epoch: [801][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0288 (0.0598)	
0.99998593 3.3218212e-06
Epoch: [801][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0610 (0.0592)	
0.9999833 3.8880803e-06
loss:  0.041528589653208714 0.039959689509458274
===========>   training    <===========
Epoch: [802][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0439 (0.0439)	
0.99998176 3.2358541e-06
===========>   testing    <===========
Epoch: [802][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0404 (0.0404)	
0.99998486 3.4378534e-06
Epoch: [802][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0263 (0.0582)	
0.999984 3.1910631e-06
Epoch: [802][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0723 (0.0572)	
0.9999819 2.9558878e-06
loss:  0.040851358439783714 0.039959689509458274
===========>   training    <===========
Epoch: [803][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0446 (0.0446)	
0.99998045 4.148509e-06
===========>   testing    <===========
Epoch: [803][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0457 (0.0457)	
0.9999852 2.823273e-06
Epoch: [803][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0305 (0.0589)	
0.9999845 3.2352311e-06
Epoch: [803][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0490 (0.0582)	
0.99998116 2.8706831e-06
loss:  0.04192362487133772 0.039959689509458274
===========>   training    <===========
Epoch: [804][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0487 (0.0487)	
0.9999881 3.1438383e-06
===========>   testing    <===========
Epoch: [804][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0450 (0.0450)	
0.99998593 3.8030842e-06
Epoch: [804][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0473 (0.0576)	
0.9999839 4.498093e-06
Epoch: [804][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0991 (0.0603)	
0.9999821 5.3174754e-06
loss:  0.04300520720702694 0.039959689509458274
===========>   training    <===========
Epoch: [805][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0433 (0.0433)	
0.9999895 1.5188782e-05
===========>   testing    <===========
Epoch: [805][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0296 (0.0296)	
0.99998975 4.4178164e-06
Epoch: [805][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0378 (0.0573)	
0.9999827 3.3619203e-06
Epoch: [805][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0665 (0.0571)	
0.9999827 4.516521e-06
loss:  0.041103785273230886 0.039959689509458274
===========>   training    <===========
Epoch: [806][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0596 (0.0596)	
0.9999918 2.6350513e-06
===========>   testing    <===========
Epoch: [806][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0324 (0.0324)	
0.9999902 3.3326924e-06
Epoch: [806][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0280 (0.0579)	
0.99999166 2.7961833e-06
Epoch: [806][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0692 (0.0578)	
0.9999858 3.3810963e-06
loss:  0.0414438806338322 0.039959689509458274
===========>   training    <===========
Epoch: [807][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0459 (0.0459)	
0.9999789 2.115766e-06
===========>   testing    <===========
Epoch: [807][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0443 (0.0443)	
0.9999893 3.4537582e-06
Epoch: [807][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0374 (0.0592)	
0.9999893 3.698365e-06
Epoch: [807][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0860 (0.0579)	
0.999987 4.116111e-06
loss:  0.04128209114902481 0.039959689509458274
===========>   training    <===========
Epoch: [808][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0394 (0.0394)	
0.9999887 2.046412e-06
===========>   testing    <===========
Epoch: [808][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0389 (0.0389)	
0.999987 4.455872e-06
Epoch: [808][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0304 (0.0633)	
0.99999046 3.8356256e-06
Epoch: [808][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0787 (0.0608)	
0.9999857 5.5835494e-06
loss:  0.042862988633149524 0.039959689509458274
===========>   training    <===========
Epoch: [809][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0403 (0.0403)	
0.9999862 2.7938643e-06
===========>   testing    <===========
Epoch: [809][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0398 (0.0398)	
0.9999881 3.6744411e-06
Epoch: [809][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0383 (0.0623)	
0.99999285 3.2485561e-06
Epoch: [809][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0757 (0.0623)	
0.99998844 3.2421217e-06
loss:  0.043203343119113446 0.039959689509458274
===========>   training    <===========
Epoch: [810][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0375 (0.0375)	
0.9999896 2.3411394e-06
===========>   testing    <===========
Epoch: [810][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0427 (0.0427)	
0.9999839 3.916662e-06
Epoch: [810][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0375 (0.0621)	
0.9999926 3.3696915e-06
Epoch: [810][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0806 (0.0602)	
0.99998343 3.0965505e-06
loss:  0.0435857166709811 0.039959689509458274
===========>   training    <===========
Epoch: [811][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0412 (0.0412)	
0.9999777 3.308555e-06
===========>   testing    <===========
Epoch: [811][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0387 (0.0387)	
0.9999876 3.7774169e-06
Epoch: [811][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0361 (0.0588)	
0.9999914 3.456813e-06
Epoch: [811][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.1013 (0.0585)	
0.9999862 3.984412e-06
loss:  0.04253925394732816 0.039959689509458274
===========>   training    <===========
Epoch: [812][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0453 (0.0453)	
0.9999714 1.8751124e-06
===========>   testing    <===========
Epoch: [812][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0432 (0.0432)	
0.99999046 3.413853e-06
Epoch: [812][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0300 (0.0575)	
0.9999896 3.180202e-06
Epoch: [812][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0671 (0.0568)	
0.9999882 4.2949737e-06
loss:  0.04187092124374758 0.039959689509458274
===========>   training    <===========
Epoch: [813][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0416 (0.0416)	
0.9999901 2.8205122e-06
===========>   testing    <===========
Epoch: [813][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0463 (0.0463)	
0.9999924 3.2246164e-06
Epoch: [813][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0260 (0.0582)	
0.9999938 3.656641e-06
Epoch: [813][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0983 (0.0581)	
0.99998975 4.1359153e-06
loss:  0.04258093392915374 0.039959689509458274
===========>   training    <===========
Epoch: [814][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0411 (0.0411)	
0.99998784 2.6765729e-06
===========>   testing    <===========
Epoch: [814][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0548 (0.0548)	
0.9999851 3.9101833e-06
Epoch: [814][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0295 (0.0576)	
0.99997663 4.102196e-06
Epoch: [814][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0628 (0.0570)	
0.99997985 5.4624843e-06
loss:  0.04189968822708956 0.039959689509458274
===========>   training    <===========
Epoch: [815][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0382 (0.0382)	
0.99998546 3.9256033e-06
===========>   testing    <===========
Epoch: [815][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0385 (0.0385)	
0.99998915 3.6354343e-06
Epoch: [815][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0590 (0.0586)	
0.99998546 3.3774932e-06
Epoch: [815][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.1379 (0.0602)	
0.99998856 5.075608e-06
loss:  0.04344849520579086 0.039959689509458274
===========>   training    <===========
Epoch: [816][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0407 (0.0407)	
0.9999889 7.452614e-06
===========>   testing    <===========
Epoch: [816][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0453 (0.0453)	
0.9999914 3.5195135e-06
Epoch: [816][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.1069 (0.0592)	
0.9999889 3.4253028e-06
Epoch: [816][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0840 (0.0598)	
0.99998903 5.3497497e-06
loss:  0.043983197017189 0.039959689509458274
===========>   training    <===========
Epoch: [817][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0385 (0.0385)	
0.9999895 1.8464607e-06
===========>   testing    <===========
Epoch: [817][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0328 (0.0328)	
0.99998665 3.1474442e-06
Epoch: [817][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0333 (0.0587)	
0.9999881 3.0908707e-06
Epoch: [817][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.1569 (0.0613)	
0.9999838 3.883563e-06
loss:  0.04412322242706779 0.039959689509458274
===========>   training    <===========
Epoch: [818][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0471 (0.0471)	
0.999984 1.5523767e-06
===========>   testing    <===========
Epoch: [818][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0491 (0.0491)	
0.9999914 4.34452e-06
Epoch: [818][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0360 (0.0588)	
0.99999297 3.9537895e-06
Epoch: [818][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0764 (0.0585)	
0.9999876 3.871132e-06
loss:  0.0430793410162853 0.039959689509458274
===========>   training    <===========
Epoch: [819][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0426 (0.0426)	
0.99999285 1.9097174e-06
===========>   testing    <===========
Epoch: [819][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0509 (0.0509)	
0.9999919 3.7044576e-06
Epoch: [819][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0259 (0.0593)	
0.9999918 3.3580015e-06
Epoch: [819][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0950 (0.0584)	
0.9999894 4.4261324e-06
loss:  0.04307718496568469 0.039959689509458274
===========>   training    <===========
Epoch: [820][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0392 (0.0392)	
0.99998736 2.0344835e-06
===========>   testing    <===========
Epoch: [820][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0507 (0.0507)	
0.99999 3.6941422e-06
Epoch: [820][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0270 (0.0576)	
0.9999883 3.4997097e-06
Epoch: [820][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0985 (0.0571)	
0.9999863 4.3341533e-06
loss:  0.04266280318130422 0.039959689509458274
===========>   training    <===========
Epoch: [821][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0471 (0.0471)	
0.99999523 2.1717728e-06
===========>   testing    <===========
Epoch: [821][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0662 (0.0662)	
0.99999046 2.5726606e-06
Epoch: [821][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0334 (0.0588)	
0.9999876 2.5910385e-06
Epoch: [821][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0718 (0.0581)	
0.9999857 2.7106603e-06
loss:  0.043122535225476044 0.039959689509458274
===========>   training    <===========
Epoch: [822][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0391 (0.0391)	
0.9999932 8.294498e-07
===========>   testing    <===========
Epoch: [822][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0520 (0.0520)	
0.9999908 2.3657785e-06
Epoch: [822][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0525 (0.0569)	
0.9999881 2.059463e-06
Epoch: [822][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0814 (0.0568)	
0.99998426 2.442702e-06
loss:  0.041693591878021574 0.039959689509458274
===========>   training    <===========
Epoch: [823][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0404 (0.0404)	
0.9999932 3.5881017e-06
===========>   testing    <===========
Epoch: [823][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0401 (0.0401)	
0.9999908 2.6716202e-06
Epoch: [823][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.1145 (0.0568)	
0.99998975 2.6771497e-06
Epoch: [823][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.1251 (0.0579)	
0.9999871 2.6636776e-06
loss:  0.04283170243385004 0.039959689509458274
===========>   training    <===========
Epoch: [824][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0483 (0.0483)	
0.999992 2.946774e-06
===========>   testing    <===========
Epoch: [824][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0354 (0.0354)	
0.9999877 2.6001107e-06
Epoch: [824][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.1086 (0.0554)	
0.9999913 2.9817372e-06
Epoch: [824][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0805 (0.0555)	
0.99998355 2.8406228e-06
loss:  0.04200753815425462 0.039959689509458274
===========>   training    <===========
Epoch: [825][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0431 (0.0431)	
0.99998486 2.6583052e-06
===========>   testing    <===========
Epoch: [825][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0511 (0.0511)	
0.9999908 2.8491852e-06
Epoch: [825][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0452 (0.0558)	
0.99999166 2.8464588e-06
Epoch: [825][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0547 (0.0561)	
0.999984 3.1576183e-06
loss:  0.041825159398761746 0.039959689509458274
===========>   training    <===========
Epoch: [826][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0382 (0.0382)	
0.99999416 3.689973e-06
===========>   testing    <===========
Epoch: [826][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0559 (0.0559)	
0.99998987 4.363117e-06
Epoch: [826][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0568 (0.0558)	
0.9999906 4.9117098e-06
Epoch: [826][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0564 (0.0552)	
0.99998474 4.6390633e-06
loss:  0.04166518671312258 0.039959689509458274
===========>   training    <===========
Epoch: [827][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0449 (0.0449)	
0.9999914 3.0472113e-06
===========>   testing    <===========
Epoch: [827][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0446 (0.0446)	
0.9999912 2.9353391e-06
Epoch: [827][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0316 (0.0542)	
0.99999154 3.041289e-06
Epoch: [827][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0905 (0.0553)	
0.99998784 3.259287e-06
loss:  0.041558743842252555 0.039959689509458274
===========>   training    <===========
Epoch: [828][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0430 (0.0430)	
0.99998343 1.3997125e-06
===========>   testing    <===========
Epoch: [828][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0498 (0.0498)	
0.9999913 3.2033965e-06
Epoch: [828][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0346 (0.0545)	
0.9999913 3.1228105e-06
Epoch: [828][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.1170 (0.0558)	
0.99998605 3.4832376e-06
loss:  0.04184154787515537 0.039959689509458274
===========>   training    <===========
Epoch: [829][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0391 (0.0391)	
0.99998844 3.3364004e-06
===========>   testing    <===========
Epoch: [829][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0436 (0.0436)	
0.9999902 3.995545e-06
Epoch: [829][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0372 (0.0554)	
0.9999895 3.7447803e-06
Epoch: [829][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0889 (0.0551)	
0.99998736 4.6345526e-06
loss:  0.04160539163129773 0.039959689509458274
===========>   training    <===========
Epoch: [830][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0413 (0.0413)	
0.99999547 8.221209e-06
===========>   testing    <===========
Epoch: [830][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0511 (0.0511)	
0.99999046 2.2355082e-06
Epoch: [830][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0308 (0.0560)	
0.9999893 2.2221595e-06
Epoch: [830][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0849 (0.0588)	
0.9999856 2.239631e-06
loss:  0.04305966307720843 0.039959689509458274
===========>   training    <===========
Epoch: [831][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0381 (0.0381)	
0.99998677 1.8626862e-06
===========>   testing    <===========
Epoch: [831][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0562 (0.0562)	
0.9999913 2.7556694e-06
Epoch: [831][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0455 (0.0560)	
0.9999906 2.7062822e-06
Epoch: [831][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0702 (0.0578)	
0.9999883 2.7506335e-06
loss:  0.04245142585759776 0.039959689509458274
===========>   training    <===========
Epoch: [832][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0369 (0.0369)	
0.9999913 6.2751396e-06
===========>   testing    <===========
Epoch: [832][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0430 (0.0430)	
0.9999858 2.2294787e-06
Epoch: [832][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.1128 (0.0568)	
0.999987 2.2340505e-06
Epoch: [832][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0887 (0.0579)	
0.99998283 2.5499153e-06
loss:  0.044019899592101064 0.039959689509458274
===========>   training    <===========
Epoch: [833][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0362 (0.0362)	
0.9999908 2.9754256e-06
===========>   testing    <===========
Epoch: [833][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0478 (0.0478)	
0.9999927 3.1677944e-06
Epoch: [833][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0798 (0.0562)	
0.9999925 3.182969e-06
Epoch: [833][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0526 (0.0552)	
0.99998915 3.8123515e-06
loss:  0.04186617249109881 0.039959689509458274
===========>   training    <===========
Epoch: [834][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0398 (0.0398)	
0.99998534 2.2546385e-06
===========>   testing    <===========
Epoch: [834][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0356 (0.0356)	
0.9999918 3.439011e-06
Epoch: [834][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0327 (0.0549)	
0.99999106 3.4523227e-06
Epoch: [834][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0504 (0.0563)	
0.9999888 3.618865e-06
loss:  0.04129541608552911 0.039959689509458274
===========>   training    <===========
Epoch: [835][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0450 (0.0450)	
0.99999285 2.349137e-06
===========>   testing    <===========
Epoch: [835][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0480 (0.0480)	
0.9999858 3.7674042e-06
Epoch: [835][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0486 (0.0544)	
0.99998534 3.7740535e-06
Epoch: [835][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0843 (0.0558)	
0.9999846 3.8611474e-06
loss:  0.04063578114149613 0.039959689509458274
===========>   training    <===========
Epoch: [836][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0416 (0.0416)	
0.9999821 2.1575122e-06
===========>   testing    <===========
Epoch: [836][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0848 (0.0848)	
0.9999919 3.8425565e-06
Epoch: [836][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0382 (0.0592)	
0.9999919 3.9117085e-06
Epoch: [836][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.1138 (0.0579)	
0.99998903 3.896778e-06
loss:  0.042953062402235065 0.039959689509458274
===========>   training    <===========
Epoch: [837][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0403 (0.0403)	
0.9999838 2.815272e-06
===========>   testing    <===========
Epoch: [837][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0442 (0.0442)	
0.9999914 3.52134e-06
Epoch: [837][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0501 (0.0549)	
0.9999913 3.5400271e-06
Epoch: [837][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0907 (0.0546)	
0.99998724 1.787062e-06
loss:  0.04078233933933573 0.039959689509458274
===========>   training    <===========
Epoch: [838][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0366 (0.0366)	
0.99999464 4.8573806e-06
===========>   testing    <===========
Epoch: [838][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0422 (0.0422)	
0.9999907 3.23322e-06
Epoch: [838][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0519 (0.0566)	
0.99998903 3.3870053e-06
Epoch: [838][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0633 (0.0548)	
0.99998784 2.2230668e-06
loss:  0.03986833534370782 0.039959689509458274
===========>   training    <===========
Epoch: [839][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0417 (0.0417)	
0.99998796 4.09931e-06
===========>   testing    <===========
Epoch: [839][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0688 (0.0688)	
0.99999046 3.7311056e-06
Epoch: [839][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0434 (0.0557)	
0.9999896 3.4951233e-06
Epoch: [839][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0596 (0.0557)	
0.9999888 3.0563879e-06
loss:  0.040911923262181404 0.03986833534370782
===========>   training    <===========
Epoch: [840][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0322 (0.0322)	
0.9999863 3.5528524e-06
===========>   testing    <===========
Epoch: [840][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0760 (0.0760)	
0.9999919 3.3802517e-06
Epoch: [840][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0560 (0.0565)	
0.999987 3.3576844e-06
Epoch: [840][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0466 (0.0557)	
0.999987 3.3895487e-06
loss:  0.04132510375627296 0.03986833534370782
===========>   training    <===========
Epoch: [841][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0416 (0.0416)	
0.9999616 2.3671553e-06
===========>   testing    <===========
Epoch: [841][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0387 (0.0387)	
0.99999166 3.745066e-06
Epoch: [841][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0404 (0.0552)	
0.9999894 3.9067427e-06
Epoch: [841][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0690 (0.0564)	
0.99998975 4.1949615e-06
loss:  0.04222130845089389 0.03986833534370782
===========>   training    <===========
Epoch: [842][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0680 (0.0680)	
0.99998736 1.573775e-06
===========>   testing    <===========
Epoch: [842][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0454 (0.0454)	
0.9999888 2.8550442e-06
Epoch: [842][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0881 (0.0572)	
0.9999889 2.8676156e-06
Epoch: [842][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0870 (0.0572)	
0.99998605 2.9681532e-06
loss:  0.041184264516752056 0.03986833534370782
===========>   training    <===========
Epoch: [843][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0411 (0.0411)	
0.9999701 2.2164577e-06
===========>   testing    <===========
Epoch: [843][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0573 (0.0573)	
0.9999876 2.2592724e-06
Epoch: [843][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0502 (0.0571)	
0.9999832 2.26521e-06
Epoch: [843][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0532 (0.0546)	
0.9999813 2.346723e-06
loss:  0.04019316649397231 0.03986833534370782
===========>   training    <===========
Epoch: [844][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0388 (0.0388)	
0.9999852 3.3170472e-06
===========>   testing    <===========
Epoch: [844][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0550 (0.0550)	
0.9999902 3.71386e-06
Epoch: [844][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0389 (0.0577)	
0.9999887 3.1940285e-06
Epoch: [844][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0637 (0.0557)	
0.9999895 3.853055e-06
loss:  0.040305717385752615 0.03986833534370782
===========>   training    <===========
Epoch: [845][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0376 (0.0376)	
0.9999752 3.995225e-06
===========>   testing    <===========
Epoch: [845][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0494 (0.0494)	
0.9999869 3.4391817e-06
Epoch: [845][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0457 (0.0585)	
0.9999846 3.0470776e-06
Epoch: [845][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0611 (0.0577)	
0.9999825 3.6611316e-06
loss:  0.041375912503688106 0.03986833534370782
===========>   training    <===========
Epoch: [846][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0413 (0.0413)	
0.99998546 2.7455283e-06
===========>   testing    <===========
Epoch: [846][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0400 (0.0400)	
0.9999913 3.340552e-06
Epoch: [846][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0703 (0.0586)	
0.9999889 3.012676e-06
Epoch: [846][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0641 (0.0565)	
0.99998605 3.3390934e-06
loss:  0.04054848759232388 0.03986833534370782
===========>   training    <===========
Epoch: [847][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0390 (0.0390)	
0.99999034 3.5542014e-06
===========>   testing    <===========
Epoch: [847][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0290 (0.0290)	
0.99999285 3.1391137e-06
Epoch: [847][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0334 (0.0595)	
0.99998987 2.6956673e-06
Epoch: [847][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.1926 (0.0611)	
0.99998724 2.5497304e-06
loss:  0.04237169282781006 0.03986833534370782
===========>   training    <===========
Epoch: [848][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0426 (0.0426)	
0.9999862 2.5111895e-06
===========>   testing    <===========
Epoch: [848][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0539 (0.0539)	
0.9999901 3.4585375e-06
Epoch: [848][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0338 (0.0579)	
0.9999907 3.1303096e-06
Epoch: [848][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.1646 (0.0570)	
0.9999857 2.1517342e-06
loss:  0.04064469836341322 0.03986833534370782
===========>   training    <===========
Epoch: [849][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0428 (0.0428)	
0.9999918 5.0315207e-06
===========>   testing    <===========
Epoch: [849][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0473 (0.0473)	
0.9999883 3.5307216e-06
Epoch: [849][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0331 (0.0552)	
0.9999833 3.7839825e-06
Epoch: [849][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0803 (0.0577)	
0.99998355 3.4853908e-06
loss:  0.041098427031165174 0.03986833534370782
===========>   training    <===========
Epoch: [850][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0446 (0.0446)	
0.9999801 2.0880893e-06
===========>   testing    <===========
Epoch: [850][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0398 (0.0398)	
0.9999887 3.926854e-06
Epoch: [850][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0290 (0.0572)	
0.99998546 3.5001e-06
Epoch: [850][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.1355 (0.0576)	
0.99998283 3.6213855e-06
loss:  0.04127668241452154 0.03986833534370782
===========>   training    <===========
Epoch: [851][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0476 (0.0476)	
0.99999154 3.6892834e-06
===========>   testing    <===========
Epoch: [851][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0403 (0.0403)	
0.99998975 5.1572583e-06
Epoch: [851][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0300 (0.0587)	
0.9999912 4.854255e-06
Epoch: [851][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0952 (0.0582)	
0.999985 5.151016e-06
loss:  0.04131691969625617 0.03986833534370782
===========>   training    <===========
Epoch: [852][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0437 (0.0437)	
0.9999845 3.9317256e-06
===========>   testing    <===========
Epoch: [852][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0476 (0.0476)	
0.9999869 5.005771e-06
Epoch: [852][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0447 (0.0580)	
0.9999908 4.9638843e-06
Epoch: [852][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0850 (0.0569)	
0.9999856 3.379897e-06
loss:  0.04241989879427732 0.03986833534370782
===========>   training    <===========
Epoch: [853][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0385 (0.0385)	
0.9999827 2.6228265e-06
===========>   testing    <===========
Epoch: [853][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0321 (0.0321)	
0.9999858 4.8606526e-06
Epoch: [853][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0389 (0.0567)	
0.9999888 4.217006e-06
Epoch: [853][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.1244 (0.0572)	
0.9999832 5.229423e-06
loss:  0.041274167951692364 0.03986833534370782
===========>   training    <===========
Epoch: [854][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0455 (0.0455)	
0.99998903 4.896402e-06
===========>   testing    <===========
Epoch: [854][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0342 (0.0342)	
0.9999814 3.4059021e-06
Epoch: [854][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0479 (0.0545)	
0.999987 3.5395042e-06
Epoch: [854][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.1401 (0.0549)	
0.99997926 3.453699e-06
loss:  0.039881708169183794 0.03986833534370782
===========>   training    <===========
Epoch: [855][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0455 (0.0455)	
0.9999889 6.185606e-06
===========>   testing    <===========
Epoch: [855][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0470 (0.0470)	
0.9999869 3.5412731e-06
Epoch: [855][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0442 (0.0574)	
0.9999888 3.2009993e-06
Epoch: [855][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.1048 (0.0557)	
0.99998045 3.1620596e-06
loss:  0.040144366738816384 0.03986833534370782
===========>   training    <===========
Epoch: [856][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0546 (0.0546)	
0.99998796 3.2552798e-06
===========>   testing    <===========
Epoch: [856][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0458 (0.0458)	
0.999984 2.9978614e-06
Epoch: [856][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0378 (0.0561)	
0.9999871 3.3494073e-06
Epoch: [856][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0721 (0.0557)	
0.99998045 2.995095e-06
loss:  0.03979034939986892 0.03986833534370782
===========>   training    <===========
Epoch: [857][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0377 (0.0377)	
0.9999616 1.9180643e-06
===========>   testing    <===========
Epoch: [857][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0296 (0.0296)	
0.9999858 3.4082188e-06
Epoch: [857][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0390 (0.0551)	
0.99998415 4.616119e-06
Epoch: [857][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.1031 (0.0557)	
0.99998176 3.5725488e-06
loss:  0.0404851576512808 0.03979034939986892
===========>   training    <===========
Epoch: [858][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0365 (0.0365)	
0.99998784 1.948091e-06
===========>   testing    <===========
Epoch: [858][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0459 (0.0459)	
0.9999889 3.2851378e-06
Epoch: [858][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0451 (0.0578)	
0.99998724 4.1138155e-06
Epoch: [858][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.1250 (0.0583)	
0.99997365 3.3829926e-06
loss:  0.04180051557320197 0.03979034939986892
===========>   training    <===========
Epoch: [859][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0407 (0.0407)	
0.9999918 2.4859485e-06
===========>   testing    <===========
Epoch: [859][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0498 (0.0498)	
0.99998546 3.2621947e-06
Epoch: [859][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0985 (0.0566)	
0.99997485 3.7231616e-06
Epoch: [859][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0517 (0.0551)	
0.9999809 3.3507686e-06
loss:  0.04171627273707401 0.03979034939986892
===========>   training    <===========
Epoch: [860][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0455 (0.0455)	
0.99997663 3.1667976e-06
===========>   testing    <===========
Epoch: [860][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0410 (0.0410)	
0.99998915 3.6274553e-06
Epoch: [860][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0683 (0.0578)	
0.99998295 3.7026246e-06
Epoch: [860][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0673 (0.0566)	
0.9999808 3.9217343e-06
loss:  0.04190188332232936 0.03979034939986892
===========>   training    <===========
Epoch: [861][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0447 (0.0447)	
0.9999863 2.3323971e-06
===========>   testing    <===========
Epoch: [861][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0643 (0.0643)	
0.99999 3.1027048e-06
Epoch: [861][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0349 (0.0583)	
0.9999839 3.6346648e-06
Epoch: [861][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.1341 (0.0568)	
0.99998164 2.7270007e-06
loss:  0.04149464533045877 0.03979034939986892
===========>   training    <===========
Epoch: [862][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0467 (0.0467)	
0.9999819 1.9086815e-06
===========>   testing    <===========
Epoch: [862][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0605 (0.0605)	
0.9999913 3.7494187e-06
Epoch: [862][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0475 (0.0570)	
0.99999154 4.5949573e-06
Epoch: [862][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0941 (0.0555)	
0.9999871 4.058048e-06
loss:  0.04191346038595101 0.03979034939986892
===========>   training    <===========
Epoch: [863][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0491 (0.0491)	
0.99999297 3.0902606e-06
===========>   testing    <===========
Epoch: [863][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0532 (0.0532)	
0.99999213 4.6304576e-06
Epoch: [863][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0341 (0.0578)	
0.9999912 4.520563e-06
Epoch: [863][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0650 (0.0564)	
0.99998474 4.9728446e-06
loss:  0.04035806833592015 0.03979034939986892
===========>   training    <===========
Epoch: [864][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0400 (0.0400)	
0.9999927 2.288836e-06
===========>   testing    <===========
Epoch: [864][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0367 (0.0367)	
0.99999046 3.4947768e-06
Epoch: [864][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0600 (0.0577)	
0.99998903 3.6502265e-06
Epoch: [864][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0929 (0.0568)	
0.9999783 3.5971707e-06
loss:  0.04223953395376112 0.03979034939986892
===========>   training    <===========
Epoch: [865][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0399 (0.0399)	
0.99998724 7.492336e-06
===========>   testing    <===========
Epoch: [865][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0386 (0.0386)	
0.9999906 4.1651274e-06
Epoch: [865][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0309 (0.0567)	
0.9999889 4.001883e-06
Epoch: [865][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.1043 (0.0573)	
0.9999826 6.039252e-06
loss:  0.04178694913467318 0.03979034939986892
===========>   training    <===========
Epoch: [866][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0406 (0.0406)	
0.9999862 2.3597802e-06
===========>   testing    <===========
Epoch: [866][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0380 (0.0380)	
0.99998736 4.055688e-06
Epoch: [866][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0285 (0.0600)	
0.99998724 3.7618252e-06
Epoch: [866][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.1106 (0.0578)	
0.99997914 5.300465e-06
loss:  0.042404285959537824 0.03979034939986892
===========>   training    <===========
Epoch: [867][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0453 (0.0453)	
0.99997807 5.0906942e-06
===========>   testing    <===========
Epoch: [867][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0669 (0.0669)	
0.9999919 4.326352e-06
Epoch: [867][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0336 (0.0602)	
0.9999919 4.3480886e-06
Epoch: [867][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.1222 (0.0599)	
0.9999876 5.61618e-06
loss:  0.043469601989279294 0.03979034939986892
===========>   training    <===========
Epoch: [868][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0437 (0.0437)	
0.99998236 5.573973e-06
===========>   testing    <===========
Epoch: [868][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0494 (0.0494)	
0.9999907 3.64633e-06
Epoch: [868][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0273 (0.0584)	
0.99998987 3.5287287e-06
Epoch: [868][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.1218 (0.0571)	
0.99998105 3.7854477e-06
loss:  0.0419384826345377 0.03979034939986892
===========>   training    <===========
Epoch: [869][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0622 (0.0622)	
0.9999908 7.204714e-06
===========>   testing    <===========
Epoch: [869][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0323 (0.0323)	
0.9999937 4.4584226e-06
Epoch: [869][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0240 (0.0575)	
0.9999924 4.5853362e-06
Epoch: [869][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.1480 (0.0578)	
0.9999856 3.6470742e-06
loss:  0.04243552588182142 0.03979034939986892
===========>   training    <===========
Epoch: [870][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0347 (0.0347)	
0.9999858 1.04503115e-05
===========>   testing    <===========
Epoch: [870][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0315 (0.0315)	
0.99999213 4.4260055e-06
Epoch: [870][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0232 (0.0561)	
0.9999827 4.392877e-06
Epoch: [870][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0758 (0.0560)	
0.99998105 5.050404e-06
loss:  0.041668185497598875 0.03979034939986892
===========>   training    <===========
Epoch: [871][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0442 (0.0442)	
0.9999831 4.4978015e-06
===========>   testing    <===========
Epoch: [871][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0620 (0.0620)	
0.9999925 3.5566325e-06
Epoch: [871][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0260 (0.0579)	
0.99998546 4.0230134e-06
Epoch: [871][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0993 (0.0571)	
0.99998367 3.8141407e-06
loss:  0.04212874830823232 0.03979034939986892
===========>   training    <===========
Epoch: [872][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0441 (0.0441)	
0.99997425 2.011648e-06
===========>   testing    <===========
Epoch: [872][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0340 (0.0340)	
0.99999106 3.9026204e-06
Epoch: [872][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0205 (0.0580)	
0.999987 3.2991122e-06
Epoch: [872][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.1114 (0.0579)	
0.9999831 4.0867876e-06
loss:  0.042737768384066066 0.03979034939986892
===========>   training    <===========
Epoch: [873][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0397 (0.0397)	
0.99998975 2.82365e-06
===========>   testing    <===========
Epoch: [873][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0398 (0.0398)	
0.99998796 3.2241026e-06
Epoch: [873][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0188 (0.0577)	
0.9999751 3.6170227e-06
Epoch: [873][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0630 (0.0580)	
0.99997926 2.6499827e-06
loss:  0.04264659454461661 0.03979034939986892
===========>   training    <===========
Epoch: [874][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0605 (0.0605)	
0.99998355 1.6885297e-06
===========>   testing    <===========
Epoch: [874][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0546 (0.0546)	
0.9999882 3.4714317e-06
Epoch: [874][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0371 (0.0579)	
0.99997234 3.5701644e-06
Epoch: [874][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0584 (0.0570)	
0.9999795 2.7693584e-06
loss:  0.04162858614129472 0.03979034939986892
===========>   training    <===========
Epoch: [875][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0523 (0.0523)	
0.9999666 7.9704745e-07
===========>   testing    <===========
Epoch: [875][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0328 (0.0328)	
0.9999882 4.077666e-06
Epoch: [875][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0852 (0.0586)	
0.9999851 4.6784226e-06
Epoch: [875][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0736 (0.0579)	
0.9999845 2.674784e-06
loss:  0.04211284095091783 0.03979034939986892
===========>   training    <===========
Epoch: [876][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0487 (0.0487)	
0.999984 1.9737327e-06
===========>   testing    <===========
Epoch: [876][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0310 (0.0310)	
0.99998915 2.9516764e-06
Epoch: [876][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0271 (0.0575)	
0.99998474 3.2567361e-06
Epoch: [876][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0605 (0.0571)	
0.9999821 2.449892e-06
loss:  0.04210701488642321 0.03979034939986892
===========>   training    <===========
Epoch: [877][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0405 (0.0405)	
0.99998295 2.8874922e-06
===========>   testing    <===========
Epoch: [877][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0487 (0.0487)	
0.9999876 3.931658e-06
Epoch: [877][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0249 (0.0591)	
0.9999746 3.6132164e-06
Epoch: [877][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0875 (0.0567)	
0.999974 4.8652764e-06
loss:  0.04112193934653785 0.03979034939986892
===========>   training    <===========
Epoch: [878][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0506 (0.0506)	
0.999985 2.8638551e-06
===========>   testing    <===========
Epoch: [878][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0705 (0.0705)	
0.9999913 3.7927325e-06
Epoch: [878][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0957 (0.0647)	
0.9999893 3.7808984e-06
Epoch: [878][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.2340 (0.0621)	
0.9999896 5.6395484e-06
loss:  0.0436002397401305 0.03979034939986892
===========>   training    <===========
Epoch: [879][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0488 (0.0488)	
0.9999912 2.3835696e-06
===========>   testing    <===========
Epoch: [879][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0277 (0.0277)	
0.9999882 3.0540045e-06
Epoch: [879][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0318 (0.0582)	
0.9999813 3.1601062e-06
Epoch: [879][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.1364 (0.0581)	
0.9999827 3.8372755e-06
loss:  0.04141764739735865 0.03979034939986892
===========>   training    <===========
Epoch: [880][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0460 (0.0460)	
0.99999464 2.1640074e-06
===========>   testing    <===========
Epoch: [880][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0356 (0.0356)	
0.999987 3.9052675e-06
Epoch: [880][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0333 (0.0593)	
0.9999889 4.0248015e-06
Epoch: [880][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0897 (0.0577)	
0.9999831 4.7293015e-06
loss:  0.04204955117078679 0.03979034939986892
===========>   training    <===========
Epoch: [881][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0415 (0.0415)	
0.99998224 3.389613e-06
===========>   testing    <===========
Epoch: [881][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0311 (0.0311)	
0.999987 4.829956e-06
Epoch: [881][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0267 (0.0612)	
0.99999225 4.7488843e-06
Epoch: [881][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.1730 (0.0598)	
0.9999845 4.78745e-06
loss:  0.0426971063263244 0.03979034939986892
===========>   training    <===========
Epoch: [882][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0384 (0.0384)	
0.9999944 6.459433e-06
===========>   testing    <===========
Epoch: [882][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0382 (0.0382)	
0.99998987 4.904571e-06
Epoch: [882][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0319 (0.0606)	
0.99999046 4.5995475e-06
Epoch: [882][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.1476 (0.0581)	
0.9999881 2.830779e-06
loss:  0.04164348568509224 0.03979034939986892
===========>   training    <===========
Epoch: [883][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0411 (0.0411)	
0.99998534 3.8543635e-06
===========>   testing    <===========
Epoch: [883][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0570 (0.0570)	
0.99998844 4.55667e-06
Epoch: [883][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0263 (0.0584)	
0.9999871 4.472748e-06
Epoch: [883][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.1169 (0.0569)	
0.99998426 3.6076044e-06
loss:  0.04156553289662768 0.03979034939986892
===========>   training    <===========
Epoch: [884][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0375 (0.0375)	
0.9999913 5.5823302e-06
===========>   testing    <===========
Epoch: [884][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0341 (0.0341)	
0.9999871 4.525157e-06
Epoch: [884][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0295 (0.0600)	
0.9999801 4.3461405e-06
Epoch: [884][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.1567 (0.0604)	
0.99998355 3.2811488e-06
loss:  0.043485832081089915 0.03979034939986892
===========>   training    <===========
Epoch: [885][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0424 (0.0424)	
0.99999213 4.356539e-06
===========>   testing    <===========
Epoch: [885][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0354 (0.0354)	
0.9999856 3.1825716e-06
Epoch: [885][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0337 (0.0589)	
0.99998736 3.2656653e-06
Epoch: [885][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0789 (0.0586)	
0.9999759 3.3132724e-06
loss:  0.04094706252167224 0.03979034939986892
===========>   training    <===========
Epoch: [886][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0386 (0.0386)	
0.9999913 3.8523126e-06
===========>   testing    <===========
Epoch: [886][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0361 (0.0361)	
0.9999864 4.248929e-06
Epoch: [886][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0279 (0.0573)	
0.9999902 3.7289678e-06
Epoch: [886][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0837 (0.0576)	
0.99998295 4.697764e-06
loss:  0.04179626344488818 0.03979034939986892
===========>   training    <===========
Epoch: [887][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0410 (0.0410)	
0.9999938 5.970123e-06
===========>   testing    <===========
Epoch: [887][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0478 (0.0478)	
0.99998605 3.7454874e-06
Epoch: [887][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0404 (0.0575)	
0.9999877 4.4342864e-06
Epoch: [887][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.1219 (0.0568)	
0.99998057 4.2884335e-06
loss:  0.04070914140448734 0.03979034939986892
===========>   training    <===========
Epoch: [888][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0411 (0.0411)	
0.9999844 1.6176698e-06
===========>   testing    <===========
Epoch: [888][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0451 (0.0451)	
0.99998677 3.9284755e-06
Epoch: [888][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0289 (0.0582)	
0.9999846 4.136992e-06
Epoch: [888][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.1054 (0.0572)	
0.99997914 4.516271e-06
loss:  0.04193932985874538 0.03979034939986892
===========>   training    <===========
Epoch: [889][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0402 (0.0402)	
0.9999819 4.1050957e-06
===========>   testing    <===========
Epoch: [889][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0460 (0.0460)	
0.9999907 4.15976e-06
Epoch: [889][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0252 (0.0575)	
0.99998355 4.273964e-06
Epoch: [889][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0762 (0.0569)	
0.999982 3.3004308e-06
loss:  0.040755522104516606 0.03979034939986892
===========>   training    <===========
Epoch: [890][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0503 (0.0503)	
0.9999924 6.5872164e-06
===========>   testing    <===========
Epoch: [890][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0352 (0.0352)	
0.99998736 3.7191337e-06
Epoch: [890][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0238 (0.0586)	
0.9999777 3.91503e-06
Epoch: [890][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0976 (0.0571)	
0.9999738 4.7267986e-06
loss:  0.03990492655810285 0.03979034939986892
===========>   training    <===========
Epoch: [891][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0437 (0.0437)	
0.999961 2.5687232e-06
===========>   testing    <===========
Epoch: [891][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0357 (0.0357)	
0.99998915 4.201743e-06
Epoch: [891][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0312 (0.0563)	
0.9999864 4.2376873e-06
Epoch: [891][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0852 (0.0557)	
0.9999809 3.222028e-06
loss:  0.04085999136004914 0.03979034939986892
===========>   training    <===========
Epoch: [892][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0403 (0.0403)	
0.9999857 2.5711595e-06
===========>   testing    <===========
Epoch: [892][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0277 (0.0277)	
0.99998915 4.677825e-06
Epoch: [892][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0295 (0.0588)	
0.99998987 4.771424e-06
Epoch: [892][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.1050 (0.0583)	
0.9999838 3.8683675e-06
loss:  0.04153725708043854 0.03979034939986892
===========>   training    <===========
Epoch: [893][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0421 (0.0421)	
0.9999844 3.3087128e-06
===========>   testing    <===========
Epoch: [893][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0413 (0.0413)	
0.9999894 4.122707e-06
Epoch: [893][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0300 (0.0594)	
0.9999882 4.1661524e-06
Epoch: [893][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.1459 (0.0592)	
0.9999827 5.074379e-06
loss:  0.042978254614265965 0.03979034939986892
===========>   training    <===========
Epoch: [894][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0392 (0.0392)	
0.99998474 2.5076474e-06
===========>   testing    <===========
Epoch: [894][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0309 (0.0309)	
0.99998903 4.487591e-06
Epoch: [894][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0227 (0.0572)	
0.99999034 4.449795e-06
Epoch: [894][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.1347 (0.0568)	
0.9999846 4.8126913e-06
loss:  0.04142096736793899 0.03979034939986892
===========>   training    <===========
Epoch: [895][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0376 (0.0376)	
0.9999863 4.1050916e-06
===========>   testing    <===========
Epoch: [895][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0370 (0.0370)	
0.9999865 3.928996e-06
Epoch: [895][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0214 (0.0563)	
0.9999887 3.661771e-06
Epoch: [895][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0585 (0.0565)	
0.99997616 3.3479769e-06
loss:  0.04116443913342327 0.03979034939986892
===========>   training    <===========
Epoch: [896][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0513 (0.0513)	
0.9999666 4.2594493e-06
===========>   testing    <===========
Epoch: [896][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0392 (0.0392)	
0.999985 5.7836564e-06
Epoch: [896][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0275 (0.0638)	
0.9999914 5.1438096e-06
Epoch: [896][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0833 (0.0660)	
0.9999863 3.3294584e-06
loss:  0.04694994493602467 0.03979034939986892
===========>   training    <===========
Epoch: [897][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0394 (0.0394)	
0.9999957 7.520556e-06
===========>   testing    <===========
Epoch: [897][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0410 (0.0410)	
0.99998975 5.518805e-06
Epoch: [897][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0296 (0.0607)	
0.99999154 4.071996e-06
Epoch: [897][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.1329 (0.0593)	
0.9999846 3.581237e-06
loss:  0.041814609997634866 0.03979034939986892
===========>   training    <===========
Epoch: [898][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0407 (0.0407)	
0.99998426 2.08706e-06
===========>   testing    <===========
Epoch: [898][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0667 (0.0667)	
0.999985 5.5195155e-06
Epoch: [898][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0593 (0.0607)	
0.99998236 5.055835e-06
Epoch: [898][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0959 (0.0600)	
0.99997425 5.7635157e-06
loss:  0.04346746644158983 0.03979034939986892
===========>   training    <===========
Epoch: [899][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0389 (0.0389)	
0.9999919 7.359709e-06
===========>   testing    <===========
Epoch: [899][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0492 (0.0492)	
0.99999106 4.594607e-06
Epoch: [899][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0856 (0.0608)	
0.99999034 4.765303e-06
Epoch: [899][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0646 (0.0585)	
0.99998593 2.512265e-06
loss:  0.04186910761158147 0.03979034939986892
===========>   training    <===========
Epoch: [900][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0498 (0.0498)	
0.9999962 3.4845002e-06
===========>   testing    <===========
Epoch: [900][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0355 (0.0355)	
0.9999896 4.3830937e-06
Epoch: [900][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0948 (0.0600)	
0.9999896 4.9239457e-06
Epoch: [900][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.1270 (0.0589)	
0.99998415 3.5984847e-06
loss:  0.04333306658262559 0.03979034939986892
===========>   training    <===========
Epoch: [901][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0402 (0.0402)	
0.99999106 3.0743988e-06
===========>   testing    <===========
Epoch: [901][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0374 (0.0374)	
0.9999881 4.799207e-06
Epoch: [901][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0393 (0.0618)	
0.99998724 4.2058728e-06
Epoch: [901][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0957 (0.0592)	
0.9999753 3.2306987e-06
loss:  0.04335271974392152 0.03979034939986892
===========>   training    <===========
Epoch: [902][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0435 (0.0435)	
0.99997985 2.523635e-06
===========>   testing    <===========
Epoch: [902][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0369 (0.0369)	
0.9999888 5.3207373e-06
Epoch: [902][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0489 (0.0588)	
0.99998724 4.758745e-06
Epoch: [902][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0855 (0.0583)	
0.9999827 3.1491857e-06
loss:  0.0415579898017836 0.03979034939986892
===========>   training    <===========
Epoch: [903][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0409 (0.0409)	
0.9999914 2.3139264e-06
===========>   testing    <===========
Epoch: [903][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0500 (0.0500)	
0.9999906 5.3180033e-06
Epoch: [903][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0649 (0.0641)	
0.9999895 4.824276e-06
Epoch: [903][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0667 (0.0624)	
0.9999875 4.104434e-06
loss:  0.043535488434215175 0.03979034939986892
===========>   training    <===========
Epoch: [904][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0411 (0.0411)	
0.9999887 2.6927382e-06
===========>   testing    <===========
Epoch: [904][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0391 (0.0391)	
0.99999344 4.2183015e-06
Epoch: [904][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0347 (0.0611)	
0.9999894 3.922026e-06
Epoch: [904][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0657 (0.0581)	
0.999987 2.1369813e-06
loss:  0.04194918667611225 0.03979034939986892
===========>   training    <===========
Epoch: [905][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0380 (0.0380)	
0.9999796 4.519304e-06
===========>   testing    <===========
Epoch: [905][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0384 (0.0384)	
0.9999908 4.3115283e-06
Epoch: [905][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0216 (0.0623)	
0.99999 3.9224224e-06
Epoch: [905][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0603 (0.0603)	
0.99998367 2.8124757e-06
loss:  0.04239740801664582 0.03979034939986892
===========>   training    <===========
Epoch: [906][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0407 (0.0407)	
0.999985 1.9214183e-06
===========>   testing    <===========
Epoch: [906][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0409 (0.0409)	
0.99999106 3.3297758e-06
Epoch: [906][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0514 (0.0586)	
0.9999893 3.2831394e-06
Epoch: [906][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0914 (0.0582)	
0.99998367 3.3439944e-06
loss:  0.04164617809579807 0.03979034939986892
===========>   training    <===========
Epoch: [907][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0390 (0.0390)	
0.99999726 6.553218e-06
===========>   testing    <===========
Epoch: [907][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0598 (0.0598)	
0.9999869 3.847628e-06
Epoch: [907][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0390 (0.0581)	
0.99998486 3.7617353e-06
Epoch: [907][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.1156 (0.0583)	
0.99998116 3.8140279e-06
loss:  0.04271733459719185 0.03979034939986892
===========>   training    <===========
Epoch: [908][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0417 (0.0417)	
0.99999666 1.3526508e-06
===========>   testing    <===========
Epoch: [908][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0420 (0.0420)	
0.99998724 3.1517186e-06
Epoch: [908][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0357 (0.0592)	
0.9999918 2.9919834e-06
Epoch: [908][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0726 (0.0576)	
0.99998295 2.5579845e-06
loss:  0.04122825908900152 0.03979034939986892
===========>   training    <===========
Epoch: [909][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0512 (0.0512)	
0.99998736 1.8903634e-06
===========>   testing    <===========
Epoch: [909][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0468 (0.0468)	
0.9999877 4.3447894e-06
Epoch: [909][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0323 (0.0600)	
0.9999865 4.279617e-06
Epoch: [909][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.1148 (0.0588)	
0.99998176 4.2051347e-06
loss:  0.041781123465758685 0.03979034939986892
===========>   training    <===========
Epoch: [910][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0348 (0.0348)	
0.99998915 2.8192696e-06
===========>   testing    <===========
Epoch: [910][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0428 (0.0428)	
0.9999926 6.8159366e-06
Epoch: [910][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0397 (0.0589)	
0.99999416 7.100385e-06
Epoch: [910][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0723 (0.0577)	
0.9999883 5.684961e-06
loss:  0.041336965341752685 0.03979034939986892
===========>   training    <===========
Epoch: [911][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0388 (0.0388)	
0.99998856 3.7237971e-06
===========>   testing    <===========
Epoch: [911][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0317 (0.0317)	
0.9999883 4.577917e-06
Epoch: [911][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0280 (0.0599)	
0.9999863 4.024652e-06
Epoch: [911][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.1126 (0.0601)	
0.9999784 3.4305433e-06
loss:  0.042532063289914546 0.03979034939986892
===========>   training    <===========
Epoch: [912][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0402 (0.0402)	
0.99999166 4.7423177e-06
===========>   testing    <===========
Epoch: [912][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0400 (0.0400)	
0.99999154 5.2247024e-06
Epoch: [912][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0188 (0.0602)	
0.9999893 5.1283705e-06
Epoch: [912][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0667 (0.0580)	
0.9999827 4.6908694e-06
loss:  0.04103697045414412 0.03979034939986892
===========>   training    <===========
Epoch: [913][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0334 (0.0334)	
0.9999889 3.9923457e-06
===========>   testing    <===========
Epoch: [913][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0401 (0.0401)	
0.99998724 3.9085685e-06
Epoch: [913][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0212 (0.0573)	
0.99998116 3.7009795e-06
Epoch: [913][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0730 (0.0583)	
0.99997866 2.2445704e-06
loss:  0.04117142155952669 0.03979034939986892
===========>   training    <===========
Epoch: [914][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0366 (0.0366)	
0.99997973 2.2721397e-06
===========>   testing    <===========
Epoch: [914][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0582 (0.0582)	
0.9999887 3.8316334e-06
Epoch: [914][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0383 (0.0579)	
0.9999864 3.9821784e-06
Epoch: [914][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0724 (0.0584)	
0.9999807 3.046171e-06
loss:  0.041084850324380584 0.03979034939986892
===========>   training    <===========
Epoch: [915][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0414 (0.0414)	
0.9999895 2.0738942e-06
===========>   testing    <===========
Epoch: [915][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0481 (0.0481)	
0.999985 3.1899556e-06
Epoch: [915][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0258 (0.0594)	
0.999985 3.481202e-06
Epoch: [915][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0499 (0.0583)	
0.99997747 2.8671645e-06
loss:  0.04139554559195391 0.03979034939986892
===========>   training    <===========
Epoch: [916][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0408 (0.0408)	
0.99999523 2.449705e-06
===========>   testing    <===========
Epoch: [916][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0339 (0.0339)	
0.9999883 4.7814046e-06
Epoch: [916][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0274 (0.0592)	
0.99998975 4.534345e-06
Epoch: [916][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0879 (0.0591)	
0.9999856 5.1339393e-06
loss:  0.042516927461770826 0.03979034939986892
===========>   training    <===========
Epoch: [917][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0460 (0.0460)	
0.9999492 2.830339e-06
===========>   testing    <===========
Epoch: [917][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0427 (0.0427)	
0.99998784 3.828375e-06
Epoch: [917][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0345 (0.0613)	
0.9999857 3.9352212e-06
Epoch: [917][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.1645 (0.0600)	
0.99997735 3.2008775e-06
loss:  0.04288253810356468 0.03979034939986892
===========>   training    <===========
Epoch: [918][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0456 (0.0456)	
0.9999896 3.2555902e-06
===========>   testing    <===========
Epoch: [918][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0324 (0.0324)	
0.99998546 3.2482403e-06
Epoch: [918][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0237 (0.0604)	
0.9999902 3.2131725e-06
Epoch: [918][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0781 (0.0580)	
0.9999784 3.0659928e-06
loss:  0.0416038849939081 0.03979034939986892
===========>   training    <===========
Epoch: [919][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0352 (0.0352)	
0.9999882 3.448917e-06
===========>   testing    <===========
Epoch: [919][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0387 (0.0387)	
0.9999902 4.1516237e-06
Epoch: [919][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0342 (0.0624)	
0.99999344 4.147251e-06
Epoch: [919][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0869 (0.0602)	
0.9999875 3.8065714e-06
loss:  0.04168059513015565 0.03979034939986892
===========>   training    <===========
Epoch: [920][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0455 (0.0455)	
0.9999757 2.6818414e-06
===========>   testing    <===========
Epoch: [920][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0372 (0.0372)	
0.9999901 4.029587e-06
Epoch: [920][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0245 (0.0604)	
0.99999094 4.408481e-06
Epoch: [920][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0930 (0.0582)	
0.99998057 3.6842487e-06
loss:  0.041295670040594756 0.03979034939986892
===========>   training    <===========
Epoch: [921][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0395 (0.0395)	
0.9999912 1.4061308e-05
===========>   testing    <===========
Epoch: [921][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0402 (0.0402)	
0.99999213 5.0507315e-06
Epoch: [921][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0203 (0.0592)	
0.99999356 5.0872386e-06
Epoch: [921][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0759 (0.0578)	
0.99998784 4.236378e-06
loss:  0.04026255389382283 0.03979034939986892
===========>   training    <===========
Epoch: [922][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0440 (0.0440)	
0.9999908 3.4086188e-06
===========>   testing    <===========
Epoch: [922][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0441 (0.0441)	
0.9999901 3.4381812e-06
Epoch: [922][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0252 (0.0599)	
0.9999918 3.6660442e-06
Epoch: [922][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0782 (0.0596)	
0.9999808 3.3307604e-06
loss:  0.04180107419058776 0.03979034939986892
===========>   training    <===========
Epoch: [923][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0379 (0.0379)	
0.99999356 5.8776945e-06
===========>   testing    <===========
Epoch: [923][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0411 (0.0411)	
0.9999871 3.0931237e-06
Epoch: [923][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0387 (0.0598)	
0.9999883 3.4103386e-06
Epoch: [923][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.1077 (0.0579)	
0.999985 3.9580677e-06
loss:  0.04127713836550073 0.03979034939986892
===========>   training    <===========
Epoch: [924][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0525 (0.0525)	
0.9999863 2.9698124e-06
===========>   testing    <===========
Epoch: [924][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0481 (0.0481)	
0.99999225 3.098766e-06
Epoch: [924][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0279 (0.0590)	
0.9999887 3.4927577e-06
Epoch: [924][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.1108 (0.0595)	
0.99999 3.3537353e-06
loss:  0.042293098144546626 0.03979034939986892
===========>   training    <===========
Epoch: [925][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0457 (0.0457)	
0.9999901 2.9334503e-06
===========>   testing    <===========
Epoch: [925][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0470 (0.0470)	
0.9999902 3.621693e-06
Epoch: [925][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0328 (0.0626)	
0.9999906 3.5146033e-06
Epoch: [925][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0775 (0.0603)	
0.99998903 3.4608802e-06
loss:  0.04250317261457037 0.03979034939986892
===========>   training    <===========
Epoch: [926][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0368 (0.0368)	
0.9999924 3.867062e-06
===========>   testing    <===========
Epoch: [926][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0434 (0.0434)	
0.99998665 3.2842324e-06
Epoch: [926][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0590 (0.0601)	
0.9999895 3.3947567e-06
Epoch: [926][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.1161 (0.0595)	
0.9999831 3.5728383e-06
loss:  0.04357669282830301 0.03979034939986892
===========>   training    <===========
Epoch: [927][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0374 (0.0374)	
0.9999944 5.0388967e-06
===========>   testing    <===========
Epoch: [927][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0353 (0.0353)	
0.999987 3.4183292e-06
Epoch: [927][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0230 (0.0587)	
0.9999907 3.4681093e-06
Epoch: [927][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0958 (0.0580)	
0.99998367 3.4526322e-06
loss:  0.041695457328629115 0.03979034939986892
===========>   training    <===========
Epoch: [928][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0418 (0.0418)	
0.9999871 3.2456514e-06
===========>   testing    <===========
Epoch: [928][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0411 (0.0411)	
0.9999889 3.002551e-06
Epoch: [928][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0217 (0.0610)	
0.99999166 3.01757e-06
Epoch: [928][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0866 (0.0593)	
0.99998295 3.1942661e-06
loss:  0.04143247797329519 0.03979034939986892
===========>   training    <===========
Epoch: [929][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0384 (0.0384)	
0.9999901 4.6789714e-06
===========>   testing    <===========
Epoch: [929][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0340 (0.0340)	
0.99998903 3.410124e-06
Epoch: [929][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0310 (0.0601)	
0.99999046 3.5088433e-06
Epoch: [929][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0783 (0.0587)	
0.99998164 3.2471685e-06
loss:  0.04201084331295912 0.03979034939986892
===========>   training    <===========
Epoch: [930][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0395 (0.0395)	
0.9999956 8.072838e-06
===========>   testing    <===========
Epoch: [930][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0486 (0.0486)	
0.9999882 3.5746375e-06
Epoch: [930][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0244 (0.0600)	
0.999985 3.842626e-06
Epoch: [930][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.1124 (0.0588)	
0.9999778 3.3017152e-06
loss:  0.0422688496403284 0.03979034939986892
===========>   training    <===========
Epoch: [931][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0376 (0.0376)	
0.9999882 4.6630416e-06
===========>   testing    <===========
Epoch: [931][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0439 (0.0439)	
0.9999902 3.8827297e-06
Epoch: [931][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0290 (0.0599)	
0.9999871 4.2786537e-06
Epoch: [931][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.1148 (0.0600)	
0.99997973 3.7443804e-06
loss:  0.04254256728743244 0.03979034939986892
===========>   training    <===========
Epoch: [932][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0350 (0.0350)	
0.99999523 6.2968165e-06
===========>   testing    <===========
Epoch: [932][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0456 (0.0456)	
0.99999046 3.689748e-06
Epoch: [932][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0399 (0.0607)	
0.9999887 4.433415e-06
Epoch: [932][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.1308 (0.0600)	
0.99998176 3.611129e-06
loss:  0.04294322870513401 0.03979034939986892
===========>   training    <===========
Epoch: [933][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0425 (0.0425)	
0.999979 2.508559e-06
===========>   testing    <===========
Epoch: [933][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0493 (0.0493)	
0.9999912 3.86464e-06
Epoch: [933][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0427 (0.0577)	
0.9999933 4.1107687e-06
Epoch: [933][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.1059 (0.0588)	
0.9999838 3.838231e-06
loss:  0.04247188983071404 0.03979034939986892
===========>   training    <===========
Epoch: [934][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0300 (0.0300)	
0.9999931 4.944085e-06
===========>   testing    <===========
Epoch: [934][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0428 (0.0428)	
0.99999213 5.025392e-06
Epoch: [934][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0305 (0.0594)	
0.99999297 5.017591e-06
Epoch: [934][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.1134 (0.0602)	
0.99998665 4.6503183e-06
loss:  0.042484748867497646 0.03979034939986892
===========>   training    <===========
Epoch: [935][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0398 (0.0398)	
0.9999932 7.1855147e-06
===========>   testing    <===========
Epoch: [935][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0273 (0.0273)	
0.99999404 3.863689e-06
Epoch: [935][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0300 (0.0563)	
0.99999535 5.129261e-06
Epoch: [935][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0960 (0.0576)	
0.9999908 3.491209e-06
loss:  0.04148518857026029 0.03979034939986892
===========>   training    <===========
Epoch: [936][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0359 (0.0359)	
0.99999475 1.2258152e-05
===========>   testing    <===========
Epoch: [936][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0404 (0.0404)	
0.99999225 3.6250758e-06
Epoch: [936][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0311 (0.0587)	
0.99999285 4.1944572e-06
Epoch: [936][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0750 (0.0588)	
0.9999863 2.9327957e-06
loss:  0.042354826204566765 0.03979034939986892
===========>   training    <===========
Epoch: [937][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0386 (0.0386)	
0.99999225 5.658269e-06
===========>   testing    <===========
Epoch: [937][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0662 (0.0662)	
0.9999907 4.7499398e-06
Epoch: [937][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0315 (0.0625)	
0.9999908 4.910974e-06
Epoch: [937][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.1619 (0.0639)	
0.9999789 2.9705375e-06
loss:  0.0440356271857818 0.03979034939986892
===========>   training    <===========
Epoch: [938][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0426 (0.0426)	
0.9999925 5.308841e-06
===========>   testing    <===========
Epoch: [938][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0574 (0.0574)	
0.9999907 4.943557e-06
Epoch: [938][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0760 (0.0573)	
0.9999913 5.6764993e-06
Epoch: [938][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.1201 (0.0589)	
0.9999889 5.3958593e-06
loss:  0.04223377620203006 0.03979034939986892
===========>   training    <===========
Epoch: [939][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0392 (0.0392)	
0.99999344 1.7502992e-06
===========>   testing    <===========
Epoch: [939][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0544 (0.0544)	
0.9999907 5.405687e-06
Epoch: [939][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0273 (0.0603)	
0.99999166 5.707227e-06
Epoch: [939][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.1297 (0.0611)	
0.9999896 4.7875965e-06
loss:  0.04292354166969259 0.03979034939986892
===========>   training    <===========
Epoch: [940][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0451 (0.0451)	
0.99999225 2.7153046e-06
===========>   testing    <===========
Epoch: [940][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0463 (0.0463)	
0.99999 3.860256e-06
Epoch: [940][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0337 (0.0584)	
0.9999895 4.3395135e-06
Epoch: [940][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0989 (0.0573)	
0.99998724 4.0002083e-06
loss:  0.041526719440377446 0.03979034939986892
===========>   training    <===========
Epoch: [941][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0467 (0.0467)	
0.99998283 2.1868677e-06
===========>   testing    <===========
Epoch: [941][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0400 (0.0400)	
0.9999918 3.840032e-06
Epoch: [941][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0382 (0.0566)	
0.9999882 4.1813255e-06
Epoch: [941][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1378 (0.0568)	
0.9999852 3.6066995e-06
loss:  0.041346359577829506 0.03979034939986892
===========>   training    <===========
Epoch: [942][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0420 (0.0420)	
0.9999968 6.9292037e-06
===========>   testing    <===========
Epoch: [942][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0400 (0.0400)	
0.9999875 3.9141005e-06
Epoch: [942][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0247 (0.0573)	
0.9999913 4.497943e-06
Epoch: [942][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1333 (0.0576)	
0.999985 3.0985e-06
loss:  0.04094287695726451 0.03979034939986892
===========>   training    <===========
Epoch: [943][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0417 (0.0417)	
0.9999938 4.0691975e-06
===========>   testing    <===========
Epoch: [943][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0449 (0.0449)	
0.99998796 3.6408849e-06
Epoch: [943][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0230 (0.0587)	
0.99999166 4.0099403e-06
Epoch: [943][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1353 (0.0579)	
0.9999869 3.9596157e-06
loss:  0.042783031665683646 0.03979034939986892
===========>   training    <===========
Epoch: [944][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0343 (0.0343)	
0.999987 3.3434715e-06
===========>   testing    <===========
Epoch: [944][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0469 (0.0469)	
0.9999906 4.2163947e-06
Epoch: [944][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0208 (0.0584)	
0.99999285 4.3854766e-06
Epoch: [944][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1077 (0.0575)	
0.99998665 4.080035e-06
loss:  0.04155072367787416 0.03979034939986892
===========>   training    <===========
Epoch: [945][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0433 (0.0433)	
0.9999893 2.8732577e-06
===========>   testing    <===========
Epoch: [945][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0434 (0.0434)	
0.99999356 3.7208122e-06
Epoch: [945][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0282 (0.0594)	
0.9999924 3.976262e-06
Epoch: [945][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1546 (0.0587)	
0.9999876 3.5021035e-06
loss:  0.04165328037066629 0.03979034939986892
===========>   training    <===========
Epoch: [946][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0388 (0.0388)	
0.99998903 4.1493477e-06
===========>   testing    <===========
Epoch: [946][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0483 (0.0483)	
0.99998915 3.292427e-06
Epoch: [946][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0605 (0.0582)	
0.9999845 3.3154913e-06
Epoch: [946][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1129 (0.0574)	
0.9999728 3.2213827e-06
loss:  0.041583294236642865 0.03979034939986892
===========>   training    <===========
Epoch: [947][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0425 (0.0425)	
0.99999404 3.2632495e-06
===========>   testing    <===========
Epoch: [947][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0434 (0.0434)	
0.99998355 3.2599087e-06
Epoch: [947][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0511 (0.0627)	
0.9999852 3.3695726e-06
Epoch: [947][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0894 (0.0590)	
0.9999716 2.6778953e-06
loss:  0.04299046393134631 0.03979034939986892
===========>   training    <===========
Epoch: [948][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0397 (0.0397)	
0.9999907 3.9736506e-06
===========>   testing    <===========
Epoch: [948][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0665 (0.0665)	
0.99998975 3.5370103e-06
Epoch: [948][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1874 (0.0626)	
0.9999912 3.3361903e-06
Epoch: [948][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0779 (0.0592)	
0.99998355 2.8545323e-06
loss:  0.04345011867908366 0.03979034939986892
===========>   training    <===========
Epoch: [949][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0397 (0.0397)	
0.99999416 4.81834e-06
===========>   testing    <===========
Epoch: [949][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0497 (0.0497)	
0.9999896 3.2543237e-06
Epoch: [949][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1103 (0.0594)	
0.99999094 2.9265232e-06
Epoch: [949][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1415 (0.0567)	
0.9999825 2.6174741e-06
loss:  0.04163323993047585 0.03979034939986892
===========>   training    <===========
Epoch: [950][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0421 (0.0421)	
0.99999475 1.3839966e-06
===========>   testing    <===========
Epoch: [950][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0419 (0.0419)	
0.9999881 2.6603213e-06
Epoch: [950][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0423 (0.0580)	
0.99998796 2.441689e-06
Epoch: [950][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1313 (0.0560)	
0.9999783 2.1550238e-06
loss:  0.04025493606561814 0.03979034939986892
===========>   training    <===========
Epoch: [951][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0433 (0.0433)	
0.99999094 3.238707e-06
===========>   testing    <===========
Epoch: [951][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0471 (0.0471)	
0.9999888 3.3179174e-06
Epoch: [951][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0556 (0.0588)	
0.9999871 3.1623067e-06
Epoch: [951][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1230 (0.0568)	
0.99998164 3.2459795e-06
loss:  0.04117409749655798 0.03979034939986892
===========>   training    <===========
Epoch: [952][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0387 (0.0387)	
0.9999906 5.910825e-06
===========>   testing    <===========
Epoch: [952][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0388 (0.0388)	
0.9999856 3.7485247e-06
Epoch: [952][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0405 (0.0591)	
0.9999864 3.547902e-06
Epoch: [952][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1531 (0.0572)	
0.9999826 3.2641085e-06
loss:  0.04171790320401414 0.03979034939986892
===========>   training    <===========
Epoch: [953][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0401 (0.0401)	
0.9999795 2.712155e-06
===========>   testing    <===========
Epoch: [953][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0344 (0.0344)	
0.9999832 4.5988677e-06
Epoch: [953][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0453 (0.0567)	
0.9999869 3.5535031e-06
Epoch: [953][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1351 (0.0562)	
0.9999831 3.990112e-06
loss:  0.041167126014866384 0.03979034939986892
===========>   training    <===========
Epoch: [954][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0370 (0.0370)	
0.99999285 3.3883853e-06
===========>   testing    <===========
Epoch: [954][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0370 (0.0370)	
0.9999883 3.6360514e-06
Epoch: [954][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0324 (0.0591)	
0.99999154 2.6549153e-06
Epoch: [954][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0851 (0.0568)	
0.9999825 3.0452766e-06
loss:  0.04199148577737721 0.03979034939986892
===========>   training    <===========
Epoch: [955][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0382 (0.0382)	
0.99998283 1.8624622e-06
===========>   testing    <===========
Epoch: [955][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0465 (0.0465)	
0.9999887 3.067183e-06
Epoch: [955][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1388 (0.0594)	
0.99998903 2.9983246e-06
Epoch: [955][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0943 (0.0580)	
0.99998677 2.721659e-06
loss:  0.043645880849434104 0.03979034939986892
===========>   training    <===========
Epoch: [956][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0397 (0.0397)	
0.9999918 2.984121e-06
===========>   testing    <===========
Epoch: [956][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0382 (0.0382)	
0.99998856 2.6584448e-06
Epoch: [956][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0439 (0.0590)	
0.9999902 2.6336645e-06
Epoch: [956][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1155 (0.0582)	
0.99998546 2.3102903e-06
loss:  0.042166589902410734 0.03979034939986892
===========>   training    <===========
Epoch: [957][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0448 (0.0448)	
0.9999907 3.1161499e-06
===========>   testing    <===========
Epoch: [957][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0445 (0.0445)	
0.99998426 3.3694055e-06
Epoch: [957][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0397 (0.0591)	
0.99998844 3.322274e-06
Epoch: [957][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0580 (0.0568)	
0.9999802 2.9124433e-06
loss:  0.04162107043794838 0.03979034939986892
===========>   training    <===========
Epoch: [958][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0447 (0.0447)	
0.9999882 5.4713473e-06
===========>   testing    <===========
Epoch: [958][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0369 (0.0369)	
0.999987 3.6467195e-06
Epoch: [958][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0359 (0.0570)	
0.99998724 3.6096037e-06
Epoch: [958][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1190 (0.0579)	
0.9999846 3.442243e-06
loss:  0.04206522533817025 0.03979034939986892
===========>   training    <===========
Epoch: [959][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0400 (0.0400)	
0.9999783 1.9830834e-06
===========>   testing    <===========
Epoch: [959][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0351 (0.0351)	
0.99999046 4.5976967e-06
Epoch: [959][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0469 (0.0584)	
0.9999902 3.4475652e-06
Epoch: [959][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1286 (0.0572)	
0.9999864 4.6513874e-06
loss:  0.04060222353245169 0.03979034939986892
===========>   training    <===========
Epoch: [960][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0385 (0.0385)	
0.99998426 3.5435805e-06
===========>   testing    <===========
Epoch: [960][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0337 (0.0337)	
0.9999888 4.20313e-06
Epoch: [960][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0355 (0.0578)	
0.9999908 3.8648313e-06
Epoch: [960][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.1716 (0.0573)	
0.9999857 4.196273e-06
loss:  0.04161802585997498 0.03979034939986892
===========>   training    <===========
Epoch: [961][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0352 (0.0352)	
0.9999957 5.2826913e-06
===========>   testing    <===========
Epoch: [961][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0427 (0.0427)	
0.9999902 4.8426446e-06
Epoch: [961][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0247 (0.0589)	
0.99999356 4.5729075e-06
Epoch: [961][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.1291 (0.0574)	
0.99999 4.428142e-06
loss:  0.04043320727132749 0.03979034939986892
===========>   training    <===========
Epoch: [962][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0345 (0.0345)	
0.99998903 4.8707775e-06
===========>   testing    <===========
Epoch: [962][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0445 (0.0445)	
0.99998903 4.240412e-06
Epoch: [962][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0235 (0.0593)	
0.9999893 4.022461e-06
Epoch: [962][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.1529 (0.0579)	
0.9999825 4.0443056e-06
loss:  0.040922895351573896 0.03979034939986892
===========>   training    <===========
Epoch: [963][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0368 (0.0368)	
0.9999901 3.045381e-06
===========>   testing    <===========
Epoch: [963][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0435 (0.0435)	
0.99998784 4.1127405e-06
Epoch: [963][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0206 (0.0589)	
0.9999907 4.624729e-06
Epoch: [963][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.1314 (0.0575)	
0.9999819 3.6963197e-06
loss:  0.0407326740374474 0.03979034939986892
===========>   training    <===========
Epoch: [964][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0319 (0.0319)	
0.99998975 1.992794e-06
===========>   testing    <===========
Epoch: [964][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0559 (0.0559)	
0.9999908 5.150112e-06
Epoch: [964][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0239 (0.0615)	
0.99999046 6.034203e-06
Epoch: [964][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0967 (0.0583)	
0.999987 4.701457e-06
loss:  0.04225494077817549 0.03979034939986892
===========>   training    <===========
Epoch: [965][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0471 (0.0471)	
0.99999356 2.658886e-06
===========>   testing    <===========
Epoch: [965][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0381 (0.0381)	
0.99998796 3.789858e-06
Epoch: [965][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0286 (0.0591)	
0.9999877 2.5888849e-06
Epoch: [965][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0947 (0.0566)	
0.99997985 3.895667e-06
loss:  0.04090852860335159 0.03979034939986892
===========>   training    <===========
Epoch: [966][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0329 (0.0329)	
0.9999925 9.148221e-06
===========>   testing    <===========
Epoch: [966][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0447 (0.0447)	
0.9999894 2.9901091e-06
Epoch: [966][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0220 (0.0592)	
0.9999908 3.0395697e-06
Epoch: [966][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0952 (0.0570)	
0.9999862 2.9274806e-06
loss:  0.0406005080876618 0.03979034939986892
===========>   training    <===========
Epoch: [967][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0365 (0.0365)	
0.99998844 1.7754631e-06
===========>   testing    <===========
Epoch: [967][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0518 (0.0518)	
0.99998295 3.315561e-06
Epoch: [967][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0270 (0.0595)	
0.99998987 3.210933e-06
Epoch: [967][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0547 (0.0574)	
0.999985 2.9980015e-06
loss:  0.040707536938052846 0.03979034939986892
===========>   training    <===========
Epoch: [968][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0361 (0.0361)	
0.9999865 2.6312243e-06
===========>   testing    <===========
Epoch: [968][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0522 (0.0522)	
0.99998724 3.8399007e-06
Epoch: [968][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0287 (0.0609)	
0.99998736 3.95437e-06
Epoch: [968][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0574 (0.0578)	
0.99998236 3.4520922e-06
loss:  0.041333297568127314 0.03979034939986892
===========>   training    <===========
Epoch: [969][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0488 (0.0488)	
0.99998224 2.8579864e-06
===========>   testing    <===========
Epoch: [969][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0353 (0.0353)	
0.9999852 3.4203022e-06
Epoch: [969][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0289 (0.0580)	
0.99998486 3.708399e-06
Epoch: [969][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0902 (0.0572)	
0.999984 2.7602302e-06
loss:  0.04075210701175025 0.03979034939986892
===========>   training    <===========
Epoch: [970][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0470 (0.0470)	
0.9999927 3.4918583e-06
===========>   testing    <===========
Epoch: [970][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0512 (0.0512)	
0.99999 3.9021443e-06
Epoch: [970][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0249 (0.0616)	
0.9999889 4.0847303e-06
Epoch: [970][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0744 (0.0589)	
0.9999846 3.938086e-06
loss:  0.041206126672983734 0.03979034939986892
===========>   training    <===========
Epoch: [971][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0511 (0.0511)	
0.9999938 2.3957668e-06
===========>   testing    <===========
Epoch: [971][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0322 (0.0322)	
0.99997413 3.5715846e-06
Epoch: [971][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0249 (0.0578)	
0.9999672 3.9732563e-06
Epoch: [971][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0817 (0.0563)	
0.9999738 2.7091796e-06
loss:  0.04015193709379361 0.03979034939986892
===========>   training    <===========
Epoch: [972][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0358 (0.0358)	
0.9999956 2.219004e-06
===========>   testing    <===========
Epoch: [972][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0469 (0.0469)	
0.99998915 2.9303271e-06
Epoch: [972][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0567 (0.0596)	
0.99998784 1.8460769e-06
Epoch: [972][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0745 (0.0574)	
0.99998856 2.5107202e-06
loss:  0.04282421194389141 0.03979034939986892
===========>   training    <===========
Epoch: [973][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0470 (0.0470)	
0.99998665 3.541378e-06
===========>   testing    <===========
Epoch: [973][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0347 (0.0347)	
0.9999896 3.3887018e-06
Epoch: [973][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0403 (0.0578)	
0.99999046 3.5836765e-06
Epoch: [973][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0840 (0.0575)	
0.99998546 3.6056954e-06
loss:  0.04135917839068548 0.03979034939986892
===========>   training    <===========
Epoch: [974][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0422 (0.0422)	
0.9999863 2.5853838e-06
===========>   testing    <===========
Epoch: [974][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0594 (0.0594)	
0.99998856 2.9415685e-06
Epoch: [974][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0512 (0.0591)	
0.9999869 2.9231956e-06
Epoch: [974][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.1110 (0.0579)	
0.9999789 3.0931562e-06
loss:  0.041265072932945124 0.03979034939986892
===========>   training    <===========
Epoch: [975][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0372 (0.0372)	
0.99999094 5.109809e-06
===========>   testing    <===========
Epoch: [975][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0336 (0.0336)	
0.9999896 3.3187368e-06
Epoch: [975][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0441 (0.0583)	
0.99998915 3.3499155e-06
Epoch: [975][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0657 (0.0571)	
0.9999875 3.3556869e-06
loss:  0.041316519914576855 0.03979034939986892
===========>   training    <===========
Epoch: [976][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0438 (0.0438)	
0.9999931 2.0324667e-06
===========>   testing    <===========
Epoch: [976][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0349 (0.0349)	
0.9999888 2.8387135e-06
Epoch: [976][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0499 (0.0576)	
0.9999913 2.8591257e-06
Epoch: [976][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0830 (0.0568)	
0.99998367 1.9472811e-06
loss:  0.041134581737638176 0.03979034939986892
===========>   training    <===========
Epoch: [977][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0347 (0.0347)	
0.99998987 3.9889055e-06
===========>   testing    <===========
Epoch: [977][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0590 (0.0590)	
0.9999882 3.7229804e-06
Epoch: [977][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0535 (0.0582)	
0.9999925 3.6173437e-06
Epoch: [977][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0858 (0.0569)	
0.9999863 3.8322546e-06
loss:  0.0416629397041427 0.03979034939986892
===========>   training    <===========
Epoch: [978][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0427 (0.0427)	
0.9999628 1.4112287e-06
===========>   testing    <===========
Epoch: [978][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0414 (0.0414)	
0.999985 3.5690443e-06
Epoch: [978][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0403 (0.0549)	
0.9999877 2.833842e-06
Epoch: [978][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0666 (0.0559)	
0.9999778 3.4147615e-06
loss:  0.04127725515715386 0.03979034939986892
===========>   training    <===========
Epoch: [979][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0419 (0.0419)	
0.9999869 3.4547663e-06
===========>   testing    <===========
Epoch: [979][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0624 (0.0624)	
0.9999871 3.4798575e-06
Epoch: [979][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0513 (0.0569)	
0.99999 2.581961e-06
Epoch: [979][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0821 (0.0566)	
0.99998116 3.223706e-06
loss:  0.04165068582115139 0.03979034939986892
===========>   training    <===========
Epoch: [980][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0400 (0.0400)	
0.99999344 3.2909827e-06
===========>   testing    <===========
Epoch: [980][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0369 (0.0369)	
0.99999046 3.9479946e-06
Epoch: [980][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0364 (0.0564)	
0.9999933 3.7714808e-06
Epoch: [980][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0991 (0.0565)	
0.9999906 3.3918964e-06
loss:  0.041665813425756926 0.03979034939986892
===========>   training    <===========
Epoch: [981][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0452 (0.0452)	
0.9999918 2.8891284e-06
===========>   testing    <===========
Epoch: [981][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0416 (0.0416)	
0.9999912 3.3455447e-06
Epoch: [981][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0464 (0.0565)	
0.99999464 3.061817e-06
Epoch: [981][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0961 (0.0568)	
0.9999887 3.1371565e-06
loss:  0.04125446717130621 0.03979034939986892
===========>   training    <===========
Epoch: [982][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0509 (0.0509)	
0.9999838 4.9872538e-06
===========>   testing    <===========
Epoch: [982][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0462 (0.0462)	
0.9999926 3.218711e-06
Epoch: [982][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1252 (0.0593)	
0.99999464 3.624737e-06
Epoch: [982][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0951 (0.0579)	
0.99998844 3.1029829e-06
loss:  0.04141814759100726 0.03979034939986892
===========>   training    <===========
Epoch: [983][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0408 (0.0408)	
0.99998593 2.5895738e-06
===========>   testing    <===========
Epoch: [983][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0329 (0.0329)	
0.9999912 2.5167733e-06
Epoch: [983][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0905 (0.0577)	
0.99999154 2.5845259e-06
Epoch: [983][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0936 (0.0582)	
0.99998415 2.3743357e-06
loss:  0.041320651476400516 0.03979034939986892
===========>   training    <===========
Epoch: [984][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0404 (0.0404)	
0.9999937 2.8111565e-06
===========>   testing    <===========
Epoch: [984][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0349 (0.0349)	
0.9999914 3.234358e-06
Epoch: [984][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0639 (0.0578)	
0.99999094 2.9689459e-06
Epoch: [984][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1168 (0.0589)	
0.99998486 2.827126e-06
loss:  0.04154588381077462 0.03979034939986892
===========>   training    <===========
Epoch: [985][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0411 (0.0411)	
0.99999213 3.3792007e-06
===========>   testing    <===========
Epoch: [985][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0403 (0.0403)	
0.999992 3.3287852e-06
Epoch: [985][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0610 (0.0592)	
0.9999914 3.5237688e-06
Epoch: [985][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1185 (0.0579)	
0.9999871 2.9170244e-06
loss:  0.04193915466029852 0.03979034939986892
===========>   training    <===========
Epoch: [986][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0389 (0.0389)	
0.9999938 3.1022728e-06
===========>   testing    <===========
Epoch: [986][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0328 (0.0328)	
0.9999925 3.1884529e-06
Epoch: [986][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0468 (0.0584)	
0.9999908 3.3566855e-06
Epoch: [986][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0807 (0.0570)	
0.9999856 2.7731378e-06
loss:  0.040178265420805714 0.03979034939986892
===========>   training    <===========
Epoch: [987][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0353 (0.0353)	
0.99999475 2.3446504e-05
===========>   testing    <===========
Epoch: [987][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0359 (0.0359)	
0.9999919 2.6733583e-06
Epoch: [987][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1202 (0.0610)	
0.9999875 2.557048e-06
Epoch: [987][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1131 (0.0598)	
0.99998415 2.45078e-06
loss:  0.042758420618817294 0.03979034939986892
===========>   training    <===========
Epoch: [988][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0348 (0.0348)	
0.99998665 1.3420682e-06
===========>   testing    <===========
Epoch: [988][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0414 (0.0414)	
0.99998844 2.561192e-06
Epoch: [988][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1627 (0.0609)	
0.9999825 2.6488888e-06
Epoch: [988][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0706 (0.0589)	
0.9999751 2.6029863e-06
loss:  0.04186746069610958 0.03979034939986892
===========>   training    <===========
Epoch: [989][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0472 (0.0472)	
0.99998343 1.2787602e-06
===========>   testing    <===========
Epoch: [989][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0463 (0.0463)	
0.99999225 3.4556624e-06
Epoch: [989][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1310 (0.0594)	
0.99998987 3.3241727e-06
Epoch: [989][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0841 (0.0578)	
0.9999858 3.3966642e-06
loss:  0.040933697988325135 0.03979034939986892
===========>   training    <===========
Epoch: [990][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0491 (0.0491)	
0.99999297 5.604746e-06
===========>   testing    <===========
Epoch: [990][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0424 (0.0424)	
0.9999924 3.3525648e-06
Epoch: [990][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0435 (0.0616)	
0.9999882 2.5867573e-06
Epoch: [990][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0858 (0.0599)	
0.99998415 3.333595e-06
loss:  0.041478322633785036 0.03979034939986892
===========>   training    <===========
Epoch: [991][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0454 (0.0454)	
0.9999865 2.4748354e-06
===========>   testing    <===========
Epoch: [991][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0415 (0.0415)	
0.99999106 3.886816e-06
Epoch: [991][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0280 (0.0573)	
0.99998546 3.4970437e-06
Epoch: [991][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0768 (0.0577)	
0.9999826 3.6825975e-06
loss:  0.041536954695934325 0.03979034939986892
===========>   training    <===========
Epoch: [992][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0339 (0.0339)	
0.9999895 6.9380764e-07
===========>   testing    <===========
Epoch: [992][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0525 (0.0525)	
0.9999919 3.4115226e-06
Epoch: [992][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0427 (0.0598)	
0.99999166 3.8959083e-06
Epoch: [992][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0730 (0.0584)	
0.99998534 3.2682826e-06
loss:  0.04209587575493967 0.03979034939986892
===========>   training    <===========
Epoch: [993][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0387 (0.0387)	
0.9999883 2.8423299e-06
===========>   testing    <===========
Epoch: [993][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0336 (0.0336)	
0.9999902 3.0147307e-06
Epoch: [993][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0456 (0.0584)	
0.99998724 3.3538888e-06
Epoch: [993][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1524 (0.0589)	
0.9999801 3.2015976e-06
loss:  0.042269617298414275 0.03979034939986892
===========>   training    <===========
Epoch: [994][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0427 (0.0427)	
0.99999166 3.322832e-06
===========>   testing    <===========
Epoch: [994][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0453 (0.0453)	
0.9999918 3.446763e-06
Epoch: [994][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0765 (0.0602)	
0.99999034 3.5520936e-06
Epoch: [994][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1365 (0.0589)	
0.9999844 3.0837662e-06
loss:  0.04235891303443695 0.03979034939986892
===========>   training    <===========
Epoch: [995][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0367 (0.0367)	
0.999992 1.8353214e-06
===========>   testing    <===========
Epoch: [995][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0349 (0.0349)	
0.99999046 3.5397236e-06
Epoch: [995][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0449 (0.0609)	
0.9999925 3.6533404e-06
Epoch: [995][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1447 (0.0591)	
0.99998784 3.4276982e-06
loss:  0.04133235144066083 0.03979034939986892
===========>   training    <===========
Epoch: [996][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0407 (0.0407)	
0.9999832 1.8596882e-06
===========>   testing    <===========
Epoch: [996][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0369 (0.0369)	
0.9999881 3.4029963e-06
Epoch: [996][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0499 (0.0585)	
0.9999895 3.6800488e-06
Epoch: [996][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1189 (0.0577)	
0.99998665 2.8837278e-06
loss:  0.040875253792147515 0.03979034939986892
===========>   training    <===========
Epoch: [997][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0356 (0.0356)	
0.99998033 1.9897384e-06
===========>   testing    <===========
Epoch: [997][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0535 (0.0535)	
0.9999919 2.9025557e-06
Epoch: [997][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0392 (0.0609)	
0.9999907 3.0387844e-06
Epoch: [997][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0806 (0.0583)	
0.9999894 2.3447053e-06
loss:  0.04140343137930991 0.03979034939986892
===========>   training    <===========
Epoch: [998][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0396 (0.0396)	
0.99998105 1.6098362e-06
===========>   testing    <===========
Epoch: [998][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0332 (0.0332)	
0.999992 2.984138e-06
Epoch: [998][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0332 (0.0594)	
0.9999875 2.8747459e-06
Epoch: [998][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1317 (0.0592)	
0.9999858 2.857959e-06
loss:  0.041016551798252365 0.03979034939986892
===========>   training    <===========
Epoch: [999][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0342 (0.0342)	
0.99999106 3.1686313e-06
===========>   testing    <===========
Epoch: [999][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0662 (0.0662)	
0.99999046 3.7851805e-06
Epoch: [999][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0456 (0.0631)	
0.99999034 3.3715976e-06
Epoch: [999][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0627 (0.0581)	
0.9999889 3.502992e-06
loss:  0.04181886749832542 0.03979034939986892
===========>   training    <===========
Epoch: [1000][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0361 (0.0361)	
0.99997866 1.0312992e-05
===========>   testing    <===========
Epoch: [1000][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0342 (0.0342)	
0.9999901 3.481846e-06
Epoch: [1000][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0284 (0.0599)	
0.99999094 3.563715e-06
Epoch: [1000][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1273 (0.0583)	
0.99998796 2.5952625e-06
loss:  0.041303324458670354 0.03979034939986892
===========>   training    <===========
Epoch: [1001][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0440 (0.0440)	
0.9999906 3.9038005e-06
===========>   testing    <===========
Epoch: [1001][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0328 (0.0328)	
0.9999881 2.8209265e-06
Epoch: [1001][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0288 (0.0597)	
0.99999094 2.638386e-06
Epoch: [1001][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1424 (0.0591)	
0.9999883 1.7437383e-06
loss:  0.041463991180386905 0.03979034939986892
===========>   training    <===========
Epoch: [1002][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0519 (0.0519)	
0.99999344 1.8727712e-06
===========>   testing    <===========
Epoch: [1002][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0373 (0.0373)	
0.9999894 3.2726678e-06
Epoch: [1002][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0298 (0.0610)	
0.9999825 3.2354008e-06
Epoch: [1002][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1498 (0.0592)	
0.999984 3.2130865e-06
loss:  0.041640899034746326 0.03979034939986892
===========>   training    <===========
Epoch: [1003][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0449 (0.0449)	
0.999984 3.118147e-06
===========>   testing    <===========
Epoch: [1003][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0491 (0.0491)	
0.9999862 3.7741256e-06
Epoch: [1003][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0503 (0.0614)	
0.999987 3.7699776e-06
Epoch: [1003][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1239 (0.0580)	
0.99998355 3.1125026e-06
loss:  0.04112581037055718 0.03979034939986892
===========>   training    <===========
Epoch: [1004][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0396 (0.0396)	
0.99998546 2.3788416e-06
===========>   testing    <===========
Epoch: [1004][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0366 (0.0366)	
0.99998474 3.9432384e-06
Epoch: [1004][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0319 (0.0619)	
0.99998355 3.7995933e-06
Epoch: [1004][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1447 (0.0581)	
0.99998105 3.278234e-06
loss:  0.040715180778764126 0.03979034939986892
===========>   training    <===========
Epoch: [1005][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0317 (0.0317)	
0.9999746 7.811789e-06
===========>   testing    <===========
Epoch: [1005][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0290 (0.0290)	
0.9999894 3.6197557e-06
Epoch: [1005][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0353 (0.0614)	
0.99999 4.0275586e-06
Epoch: [1005][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1579 (0.0578)	
0.9999865 3.2094176e-06
loss:  0.040888723842827046 0.03979034939986892
===========>   training    <===========
Epoch: [1006][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0426 (0.0426)	
0.9999851 1.3599252e-06
===========>   testing    <===========
Epoch: [1006][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0313 (0.0313)	
0.9999894 3.2363173e-06
Epoch: [1006][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0302 (0.0603)	
0.99998724 2.6569442e-06
Epoch: [1006][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0927 (0.0578)	
0.9999896 2.13734e-06
loss:  0.041182900384580834 0.03979034939986892
===========>   training    <===========
Epoch: [1007][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0420 (0.0420)	
0.9999888 4.1897797e-06
===========>   testing    <===========
Epoch: [1007][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0383 (0.0383)	
0.99998665 3.1616376e-06
Epoch: [1007][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0438 (0.0602)	
0.9999851 1.7386619e-06
Epoch: [1007][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1567 (0.0584)	
0.99998415 2.3583448e-06
loss:  0.04125716379127675 0.03979034939986892
===========>   training    <===========
Epoch: [1008][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0364 (0.0364)	
0.99998856 2.8832355e-06
===========>   testing    <===========
Epoch: [1008][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0425 (0.0425)	
0.99998677 2.4451165e-06
Epoch: [1008][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0365 (0.0612)	
0.99998856 1.4311494e-06
Epoch: [1008][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1311 (0.0581)	
0.9999814 1.8322033e-06
loss:  0.040880817931673974 0.03979034939986892
===========>   training    <===========
Epoch: [1009][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0314 (0.0314)	
0.9999914 1.6420446e-06
===========>   testing    <===========
Epoch: [1009][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0285 (0.0285)	
0.9999896 3.936655e-06
Epoch: [1009][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0281 (0.0599)	
0.9999913 3.4644995e-06
Epoch: [1009][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1303 (0.0574)	
0.9999887 3.880882e-06
loss:  0.04025367832405968 0.03979034939986892
===========>   training    <===========
Epoch: [1010][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0383 (0.0383)	
0.9999784 2.265214e-06
===========>   testing    <===========
Epoch: [1010][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0387 (0.0387)	
0.99999106 3.68557e-06
Epoch: [1010][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0772 (0.0626)	
0.9999908 3.3322792e-06
Epoch: [1010][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1118 (0.0588)	
0.99999 3.3331562e-06
loss:  0.0411049086379337 0.03979034939986892
===========>   training    <===========
Epoch: [1011][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0432 (0.0432)	
0.9999795 1.7457049e-06
===========>   testing    <===========
Epoch: [1011][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0299 (0.0299)	
0.99998736 3.8916974e-06
Epoch: [1011][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0337 (0.0611)	
0.9999815 3.5823573e-06
Epoch: [1011][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0862 (0.0582)	
0.99998474 2.5144557e-06
loss:  0.04146846684874661 0.03979034939986892
===========>   training    <===========
Epoch: [1012][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0346 (0.0346)	
0.99999034 2.790943e-06
===========>   testing    <===========
Epoch: [1012][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0429 (0.0429)	
0.9999895 3.6813335e-06
Epoch: [1012][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0448 (0.0615)	
0.99998724 3.6291265e-06
Epoch: [1012][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0788 (0.0577)	
0.9999882 3.6657154e-06
loss:  0.04072876565645689 0.03979034939986892
===========>   training    <===========
Epoch: [1013][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0339 (0.0339)	
0.99999726 9.393338e-06
===========>   testing    <===========
Epoch: [1013][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0330 (0.0330)	
0.9999869 3.081347e-06
Epoch: [1013][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0387 (0.0603)	
0.9999887 2.9092566e-06
Epoch: [1013][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1024 (0.0578)	
0.9999871 2.7164313e-06
loss:  0.04032171657927819 0.03979034939986892
===========>   training    <===========
Epoch: [1014][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0343 (0.0343)	
0.9999908 2.6481157e-06
===========>   testing    <===========
Epoch: [1014][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0311 (0.0311)	
0.99998987 2.8745294e-06
Epoch: [1014][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0291 (0.0587)	
0.99999034 2.7169547e-06
Epoch: [1014][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1001 (0.0572)	
0.9999881 2.6720686e-06
loss:  0.04009433907646531 0.03979034939986892
===========>   training    <===========
Epoch: [1015][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0447 (0.0447)	
0.99999225 3.9214647e-06
===========>   testing    <===========
Epoch: [1015][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0379 (0.0379)	
0.9999914 3.1699583e-06
Epoch: [1015][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0375 (0.0602)	
0.99999094 2.0966718e-06
Epoch: [1015][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0866 (0.0579)	
0.9999901 3.2188461e-06
loss:  0.040726082738606895 0.03979034939986892
===========>   training    <===========
Epoch: [1016][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0363 (0.0363)	
0.9999881 2.2601087e-06
===========>   testing    <===========
Epoch: [1016][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0356 (0.0356)	
0.99998987 3.7327216e-06
Epoch: [1016][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0526 (0.0587)	
0.9999887 3.863851e-06
Epoch: [1016][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1096 (0.0567)	
0.99998796 3.815974e-06
loss:  0.03999651005619542 0.03979034939986892
===========>   training    <===========
Epoch: [1017][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0411 (0.0411)	
0.9999883 2.4835979e-06
===========>   testing    <===========
Epoch: [1017][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0393 (0.0393)	
0.99999034 3.6120348e-06
Epoch: [1017][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0392 (0.0587)	
0.99998987 3.6325025e-06
Epoch: [1017][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1167 (0.0576)	
0.99998903 3.281512e-06
loss:  0.04005088480650021 0.03979034939986892
===========>   training    <===========
Epoch: [1018][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0325 (0.0325)	
0.99998915 3.4820018e-06
===========>   testing    <===========
Epoch: [1018][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0393 (0.0393)	
0.9999919 4.5088086e-06
Epoch: [1018][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0400 (0.0599)	
0.9999919 4.562671e-06
Epoch: [1018][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1207 (0.0585)	
0.9999907 4.1457165e-06
loss:  0.040955546653297814 0.03979034939986892
===========>   training    <===========
Epoch: [1019][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0387 (0.0387)	
0.9999943 3.4389911e-06
===========>   testing    <===========
Epoch: [1019][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0315 (0.0315)	
0.9999924 3.0408364e-06
Epoch: [1019][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0457 (0.0575)	
0.9999882 3.0836572e-06
Epoch: [1019][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1401 (0.0576)	
0.9999869 2.9147775e-06
loss:  0.04124173871540637 0.03979034939986892
===========>   training    <===========
Epoch: [1020][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0374 (0.0374)	
0.99998844 1.2704264e-06
===========>   testing    <===========
Epoch: [1020][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0329 (0.0329)	
0.9999908 3.1618306e-06
Epoch: [1020][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0642 (0.0598)	
0.99998975 2.9795767e-06
Epoch: [1020][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.1267 (0.0588)	
0.9999857 3.196015e-06
loss:  0.04217611712903413 0.03979034939986892
===========>   training    <===========
Epoch: [1021][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0321 (0.0321)	
0.99998796 2.1665142e-06
===========>   testing    <===========
Epoch: [1021][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0303 (0.0303)	
0.99999094 3.228906e-06
Epoch: [1021][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0490 (0.0578)	
0.9999851 3.0790172e-06
Epoch: [1021][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.1397 (0.0588)	
0.9999789 2.2203633e-06
loss:  0.04136078366041185 0.03979034939986892
===========>   training    <===========
Epoch: [1022][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0395 (0.0395)	
0.99997866 4.0304403e-06
===========>   testing    <===========
Epoch: [1022][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0355 (0.0355)	
0.99999046 3.226228e-06
Epoch: [1022][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0679 (0.0596)	
0.99998987 3.279028e-06
Epoch: [1022][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.1439 (0.0586)	
0.9999865 3.5120033e-06
loss:  0.04186135356252718 0.03979034939986892
===========>   training    <===========
Epoch: [1023][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0391 (0.0391)	
0.9999906 3.0745748e-06
===========>   testing    <===========
Epoch: [1023][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0376 (0.0376)	
0.99999166 3.2022085e-06
Epoch: [1023][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0325 (0.0589)	
0.99999213 2.902622e-06
Epoch: [1023][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.1319 (0.0573)	
0.9999881 2.8390818e-06
loss:  0.040540491209246965 0.03979034939986892
===========>   training    <===========
Epoch: [1024][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0470 (0.0470)	
0.99998593 1.6462783e-06
===========>   testing    <===========
Epoch: [1024][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0296 (0.0296)	
0.9999919 3.0917465e-06
Epoch: [1024][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0295 (0.0604)	
0.9999908 2.9006687e-06
Epoch: [1024][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.1179 (0.0587)	
0.99998593 3.0990616e-06
loss:  0.040905946623017164 0.03979034939986892
===========>   training    <===========
Epoch: [1025][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0334 (0.0334)	
0.9999926 1.8586244e-06
===========>   testing    <===========
Epoch: [1025][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0327 (0.0327)	
0.9999908 3.2817247e-06
Epoch: [1025][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0519 (0.0601)	
0.9999882 3.144192e-06
Epoch: [1025][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0849 (0.0575)	
0.9999856 3.6122551e-06
loss:  0.04019313629349419 0.03979034939986892
===========>   training    <===========
Epoch: [1026][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0315 (0.0315)	
0.9999784 2.535603e-06
===========>   testing    <===========
Epoch: [1026][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0339 (0.0339)	
0.9999918 2.7079345e-06
Epoch: [1026][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0489 (0.0578)	
0.99998915 2.6860494e-06
Epoch: [1026][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.1390 (0.0566)	
0.99998355 1.9469098e-06
loss:  0.03968790006119671 0.03979034939986892
===========>   training    <===========
Epoch: [1027][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0353 (0.0353)	
0.99999297 2.6356245e-06
===========>   testing    <===========
Epoch: [1027][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0384 (0.0384)	
0.99999166 3.3914043e-06
Epoch: [1027][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0418 (0.0591)	
0.9999924 2.794629e-06
Epoch: [1027][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.1110 (0.0568)	
0.9999877 2.785614e-06
loss:  0.03976847105935988 0.03968790006119671
===========>   training    <===========
Epoch: [1028][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0442 (0.0442)	
0.99999285 2.7986698e-06
===========>   testing    <===========
Epoch: [1028][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0355 (0.0355)	
0.99999106 2.7838905e-06
Epoch: [1028][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0468 (0.0588)	
0.999992 2.8758895e-06
Epoch: [1028][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0968 (0.0558)	
0.9999845 2.7870303e-06
loss:  0.039591135504582375 0.03968790006119671
===========>   training    <===========
Epoch: [1029][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0345 (0.0345)	
0.9999752 2.2064883e-06
===========>   testing    <===========
Epoch: [1029][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0430 (0.0430)	
0.9999925 3.3620836e-06
Epoch: [1029][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0433 (0.0593)	
0.9999937 4.1498306e-06
Epoch: [1029][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0884 (0.0567)	
0.99998844 3.469274e-06
loss:  0.04086559672308543 0.039591135504582375
===========>   training    <===========
Epoch: [1030][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0348 (0.0348)	
0.9999933 4.639696e-06
===========>   testing    <===========
Epoch: [1030][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0383 (0.0383)	
0.9999907 2.6120529e-06
Epoch: [1030][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0316 (0.0617)	
0.9999937 3.0824372e-06
Epoch: [1030][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0897 (0.0571)	
0.99998486 2.7252745e-06
loss:  0.040909588775722816 0.039591135504582375
===========>   training    <===========
Epoch: [1031][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0305 (0.0305)	
0.99998987 1.7912049e-06
===========>   testing    <===========
Epoch: [1031][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0415 (0.0415)	
0.9999913 2.5048964e-06
Epoch: [1031][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0299 (0.0608)	
0.99999106 2.8393797e-06
Epoch: [1031][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0896 (0.0565)	
0.99998283 2.7231285e-06
loss:  0.03960291960746909 0.039591135504582375
===========>   training    <===========
Epoch: [1032][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0357 (0.0357)	
0.9999893 6.2547724e-06
===========>   testing    <===========
Epoch: [1032][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0301 (0.0301)	
0.99999154 2.619744e-06
Epoch: [1032][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0294 (0.0592)	
0.9999913 2.6795942e-06
Epoch: [1032][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.1266 (0.0577)	
0.9999852 2.7577726e-06
loss:  0.040832633656220474 0.039591135504582375
===========>   training    <===========
Epoch: [1033][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0353 (0.0353)	
0.9999882 2.0088298e-06
===========>   testing    <===========
Epoch: [1033][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0641 (0.0641)	
0.99999285 2.5199963e-06
Epoch: [1033][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0300 (0.0615)	
0.999992 2.5069612e-06
Epoch: [1033][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.1004 (0.0595)	
0.99998474 2.5917084e-06
loss:  0.041459762722362736 0.039591135504582375
===========>   training    <===========
Epoch: [1034][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0433 (0.0433)	
0.9999939 1.4089802e-06
===========>   testing    <===========
Epoch: [1034][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0505 (0.0505)	
0.99999225 2.8429563e-06
Epoch: [1034][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0300 (0.0622)	
0.99999344 2.601527e-06
Epoch: [1034][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0882 (0.0594)	
0.99998796 2.3350656e-06
loss:  0.04163456037430879 0.039591135504582375
===========>   training    <===========
Epoch: [1035][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0402 (0.0402)	
0.999985 1.7784593e-06
===========>   testing    <===========
Epoch: [1035][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0668 (0.0668)	
0.9999918 2.5445079e-06
Epoch: [1035][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0359 (0.0615)	
0.9999932 2.383772e-06
Epoch: [1035][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0878 (0.0589)	
0.9999845 2.5570064e-06
loss:  0.042057041874495216 0.039591135504582375
===========>   training    <===========
Epoch: [1036][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0381 (0.0381)	
0.99998975 1.9571485e-06
===========>   testing    <===========
Epoch: [1036][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0699 (0.0699)	
0.99998903 2.474826e-06
Epoch: [1036][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0443 (0.0580)	
0.9999902 2.0626098e-06
Epoch: [1036][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0893 (0.0567)	
0.99997544 2.371168e-06
loss:  0.040549335812387066 0.039591135504582375
===========>   training    <===========
Epoch: [1037][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0364 (0.0364)	
0.9999864 1.5086755e-06
===========>   testing    <===========
Epoch: [1037][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0547 (0.0547)	
0.9999889 2.718261e-06
Epoch: [1037][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0471 (0.0613)	
0.99999404 2.470737e-06
Epoch: [1037][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0856 (0.0580)	
0.99998593 2.6766747e-06
loss:  0.04160117861220736 0.039591135504582375
===========>   training    <===========
Epoch: [1038][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0388 (0.0388)	
0.99998486 1.8489785e-06
===========>   testing    <===========
Epoch: [1038][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0524 (0.0524)	
0.999985 2.8209856e-06
Epoch: [1038][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0331 (0.0616)	
0.9999939 2.8637814e-06
Epoch: [1038][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.1031 (0.0587)	
0.9999826 2.810545e-06
loss:  0.0412441167756894 0.039591135504582375
===========>   training    <===========
Epoch: [1039][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0359 (0.0359)	
0.99998355 1.2268491e-06
===========>   testing    <===========
Epoch: [1039][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0327 (0.0327)	
0.9999863 2.5444544e-06
Epoch: [1039][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0402 (0.0671)	
0.9999902 2.1288552e-06
Epoch: [1039][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0842 (0.0643)	
0.9999814 1.9433112e-06
loss:  0.045228228754573996 0.039591135504582375
===========>   training    <===========
Epoch: [1040][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0414 (0.0414)	
0.9999888 2.8497281e-05
===========>   testing    <===========
Epoch: [1040][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0383 (0.0383)	
0.99998796 3.2218068e-06
Epoch: [1040][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0407 (0.0605)	
0.9999926 3.6368767e-06
Epoch: [1040][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0629 (0.0574)	
0.99998295 4.263176e-06
loss:  0.04014339230579922 0.039591135504582375
===========>   training    <===========
Epoch: [1041][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0357 (0.0357)	
0.99999034 7.889127e-06
===========>   testing    <===========
Epoch: [1041][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0442 (0.0442)	
0.99998343 2.638207e-06
Epoch: [1041][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0389 (0.0579)	
0.99998903 2.3663267e-06
Epoch: [1041][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0764 (0.0552)	
0.9999764 2.699678e-06
loss:  0.03955290135170042 0.039591135504582375
===========>   training    <===========
Epoch: [1042][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0521 (0.0521)	
0.9999865 3.9934007e-06
===========>   testing    <===========
Epoch: [1042][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0422 (0.0422)	
0.9999871 2.9292455e-06
Epoch: [1042][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0391 (0.0566)	
0.99999404 3.3576011e-06
Epoch: [1042][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0624 (0.0544)	
0.999987 3.4544632e-06
loss:  0.03979839224799753 0.03955290135170042
===========>   training    <===========
Epoch: [1043][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0375 (0.0375)	
0.99999034 3.6610547e-06
===========>   testing    <===========
Epoch: [1043][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0380 (0.0380)	
0.9999887 2.675103e-06
Epoch: [1043][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0376 (0.0573)	
0.9999938 3.0398392e-06
Epoch: [1043][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0999 (0.0546)	
0.99998534 2.608548e-06
loss:  0.03997011285378582 0.03955290135170042
===========>   training    <===========
Epoch: [1044][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0386 (0.0386)	
0.9999931 2.793614e-06
===========>   testing    <===========
Epoch: [1044][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0449 (0.0449)	
0.99998987 3.8027433e-06
Epoch: [1044][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0300 (0.0591)	
0.99999285 4.4960516e-06
Epoch: [1044][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0953 (0.0562)	
0.99998736 4.1789453e-06
loss:  0.04037467601309386 0.03955290135170042
===========>   training    <===========
Epoch: [1045][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0329 (0.0329)	
0.99999034 4.425394e-06
===========>   testing    <===========
Epoch: [1045][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0340 (0.0340)	
0.9999896 3.203241e-06
Epoch: [1045][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0297 (0.0574)	
0.9999901 3.2543112e-06
Epoch: [1045][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0831 (0.0555)	
0.99998224 3.4744126e-06
loss:  0.04017673251054921 0.03955290135170042
===========>   training    <===========
Epoch: [1046][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0402 (0.0402)	
0.99998844 1.1029379e-05
===========>   testing    <===========
Epoch: [1046][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0365 (0.0365)	
0.99999046 3.369248e-06
Epoch: [1046][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0273 (0.0581)	
0.9999927 4.061374e-06
Epoch: [1046][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.1070 (0.0566)	
0.99998605 3.8453313e-06
loss:  0.040643492557189465 0.03955290135170042
===========>   training    <===========
Epoch: [1047][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0443 (0.0443)	
0.99999607 3.0439787e-06
===========>   testing    <===========
Epoch: [1047][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0306 (0.0306)	
0.99998915 3.177646e-06
Epoch: [1047][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0279 (0.0567)	
0.99999166 3.93972e-06
Epoch: [1047][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0826 (0.0549)	
0.9999833 3.0713013e-06
loss:  0.039357641835424007 0.03955290135170042
===========>   training    <===========
Epoch: [1048][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0356 (0.0356)	
0.9999838 2.594409e-06
===========>   testing    <===========
Epoch: [1048][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0432 (0.0432)	
0.99998856 3.2081937e-06
Epoch: [1048][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0411 (0.0577)	
0.9999924 3.2049459e-06
Epoch: [1048][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0947 (0.0555)	
0.99998164 3.2871437e-06
loss:  0.04022033195124419 0.039357641835424007
===========>   training    <===========
Epoch: [1049][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0337 (0.0337)	
0.99999094 2.8960415e-06
===========>   testing    <===========
Epoch: [1049][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0408 (0.0408)	
0.9999889 3.031623e-06
Epoch: [1049][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0404 (0.0595)	
0.9999907 3.515663e-06
Epoch: [1049][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0921 (0.0563)	
0.9999825 2.8742716e-06
loss:  0.040896732558329485 0.039357641835424007
===========>   training    <===========
Epoch: [1050][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0354 (0.0354)	
0.9999893 3.5726541e-06
===========>   testing    <===========
Epoch: [1050][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0364 (0.0364)	
0.9999883 3.0399058e-06
Epoch: [1050][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0286 (0.0589)	
0.9999906 2.9478956e-06
Epoch: [1050][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0927 (0.0569)	
0.999979 2.6952455e-06
loss:  0.04150115328753046 0.039357641835424007
===========>   training    <===========
Epoch: [1051][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0321 (0.0321)	
0.99999404 2.0844425e-06
===========>   testing    <===========
Epoch: [1051][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0372 (0.0372)	
0.9999908 3.4825798e-06
Epoch: [1051][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0291 (0.0606)	
0.99999297 3.8146352e-06
Epoch: [1051][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0643 (0.0580)	
0.99998605 3.2237615e-06
loss:  0.04085142736625802 0.039357641835424007
===========>   training    <===========
Epoch: [1052][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0409 (0.0409)	
0.99999607 3.8177762e-07
===========>   testing    <===========
Epoch: [1052][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0325 (0.0325)	
0.9999907 3.5825692e-06
Epoch: [1052][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0307 (0.0598)	
0.99999416 4.0750224e-06
Epoch: [1052][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0654 (0.0566)	
0.99998677 3.3204085e-06
loss:  0.04090074141778721 0.039357641835424007
===========>   training    <===========
Epoch: [1053][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0507 (0.0507)	
0.9999949 1.2439524e-06
===========>   testing    <===========
Epoch: [1053][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0372 (0.0372)	
0.999987 2.811489e-06
Epoch: [1053][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0334 (0.0586)	
0.9999889 2.6178184e-06
Epoch: [1053][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0764 (0.0565)	
0.99998164 2.9354344e-06
loss:  0.04058378913324068 0.039357641835424007
===========>   training    <===========
Epoch: [1054][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0336 (0.0336)	
0.99998534 2.3187465e-06
===========>   testing    <===========
Epoch: [1054][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0418 (0.0418)	
0.99998724 2.8891698e-06
Epoch: [1054][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0356 (0.0613)	
0.99998796 2.8041786e-06
Epoch: [1054][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0602 (0.0582)	
0.999979 2.253149e-06
loss:  0.04211445457510088 0.039357641835424007
===========>   training    <===========
Epoch: [1055][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0396 (0.0396)	
0.99998426 2.203576e-06
===========>   testing    <===========
Epoch: [1055][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0340 (0.0340)	
0.9999914 3.2310468e-06
Epoch: [1055][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0364 (0.0617)	
0.9999925 3.8117005e-06
Epoch: [1055][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0559 (0.0590)	
0.99998736 2.6750265e-06
loss:  0.04215345617240507 0.039357641835424007
===========>   training    <===========
Epoch: [1056][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0423 (0.0423)	
0.99999285 2.782802e-06
===========>   testing    <===========
Epoch: [1056][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0305 (0.0305)	
0.9999882 2.5226198e-06
Epoch: [1056][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0778 (0.0588)	
0.9999883 1.8300483e-06
Epoch: [1056][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0560 (0.0569)	
0.9999782 2.3418806e-06
loss:  0.040329852508511066 0.039357641835424007
===========>   training    <===========
Epoch: [1057][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0408 (0.0408)	
0.99998796 4.1162016e-06
===========>   testing    <===========
Epoch: [1057][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0348 (0.0348)	
0.99998975 3.5110256e-06
Epoch: [1057][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.1263 (0.0615)	
0.9999852 2.1198216e-06
Epoch: [1057][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0740 (0.0590)	
0.999982 3.1663055e-06
loss:  0.04200597210474655 0.039357641835424007
===========>   training    <===========
Epoch: [1058][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0426 (0.0426)	
0.99998665 3.5020703e-06
===========>   testing    <===========
Epoch: [1058][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0445 (0.0445)	
0.9999924 3.4556922e-06
Epoch: [1058][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0715 (0.0655)	
0.99999 3.5477804e-06
Epoch: [1058][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0822 (0.0603)	
0.9999845 2.8344205e-06
loss:  0.04187079610727218 0.039357641835424007
===========>   training    <===========
Epoch: [1059][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0402 (0.0402)	
0.9999943 3.904597e-06
===========>   testing    <===========
Epoch: [1059][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0358 (0.0358)	
0.9999927 3.5473067e-06
Epoch: [1059][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0397 (0.0607)	
0.9999933 3.6569131e-06
Epoch: [1059][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0755 (0.0575)	
0.99998796 2.2492802e-06
loss:  0.04125726340556368 0.039357641835424007
===========>   training    <===========
Epoch: [1060][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0545 (0.0545)	
0.9999863 1.9782667e-06
===========>   testing    <===========
Epoch: [1060][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0422 (0.0422)	
0.99999034 2.9220553e-06
Epoch: [1060][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0315 (0.0606)	
0.9999881 3.1535856e-06
Epoch: [1060][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.1038 (0.0588)	
0.9999751 1.661044e-06
loss:  0.041571868539764356 0.039357641835424007
===========>   training    <===========
Epoch: [1061][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0499 (0.0499)	
0.99998486 2.9866892e-06
===========>   testing    <===========
Epoch: [1061][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0344 (0.0344)	
0.99998975 2.9812538e-06
Epoch: [1061][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0279 (0.0592)	
0.9999932 3.1267411e-06
Epoch: [1061][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.1173 (0.0572)	
0.9999819 2.1533886e-06
loss:  0.03967898324018493 0.039357641835424007
===========>   training    <===========
Epoch: [1062][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0417 (0.0417)	
0.99998724 2.8093955e-06
===========>   testing    <===========
Epoch: [1062][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0315 (0.0315)	
0.99999034 3.053524e-06
Epoch: [1062][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0295 (0.0588)	
0.99999523 3.9673796e-06
Epoch: [1062][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0951 (0.0563)	
0.9999888 2.0195637e-06
loss:  0.03858705330121737 0.039357641835424007
===========>   training    <===========
Epoch: [1063][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0379 (0.0379)	
0.9999887 5.7151087e-06
===========>   testing    <===========
Epoch: [1063][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0329 (0.0329)	
0.99998903 2.6572204e-06
Epoch: [1063][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0292 (0.0582)	
0.99999225 2.990015e-06
Epoch: [1063][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.1072 (0.0560)	
0.9999821 2.0065188e-06
loss:  0.039159217750408204 0.03858705330121737
===========>   training    <===========
Epoch: [1064][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0337 (0.0337)	
0.99999344 3.0997473e-06
===========>   testing    <===========
Epoch: [1064][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0293 (0.0293)	
0.99998987 2.748777e-06
Epoch: [1064][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0350 (0.0592)	
0.9999895 3.0418837e-06
Epoch: [1064][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0754 (0.0571)	
0.99997866 1.9917775e-06
loss:  0.04014286067538597 0.03858705330121737
===========>   training    <===========
Epoch: [1065][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0352 (0.0352)	
0.9999881 1.4480801e-06
===========>   testing    <===========
Epoch: [1065][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0345 (0.0345)	
0.99999046 3.1175082e-06
Epoch: [1065][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0340 (0.0595)	
0.9999919 3.1563536e-06
Epoch: [1065][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0749 (0.0581)	
0.999984 3.3133483e-06
loss:  0.04132398712191554 0.03858705330121737
===========>   training    <===========
Epoch: [1066][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0389 (0.0389)	
0.9999901 2.637304e-06
===========>   testing    <===========
Epoch: [1066][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0279 (0.0279)	
0.9999893 2.913485e-06
Epoch: [1066][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0264 (0.0591)	
0.99999106 3.1342884e-06
Epoch: [1066][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.1032 (0.0586)	
0.9999856 2.0036352e-06
loss:  0.04095056948959397 0.03858705330121737
===========>   training    <===========
Epoch: [1067][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0351 (0.0351)	
0.99998534 2.2936956e-06
===========>   testing    <===========
Epoch: [1067][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0365 (0.0365)	
0.99999 2.132232e-06
Epoch: [1067][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0385 (0.0594)	
0.999987 2.2166776e-06
Epoch: [1067][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0794 (0.0568)	
0.99997973 1.3139706e-06
loss:  0.040401896128538395 0.03858705330121737
===========>   training    <===========
Epoch: [1068][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0356 (0.0356)	
0.99999726 2.639775e-06
===========>   testing    <===========
Epoch: [1068][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0362 (0.0362)	
0.99999106 2.5473219e-06
Epoch: [1068][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0303 (0.0594)	
0.99999034 2.6954203e-06
Epoch: [1068][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0675 (0.0565)	
0.9999819 2.1089406e-06
loss:  0.03964370637728731 0.03858705330121737
===========>   training    <===========
Epoch: [1069][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0398 (0.0398)	
0.99998677 1.5452646e-06
===========>   testing    <===========
Epoch: [1069][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0293 (0.0293)	
0.9999901 3.2773153e-06
Epoch: [1069][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0311 (0.0620)	
0.9999932 3.797626e-06
Epoch: [1069][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0929 (0.0584)	
0.9999882 2.2288834e-06
loss:  0.040675383097768525 0.03858705330121737
===========>   training    <===========
Epoch: [1070][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0386 (0.0386)	
0.9999839 1.4857931e-06
===========>   testing    <===========
Epoch: [1070][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0309 (0.0309)	
0.99999094 3.1421357e-06
Epoch: [1070][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0367 (0.0589)	
0.99999404 3.237626e-06
Epoch: [1070][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0858 (0.0564)	
0.9999889 1.979116e-06
loss:  0.040391959423159096 0.03858705330121737
===========>   training    <===========
Epoch: [1071][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0393 (0.0393)	
0.99998915 2.6768944e-06
===========>   testing    <===========
Epoch: [1071][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0315 (0.0315)	
0.9999914 3.6713973e-06
Epoch: [1071][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0297 (0.0616)	
0.9999938 3.984948e-06
Epoch: [1071][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0653 (0.0582)	
0.99999106 2.9905996e-06
loss:  0.04110799183296687 0.03858705330121737
===========>   training    <===========
Epoch: [1072][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0401 (0.0401)	
0.9999919 2.8896934e-06
===========>   testing    <===========
Epoch: [1072][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0351 (0.0351)	
0.99998796 3.6792628e-06
Epoch: [1072][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0297 (0.0594)	
0.99999154 4.2764796e-06
Epoch: [1072][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0967 (0.0573)	
0.99998605 1.8470597e-06
loss:  0.04094895191098169 0.03858705330121737
===========>   training    <===========
Epoch: [1073][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0398 (0.0398)	
0.99999344 7.69073e-07
===========>   testing    <===========
Epoch: [1073][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0310 (0.0310)	
0.9999877 3.4194836e-06
Epoch: [1073][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0431 (0.0591)	
0.9999906 3.520353e-06
Epoch: [1073][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0764 (0.0567)	
0.9999808 1.3520627e-06
loss:  0.04138671279094197 0.03858705330121737
===========>   training    <===========
Epoch: [1074][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0404 (0.0404)	
0.99998844 2.362248e-06
===========>   testing    <===========
Epoch: [1074][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0290 (0.0290)	
0.9999863 3.0623721e-06
Epoch: [1074][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0313 (0.0595)	
0.9999881 2.9993514e-06
Epoch: [1074][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0639 (0.0567)	
0.9999728 1.5747297e-06
loss:  0.04086087732642629 0.03858705330121737
===========>   training    <===========
Epoch: [1075][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0387 (0.0387)	
0.99998677 1.1013727e-06
===========>   testing    <===========
Epoch: [1075][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0351 (0.0351)	
0.99998415 3.2994112e-06
Epoch: [1075][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0524 (0.0602)	
0.9999883 3.7506632e-06
Epoch: [1075][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0603 (0.0577)	
0.9999807 3.7063376e-06
loss:  0.04085029051988831 0.03858705330121737
===========>   training    <===========
Epoch: [1076][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0418 (0.0418)	
0.9999887 6.337288e-06
===========>   testing    <===========
Epoch: [1076][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0327 (0.0327)	
0.9999875 3.3024774e-06
Epoch: [1076][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0327 (0.0617)	
0.99998665 3.2391981e-06
Epoch: [1076][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0527 (0.0585)	
0.9999795 2.9336013e-06
loss:  0.04111487639487921 0.03858705330121737
===========>   training    <===========
Epoch: [1077][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0401 (0.0401)	
0.9999827 1.6794174e-06
===========>   testing    <===========
Epoch: [1077][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0285 (0.0285)	
0.9999893 3.0837014e-06
Epoch: [1077][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0670 (0.0601)	
0.9999906 3.1986253e-06
Epoch: [1077][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0740 (0.0571)	
0.9999827 2.1060343e-06
loss:  0.04085049409056263 0.03858705330121737
===========>   training    <===========
Epoch: [1078][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0425 (0.0425)	
0.9999794 8.3442916e-07
===========>   testing    <===========
Epoch: [1078][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0264 (0.0264)	
0.9999865 3.3523795e-06
Epoch: [1078][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0416 (0.0589)	
0.99998665 3.4458099e-06
Epoch: [1078][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0986 (0.0574)	
0.9999776 2.320921e-06
loss:  0.040016600325297635 0.03858705330121737
===========>   training    <===========
Epoch: [1079][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0432 (0.0432)	
0.9999765 1.6718174e-06
===========>   testing    <===========
Epoch: [1079][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0308 (0.0308)	
0.9999906 3.1574978e-06
Epoch: [1079][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0553 (0.0584)	
0.99999166 3.4898974e-06
Epoch: [1079][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0940 (0.0573)	
0.9999864 2.0252978e-06
loss:  0.039693552001048626 0.03858705330121737
===========>   training    <===========
Epoch: [1080][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0360 (0.0360)	
0.9999888 4.7125177e-06
===========>   testing    <===========
Epoch: [1080][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0289 (0.0289)	
0.9999871 2.9759703e-06
Epoch: [1080][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0395 (0.0573)	
0.99998724 3.2135463e-06
Epoch: [1080][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.1139 (0.0563)	
0.9999821 2.252672e-06
loss:  0.03916686797849678 0.03858705330121737
===========>   training    <===========
Epoch: [1081][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0429 (0.0429)	
0.9999862 2.7730161e-06
===========>   testing    <===========
Epoch: [1081][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0305 (0.0305)	
0.9999925 3.4513153e-06
Epoch: [1081][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0431 (0.0599)	
0.9999927 4.1021603e-06
Epoch: [1081][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0640 (0.0572)	
0.9999889 3.6965666e-06
loss:  0.03985229553677094 0.03858705330121737
===========>   training    <===========
Epoch: [1082][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0404 (0.0404)	
0.99998903 2.581277e-06
===========>   testing    <===========
Epoch: [1082][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0288 (0.0288)	
0.9999883 2.4649285e-06
Epoch: [1082][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0380 (0.0597)	
0.9999875 2.6632e-06
Epoch: [1082][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0990 (0.0569)	
0.9999778 1.1900548e-06
loss:  0.03993773760889008 0.03858705330121737
===========>   training    <===========
Epoch: [1083][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0367 (0.0367)	
0.9999908 1.8290225e-06
===========>   testing    <===========
Epoch: [1083][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0288 (0.0288)	
0.9999889 3.1553243e-06
Epoch: [1083][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0384 (0.0599)	
0.9999887 3.2328962e-06
Epoch: [1083][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0992 (0.0574)	
0.99998236 1.6558042e-06
loss:  0.039553283471882916 0.03858705330121737
===========>   training    <===========
Epoch: [1084][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0378 (0.0378)	
0.99998176 1.4456556e-05
===========>   testing    <===========
Epoch: [1084][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0302 (0.0302)	
0.9999877 2.525737e-06
Epoch: [1084][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0349 (0.0590)	
0.9999888 2.8052484e-06
Epoch: [1084][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.1245 (0.0575)	
0.99998057 1.5201326e-06
loss:  0.03984910092457883 0.03858705330121737
===========>   training    <===========
Epoch: [1085][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0325 (0.0325)	
0.99999046 2.7707904e-06
===========>   testing    <===========
Epoch: [1085][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0306 (0.0306)	
0.99999046 2.9958635e-06
Epoch: [1085][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0294 (0.0607)	
0.99999094 3.4830016e-06
Epoch: [1085][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.1010 (0.0578)	
0.99998474 2.1496994e-06
loss:  0.04017004063264029 0.03858705330121737
===========>   training    <===========
Epoch: [1086][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0458 (0.0458)	
0.9999685 8.8440936e-07
===========>   testing    <===========
Epoch: [1086][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0323 (0.0323)	
0.9999907 3.109067e-06
Epoch: [1086][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0294 (0.0604)	
0.99999106 3.3388576e-06
Epoch: [1086][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.1276 (0.0577)	
0.9999852 1.7776047e-06
loss:  0.04028700894550963 0.03858705330121737
===========>   training    <===========
Epoch: [1087][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0409 (0.0409)	
0.9999901 6.862938e-06
===========>   testing    <===========
Epoch: [1087][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0303 (0.0303)	
0.99998975 3.2619425e-06
Epoch: [1087][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0301 (0.0603)	
0.999992 3.9665815e-06
Epoch: [1087][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.1370 (0.0577)	
0.99998677 2.2981976e-06
loss:  0.04026461467105158 0.03858705330121737
===========>   training    <===========
Epoch: [1088][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0529 (0.0529)	
0.9999683 2.026343e-06
===========>   testing    <===========
Epoch: [1088][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0342 (0.0342)	
0.9999894 3.1105856e-06
Epoch: [1088][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0336 (0.0619)	
0.9999924 3.253188e-06
Epoch: [1088][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0946 (0.0581)	
0.99998283 2.4983021e-06
loss:  0.04123284404650174 0.03858705330121737
===========>   training    <===========
Epoch: [1089][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0387 (0.0387)	
0.9999826 8.653106e-07
===========>   testing    <===========
Epoch: [1089][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0334 (0.0334)	
0.99999034 3.5973217e-06
Epoch: [1089][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0331 (0.0613)	
0.9999944 3.843557e-06
Epoch: [1089][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.1132 (0.0586)	
0.9999871 3.864146e-06
loss:  0.0412951243401648 0.03858705330121737
===========>   training    <===========
Epoch: [1090][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0312 (0.0312)	
0.999997 8.58374e-06
===========>   testing    <===========
Epoch: [1090][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0289 (0.0289)	
0.99999 3.7112293e-06
Epoch: [1090][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0323 (0.0599)	
0.9999933 4.805839e-06
Epoch: [1090][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.1233 (0.0581)	
0.9999858 2.376284e-06
loss:  0.04017238098097298 0.03858705330121737
===========>   training    <===========
Epoch: [1091][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0395 (0.0395)	
0.9999864 2.3267519e-06
===========>   testing    <===========
Epoch: [1091][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0327 (0.0327)	
0.99998474 3.2930172e-06
Epoch: [1091][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0337 (0.0602)	
0.9999894 3.2773278e-06
Epoch: [1091][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.1202 (0.0579)	
0.99998057 2.6884481e-06
loss:  0.041103195580778684 0.03858705330121737
===========>   training    <===========
Epoch: [1092][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0367 (0.0367)	
0.999992 6.759555e-06
===========>   testing    <===========
Epoch: [1092][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0342 (0.0342)	
0.99998724 3.0633885e-06
Epoch: [1092][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0335 (0.0593)	
0.99999 3.0778633e-06
Epoch: [1092][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0721 (0.0567)	
0.99997973 2.384104e-06
loss:  0.04068530257835046 0.03858705330121737
===========>   training    <===========
Epoch: [1093][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0430 (0.0430)	
0.9999902 1.739765e-06
===========>   testing    <===========
Epoch: [1093][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0425 (0.0425)	
0.9999875 3.4042685e-06
Epoch: [1093][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0456 (0.0595)	
0.99999046 3.5495198e-06
Epoch: [1093][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0942 (0.0576)	
0.99998534 3.4921281e-06
loss:  0.04150475345472082 0.03858705330121737
===========>   training    <===========
Epoch: [1094][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0324 (0.0324)	
0.99997973 1.8081552e-06
===========>   testing    <===========
Epoch: [1094][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0355 (0.0355)	
0.99998593 3.584442e-06
Epoch: [1094][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0430 (0.0591)	
0.99998856 3.6591355e-06
Epoch: [1094][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0677 (0.0571)	
0.9999784 1.7426012e-06
loss:  0.041217458403566276 0.03858705330121737
===========>   training    <===========
Epoch: [1095][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0363 (0.0363)	
0.9999876 2.4181472e-06
===========>   testing    <===========
Epoch: [1095][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0325 (0.0325)	
0.9999918 5.184212e-06
Epoch: [1095][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0345 (0.0590)	
0.9999932 5.5869264e-06
Epoch: [1095][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.1018 (0.0578)	
0.99998796 4.208786e-06
loss:  0.04098590101640087 0.03858705330121737
===========>   training    <===========
Epoch: [1096][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0400 (0.0400)	
0.99998426 1.5286897e-06
===========>   testing    <===========
Epoch: [1096][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0317 (0.0317)	
0.9999906 3.961633e-06
Epoch: [1096][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0364 (0.0597)	
0.99999297 4.221368e-06
Epoch: [1096][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0935 (0.0573)	
0.9999852 2.0073628e-06
loss:  0.04034763798848606 0.03858705330121737
===========>   training    <===========
Epoch: [1097][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0384 (0.0384)	
0.9999862 2.0103937e-06
===========>   testing    <===========
Epoch: [1097][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0321 (0.0321)	
0.9999906 3.5650849e-06
Epoch: [1097][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0357 (0.0598)	
0.9999912 3.4111258e-06
Epoch: [1097][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0852 (0.0572)	
0.99998367 1.6913888e-06
loss:  0.04067217434505932 0.03858705330121737
===========>   training    <===========
Epoch: [1098][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0484 (0.0484)	
0.9999827 1.7358702e-06
===========>   testing    <===========
Epoch: [1098][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0335 (0.0335)	
0.99999046 2.9114103e-06
Epoch: [1098][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0264 (0.0598)	
0.99998724 2.8460677e-06
Epoch: [1098][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0850 (0.0576)	
0.9999807 1.7146688e-06
loss:  0.04059962656259486 0.03858705330121737
===========>   training    <===========
Epoch: [1099][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0523 (0.0523)	
0.9999846 1.3878878e-06
===========>   testing    <===========
Epoch: [1099][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0359 (0.0359)	
0.99998844 3.8100543e-06
Epoch: [1099][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0286 (0.0597)	
0.9999889 3.6302827e-06
Epoch: [1099][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0817 (0.0580)	
0.99998605 2.2094596e-06
loss:  0.04122826089379861 0.03858705330121737
===========>   training    <===========
Epoch: [1100][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0354 (0.0354)	
0.9999902 5.75391e-06
===========>   testing    <===========
Epoch: [1100][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0375 (0.0375)	
0.9999869 3.2034975e-06
Epoch: [1100][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0382 (0.0586)	
0.9999888 2.9990624e-06
Epoch: [1100][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0499 (0.0565)	
0.9999862 1.2501354e-06
loss:  0.040311552977336795 0.03858705330121737
===========>   training    <===========
Epoch: [1101][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0503 (0.0503)	
0.99999106 5.1737907e-06
===========>   testing    <===========
Epoch: [1101][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0287 (0.0287)	
0.99998844 3.5889846e-06
Epoch: [1101][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0356 (0.0585)	
0.99998856 3.4864113e-06
Epoch: [1101][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0494 (0.0578)	
0.99998593 2.2751603e-06
loss:  0.04048887096367215 0.03858705330121737
===========>   training    <===========
Epoch: [1102][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0358 (0.0358)	
0.9999896 2.4320514e-06
===========>   testing    <===========
Epoch: [1102][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0320 (0.0320)	
0.99999 2.9090402e-06
Epoch: [1102][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0407 (0.0586)	
0.99999285 3.0889819e-06
Epoch: [1102][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0494 (0.0572)	
0.9999876 1.6473273e-06
loss:  0.0401340839122174 0.03858705330121737
===========>   training    <===========
Epoch: [1103][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0382 (0.0382)	
0.9999932 2.2363952e-06
===========>   testing    <===========
Epoch: [1103][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0303 (0.0303)	
0.9999896 2.4205883e-06
Epoch: [1103][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0353 (0.0599)	
0.99999213 2.374347e-06
Epoch: [1103][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0576 (0.0584)	
0.99998426 9.605649e-07
loss:  0.04127025222079905 0.03858705330121737
===========>   training    <===========
Epoch: [1104][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0394 (0.0394)	
0.9999907 3.829558e-06
===========>   testing    <===========
Epoch: [1104][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0298 (0.0298)	
0.99998903 2.823976e-06
Epoch: [1104][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0303 (0.0585)	
0.9999896 2.7762947e-06
Epoch: [1104][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0696 (0.0580)	
0.9999815 1.2218692e-06
loss:  0.04077375046414278 0.03858705330121737
===========>   training    <===========
Epoch: [1105][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0364 (0.0364)	
0.9999956 1.2957453e-06
===========>   testing    <===========
Epoch: [1105][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0325 (0.0325)	
0.99998844 2.841891e-06
Epoch: [1105][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0282 (0.0575)	
0.9999908 2.7259296e-06
Epoch: [1105][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0731 (0.0575)	
0.99998224 2.2672912e-06
loss:  0.03997948643464477 0.03858705330121737
===========>   training    <===========
Epoch: [1106][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0389 (0.0389)	
0.9999771 1.9500112e-06
===========>   testing    <===========
Epoch: [1106][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0401 (0.0401)	
0.9999893 3.327465e-06
Epoch: [1106][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0236 (0.0588)	
0.9999913 3.0648819e-06
Epoch: [1106][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0891 (0.0578)	
0.99998224 2.5014015e-06
loss:  0.04108471154857152 0.03858705330121737
===========>   training    <===========
Epoch: [1107][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0312 (0.0312)	
0.99998415 1.3441431e-06
===========>   testing    <===========
Epoch: [1107][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0406 (0.0406)	
0.9999883 3.3589142e-06
Epoch: [1107][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0276 (0.0592)	
0.9999914 3.0491067e-06
Epoch: [1107][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0603 (0.0570)	
0.99998045 1.585486e-06
loss:  0.04120517178829042 0.03858705330121737
===========>   training    <===========
Epoch: [1108][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0329 (0.0329)	
0.99999297 1.1241861e-05
===========>   testing    <===========
Epoch: [1108][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0316 (0.0316)	
0.9999896 3.2326404e-06
Epoch: [1108][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0319 (0.0582)	
0.9999938 3.1098796e-06
Epoch: [1108][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0725 (0.0572)	
0.99998665 1.8161185e-06
loss:  0.04126994483964097 0.03858705330121737
===========>   training    <===========
Epoch: [1109][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0365 (0.0365)	
0.99998415 6.282621e-07
===========>   testing    <===========
Epoch: [1109][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0363 (0.0363)	
0.99999094 2.0936545e-06
Epoch: [1109][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0404 (0.0617)	
0.99999416 2.0051607e-06
Epoch: [1109][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0603 (0.0587)	
0.9999833 9.254751e-07
loss:  0.041715618929417664 0.03858705330121737
===========>   training    <===========
Epoch: [1110][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0434 (0.0434)	
0.999987 1.7762524e-06
===========>   testing    <===========
Epoch: [1110][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0356 (0.0356)	
0.9999894 2.456827e-06
Epoch: [1110][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0301 (0.0610)	
0.99999213 2.4769179e-06
Epoch: [1110][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0933 (0.0594)	
0.9999831 1.6261366e-06
loss:  0.04138543169347764 0.03858705330121737
===========>   training    <===========
Epoch: [1111][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0420 (0.0420)	
0.9999908 1.7325244e-06
===========>   testing    <===========
Epoch: [1111][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0358 (0.0358)	
0.9999913 3.063593e-06
Epoch: [1111][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0730 (0.0626)	
0.99999285 2.9012965e-06
Epoch: [1111][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.1065 (0.0601)	
0.9999882 2.2139839e-06
loss:  0.041549198255372066 0.03858705330121737
===========>   training    <===========
Epoch: [1112][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0445 (0.0445)	
0.9999939 1.436896e-06
===========>   testing    <===========
Epoch: [1112][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0318 (0.0318)	
0.99998796 2.1053156e-06
Epoch: [1112][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0532 (0.0594)	
0.99999034 1.7689158e-06
Epoch: [1112][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0780 (0.0578)	
0.99997914 1.1759828e-06
loss:  0.04139316743150723 0.03858705330121737
===========>   training    <===========
Epoch: [1113][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0390 (0.0390)	
0.99999034 1.3041457e-06
===========>   testing    <===========
Epoch: [1113][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0285 (0.0285)	
0.9999887 2.8092e-06
Epoch: [1113][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0429 (0.0591)	
0.99999154 2.307386e-06
Epoch: [1113][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0839 (0.0575)	
0.99998426 1.9663496e-06
loss:  0.041270627183982556 0.03858705330121737
===========>   training    <===========
Epoch: [1114][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0371 (0.0371)	
0.9999844 1.913796e-06
===========>   testing    <===========
Epoch: [1114][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0271 (0.0271)	
0.9999888 2.7056137e-06
Epoch: [1114][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0277 (0.0566)	
0.9999926 2.6357727e-06
Epoch: [1114][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.1065 (0.0571)	
0.9999857 2.36123e-06
loss:  0.040423963576691424 0.03858705330121737
===========>   training    <===========
Epoch: [1115][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0378 (0.0378)	
0.99999034 2.8901095e-06
===========>   testing    <===========
Epoch: [1115][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0299 (0.0299)	
0.9999895 3.1950399e-06
Epoch: [1115][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0259 (0.0572)	
0.99999094 3.1175232e-06
Epoch: [1115][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0999 (0.0567)	
0.9999851 2.1104136e-06
loss:  0.04019756145369824 0.03858705330121737
===========>   training    <===========
Epoch: [1116][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0390 (0.0390)	
0.99999094 3.2334203e-06
===========>   testing    <===========
Epoch: [1116][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0344 (0.0344)	
0.9999924 3.4217146e-06
Epoch: [1116][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0313 (0.0587)	
0.9999944 3.5388123e-06
Epoch: [1116][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0576 (0.0570)	
0.9999895 3.1435536e-06
loss:  0.040143714423438226 0.03858705330121737
===========>   training    <===========
Epoch: [1117][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0377 (0.0377)	
0.9999912 1.4255617e-06
===========>   testing    <===========
Epoch: [1117][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0278 (0.0278)	
0.99998975 2.7532108e-06
Epoch: [1117][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0260 (0.0573)	
0.99999344 2.86258e-06
Epoch: [1117][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.1034 (0.0566)	
0.999987 1.2658307e-06
loss:  0.04096892889906634 0.03858705330121737
===========>   training    <===========
Epoch: [1118][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0411 (0.0411)	
0.9999808 1.054295e-06
===========>   testing    <===========
Epoch: [1118][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0272 (0.0272)	
0.99998987 2.514216e-06
Epoch: [1118][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0293 (0.0564)	
0.9999927 2.5604888e-06
Epoch: [1118][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.1227 (0.0571)	
0.99998474 1.7934818e-06
loss:  0.040906605842360166 0.03858705330121737
===========>   training    <===========
Epoch: [1119][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0352 (0.0352)	
0.99999547 1.7219938e-06
===========>   testing    <===========
Epoch: [1119][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0373 (0.0373)	
0.99999213 2.7134797e-06
Epoch: [1119][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0240 (0.0572)	
0.99999344 3.024346e-06
Epoch: [1119][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.1116 (0.0578)	
0.99999034 2.6960167e-06
loss:  0.04096704820204744 0.03858705330121737
===========>   training    <===========
Epoch: [1120][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0339 (0.0339)	
0.99998176 6.8839468e-06
===========>   testing    <===========
Epoch: [1120][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0366 (0.0366)	
0.99999034 2.2560516e-06
Epoch: [1120][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0260 (0.0580)	
0.999992 2.2630118e-06
Epoch: [1120][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0822 (0.0577)	
0.999987 1.5964147e-06
loss:  0.0409440940861604 0.03858705330121737
===========>   training    <===========
Epoch: [1121][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0435 (0.0435)	
0.9999813 2.7803721e-06
===========>   testing    <===========
Epoch: [1121][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0325 (0.0325)	
0.99999 3.0289123e-06
Epoch: [1121][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0241 (0.0585)	
0.99999094 3.0672647e-06
Epoch: [1121][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0984 (0.0586)	
0.9999864 2.6114976e-06
loss:  0.04031514655454116 0.03858705330121737
===========>   training    <===========
Epoch: [1122][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0385 (0.0385)	
0.9999919 3.627725e-06
===========>   testing    <===========
Epoch: [1122][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0355 (0.0355)	
0.99998796 2.7422468e-06
Epoch: [1122][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0267 (0.0572)	
0.9999888 2.7630774e-06
Epoch: [1122][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0700 (0.0575)	
0.9999825 1.9214845e-06
loss:  0.040799686450840644 0.03858705330121737
===========>   training    <===========
Epoch: [1123][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0396 (0.0396)	
0.9999821 1.6199236e-06
===========>   testing    <===========
Epoch: [1123][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0391 (0.0391)	
0.99999034 3.4712396e-06
Epoch: [1123][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0247 (0.0590)	
0.9999924 3.3476383e-06
Epoch: [1123][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.1073 (0.0596)	
0.99998844 2.9559865e-06
loss:  0.04219640109947953 0.03858705330121737
===========>   training    <===========
Epoch: [1124][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0368 (0.0368)	
0.9999857 1.0550826e-06
===========>   testing    <===========
Epoch: [1124][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0464 (0.0464)	
0.99999 3.0004442e-06
Epoch: [1124][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0284 (0.0587)	
0.9999888 2.8340205e-06
Epoch: [1124][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0757 (0.0591)	
0.999984 2.3328798e-06
loss:  0.04242882059783459 0.03858705330121737
===========>   training    <===========
Epoch: [1125][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0292 (0.0292)	
0.9999763 2.123652e-06
===========>   testing    <===========
Epoch: [1125][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0330 (0.0330)	
0.99998903 2.7118006e-06
Epoch: [1125][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0320 (0.0594)	
0.99998546 2.1810754e-06
Epoch: [1125][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.1081 (0.0591)	
0.9999807 1.6214924e-06
loss:  0.04191396417463633 0.03858705330121737
===========>   training    <===========
Epoch: [1126][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0385 (0.0385)	
0.99998367 1.3959212e-06
===========>   testing    <===========
Epoch: [1126][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0410 (0.0410)	
0.99998987 3.2847902e-06
Epoch: [1126][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0275 (0.0603)	
0.9999863 3.2879523e-06
Epoch: [1126][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.1102 (0.0585)	
0.9999846 2.5069419e-06
loss:  0.0401699206853513 0.03858705330121737
===========>   training    <===========
Epoch: [1127][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0305 (0.0305)	
0.99999213 5.291313e-06
===========>   testing    <===========
Epoch: [1127][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0301 (0.0301)	
0.99998844 4.0384048e-06
Epoch: [1127][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0305 (0.0577)	
0.9999881 3.6971378e-06
Epoch: [1127][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.1222 (0.0569)	
0.9999815 1.9420625e-06
loss:  0.039633888296920494 0.03858705330121737
===========>   training    <===========
Epoch: [1128][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0345 (0.0345)	
0.9999927 1.9776367e-06
===========>   testing    <===========
Epoch: [1128][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0340 (0.0340)	
0.9999908 3.6854049e-06
Epoch: [1128][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0256 (0.0577)	
0.99999297 3.5264986e-06
Epoch: [1128][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0857 (0.0569)	
0.99998736 3.9227516e-06
loss:  0.040651250406109285 0.03858705330121737
===========>   training    <===========
Epoch: [1129][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0386 (0.0386)	
0.9999913 2.3802984e-06
===========>   testing    <===========
Epoch: [1129][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0304 (0.0304)	
0.9999907 3.1719692e-06
Epoch: [1129][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0286 (0.0564)	
0.9999918 2.7954688e-06
Epoch: [1129][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0910 (0.0559)	
0.99998415 2.0863756e-06
loss:  0.04063309054054565 0.03858705330121737
===========>   training    <===========
Epoch: [1130][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0341 (0.0341)	
0.99999166 4.080712e-06
===========>   testing    <===========
Epoch: [1130][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0301 (0.0301)	
0.9999918 4.0504237e-06
Epoch: [1130][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0252 (0.0583)	
0.99999523 3.9468578e-06
Epoch: [1130][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.1031 (0.0566)	
0.9999881 3.2379596e-06
loss:  0.04043916978133366 0.03858705330121737
===========>   training    <===========
Epoch: [1131][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0389 (0.0389)	
0.999987 1.5546391e-06
===========>   testing    <===========
Epoch: [1131][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0360 (0.0360)	
0.99999034 3.5817698e-06
Epoch: [1131][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0311 (0.0564)	
0.99999344 3.2471253e-06
Epoch: [1131][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0740 (0.0553)	
0.99998534 3.528184e-06
loss:  0.039695420603776066 0.03858705330121737
===========>   training    <===========
Epoch: [1132][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0346 (0.0346)	
0.9999833 3.612796e-06
===========>   testing    <===========
Epoch: [1132][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0388 (0.0388)	
0.9999877 3.107019e-06
Epoch: [1132][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0364 (0.0578)	
0.9999914 3.072561e-06
Epoch: [1132][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0832 (0.0566)	
0.9999846 3.3547556e-06
loss:  0.040638162981249226 0.03858705330121737
===========>   training    <===========
Epoch: [1133][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0376 (0.0376)	
0.99998784 2.8501936e-06
===========>   testing    <===========
Epoch: [1133][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0454 (0.0454)	
0.99999034 2.8585478e-06
Epoch: [1133][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0366 (0.0585)	
0.99999297 3.4012896e-06
Epoch: [1133][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0901 (0.0569)	
0.9999864 3.0868673e-06
loss:  0.040245685674357046 0.03858705330121737
===========>   training    <===========
Epoch: [1134][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0399 (0.0399)	
0.99999094 5.70039e-06
===========>   testing    <===========
Epoch: [1134][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0373 (0.0373)	
0.9999865 2.878705e-06
Epoch: [1134][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0435 (0.0567)	
0.99999034 2.906597e-06
Epoch: [1134][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0983 (0.0558)	
0.9999801 2.9962323e-06
loss:  0.040600365335078714 0.03858705330121737
===========>   training    <===========
Epoch: [1135][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0406 (0.0406)	
0.99999547 1.1896032e-06
===========>   testing    <===========
Epoch: [1135][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0373 (0.0373)	
0.99998784 2.2161364e-06
Epoch: [1135][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0377 (0.0595)	
0.99999 2.4151534e-06
Epoch: [1135][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.1029 (0.0580)	
0.99998176 2.287374e-06
loss:  0.04112690106913053 0.03858705330121737
===========>   training    <===========
Epoch: [1136][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0360 (0.0360)	
0.9999821 1.174686e-06
===========>   testing    <===========
Epoch: [1136][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0350 (0.0350)	
0.9999895 2.9060152e-06
Epoch: [1136][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0281 (0.0589)	
0.9999919 3.17439e-06
Epoch: [1136][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.1006 (0.0569)	
0.9999864 3.1020124e-06
loss:  0.040487523338021414 0.03858705330121737
===========>   training    <===========
Epoch: [1137][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0379 (0.0379)	
0.99998736 1.1340453e-06
===========>   testing    <===========
Epoch: [1137][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0305 (0.0305)	
0.9999889 2.750046e-06
Epoch: [1137][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0303 (0.0588)	
0.99999297 3.0221174e-06
Epoch: [1137][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0703 (0.0564)	
0.9999845 2.845487e-06
loss:  0.04028349855511881 0.03858705330121737
===========>   training    <===========
Epoch: [1138][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0434 (0.0434)	
0.9999943 2.3972248e-06
===========>   testing    <===========
Epoch: [1138][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0374 (0.0374)	
0.99998796 2.2908976e-06
Epoch: [1138][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0294 (0.0582)	
0.99998856 2.6119058e-06
Epoch: [1138][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0883 (0.0565)	
0.99998176 2.395753e-06
loss:  0.039837928493186014 0.03858705330121737
===========>   training    <===========
Epoch: [1139][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0307 (0.0307)	
0.9999908 2.1320468e-06
===========>   testing    <===========
Epoch: [1139][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0415 (0.0415)	
0.99998915 2.4718538e-06
Epoch: [1139][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0291 (0.0574)	
0.99999297 2.6954408e-06
Epoch: [1139][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0965 (0.0566)	
0.9999852 2.6801004e-06
loss:  0.03969060955014525 0.03858705330121737
===========>   training    <===========
Epoch: [1140][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0376 (0.0376)	
0.999985 2.444291e-06
===========>   testing    <===========
Epoch: [1140][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0401 (0.0401)	
0.9999856 2.2396052e-06
Epoch: [1140][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0357 (0.0590)	
0.99999034 2.2087431e-06
Epoch: [1140][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.1072 (0.0575)	
0.9999802 1.2952646e-06
loss:  0.040909904837045596 0.03858705330121737
===========>   training    <===========
Epoch: [1141][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0364 (0.0364)	
0.999992 3.0128658e-06
===========>   testing    <===========
Epoch: [1141][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0500 (0.0500)	
0.9999877 1.936067e-06
Epoch: [1141][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0311 (0.0606)	
0.99999046 1.7804906e-06
Epoch: [1141][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0943 (0.0584)	
0.99997914 1.4522416e-06
loss:  0.040488927504010785 0.03858705330121737
===========>   training    <===========
Epoch: [1142][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0391 (0.0391)	
0.9999858 2.9243415e-06
===========>   testing    <===========
Epoch: [1142][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0373 (0.0373)	
0.9999882 2.61466e-06
Epoch: [1142][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0259 (0.0592)	
0.9999913 2.619047e-06
Epoch: [1142][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0884 (0.0574)	
0.9999863 1.8283143e-06
loss:  0.04010969569281231 0.03858705330121737
===========>   training    <===========
Epoch: [1143][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0385 (0.0385)	
0.99997675 1.1997088e-06
===========>   testing    <===========
Epoch: [1143][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0455 (0.0455)	
0.9999887 2.224827e-06
Epoch: [1143][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0266 (0.0601)	
0.99999225 2.3511855e-06
Epoch: [1143][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0890 (0.0579)	
0.999987 1.920462e-06
loss:  0.04016490723975219 0.03858705330121737
===========>   training    <===========
Epoch: [1144][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0334 (0.0334)	
0.9999924 2.3261105e-06
===========>   testing    <===========
Epoch: [1144][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0367 (0.0367)	
0.99998975 2.3534692e-06
Epoch: [1144][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0262 (0.0601)	
0.9999931 2.6196467e-06
Epoch: [1144][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0576 (0.0570)	
0.99998844 2.0587854e-06
loss:  0.04020318012209889 0.03858705330121737
===========>   training    <===========
Epoch: [1145][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0431 (0.0431)	
0.99999547 3.981328e-06
===========>   testing    <===========
Epoch: [1145][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0379 (0.0379)	
0.99999034 2.109498e-06
Epoch: [1145][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0313 (0.0602)	
0.999992 2.3837472e-06
Epoch: [1145][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0813 (0.0577)	
0.99998736 1.7847219e-06
loss:  0.04001415404093456 0.03858705330121737
===========>   training    <===========
Epoch: [1146][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0367 (0.0367)	
0.9999825 6.1910296e-06
===========>   testing    <===========
Epoch: [1146][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0437 (0.0437)	
0.9999881 2.325117e-06
Epoch: [1146][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0314 (0.0596)	
0.99998534 2.5139282e-06
Epoch: [1146][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0906 (0.0580)	
0.9999789 2.326772e-06
loss:  0.03976665744880514 0.03858705330121737
===========>   training    <===========
Epoch: [1147][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0458 (0.0458)	
0.99999094 1.6912791e-06
===========>   testing    <===========
Epoch: [1147][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0445 (0.0445)	
0.9999924 2.6015816e-06
Epoch: [1147][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0513 (0.0606)	
0.99999154 3.1224445e-06
Epoch: [1147][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0586 (0.0581)	
0.99998915 2.68178e-06
loss:  0.04020787636155365 0.03858705330121737
===========>   training    <===========
Epoch: [1148][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0465 (0.0465)	
0.9999894 1.6259553e-06
===========>   testing    <===========
Epoch: [1148][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0606 (0.0606)	
0.99999285 2.7597616e-06
Epoch: [1148][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0608 (0.0606)	
0.9999938 2.8328964e-06
Epoch: [1148][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0634 (0.0585)	
0.9999926 1.9577458e-06
loss:  0.04111543716749211 0.03858705330121737
===========>   training    <===========
Epoch: [1149][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0466 (0.0466)	
0.9999962 5.314854e-06
===========>   testing    <===========
Epoch: [1149][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0545 (0.0545)	
0.9999918 2.295709e-06
Epoch: [1149][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0395 (0.0595)	
0.99999356 2.4061255e-06
Epoch: [1149][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0838 (0.0575)	
0.9999864 1.9790932e-06
loss:  0.04030965339743309 0.03858705330121737
===========>   training    <===========
Epoch: [1150][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0387 (0.0387)	
0.99998367 1.3577404e-06
===========>   testing    <===========
Epoch: [1150][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0486 (0.0486)	
0.9999883 2.2854879e-06
Epoch: [1150][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0492 (0.0596)	
0.9999926 2.4859296e-06
Epoch: [1150][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.1111 (0.0578)	
0.9999825 2.4057858e-06
loss:  0.04070581706715248 0.03858705330121737
===========>   training    <===========
Epoch: [1151][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0318 (0.0318)	
0.99999034 2.3199077e-06
===========>   testing    <===========
Epoch: [1151][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0407 (0.0407)	
0.9999882 2.5723614e-06
Epoch: [1151][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0519 (0.0597)	
0.9999938 2.6301154e-06
Epoch: [1151][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0830 (0.0577)	
0.999984 2.4950975e-06
loss:  0.040464508624725615 0.03858705330121737
===========>   training    <===========
Epoch: [1152][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0363 (0.0363)	
0.99998844 1.989192e-06
===========>   testing    <===========
Epoch: [1152][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0409 (0.0409)	
0.99998844 2.215211e-06
Epoch: [1152][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0504 (0.0598)	
0.99999094 2.3625635e-06
Epoch: [1152][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.1094 (0.0578)	
0.99998164 2.2925585e-06
loss:  0.04049136130541586 0.03858705330121737
===========>   training    <===========
Epoch: [1153][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0354 (0.0354)	
0.9999919 2.2148074e-06
===========>   testing    <===========
Epoch: [1153][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0405 (0.0405)	
0.99998903 2.2948007e-06
Epoch: [1153][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0423 (0.0607)	
0.9999926 2.7442743e-06
Epoch: [1153][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0786 (0.0591)	
0.99998915 2.4118829e-06
loss:  0.0402503666438454 0.03858705330121737
===========>   training    <===========
Epoch: [1154][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0327 (0.0327)	
0.9999882 2.9634805e-06
===========>   testing    <===========
Epoch: [1154][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0581 (0.0581)	
0.9999883 1.9604327e-06
Epoch: [1154][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0789 (0.0620)	
0.99999 2.2410154e-06
Epoch: [1154][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0928 (0.0596)	
0.99998605 1.9586498e-06
loss:  0.04202996435330153 0.03858705330121737
===========>   training    <===========
Epoch: [1155][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0349 (0.0349)	
0.9999752 1.1088068e-06
===========>   testing    <===========
Epoch: [1155][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0572 (0.0572)	
0.9999876 2.164798e-06
Epoch: [1155][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.1228 (0.0623)	
0.9999869 2.4263063e-06
Epoch: [1155][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0697 (0.0592)	
0.99998355 2.256284e-06
loss:  0.041800670434125164 0.03858705330121737
===========>   training    <===========
Epoch: [1156][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0367 (0.0367)	
0.99999416 6.1248284e-06
===========>   testing    <===========
Epoch: [1156][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0367 (0.0367)	
0.99998724 1.6179196e-06
Epoch: [1156][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0878 (0.0600)	
0.99998844 1.769962e-06
Epoch: [1156][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0560 (0.0582)	
0.99997854 1.4556109e-06
loss:  0.04104224894774411 0.03858705330121737
===========>   training    <===========
Epoch: [1157][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0302 (0.0302)	
0.99999356 3.7714449e-06
===========>   testing    <===========
Epoch: [1157][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0371 (0.0371)	
0.9999912 2.8627574e-06
Epoch: [1157][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0410 (0.0588)	
0.999987 2.6846458e-06
Epoch: [1157][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0540 (0.0570)	
0.99998164 2.885246e-06
loss:  0.040799003317577465 0.03858705330121737
===========>   training    <===========
Epoch: [1158][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0423 (0.0423)	
0.99999046 2.1107799e-06
===========>   testing    <===========
Epoch: [1158][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0359 (0.0359)	
0.99998987 2.7205483e-06
Epoch: [1158][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0534 (0.0593)	
0.9999913 2.7475687e-06
Epoch: [1158][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.1116 (0.0574)	
0.9999864 2.6619152e-06
loss:  0.04082931245348098 0.03858705330121737
===========>   training    <===========
Epoch: [1159][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0406 (0.0406)	
0.99999094 2.893811e-06
===========>   testing    <===========
Epoch: [1159][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0370 (0.0370)	
0.99999034 2.897351e-06
Epoch: [1159][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.1266 (0.0593)	
0.99999464 2.998473e-06
Epoch: [1159][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0784 (0.0572)	
0.99999 3.0478798e-06
loss:  0.040391884766152186 0.03858705330121737
===========>   training    <===========
Epoch: [1160][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0424 (0.0424)	
0.99998593 2.5131276e-06
===========>   testing    <===========
Epoch: [1160][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0485 (0.0485)	
0.99998903 2.1845726e-06
Epoch: [1160][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0676 (0.0588)	
0.9999932 2.1890692e-06
Epoch: [1160][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0837 (0.0575)	
0.9999845 2.1074186e-06
loss:  0.04037029907976908 0.03858705330121737
===========>   training    <===========
Epoch: [1161][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0332 (0.0332)	
0.9999962 3.5389203e-06
===========>   testing    <===========
Epoch: [1161][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0387 (0.0387)	
0.99998975 2.3212467e-06
Epoch: [1161][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0294 (0.0595)	
0.9999937 2.334981e-06
Epoch: [1161][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0945 (0.0580)	
0.9999882 2.4752508e-06
loss:  0.039918319048657946 0.03858705330121737
===========>   training    <===========
Epoch: [1162][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0352 (0.0352)	
0.99998033 9.880252e-07
===========>   testing    <===========
Epoch: [1162][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0356 (0.0356)	
0.9999877 2.0499983e-06
Epoch: [1162][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0328 (0.0583)	
0.9999912 2.176334e-06
Epoch: [1162][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.1181 (0.0575)	
0.99998593 2.0372695e-06
loss:  0.03947451231215793 0.03858705330121737
===========>   training    <===========
Epoch: [1163][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0374 (0.0374)	
0.99998045 1.6886537e-06
===========>   testing    <===========
Epoch: [1163][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0338 (0.0338)	
0.9999875 2.0769876e-06
Epoch: [1163][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0522 (0.0584)	
0.99999154 2.4098526e-06
Epoch: [1163][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.1231 (0.0572)	
0.99998975 2.09392e-06
loss:  0.039503800790482546 0.03858705330121737
===========>   training    <===========
Epoch: [1164][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0370 (0.0370)	
0.9999951 4.464392e-06
===========>   testing    <===========
Epoch: [1164][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0340 (0.0340)	
0.9999913 2.4130768e-06
Epoch: [1164][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0340 (0.0575)	
0.9999932 2.8053528e-06
Epoch: [1164][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.1517 (0.0576)	
0.99999166 2.4354447e-06
loss:  0.03947184981783547 0.03858705330121737
===========>   training    <===========
Epoch: [1165][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0386 (0.0386)	
0.99999154 1.2670844e-06
===========>   testing    <===========
Epoch: [1165][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0361 (0.0361)	
0.9999888 1.8250271e-06
Epoch: [1165][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0670 (0.0586)	
0.9999893 1.8552967e-06
Epoch: [1165][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.1164 (0.0577)	
0.9999875 1.3813409e-06
loss:  0.03997713976970019 0.03858705330121737
===========>   training    <===========
Epoch: [1166][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0370 (0.0370)	
0.999995 2.0345651e-06
===========>   testing    <===========
Epoch: [1166][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0361 (0.0361)	
0.99998975 2.1106027e-06
Epoch: [1166][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0270 (0.0584)	
0.9999918 2.233194e-06
Epoch: [1166][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.1104 (0.0585)	
0.999987 2.0780317e-06
loss:  0.040225301482124665 0.03858705330121737
===========>   training    <===========
Epoch: [1167][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0377 (0.0377)	
0.9999832 1.7218658e-06
===========>   testing    <===========
Epoch: [1167][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0343 (0.0343)	
0.99999 2.594869e-06
Epoch: [1167][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0224 (0.0563)	
0.9999919 2.4064743e-06
Epoch: [1167][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0783 (0.0572)	
0.99998784 2.6065536e-06
loss:  0.03947167644930849 0.03858705330121737
===========>   training    <===========
Epoch: [1168][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0331 (0.0331)	
0.99998593 2.2156885e-06
===========>   testing    <===========
Epoch: [1168][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0649 (0.0649)	
0.99999 2.2056763e-06
Epoch: [1168][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0697 (0.0580)	
0.9999924 2.2351883e-06
Epoch: [1168][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0939 (0.0575)	
0.99998593 1.6149783e-06
loss:  0.039839150635972764 0.03858705330121737
===========>   training    <===========
Epoch: [1169][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0288 (0.0288)	
0.9999945 2.6101457e-06
===========>   testing    <===========
Epoch: [1169][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0586 (0.0586)	
0.9999912 2.2143956e-06
Epoch: [1169][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.1138 (0.0579)	
0.99999285 2.2344746e-06
Epoch: [1169][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0739 (0.0564)	
0.99998844 2.015602e-06
loss:  0.03984381010301463 0.03858705330121737
===========>   training    <===========
Epoch: [1170][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0306 (0.0306)	
0.99999607 1.5897192e-06
===========>   testing    <===========
Epoch: [1170][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0420 (0.0420)	
0.9999895 2.4883489e-06
Epoch: [1170][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0826 (0.0590)	
0.99999344 2.4947408e-06
Epoch: [1170][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0824 (0.0567)	
0.9999882 2.0768587e-06
loss:  0.04053385550188959 0.03858705330121737
===========>   training    <===========
Epoch: [1171][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0348 (0.0348)	
0.9999827 1.9380623e-06
===========>   testing    <===========
Epoch: [1171][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0359 (0.0359)	
0.9999902 2.4525896e-06
Epoch: [1171][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0929 (0.0580)	
0.9999931 2.5985912e-06
Epoch: [1171][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.1164 (0.0574)	
0.9999881 2.5927268e-06
loss:  0.04043744185333875 0.03858705330121737
===========>   training    <===========
Epoch: [1172][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0351 (0.0351)	
0.9999938 2.0875536e-06
===========>   testing    <===========
Epoch: [1172][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0434 (0.0434)	
0.9999907 2.3801306e-06
Epoch: [1172][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0702 (0.0582)	
0.9999913 2.1240874e-06
Epoch: [1172][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0908 (0.0574)	
0.99998486 2.1204523e-06
loss:  0.04002463383774135 0.03858705330121737
===========>   training    <===========
Epoch: [1173][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0383 (0.0383)	
0.99999213 1.1402506e-06
===========>   testing    <===========
Epoch: [1173][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0539 (0.0539)	
0.9999907 2.3473858e-06
Epoch: [1173][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0480 (0.0588)	
0.9999914 2.3000678e-06
Epoch: [1173][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.1023 (0.0582)	
0.99998784 1.9341478e-06
loss:  0.04084309645870443 0.03858705330121737
===========>   training    <===========
Epoch: [1174][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0396 (0.0396)	
0.99999154 1.5503795e-06
===========>   testing    <===========
Epoch: [1174][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0610 (0.0610)	
0.9999901 2.461743e-06
Epoch: [1174][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0625 (0.0565)	
0.99999154 2.7648723e-06
Epoch: [1174][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0974 (0.0560)	
0.99998605 1.942792e-06
loss:  0.03975837464027865 0.03858705330121737
===========>   training    <===========
Epoch: [1175][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0314 (0.0314)	
0.9999969 1.4703876e-06
===========>   testing    <===========
Epoch: [1175][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0387 (0.0387)	
0.99998784 2.401829e-06
Epoch: [1175][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0444 (0.0580)	
0.999992 2.2907009e-06
Epoch: [1175][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.1197 (0.0574)	
0.99998236 1.340904e-06
loss:  0.04079916160388075 0.03858705330121737
===========>   training    <===========
Epoch: [1176][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0335 (0.0335)	
0.99998903 2.9209993e-06
===========>   testing    <===========
Epoch: [1176][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0316 (0.0316)	
0.9999914 2.4279939e-06
Epoch: [1176][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0269 (0.0560)	
0.99999464 2.5586066e-06
Epoch: [1176][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0978 (0.0566)	
0.99998796 1.3806705e-06
loss:  0.039102813270490366 0.03858705330121737
===========>   training    <===========
Epoch: [1177][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0345 (0.0345)	
0.99999416 4.5496445e-06
===========>   testing    <===========
Epoch: [1177][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0297 (0.0297)	
0.9999918 2.3410723e-06
Epoch: [1177][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0324 (0.0568)	
0.9999926 2.5434354e-06
Epoch: [1177][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0592 (0.0568)	
0.9999883 1.3565367e-06
loss:  0.03948845154238734 0.03858705330121737
===========>   training    <===========
Epoch: [1178][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0417 (0.0417)	
0.99999297 4.0158607e-06
===========>   testing    <===========
Epoch: [1178][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0373 (0.0373)	
0.9999893 2.4632504e-06
Epoch: [1178][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0636 (0.0563)	
0.9999939 2.4603653e-06
Epoch: [1178][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0934 (0.0564)	
0.9999883 1.6178842e-06
loss:  0.04070340273714068 0.03858705330121737
===========>   training    <===========
Epoch: [1179][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0389 (0.0389)	
0.9999914 2.0385114e-06
===========>   testing    <===========
Epoch: [1179][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0379 (0.0379)	
0.9999882 2.044473e-06
Epoch: [1179][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0502 (0.0577)	
0.99999094 2.179728e-06
Epoch: [1179][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.1025 (0.0576)	
0.99998367 1.3340442e-06
loss:  0.04136741365370855 0.03858705330121737
===========>   training    <===========
Epoch: [1180][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0426 (0.0426)	
0.9999939 1.3916637e-06
===========>   testing    <===========
Epoch: [1180][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0391 (0.0391)	
0.9999871 2.4236651e-06
Epoch: [1180][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0490 (0.0591)	
0.9999889 2.4939413e-06
Epoch: [1180][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0861 (0.0591)	
0.9999852 1.9893002e-06
loss:  0.04155890286724773 0.03858705330121737
===========>   training    <===========
Epoch: [1181][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0378 (0.0378)	
0.99999607 2.2697013e-06
===========>   testing    <===========
Epoch: [1181][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0362 (0.0362)	
0.99999046 2.320047e-06
Epoch: [1181][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0499 (0.0593)	
0.9999931 2.5701936e-06
Epoch: [1181][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0912 (0.0594)	
0.99998903 1.805913e-06
loss:  0.04148948151715237 0.03858705330121737
===========>   training    <===========
Epoch: [1182][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0391 (0.0391)	
0.9999896 1.4523163e-06
===========>   testing    <===========
Epoch: [1182][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0355 (0.0355)	
0.9999918 2.362764e-06
Epoch: [1182][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0515 (0.0603)	
0.99999213 2.784124e-06
Epoch: [1182][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.1268 (0.0601)	
0.9999889 1.6227718e-06
loss:  0.04132234001929569 0.03858705330121737
===========>   training    <===========
Epoch: [1183][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0427 (0.0427)	
0.999987 1.7685616e-06
===========>   testing    <===========
Epoch: [1183][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0323 (0.0323)	
0.9999908 2.6089808e-06
Epoch: [1183][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0426 (0.0602)	
0.999987 2.605276e-06
Epoch: [1183][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0963 (0.0589)	
0.999984 2.3153966e-06
loss:  0.040585343130185136 0.03858705330121737
===========>   training    <===========
Epoch: [1184][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0403 (0.0403)	
0.9999931 2.6030484e-06
===========>   testing    <===========
Epoch: [1184][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0344 (0.0344)	
0.99999034 2.65067e-06
Epoch: [1184][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0529 (0.0591)	
0.99999094 2.8112852e-06
Epoch: [1184][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0902 (0.0575)	
0.9999844 1.4574209e-06
loss:  0.04031049683679211 0.03858705330121737
===========>   training    <===========
Epoch: [1185][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0367 (0.0367)	
0.9999969 8.6500035e-07
===========>   testing    <===========
Epoch: [1185][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0377 (0.0377)	
0.9999914 2.5366262e-06
Epoch: [1185][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0416 (0.0597)	
0.99999034 2.7725878e-06
Epoch: [1185][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0918 (0.0595)	
0.9999862 1.5575179e-06
loss:  0.04102967055648321 0.03858705330121737
===========>   training    <===========
Epoch: [1186][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0404 (0.0404)	
0.999985 2.087482e-06
===========>   testing    <===========
Epoch: [1186][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0319 (0.0319)	
0.9999912 2.9518258e-06
Epoch: [1186][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0331 (0.0589)	
0.99998856 2.624718e-06
Epoch: [1186][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0723 (0.0580)	
0.999984 1.4159957e-06
loss:  0.04077332868196748 0.03858705330121737
===========>   training    <===========
Epoch: [1187][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0334 (0.0334)	
0.999992 2.315984e-06
===========>   testing    <===========
Epoch: [1187][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0316 (0.0316)	
0.9999912 2.8200873e-06
Epoch: [1187][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0347 (0.0579)	
0.9999894 2.5683926e-06
Epoch: [1187][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0990 (0.0570)	
0.9999831 2.7163537e-06
loss:  0.039932092466957725 0.03858705330121737
===========>   training    <===========
Epoch: [1188][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0393 (0.0393)	
0.99999106 1.4709541e-06
===========>   testing    <===========
Epoch: [1188][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0318 (0.0318)	
0.9999908 2.621636e-06
Epoch: [1188][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0367 (0.0596)	
0.99999046 2.7537253e-06
Epoch: [1188][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0804 (0.0577)	
0.99998677 2.1613466e-06
loss:  0.039937904511829436 0.03858705330121737
===========>   training    <===========
Epoch: [1189][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0383 (0.0383)	
0.9999895 3.0101603e-06
===========>   testing    <===========
Epoch: [1189][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0289 (0.0289)	
0.9999913 2.5964807e-06
Epoch: [1189][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0622 (0.0580)	
0.99998987 2.8180548e-06
Epoch: [1189][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0606 (0.0567)	
0.9999883 2.270907e-06
loss:  0.039910904490083166 0.03858705330121737
===========>   training    <===========
Epoch: [1190][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0339 (0.0339)	
0.99999535 3.8291855e-06
===========>   testing    <===========
Epoch: [1190][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0329 (0.0329)	
0.99999106 2.5130078e-06
Epoch: [1190][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0601 (0.0592)	
0.9999913 2.9034413e-06
Epoch: [1190][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0606 (0.0579)	
0.99999 1.6409863e-06
loss:  0.040512590221225 0.03858705330121737
===========>   training    <===========
Epoch: [1191][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0334 (0.0334)	
0.99998367 1.4162847e-06
===========>   testing    <===========
Epoch: [1191][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0439 (0.0439)	
0.9999901 2.4845926e-06
Epoch: [1191][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0469 (0.0591)	
0.9999919 3.0074257e-06
Epoch: [1191][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0666 (0.0578)	
0.99998784 1.9066947e-06
loss:  0.04060029233423579 0.03858705330121737
===========>   training    <===========
Epoch: [1192][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0335 (0.0335)	
0.99999297 2.4379033e-06
===========>   testing    <===========
Epoch: [1192][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0327 (0.0327)	
0.99999034 2.5622523e-06
Epoch: [1192][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0370 (0.0585)	
0.99999344 2.864423e-06
Epoch: [1192][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0704 (0.0584)	
0.9999877 1.814576e-06
loss:  0.04050851506086328 0.03858705330121737
===========>   training    <===========
Epoch: [1193][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0409 (0.0409)	
0.9999894 2.7217318e-06
===========>   testing    <===========
Epoch: [1193][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0276 (0.0276)	
0.99998987 2.5405918e-06
Epoch: [1193][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0605 (0.0582)	
0.99999297 2.6962532e-06
Epoch: [1193][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0780 (0.0577)	
0.99998605 2.0807704e-06
loss:  0.040848742229096624 0.03858705330121737
===========>   training    <===========
Epoch: [1194][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0321 (0.0321)	
0.99999607 2.567063e-06
===========>   testing    <===========
Epoch: [1194][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0293 (0.0293)	
0.9999913 2.6379078e-06
Epoch: [1194][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0617 (0.0584)	
0.9999938 3.0504825e-06
Epoch: [1194][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0731 (0.0583)	
0.99999034 1.7614549e-06
loss:  0.04032544789296655 0.03858705330121737
===========>   training    <===========
Epoch: [1195][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0330 (0.0330)	
0.9999883 2.1478388e-06
===========>   testing    <===========
Epoch: [1195][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0365 (0.0365)	
0.99998856 2.553244e-06
Epoch: [1195][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0873 (0.0589)	
0.99999166 2.524988e-06
Epoch: [1195][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0634 (0.0586)	
0.9999852 2.118225e-06
loss:  0.03987069819032252 0.03858705330121737
===========>   training    <===========
Epoch: [1196][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0452 (0.0452)	
0.9999671 1.0994188e-06
===========>   testing    <===========
Epoch: [1196][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0335 (0.0335)	
0.9999887 2.3737698e-06
Epoch: [1196][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0965 (0.0612)	
0.999992 2.5426593e-06
Epoch: [1196][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0461 (0.0586)	
0.9999863 2.2566585e-06
loss:  0.041028871716192405 0.03858705330121737
===========>   training    <===========
Epoch: [1197][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0387 (0.0387)	
0.999992 3.0204721e-06
===========>   testing    <===========
Epoch: [1197][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0278 (0.0278)	
0.9999918 2.3441733e-06
Epoch: [1197][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0646 (0.0585)	
0.99999154 2.5462703e-06
Epoch: [1197][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0703 (0.0569)	
0.9999883 2.5269344e-06
loss:  0.03884117282685462 0.03858705330121737
===========>   training    <===========
Epoch: [1198][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0320 (0.0320)	
0.99999356 4.071165e-06
===========>   testing    <===========
Epoch: [1198][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0285 (0.0285)	
0.99999034 1.8624891e-06
Epoch: [1198][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0750 (0.0580)	
0.99998975 1.9930374e-06
Epoch: [1198][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0908 (0.0566)	
0.99998474 1.5247876e-06
loss:  0.03986859783038865 0.03858705330121737
===========>   training    <===========
Epoch: [1199][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0367 (0.0367)	
0.99998474 2.4110823e-06
===========>   testing    <===========
Epoch: [1199][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0332 (0.0332)	
0.9999906 1.7003616e-06
Epoch: [1199][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0928 (0.0571)	
0.99998784 1.9913787e-06
Epoch: [1199][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0908 (0.0560)	
0.9999819 1.7570592e-06
loss:  0.03943744060571808 0.03858705330121737
===========>   training    <===========
Epoch: [1200][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0362 (0.0362)	
0.99998593 1.3810813e-06
===========>   testing    <===========
Epoch: [1200][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0365 (0.0365)	
0.9999912 1.8843534e-06
Epoch: [1200][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0652 (0.0604)	
0.99998915 2.1010353e-06
Epoch: [1200][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0780 (0.0578)	
0.9999826 1.915085e-06
loss:  0.040425391040190384 0.03858705330121737
===========>   training    <===========
Epoch: [1201][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0403 (0.0403)	
0.99997675 1.2664103e-06
===========>   testing    <===========
Epoch: [1201][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0390 (0.0390)	
0.9999924 2.167808e-06
Epoch: [1201][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0661 (0.0610)	
0.99999213 2.644628e-06
Epoch: [1201][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0541 (0.0584)	
0.99998844 2.2872082e-06
loss:  0.0402822807645522 0.03858705330121737
===========>   training    <===========
Epoch: [1202][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0336 (0.0336)	
0.99999475 2.8212412e-06
===========>   testing    <===========
Epoch: [1202][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0332 (0.0332)	
0.9999895 1.6547056e-06
Epoch: [1202][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.1097 (0.0585)	
0.99998546 1.995329e-06
Epoch: [1202][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0829 (0.0572)	
0.9999819 1.7639328e-06
loss:  0.03977758072980808 0.03858705330121737
===========>   training    <===========
Epoch: [1203][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0358 (0.0358)	
0.9999927 1.4070681e-06
===========>   testing    <===========
Epoch: [1203][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0389 (0.0389)	
0.9999906 1.7410231e-06
Epoch: [1203][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.1243 (0.0603)	
0.9999926 2.0730556e-06
Epoch: [1203][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0577 (0.0589)	
0.99998724 1.9722481e-06
loss:  0.04097156462054952 0.03858705330121737
===========>   training    <===========
Epoch: [1204][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0408 (0.0408)	
0.9999943 7.2762305e-07
===========>   testing    <===========
Epoch: [1204][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0281 (0.0281)	
0.99999 1.63304e-06
Epoch: [1204][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0864 (0.0582)	
0.9999907 1.9544104e-06
Epoch: [1204][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0740 (0.0578)	
0.9999845 1.6988931e-06
loss:  0.040131022257407944 0.03858705330121737
===========>   training    <===========
Epoch: [1205][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0371 (0.0371)	
0.9999893 7.893807e-07
===========>   testing    <===========
Epoch: [1205][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0290 (0.0290)	
0.9999906 1.785488e-06
Epoch: [1205][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.1151 (0.0592)	
0.9999937 2.2890324e-06
Epoch: [1205][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0617 (0.0592)	
0.99999106 2.011082e-06
loss:  0.04090729073692889 0.03858705330121737
===========>   training    <===========
Epoch: [1206][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0323 (0.0323)	
0.99999404 6.4345077e-06
===========>   testing    <===========
Epoch: [1206][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0290 (0.0290)	
0.9999895 1.6933094e-06
Epoch: [1206][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.1248 (0.0597)	
0.9999927 2.0733246e-06
Epoch: [1206][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0727 (0.0588)	
0.99998736 1.6392377e-06
loss:  0.04032956562381296 0.03858705330121737
===========>   training    <===========
Epoch: [1207][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0350 (0.0350)	
0.999992 1.8458709e-06
===========>   testing    <===========
Epoch: [1207][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0307 (0.0307)	
0.9999913 1.7858065e-06
Epoch: [1207][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.1515 (0.0589)	
0.9999938 2.353669e-06
Epoch: [1207][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0818 (0.0589)	
0.9999908 1.9022813e-06
loss:  0.040696751467323766 0.03858705330121737
===========>   training    <===========
Epoch: [1208][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0410 (0.0410)	
0.99998665 1.5136288e-06
===========>   testing    <===========
Epoch: [1208][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0315 (0.0315)	
0.99999154 1.6822306e-06
Epoch: [1208][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0580 (0.0584)	
0.9999927 2.0500531e-06
Epoch: [1208][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0768 (0.0575)	
0.9999882 1.8152284e-06
loss:  0.040457737039928054 0.03858705330121737
===========>   training    <===========
Epoch: [1209][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0377 (0.0377)	
0.99999416 1.1976374e-06
===========>   testing    <===========
Epoch: [1209][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0349 (0.0349)	
0.99999094 1.9722688e-06
Epoch: [1209][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0295 (0.0578)	
0.9999927 2.288395e-06
Epoch: [1209][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0728 (0.0577)	
0.9999877 2.1139667e-06
loss:  0.04045104891991047 0.03858705330121737
===========>   training    <===========
Epoch: [1210][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0369 (0.0369)	
0.9999907 2.12583e-06
===========>   testing    <===========
Epoch: [1210][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0358 (0.0358)	
0.99999 1.7213536e-06
Epoch: [1210][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0314 (0.0597)	
0.99998796 1.8595481e-06
Epoch: [1210][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0831 (0.0593)	
0.9999831 1.7694877e-06
loss:  0.041328484873235594 0.03858705330121737
===========>   training    <===========
Epoch: [1211][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0364 (0.0364)	
0.9999889 3.387503e-06
===========>   testing    <===========
Epoch: [1211][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0348 (0.0348)	
0.99999225 2.3322168e-06
Epoch: [1211][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0379 (0.0587)	
0.9999937 2.7041383e-06
Epoch: [1211][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0667 (0.0592)	
0.999992 2.667272e-06
loss:  0.04043902192909832 0.03858705330121737
===========>   training    <===========
Epoch: [1212][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0400 (0.0400)	
0.9999902 7.57294e-07
===========>   testing    <===========
Epoch: [1212][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0324 (0.0324)	
0.9999901 2.388389e-06
Epoch: [1212][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0502 (0.0578)	
0.99999213 2.566003e-06
Epoch: [1212][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0670 (0.0583)	
0.99998915 2.9499402e-06
loss:  0.04035252553118329 0.03858705330121737
===========>   training    <===========
Epoch: [1213][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0479 (0.0479)	
0.9999875 6.5998336e-07
===========>   testing    <===========
Epoch: [1213][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0437 (0.0437)	
0.9999881 2.3680561e-06
Epoch: [1213][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.1066 (0.0594)	
0.9999888 2.5518177e-06
Epoch: [1213][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0625 (0.0588)	
0.99998903 2.8504464e-06
loss:  0.04122795541909585 0.03858705330121737
===========>   training    <===========
Epoch: [1214][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0413 (0.0413)	
0.99998415 1.285408e-06
===========>   testing    <===========
Epoch: [1214][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0511 (0.0511)	
0.9999906 2.4113262e-06
Epoch: [1214][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0733 (0.0575)	
0.9999876 2.5407348e-06
Epoch: [1214][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0791 (0.0577)	
0.99998784 2.9510375e-06
loss:  0.04082273893515065 0.03858705330121737
===========>   training    <===========
Epoch: [1215][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0291 (0.0291)	
0.9999809 2.1174535e-06
===========>   testing    <===========
Epoch: [1215][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0408 (0.0408)	
0.9999914 2.9507505e-06
Epoch: [1215][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0922 (0.0582)	
0.9999927 2.82677e-06
Epoch: [1215][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0673 (0.0583)	
0.9999914 4.268269e-06
loss:  0.040727749202488006 0.03858705330121737
===========>   training    <===========
Epoch: [1216][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0355 (0.0355)	
0.9999856 2.5396012e-06
===========>   testing    <===========
Epoch: [1216][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0459 (0.0459)	
0.9999906 2.5248e-06
Epoch: [1216][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0643 (0.0575)	
0.9999925 2.5160869e-06
Epoch: [1216][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0809 (0.0571)	
0.99999154 3.176177e-06
loss:  0.04032588593534325 0.03858705330121737
===========>   training    <===========
Epoch: [1217][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0340 (0.0340)	
0.9999902 1.102123e-06
===========>   testing    <===========
Epoch: [1217][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0442 (0.0442)	
0.9999875 1.9292108e-06
Epoch: [1217][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0958 (0.0592)	
0.99998605 2.0731504e-06
Epoch: [1217][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0683 (0.0573)	
0.99998856 2.1121168e-06
loss:  0.04160061770141921 0.03858705330121737
===========>   training    <===========
Epoch: [1218][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0356 (0.0356)	
0.9999856 1.8663776e-06
===========>   testing    <===========
Epoch: [1218][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0340 (0.0340)	
0.99998856 1.9340482e-06
Epoch: [1218][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0585 (0.0581)	
0.99999297 2.2325596e-06
Epoch: [1218][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0760 (0.0575)	
0.99999106 2.1653782e-06
loss:  0.04029124275351481 0.03858705330121737
===========>   training    <===========
Epoch: [1219][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0360 (0.0360)	
0.99998975 8.363252e-07
===========>   testing    <===========
Epoch: [1219][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0381 (0.0381)	
0.9999864 1.867282e-06
Epoch: [1219][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0694 (0.0583)	
0.99999 2.1578085e-06
Epoch: [1219][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0575 (0.0575)	
0.99998844 1.7472605e-06
loss:  0.04036780068903123 0.03858705330121737
===========>   training    <===========
Epoch: [1220][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0354 (0.0354)	
0.999995 2.5263753e-06
===========>   testing    <===========
Epoch: [1220][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0466 (0.0466)	
0.99998593 1.6954747e-06
Epoch: [1220][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0676 (0.0594)	
0.99998903 1.508067e-06
Epoch: [1220][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0609 (0.0580)	
0.99998665 1.7047e-06
loss:  0.04147167820491959 0.03858705330121737
===========>   training    <===========
Epoch: [1221][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0353 (0.0353)	
0.9999881 1.276136e-06
===========>   testing    <===========
Epoch: [1221][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0328 (0.0328)	
0.9999888 2.157681e-06
Epoch: [1221][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.1860 (0.0600)	
0.99999166 2.3964064e-06
Epoch: [1221][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0686 (0.0573)	
0.99999046 2.1740314e-06
loss:  0.040657602462065845 0.03858705330121737
===========>   training    <===========
Epoch: [1222][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0377 (0.0377)	
0.99999416 1.8997015e-06
===========>   testing    <===========
Epoch: [1222][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0293 (0.0293)	
0.99998724 2.299491e-06
Epoch: [1222][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0472 (0.0571)	
0.999987 2.464275e-06
Epoch: [1222][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.1031 (0.0563)	
0.9999883 1.7119924e-06
loss:  0.03936054369291264 0.03858705330121737
===========>   training    <===========
Epoch: [1223][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0371 (0.0371)	
0.99999607 4.3471437e-06
===========>   testing    <===========
Epoch: [1223][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0328 (0.0328)	
0.99999166 2.5978975e-06
Epoch: [1223][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0923 (0.0597)	
0.9999938 3.0085416e-06
Epoch: [1223][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0641 (0.0571)	
0.9999939 2.5551587e-06
loss:  0.040162923446940724 0.03858705330121737
===========>   training    <===========
Epoch: [1224][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0416 (0.0416)	
0.9999962 1.4652306e-06
===========>   testing    <===========
Epoch: [1224][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0397 (0.0397)	
0.9999906 2.4295618e-06
Epoch: [1224][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0658 (0.0566)	
0.99999166 2.737225e-06
Epoch: [1224][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0685 (0.0555)	
0.9999902 1.3150075e-06
loss:  0.0390908035802352 0.03858705330121737
===========>   training    <===========
Epoch: [1225][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0362 (0.0362)	
0.99998045 2.3595508e-06
===========>   testing    <===========
Epoch: [1225][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0370 (0.0370)	
0.9999857 2.5567579e-06
Epoch: [1225][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0443 (0.0563)	
0.99999106 2.4417286e-06
Epoch: [1225][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0731 (0.0555)	
0.99998736 1.7444801e-06
loss:  0.03900023154002197 0.03858705330121737
===========>   training    <===========
Epoch: [1226][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0353 (0.0353)	
0.99999154 2.8398156e-06
===========>   testing    <===========
Epoch: [1226][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0457 (0.0457)	
0.9999912 2.5509905e-06
Epoch: [1226][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.1145 (0.0595)	
0.99999285 3.0184794e-06
Epoch: [1226][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0662 (0.0576)	
0.9999908 1.9286497e-06
loss:  0.04069080556942095 0.03858705330121737
===========>   training    <===========
Epoch: [1227][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0398 (0.0398)	
0.9999933 4.303748e-06
===========>   testing    <===========
Epoch: [1227][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0425 (0.0425)	
0.99999034 2.4019894e-06
Epoch: [1227][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0553 (0.0576)	
0.9999881 2.580199e-06
Epoch: [1227][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0728 (0.0565)	
0.9999865 2.7117258e-06
loss:  0.03977608359476714 0.03858705330121737
===========>   training    <===========
Epoch: [1228][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0352 (0.0352)	
0.99998915 1.9920662e-06
===========>   testing    <===========
Epoch: [1228][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0393 (0.0393)	
0.9999901 2.7111748e-06
Epoch: [1228][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0499 (0.0588)	
0.9999894 2.9876405e-06
Epoch: [1228][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0757 (0.0570)	
0.99998677 3.4673026e-06
loss:  0.039396771869342984 0.03858705330121737
===========>   training    <===========
Epoch: [1229][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0360 (0.0360)	
0.9999956 4.472565e-06
===========>   testing    <===========
Epoch: [1229][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0313 (0.0313)	
0.9999912 2.39184e-06
Epoch: [1229][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0796 (0.0585)	
0.999992 3.2491203e-06
Epoch: [1229][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0882 (0.0570)	
0.9999902 2.937924e-06
loss:  0.03903607746881366 0.03858705330121737
===========>   training    <===========
Epoch: [1230][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0407 (0.0407)	
0.9999926 1.781853e-06
===========>   testing    <===========
Epoch: [1230][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0406 (0.0406)	
0.9999902 2.0227674e-06
Epoch: [1230][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0754 (0.0591)	
0.99998903 2.3235632e-06
Epoch: [1230][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0871 (0.0573)	
0.9999869 1.6685553e-06
loss:  0.04001236233551253 0.03858705330121737
===========>   training    <===========
Epoch: [1231][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0348 (0.0348)	
0.9999949 2.805061e-06
===========>   testing    <===========
Epoch: [1231][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0393 (0.0393)	
0.9999896 2.4785202e-06
Epoch: [1231][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0689 (0.0617)	
0.99999046 2.8044085e-06
Epoch: [1231][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0796 (0.0594)	
0.9999852 2.7530505e-06
loss:  0.0408803716659808 0.03858705330121737
===========>   training    <===========
Epoch: [1232][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0359 (0.0359)	
0.99998295 1.3421526e-06
===========>   testing    <===========
Epoch: [1232][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0392 (0.0392)	
0.99999 2.3487203e-06
Epoch: [1232][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0716 (0.0600)	
0.99999344 2.8409859e-06
Epoch: [1232][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0681 (0.0573)	
0.9999914 2.1421274e-06
loss:  0.04077023782407352 0.03858705330121737
===========>   training    <===========
Epoch: [1233][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0328 (0.0328)	
0.9999943 3.025526e-06
===========>   testing    <===========
Epoch: [1233][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0368 (0.0368)	
0.9999901 2.2706213e-06
Epoch: [1233][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0412 (0.0580)	
0.9999919 2.4911078e-06
Epoch: [1233][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0727 (0.0564)	
0.99999 1.3973316e-06
loss:  0.03969753003363985 0.03858705330121737
===========>   training    <===========
Epoch: [1234][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0322 (0.0322)	
0.9999925 1.4432959e-06
===========>   testing    <===========
Epoch: [1234][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0429 (0.0429)	
0.99998987 2.1205615e-06
Epoch: [1234][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0474 (0.0582)	
0.9999901 2.506789e-06
Epoch: [1234][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0803 (0.0572)	
0.9999888 1.206972e-06
loss:  0.04017511251175987 0.03858705330121737
===========>   training    <===========
Epoch: [1235][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0346 (0.0346)	
0.9999951 6.3203406e-06
===========>   testing    <===========
Epoch: [1235][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0297 (0.0297)	
0.99999034 2.3710231e-06
Epoch: [1235][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0249 (0.0580)	
0.9999913 2.9633138e-06
Epoch: [1235][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0856 (0.0572)	
0.9999914 2.043132e-06
loss:  0.04004387158750666 0.03858705330121737
===========>   training    <===========
Epoch: [1236][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0339 (0.0339)	
0.9999925 1.9568448e-07
===========>   testing    <===========
Epoch: [1236][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0356 (0.0356)	
0.9999893 2.043937e-06
Epoch: [1236][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0217 (0.0600)	
0.9999906 2.1982237e-06
Epoch: [1236][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0705 (0.0585)	
0.9999876 1.4445051e-06
loss:  0.040530169696854745 0.03858705330121737
===========>   training    <===========
Epoch: [1237][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0345 (0.0345)	
0.9999882 1.5047198e-06
===========>   testing    <===========
Epoch: [1237][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0356 (0.0356)	
0.9999906 2.3553398e-06
Epoch: [1237][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0224 (0.0605)	
0.9999913 2.5181419e-06
Epoch: [1237][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0651 (0.0588)	
0.99998975 2.414023e-06
loss:  0.040230937756572716 0.03858705330121737
===========>   training    <===========
Epoch: [1238][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0285 (0.0285)	
0.9999918 2.5940228e-06
===========>   testing    <===========
Epoch: [1238][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0336 (0.0336)	
0.9999901 2.4272206e-06
Epoch: [1238][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0240 (0.0602)	
0.9999896 2.6830025e-06
Epoch: [1238][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0822 (0.0583)	
0.99998856 2.0428338e-06
loss:  0.040337714470159325 0.03858705330121737
===========>   training    <===========
Epoch: [1239][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0444 (0.0444)	
0.9999912 1.2386986e-06
===========>   testing    <===========
Epoch: [1239][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0283 (0.0283)	
0.9999883 2.1968574e-06
Epoch: [1239][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0305 (0.0592)	
0.9999893 2.513468e-06
Epoch: [1239][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0811 (0.0575)	
0.99998784 2.0967057e-06
loss:  0.040136848954519966 0.03858705330121737
===========>   training    <===========
Epoch: [1240][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0352 (0.0352)	
0.9999906 1.2431044e-06
===========>   testing    <===========
Epoch: [1240][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0306 (0.0306)	
0.9999906 2.1300998e-06
Epoch: [1240][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0497 (0.0590)	
0.99999094 2.443075e-06
Epoch: [1240][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0900 (0.0573)	
0.9999895 2.2633828e-06
loss:  0.040065890379810454 0.03858705330121737
===========>   training    <===========
Epoch: [1241][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0392 (0.0392)	
0.9999925 4.0603322e-06
===========>   testing    <===========
Epoch: [1241][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0301 (0.0301)	
0.99999285 2.5424267e-06
Epoch: [1241][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0324 (0.0597)	
0.9999914 2.9751134e-06
Epoch: [1241][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0819 (0.0575)	
0.9999912 2.3789187e-06
loss:  0.03952343706886274 0.03858705330121737
===========>   training    <===========
Epoch: [1242][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0365 (0.0365)	
0.9999908 2.4812705e-06
===========>   testing    <===========
Epoch: [1242][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0294 (0.0294)	
0.9999907 2.264415e-06
Epoch: [1242][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0265 (0.0579)	
0.99999106 2.7311441e-06
Epoch: [1242][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1138 (0.0570)	
0.9999896 2.330016e-06
loss:  0.03972108485934267 0.03858705330121737
===========>   training    <===========
Epoch: [1243][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0396 (0.0396)	
0.99999404 1.6352561e-06
===========>   testing    <===========
Epoch: [1243][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0315 (0.0315)	
0.9999901 2.2021686e-06
Epoch: [1243][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0181 (0.0585)	
0.99998903 2.4646745e-06
Epoch: [1243][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0816 (0.0577)	
0.99998593 2.2793236e-06
loss:  0.04007332174645284 0.03858705330121737
===========>   training    <===========
Epoch: [1244][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0416 (0.0416)	
0.9999838 4.5049533e-06
===========>   testing    <===========
Epoch: [1244][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0314 (0.0314)	
0.99999213 2.4300903e-06
Epoch: [1244][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0250 (0.0580)	
0.9999932 2.7090066e-06
Epoch: [1244][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1131 (0.0581)	
0.99999094 2.0345494e-06
loss:  0.04041616420664651 0.03858705330121737
===========>   training    <===========
Epoch: [1245][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0325 (0.0325)	
0.99998593 2.8545815e-06
===========>   testing    <===========
Epoch: [1245][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0282 (0.0282)	
0.9999901 2.4086326e-06
Epoch: [1245][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0258 (0.0579)	
0.9999913 2.6435766e-06
Epoch: [1245][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0693 (0.0571)	
0.9999896 1.4910663e-06
loss:  0.040372339735312734 0.03858705330121737
===========>   training    <===========
Epoch: [1246][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0360 (0.0360)	
0.99998534 2.352262e-06
===========>   testing    <===========
Epoch: [1246][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0310 (0.0310)	
0.99998987 2.5654085e-06
Epoch: [1246][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0357 (0.0567)	
0.9999907 2.7948531e-06
Epoch: [1246][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0714 (0.0573)	
0.9999906 2.2073366e-06
loss:  0.04062658140736963 0.03858705330121737
===========>   training    <===========
Epoch: [1247][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0416 (0.0416)	
0.99999094 4.764676e-06
===========>   testing    <===========
Epoch: [1247][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0302 (0.0302)	
0.99998987 2.2511344e-06
Epoch: [1247][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0303 (0.0573)	
0.9999902 2.588164e-06
Epoch: [1247][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0726 (0.0577)	
0.99998844 1.7362229e-06
loss:  0.039879112443124254 0.03858705330121737
===========>   training    <===========
Epoch: [1248][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0321 (0.0321)	
0.99998975 2.2313504e-06
===========>   testing    <===========
Epoch: [1248][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0285 (0.0285)	
0.9999924 2.4421106e-06
Epoch: [1248][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0325 (0.0573)	
0.9999931 2.6574764e-06
Epoch: [1248][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0861 (0.0581)	
0.9999908 1.7947651e-06
loss:  0.04036574191859621 0.03858705330121737
===========>   training    <===========
Epoch: [1249][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0326 (0.0326)	
0.9999901 2.4870178e-06
===========>   testing    <===========
Epoch: [1249][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0316 (0.0316)	
0.99998987 2.5028858e-06
Epoch: [1249][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0729 (0.0596)	
0.999992 2.673379e-06
Epoch: [1249][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1056 (0.0595)	
0.9999896 2.9478983e-06
loss:  0.04095139757225752 0.03858705330121737
===========>   training    <===========
Epoch: [1250][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0408 (0.0408)	
0.99999154 3.4591444e-06
===========>   testing    <===========
Epoch: [1250][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0349 (0.0349)	
0.9999907 2.7704018e-06
Epoch: [1250][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0432 (0.0596)	
0.99999213 3.1664715e-06
Epoch: [1250][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0945 (0.0586)	
0.99999 3.175168e-06
loss:  0.040502214558981287 0.03858705330121737
===========>   training    <===========
Epoch: [1251][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0360 (0.0360)	
0.99998844 7.3483407e-06
===========>   testing    <===========
Epoch: [1251][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0379 (0.0379)	
0.9999906 2.4341443e-06
Epoch: [1251][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0298 (0.0583)	
0.9999895 2.9454648e-06
Epoch: [1251][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0902 (0.0583)	
0.9999894 2.763138e-06
loss:  0.04054786623720852 0.03858705330121737
===========>   training    <===========
Epoch: [1252][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0315 (0.0315)	
0.9999865 1.4957634e-06
===========>   testing    <===========
Epoch: [1252][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0303 (0.0303)	
0.9999901 2.6130995e-06
Epoch: [1252][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0225 (0.0571)	
0.9999906 3.0915282e-06
Epoch: [1252][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0742 (0.0577)	
0.99998975 3.0056221e-06
loss:  0.03981383858066356 0.03858705330121737
===========>   training    <===========
Epoch: [1253][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0340 (0.0340)	
0.9999975 5.1066813e-06
===========>   testing    <===========
Epoch: [1253][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0300 (0.0300)	
0.9999908 2.25107e-06
Epoch: [1253][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0247 (0.0570)	
0.9999894 2.546066e-06
Epoch: [1253][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0658 (0.0576)	
0.99998796 1.8153306e-06
loss:  0.04021169203544395 0.03858705330121737
===========>   training    <===========
Epoch: [1254][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0404 (0.0404)	
0.9999949 2.3914502e-06
===========>   testing    <===========
Epoch: [1254][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0432 (0.0432)	
0.99999034 2.7583355e-06
Epoch: [1254][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0253 (0.0585)	
0.9999896 3.0747713e-06
Epoch: [1254][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0808 (0.0582)	
0.9999881 3.0454448e-06
loss:  0.04037148292678827 0.03858705330121737
===========>   training    <===========
Epoch: [1255][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0298 (0.0298)	
0.99999344 1.323708e-06
===========>   testing    <===========
Epoch: [1255][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0366 (0.0366)	
0.9999901 2.6428734e-06
Epoch: [1255][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0237 (0.0595)	
0.9999889 2.8085221e-06
Epoch: [1255][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0843 (0.0589)	
0.999987 2.9824112e-06
loss:  0.040048144330484425 0.03858705330121737
===========>   training    <===========
Epoch: [1256][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0341 (0.0341)	
0.999984 2.437694e-06
===========>   testing    <===========
Epoch: [1256][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0344 (0.0344)	
0.9999927 2.8022375e-06
Epoch: [1256][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0280 (0.0588)	
0.9999918 3.139976e-06
Epoch: [1256][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0808 (0.0591)	
0.9999889 3.208616e-06
loss:  0.040689760574424416 0.03858705330121737
===========>   training    <===========
Epoch: [1257][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0361 (0.0361)	
0.99999225 2.2516367e-06
===========>   testing    <===========
Epoch: [1257][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0302 (0.0302)	
0.99999285 2.7818842e-06
Epoch: [1257][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0355 (0.0581)	
0.99999285 3.2781654e-06
Epoch: [1257][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0968 (0.0584)	
0.99998987 2.927196e-06
loss:  0.040410323435127626 0.03858705330121737
===========>   training    <===========
Epoch: [1258][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0403 (0.0403)	
0.99999607 8.199318e-07
===========>   testing    <===========
Epoch: [1258][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0304 (0.0304)	
0.9999889 2.3278549e-06
Epoch: [1258][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0340 (0.0592)	
0.9999875 2.2625497e-06
Epoch: [1258][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0670 (0.0582)	
0.9999851 1.695714e-06
loss:  0.04064860176143359 0.03858705330121737
===========>   training    <===========
Epoch: [1259][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0382 (0.0382)	
0.9999783 1.9067239e-06
===========>   testing    <===========
Epoch: [1259][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0310 (0.0310)	
0.99999297 2.7298838e-06
Epoch: [1259][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0227 (0.0590)	
0.9999918 3.020109e-06
Epoch: [1259][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1018 (0.0589)	
0.9999902 2.3424122e-06
loss:  0.0401017859863213 0.03858705330121737
===========>   training    <===========
Epoch: [1260][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0401 (0.0401)	
0.99998295 2.252528e-06
===========>   testing    <===========
Epoch: [1260][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0343 (0.0343)	
0.9999895 2.1875478e-06
Epoch: [1260][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0332 (0.0575)	
0.9999881 2.3710775e-06
Epoch: [1260][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0703 (0.0571)	
0.99998593 2.3852388e-06
loss:  0.03984687095039552 0.03858705330121737
===========>   training    <===========
Epoch: [1261][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0362 (0.0362)	
0.99998367 1.7995967e-06
===========>   testing    <===========
Epoch: [1261][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0296 (0.0296)	
0.99999 2.0006814e-06
Epoch: [1261][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0284 (0.0576)	
0.99999225 2.4540075e-06
Epoch: [1261][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0906 (0.0580)	
0.99998784 1.8316442e-06
loss:  0.04072021137373938 0.03858705330121737
===========>   training    <===========
Epoch: [1262][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0401 (0.0401)	
0.99999297 5.530006e-06
===========>   testing    <===========
Epoch: [1262][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0288 (0.0288)	
0.9999907 2.0209663e-06
Epoch: [1262][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0267 (0.0578)	
0.9999931 2.5378554e-06
Epoch: [1262][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0942 (0.0585)	
0.9999908 1.186243e-06
loss:  0.04011163691346342 0.03858705330121737
===========>   training    <===========
Epoch: [1263][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0397 (0.0397)	
0.9999945 1.8823688e-06
===========>   testing    <===========
Epoch: [1263][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0286 (0.0286)	
0.9999902 1.9581307e-06
Epoch: [1263][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0269 (0.0584)	
0.9999896 2.0104205e-06
Epoch: [1263][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0836 (0.0590)	
0.99998677 1.4909696e-06
loss:  0.04065041583110163 0.03858705330121737
===========>   training    <===========
Epoch: [1264][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0350 (0.0350)	
0.99998534 2.9129546e-06
===========>   testing    <===========
Epoch: [1264][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0336 (0.0336)	
0.9999902 2.2345619e-06
Epoch: [1264][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0314 (0.0585)	
0.99998915 2.461616e-06
Epoch: [1264][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0768 (0.0586)	
0.99998844 1.3521156e-06
loss:  0.03978757426448243 0.03858705330121737
===========>   training    <===========
Epoch: [1265][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0454 (0.0454)	
0.9999945 1.880831e-06
===========>   testing    <===========
Epoch: [1265][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0316 (0.0316)	
0.9999908 2.6701048e-06
Epoch: [1265][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0292 (0.0579)	
0.9999932 3.1035422e-06
Epoch: [1265][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0761 (0.0586)	
0.9999896 2.5873173e-06
loss:  0.04042929845401566 0.03858705330121737
===========>   training    <===========
Epoch: [1266][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0404 (0.0404)	
0.9999926 3.0249173e-06
===========>   testing    <===========
Epoch: [1266][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0343 (0.0343)	
0.9999889 2.4100525e-06
Epoch: [1266][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0420 (0.0589)	
0.99999154 2.8627765e-06
Epoch: [1266][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0558 (0.0582)	
0.9999862 2.3686187e-06
loss:  0.04027767151412176 0.03858705330121737
===========>   training    <===========
Epoch: [1267][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0341 (0.0341)	
0.9999951 1.3212172e-06
===========>   testing    <===========
Epoch: [1267][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0329 (0.0329)	
0.9999912 2.66382e-06
Epoch: [1267][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0550 (0.0600)	
0.9999933 3.1696861e-06
Epoch: [1267][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0656 (0.0598)	
0.99998915 2.486859e-06
loss:  0.04138233959632864 0.03858705330121737
===========>   training    <===========
Epoch: [1268][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0363 (0.0363)	
0.99999416 2.5171933e-06
===========>   testing    <===========
Epoch: [1268][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0316 (0.0316)	
0.9999914 2.604496e-06
Epoch: [1268][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0668 (0.0595)	
0.99999523 2.896185e-06
Epoch: [1268][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0669 (0.0593)	
0.9999913 2.4965782e-06
loss:  0.04057389328666694 0.03858705330121737
===========>   training    <===========
Epoch: [1269][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0390 (0.0390)	
0.99999285 2.511618e-06
===========>   testing    <===========
Epoch: [1269][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0348 (0.0348)	
0.99998975 2.2723195e-06
Epoch: [1269][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.1019 (0.0603)	
0.9999945 2.6331397e-06
Epoch: [1269][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0779 (0.0594)	
0.99999166 2.323191e-06
loss:  0.04077161400006535 0.03858705330121737
===========>   training    <===========
Epoch: [1270][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0293 (0.0293)	
0.9999856 1.9650372e-06
===========>   testing    <===========
Epoch: [1270][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0300 (0.0300)	
0.9999896 2.2561442e-06
Epoch: [1270][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0565 (0.0591)	
0.99999297 2.6855369e-06
Epoch: [1270][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.1040 (0.0588)	
0.99999034 2.6147795e-06
loss:  0.040772762488864855 0.03858705330121737
===========>   training    <===========
Epoch: [1271][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0395 (0.0395)	
0.99998975 1.6541408e-06
===========>   testing    <===========
Epoch: [1271][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0290 (0.0290)	
0.99999094 2.117522e-06
Epoch: [1271][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0426 (0.0604)	
0.99999285 2.4417589e-06
Epoch: [1271][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0911 (0.0589)	
0.99998796 2.450752e-06
loss:  0.040483487969411924 0.03858705330121737
===========>   training    <===========
Epoch: [1272][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0319 (0.0319)	
0.9999894 1.6480611e-06
===========>   testing    <===========
Epoch: [1272][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0285 (0.0285)	
0.999992 2.3218731e-06
Epoch: [1272][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0341 (0.0586)	
0.9999943 2.8941197e-06
Epoch: [1272][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0807 (0.0581)	
0.99999046 2.824221e-06
loss:  0.039912433419182713 0.03858705330121737
===========>   training    <===========
Epoch: [1273][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0315 (0.0315)	
0.99999166 1.6273126e-06
===========>   testing    <===========
Epoch: [1273][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0353 (0.0353)	
0.99999154 3.040535e-06
Epoch: [1273][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0291 (0.0592)	
0.9999944 3.0581257e-06
Epoch: [1273][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.1033 (0.0580)	
0.99999046 3.4199986e-06
loss:  0.040815847076080325 0.03858705330121737
===========>   training    <===========
Epoch: [1274][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0315 (0.0315)	
0.99998116 8.954457e-07
===========>   testing    <===========
Epoch: [1274][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0303 (0.0303)	
0.99999213 2.2513618e-06
Epoch: [1274][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0291 (0.0593)	
0.9999945 2.106141e-06
Epoch: [1274][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.1049 (0.0580)	
0.99998784 2.1175665e-06
loss:  0.04038178181384289 0.03858705330121737
===========>   training    <===========
Epoch: [1275][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0309 (0.0309)	
0.9999882 1.0140614e-06
===========>   testing    <===========
Epoch: [1275][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0352 (0.0352)	
0.99999225 2.5436489e-06
Epoch: [1275][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0341 (0.0579)	
0.99999535 3.0766837e-06
Epoch: [1275][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.1161 (0.0571)	
0.99999213 2.4599124e-06
loss:  0.039952433562351564 0.03858705330121737
===========>   training    <===========
Epoch: [1276][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0371 (0.0371)	
0.9999821 9.4001336e-07
===========>   testing    <===========
Epoch: [1276][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0335 (0.0335)	
0.9999912 2.3510734e-06
Epoch: [1276][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0287 (0.0576)	
0.9999951 2.4669814e-06
Epoch: [1276][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0858 (0.0571)	
0.9999877 2.208579e-06
loss:  0.04021763908697629 0.03858705330121737
===========>   training    <===========
Epoch: [1277][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0324 (0.0324)	
0.9999944 2.9436787e-06
===========>   testing    <===========
Epoch: [1277][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0317 (0.0317)	
0.99998987 2.7241883e-06
Epoch: [1277][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0281 (0.0570)	
0.999995 3.3678311e-06
Epoch: [1277][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0811 (0.0572)	
0.9999893 3.1732852e-06
loss:  0.04048979791807161 0.03858705330121737
===========>   training    <===========
Epoch: [1278][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0444 (0.0444)	
0.99998975 2.556119e-06
===========>   testing    <===========
Epoch: [1278][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0390 (0.0390)	
0.99998987 2.4765661e-06
Epoch: [1278][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0349 (0.0565)	
0.9999943 2.8278703e-06
Epoch: [1278][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0899 (0.0566)	
0.9999896 2.7036742e-06
loss:  0.04022361200544722 0.03858705330121737
===========>   training    <===========
Epoch: [1279][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0338 (0.0338)	
0.9999964 9.466739e-06
===========>   testing    <===========
Epoch: [1279][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0404 (0.0404)	
0.99998987 2.4774895e-06
Epoch: [1279][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0371 (0.0572)	
0.99999416 2.8997254e-06
Epoch: [1279][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0900 (0.0575)	
0.99998987 2.8143647e-06
loss:  0.040205255548210195 0.03858705330121737
===========>   training    <===========
Epoch: [1280][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0365 (0.0365)	
0.9999809 8.5682944e-07
===========>   testing    <===========
Epoch: [1280][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0406 (0.0406)	
0.9999883 2.1592966e-06
Epoch: [1280][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0346 (0.0575)	
0.9999937 2.6430246e-06
Epoch: [1280][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.1025 (0.0572)	
0.99998736 2.3262858e-06
loss:  0.04022941952514569 0.03858705330121737
===========>   training    <===========
Epoch: [1281][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0305 (0.0305)	
0.9999912 1.7487474e-06
===========>   testing    <===========
Epoch: [1281][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0402 (0.0402)	
0.9999908 2.3261462e-06
Epoch: [1281][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0510 (0.0597)	
0.99999523 3.061718e-06
Epoch: [1281][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0931 (0.0578)	
0.99999166 2.643758e-06
loss:  0.040136485516921505 0.03858705330121737
===========>   training    <===========
Epoch: [1282][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0397 (0.0397)	
0.99998415 1.0403172e-06
===========>   testing    <===========
Epoch: [1282][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0350 (0.0350)	
0.9999887 2.2721592e-06
Epoch: [1282][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0492 (0.0597)	
0.9999937 2.787575e-06
Epoch: [1282][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0976 (0.0583)	
0.99998903 2.5809127e-06
loss:  0.03989454016133942 0.03858705330121737
===========>   training    <===========
Epoch: [1283][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0345 (0.0345)	
0.99998724 1.9747417e-06
===========>   testing    <===========
Epoch: [1283][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0363 (0.0363)	
0.9999881 2.2899844e-06
Epoch: [1283][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0485 (0.0594)	
0.9999932 3.0111823e-06
Epoch: [1283][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.1174 (0.0585)	
0.9999875 2.572013e-06
loss:  0.04011390987927255 0.03858705330121737
===========>   training    <===========
Epoch: [1284][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0426 (0.0426)	
0.9999895 7.917292e-07
===========>   testing    <===========
Epoch: [1284][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0314 (0.0314)	
0.9999908 2.0510424e-06
Epoch: [1284][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0337 (0.0576)	
0.9999927 2.656002e-06
Epoch: [1284][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0986 (0.0576)	
0.9999871 2.3232974e-06
loss:  0.03965453361375326 0.03858705330121737
===========>   training    <===========
Epoch: [1285][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0413 (0.0413)	
0.9999832 5.082256e-07
===========>   testing    <===========
Epoch: [1285][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0312 (0.0312)	
0.9999931 2.434581e-06
Epoch: [1285][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0420 (0.0575)	
0.9999957 3.3836768e-06
Epoch: [1285][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.1179 (0.0578)	
0.9999913 2.757841e-06
loss:  0.039461600607692104 0.03858705330121737
===========>   training    <===========
Epoch: [1286][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0311 (0.0311)	
0.99999475 1.4674039e-06
===========>   testing    <===========
Epoch: [1286][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0351 (0.0351)	
0.9999919 2.1847727e-06
Epoch: [1286][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0445 (0.0567)	
0.9999945 2.5744694e-06
Epoch: [1286][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.1381 (0.0577)	
0.9999893 1.9990164e-06
loss:  0.03976216114237652 0.03858705330121737
===========>   training    <===========
Epoch: [1287][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0399 (0.0399)	
0.9999833 3.0079677e-06
===========>   testing    <===========
Epoch: [1287][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0333 (0.0333)	
0.9999913 2.3274708e-06
Epoch: [1287][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0657 (0.0571)	
0.99999464 2.7710362e-06
Epoch: [1287][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.1071 (0.0574)	
0.99998903 2.0485597e-06
loss:  0.03997693639572686 0.03858705330121737
===========>   training    <===========
Epoch: [1288][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0416 (0.0416)	
0.9999939 2.651922e-06
===========>   testing    <===========
Epoch: [1288][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0388 (0.0388)	
0.9999901 2.3374225e-06
Epoch: [1288][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0663 (0.0580)	
0.99999297 2.9988137e-06
Epoch: [1288][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.1077 (0.0577)	
0.99998593 2.7590643e-06
loss:  0.040248401821399216 0.03858705330121737
===========>   training    <===========
Epoch: [1289][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0337 (0.0337)	
0.9999918 1.1445475e-06
===========>   testing    <===========
Epoch: [1289][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0368 (0.0368)	
0.9999894 2.485735e-06
Epoch: [1289][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0610 (0.0599)	
0.9999926 2.9113298e-06
Epoch: [1289][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.1142 (0.0587)	
0.9999871 2.9254431e-06
loss:  0.03962147362226809 0.03858705330121737
===========>   training    <===========
Epoch: [1290][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0405 (0.0405)	
0.99999213 1.701536e-06
===========>   testing    <===========
Epoch: [1290][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0403 (0.0403)	
0.99999166 2.5095205e-06
Epoch: [1290][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0534 (0.0601)	
0.9999944 3.0380422e-06
Epoch: [1290][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0960 (0.0585)	
0.9999894 2.7869612e-06
loss:  0.040036235062516856 0.03858705330121737
===========>   training    <===========
Epoch: [1291][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0344 (0.0344)	
0.99999356 2.6439625e-06
===========>   testing    <===========
Epoch: [1291][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0370 (0.0370)	
0.9999894 2.2167749e-06
Epoch: [1291][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0402 (0.0601)	
0.9999924 2.621241e-06
Epoch: [1291][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.1254 (0.0601)	
0.9999851 1.8666393e-06
loss:  0.04064321232102153 0.03858705330121737
===========>   training    <===========
Epoch: [1292][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0336 (0.0336)	
0.99999106 5.361124e-06
===========>   testing    <===========
Epoch: [1292][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0385 (0.0385)	
0.9999896 2.3298649e-06
Epoch: [1292][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0572 (0.0586)	
0.99999 2.7700821e-06
Epoch: [1292][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.1293 (0.0586)	
0.999984 3.0143196e-06
loss:  0.03993478709869569 0.03858705330121737
===========>   training    <===========
Epoch: [1293][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0330 (0.0330)	
0.99998844 1.9486058e-06
===========>   testing    <===========
Epoch: [1293][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0418 (0.0418)	
0.99998903 2.4291194e-06
Epoch: [1293][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0380 (0.0586)	
0.99998975 2.911638e-06
Epoch: [1293][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.1131 (0.0587)	
0.9999832 2.5203497e-06
loss:  0.040882293109228196 0.03858705330121737
===========>   training    <===========
Epoch: [1294][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0391 (0.0391)	
0.9999856 1.6606418e-06
===========>   testing    <===========
Epoch: [1294][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0375 (0.0375)	
0.9999901 2.0971017e-06
Epoch: [1294][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0352 (0.0596)	
0.9999902 2.4875992e-06
Epoch: [1294][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0764 (0.0585)	
0.9999845 1.8627235e-06
loss:  0.04038318983596678 0.03858705330121737
===========>   training    <===========
Epoch: [1295][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0406 (0.0406)	
0.99999607 3.2180174e-06
===========>   testing    <===========
Epoch: [1295][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0342 (0.0342)	
0.99999 2.4429492e-06
Epoch: [1295][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0281 (0.0596)	
0.9999908 2.9635712e-06
Epoch: [1295][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.1064 (0.0587)	
0.9999856 2.9350088e-06
loss:  0.04038380165840305 0.03858705330121737
===========>   training    <===========
Epoch: [1296][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0371 (0.0371)	
0.99999225 7.6413374e-07
===========>   testing    <===========
Epoch: [1296][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0349 (0.0349)	
0.99999034 2.0829225e-06
Epoch: [1296][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0321 (0.0594)	
0.9999907 2.4511587e-06
Epoch: [1296][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0876 (0.0583)	
0.9999858 1.5411879e-06
loss:  0.04015368713489653 0.03858705330121737
===========>   training    <===========
Epoch: [1297][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0355 (0.0355)	
0.99998677 1.5131164e-06
===========>   testing    <===========
Epoch: [1297][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0365 (0.0365)	
0.9999882 2.0540258e-06
Epoch: [1297][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0350 (0.0592)	
0.9999906 2.6715006e-06
Epoch: [1297][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.1295 (0.0584)	
0.99998915 1.8158155e-06
loss:  0.040810373518986864 0.03858705330121737
===========>   training    <===========
Epoch: [1298][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0362 (0.0362)	
0.9999957 2.2882598e-06
===========>   testing    <===========
Epoch: [1298][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0480 (0.0480)	
0.9999919 2.270775e-06
Epoch: [1298][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0479 (0.0593)	
0.9999938 3.0409556e-06
Epoch: [1298][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.1066 (0.0585)	
0.9999931 2.434474e-06
loss:  0.04117586666381756 0.03858705330121737
===========>   training    <===========
Epoch: [1299][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0360 (0.0360)	
0.999985 1.7602022e-06
===========>   testing    <===========
Epoch: [1299][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0391 (0.0391)	
0.9999907 2.1820324e-06
Epoch: [1299][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0423 (0.0591)	
0.99999285 2.9204732e-06
Epoch: [1299][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.1059 (0.0586)	
0.99999034 2.5093054e-06
loss:  0.04160924959466061 0.03858705330121737
===========>   training    <===========
Epoch: [1300][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0324 (0.0324)	
0.9999927 8.805867e-07
===========>   testing    <===========
Epoch: [1300][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0337 (0.0337)	
0.99998975 2.2149954e-06
Epoch: [1300][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0344 (0.0581)	
0.9999913 2.893601e-06
Epoch: [1300][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.1369 (0.0590)	
0.99998796 2.107067e-06
loss:  0.04090469235756489 0.03858705330121737
===========>   training    <===========
Epoch: [1301][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0312 (0.0312)	
0.9999933 3.7405687e-06
===========>   testing    <===========
Epoch: [1301][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0387 (0.0387)	
0.99998987 1.87107e-06
Epoch: [1301][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0453 (0.0587)	
0.99998844 2.1656012e-06
Epoch: [1301][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.1063 (0.0587)	
0.99998486 2.0952007e-06
loss:  0.04159356870877695 0.03858705330121737
===========>   training    <===========
Epoch: [1302][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0388 (0.0388)	
0.99999 2.0649225e-06
===========>   testing    <===========
Epoch: [1302][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0438 (0.0438)	
0.9999907 2.1139952e-06
Epoch: [1302][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0464 (0.0592)	
0.99998915 1.9282065e-06
Epoch: [1302][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0986 (0.0583)	
0.9999858 1.9324405e-06
loss:  0.041399588421243805 0.03858705330121737
===========>   training    <===========
Epoch: [1303][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0419 (0.0419)	
0.9999857 2.139008e-06
===========>   testing    <===========
Epoch: [1303][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0392 (0.0392)	
0.9999926 2.4998897e-06
Epoch: [1303][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0675 (0.0587)	
0.9999944 3.1517604e-06
Epoch: [1303][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0953 (0.0575)	
0.9999927 3.0358094e-06
loss:  0.040428637087134955 0.03858705330121737
===========>   training    <===========
Epoch: [1304][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0457 (0.0457)	
0.9999838 1.0233566e-06
===========>   testing    <===========
Epoch: [1304][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0386 (0.0386)	
0.999992 2.7714643e-06
Epoch: [1304][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0401 (0.0593)	
0.9999949 3.2459984e-06
Epoch: [1304][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0892 (0.0585)	
0.9999925 2.8797292e-06
loss:  0.04025868952052536 0.03858705330121737
===========>   training    <===========
Epoch: [1305][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0325 (0.0325)	
0.9999902 2.5487143e-06
===========>   testing    <===========
Epoch: [1305][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0496 (0.0496)	
0.9999926 2.2089412e-06
Epoch: [1305][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0410 (0.0604)	
0.9999951 2.6799546e-06
Epoch: [1305][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0988 (0.0650)	
0.99999225 2.6955488e-06
loss:  0.04439447133553287 0.03858705330121737
===========>   training    <===========
Epoch: [1306][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0355 (0.0355)	
0.9999958 3.4985917e-06
===========>   testing    <===========
Epoch: [1306][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0411 (0.0411)	
0.9999918 1.7835786e-06
Epoch: [1306][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0313 (0.0588)	
0.99999356 2.2994034e-06
Epoch: [1306][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0961 (0.0581)	
0.9999919 1.9686345e-06
loss:  0.04051584483111215 0.03858705330121737
===========>   training    <===========
Epoch: [1307][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0395 (0.0395)	
0.9999968 1.030396e-06
===========>   testing    <===========
Epoch: [1307][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0344 (0.0344)	
0.9999896 2.1416574e-06
Epoch: [1307][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0213 (0.0599)	
0.99999213 2.4927763e-06
Epoch: [1307][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0857 (0.0590)	
0.9999902 2.5362538e-06
loss:  0.04066993619685344 0.03858705330121737
===========>   training    <===========
Epoch: [1308][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0349 (0.0349)	
0.99996483 9.540445e-07
===========>   testing    <===========
Epoch: [1308][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0346 (0.0346)	
0.99998975 1.8796079e-06
Epoch: [1308][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0249 (0.0588)	
0.9999926 2.3724074e-06
Epoch: [1308][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0882 (0.0582)	
0.9999887 2.2525583e-06
loss:  0.040714450202726016 0.03858705330121737
===========>   training    <===========
Epoch: [1309][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0411 (0.0411)	
0.9999801 1.5290208e-06
===========>   testing    <===========
Epoch: [1309][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0449 (0.0449)	
0.9999896 1.980615e-06
Epoch: [1309][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0326 (0.0612)	
0.9999933 2.3395903e-06
Epoch: [1309][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0926 (0.0601)	
0.99999094 2.463354e-06
loss:  0.04114099867696941 0.03858705330121737
===========>   training    <===========
Epoch: [1310][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0377 (0.0377)	
0.99998844 1.2856678e-06
===========>   testing    <===========
Epoch: [1310][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0377 (0.0377)	
0.9999896 1.812357e-06
Epoch: [1310][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0213 (0.0603)	
0.9999906 1.9754464e-06
Epoch: [1310][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.1071 (0.0592)	
0.99998593 1.5969065e-06
loss:  0.04089628413733171 0.03858705330121737
===========>   training    <===========
Epoch: [1311][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0426 (0.0426)	
0.9999963 6.1038264e-07
===========>   testing    <===========
Epoch: [1311][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0334 (0.0334)	
0.99998987 2.1833105e-06
Epoch: [1311][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0205 (0.0591)	
0.99999404 2.3621062e-06
Epoch: [1311][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0788 (0.0590)	
0.9999895 2.3139507e-06
loss:  0.04129131514356654 0.03858705330121737
===========>   training    <===========
Epoch: [1312][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0396 (0.0396)	
0.9999882 1.244516e-06
===========>   testing    <===========
Epoch: [1312][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0525 (0.0525)	
0.9999906 2.2415798e-06
Epoch: [1312][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0239 (0.0620)	
0.99999404 2.6264458e-06
Epoch: [1312][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0817 (0.0606)	
0.9999896 1.8569183e-06
loss:  0.0412275477474765 0.03858705330121737
===========>   training    <===========
Epoch: [1313][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0315 (0.0315)	
0.9999924 3.6784697e-06
===========>   testing    <===========
Epoch: [1313][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0624 (0.0624)	
0.99998975 2.169682e-06
Epoch: [1313][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0294 (0.0609)	
0.9999945 2.908258e-06
Epoch: [1313][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0869 (0.0595)	
0.9999894 2.1628355e-06
loss:  0.04089729056641189 0.03858705330121737
===========>   training    <===========
Epoch: [1314][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0318 (0.0318)	
0.99999213 2.0338277e-06
===========>   testing    <===========
Epoch: [1314][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0398 (0.0398)	
0.9999937 2.7521712e-06
Epoch: [1314][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0242 (0.0605)	
0.9999968 3.9213937e-06
Epoch: [1314][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.1109 (0.0606)	
0.99999404 3.8568783e-06
loss:  0.04078453086162548 0.03858705330121737
===========>   training    <===========
Epoch: [1315][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0382 (0.0382)	
0.9999751 6.3821545e-07
===========>   testing    <===========
Epoch: [1315][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0470 (0.0470)	
0.99998975 2.2218544e-06
Epoch: [1315][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0477 (0.0594)	
0.9999945 2.8579564e-06
Epoch: [1315][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.1063 (0.0593)	
0.99998915 1.6412869e-06
loss:  0.04151927764241137 0.03858705330121737
===========>   training    <===========
Epoch: [1316][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0407 (0.0407)	
0.9999789 1.7851102e-06
===========>   testing    <===========
Epoch: [1316][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0536 (0.0536)	
0.9999901 2.4341768e-06
Epoch: [1316][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0473 (0.0591)	
0.9999956 3.215094e-06
Epoch: [1316][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.1120 (0.0590)	
0.9999927 2.140616e-06
loss:  0.04022845330948588 0.03858705330121737
===========>   training    <===========
Epoch: [1317][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0364 (0.0364)	
0.9999871 1.942357e-06
===========>   testing    <===========
Epoch: [1317][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0403 (0.0403)	
0.99999 2.1679982e-06
Epoch: [1317][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0248 (0.0592)	
0.9999956 3.050497e-06
Epoch: [1317][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.1224 (0.0593)	
0.9999938 2.5317322e-06
loss:  0.0402494312167051 0.03858705330121737
===========>   training    <===========
Epoch: [1318][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0343 (0.0343)	
0.9999943 3.5063279e-06
===========>   testing    <===========
Epoch: [1318][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0431 (0.0431)	
0.9999889 2.1063117e-06
Epoch: [1318][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0280 (0.0607)	
0.9999931 2.5794754e-06
Epoch: [1318][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.1020 (0.0599)	
0.99999154 1.8038769e-06
loss:  0.04072674508279106 0.03858705330121737
===========>   training    <===========
Epoch: [1319][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0367 (0.0367)	
0.9999863 1.8578287e-06
===========>   testing    <===========
Epoch: [1319][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0389 (0.0389)	
0.9999887 2.4933588e-06
Epoch: [1319][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0180 (0.0596)	
0.9999943 3.0048714e-06
Epoch: [1319][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0999 (0.0598)	
0.9999924 2.1059038e-06
loss:  0.04061995782987038 0.03858705330121737
===========>   training    <===========
Epoch: [1320][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0404 (0.0404)	
0.9999964 6.2383724e-06
===========>   testing    <===========
Epoch: [1320][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0427 (0.0427)	
0.9999888 1.9219297e-06
Epoch: [1320][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0253 (0.0600)	
0.9999918 2.604814e-06
Epoch: [1320][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.1094 (0.0598)	
0.99998915 2.1117644e-06
loss:  0.041484575786046585 0.03858705330121737
===========>   training    <===========
Epoch: [1321][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0347 (0.0347)	
0.9999968 4.239108e-07
===========>   testing    <===========
Epoch: [1321][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0525 (0.0525)	
0.99998844 1.7379839e-06
Epoch: [1321][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0367 (0.0599)	
0.9999894 2.5014801e-06
Epoch: [1321][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.1275 (0.0590)	
0.9999865 1.412706e-06
loss:  0.04064942115037551 0.03858705330121737
===========>   training    <===========
Epoch: [1322][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0310 (0.0310)	
0.99998844 1.4491301e-06
===========>   testing    <===========
Epoch: [1322][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0362 (0.0362)	
0.99998915 1.5713244e-06
Epoch: [1322][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0301 (0.0608)	
0.9999906 2.2673148e-06
Epoch: [1322][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.1349 (0.0600)	
0.99998856 1.5886006e-06
loss:  0.04119868110898295 0.03858705330121737
===========>   training    <===========
Epoch: [1323][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0354 (0.0354)	
0.9999877 9.2374506e-07
===========>   testing    <===========
Epoch: [1323][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0384 (0.0384)	
0.99999166 1.8322347e-06
Epoch: [1323][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0264 (0.0604)	
0.99999404 2.6064665e-06
Epoch: [1323][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.1148 (0.0595)	
0.99999297 1.6687814e-06
loss:  0.04037007723824815 0.03858705330121737
===========>   training    <===========
Epoch: [1324][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0342 (0.0342)	
0.9999932 2.075198e-06
===========>   testing    <===========
Epoch: [1324][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0462 (0.0462)	
0.99998856 1.7746607e-06
Epoch: [1324][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0259 (0.0598)	
0.9999913 2.497364e-06
Epoch: [1324][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0975 (0.0592)	
0.9999908 1.8662565e-06
loss:  0.04053872333988606 0.03858705330121737
===========>   training    <===========
Epoch: [1325][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0346 (0.0346)	
0.9999976 3.6984954e-06
===========>   testing    <===========
Epoch: [1325][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0492 (0.0492)	
0.99998915 1.9144732e-06
Epoch: [1325][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0339 (0.0606)	
0.99998903 2.2904953e-06
Epoch: [1325][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.1150 (0.0597)	
0.99998903 1.3333014e-06
loss:  0.040635574569993116 0.03858705330121737
===========>   training    <===========
Epoch: [1326][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0362 (0.0362)	
0.9999937 3.1160962e-06
===========>   testing    <===========
Epoch: [1326][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0605 (0.0605)	
0.9999888 2.0774094e-06
Epoch: [1326][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0353 (0.0596)	
0.9999882 2.4714816e-06
Epoch: [1326][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.1388 (0.0589)	
0.99998975 1.5796239e-06
loss:  0.039820606465313935 0.03858705330121737
===========>   training    <===========
Epoch: [1327][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0361 (0.0361)	
0.9999794 3.290481e-06
===========>   testing    <===========
Epoch: [1327][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0452 (0.0452)	
0.99998856 2.349704e-06
Epoch: [1327][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0255 (0.0603)	
0.99999034 3.092289e-06
Epoch: [1327][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.1134 (0.0592)	
0.9999913 2.1993897e-06
loss:  0.039966285652444644 0.03858705330121737
===========>   training    <===========
Epoch: [1328][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0286 (0.0286)	
0.9999871 2.659662e-06
===========>   testing    <===========
Epoch: [1328][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0492 (0.0492)	
0.9999902 1.8229676e-06
Epoch: [1328][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0313 (0.0600)	
0.9999889 2.4538062e-06
Epoch: [1328][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0917 (0.0586)	
0.99998844 1.6026215e-06
loss:  0.04024890186610164 0.03858705330121737
===========>   training    <===========
Epoch: [1329][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0365 (0.0365)	
0.999992 2.9838707e-06
===========>   testing    <===========
Epoch: [1329][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0311 (0.0311)	
0.9999893 1.8683295e-06
Epoch: [1329][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0260 (0.0601)	
0.99998736 2.463086e-06
Epoch: [1329][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0907 (0.0588)	
0.99998915 2.0034843e-06
loss:  0.03978315037165636 0.03858705330121737
===========>   training    <===========
Epoch: [1330][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0312 (0.0312)	
0.9999944 2.6245755e-06
===========>   testing    <===========
Epoch: [1330][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0343 (0.0343)	
0.9999906 1.8311273e-06
Epoch: [1330][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0296 (0.0594)	
0.9999883 2.2477964e-06
Epoch: [1330][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0919 (0.0582)	
0.9999901 1.4261586e-06
loss:  0.039885775322604844 0.03858705330121737
===========>   training    <===========
Epoch: [1331][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0344 (0.0344)	
0.9999925 1.983318e-06
===========>   testing    <===========
Epoch: [1331][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0414 (0.0414)	
0.99998856 1.6736648e-06
Epoch: [1331][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0346 (0.0594)	
0.9999896 2.2502606e-06
Epoch: [1331][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0739 (0.0577)	
0.99998987 1.7198538e-06
loss:  0.039625632435424274 0.03858705330121737
===========>   training    <===========
Epoch: [1332][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0346 (0.0346)	
0.99999404 1.811659e-06
===========>   testing    <===========
Epoch: [1332][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0598 (0.0598)	
0.9999882 1.7674437e-06
Epoch: [1332][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0451 (0.0600)	
0.99998736 2.2780348e-06
Epoch: [1332][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.1013 (0.0583)	
0.99998677 1.916119e-06
loss:  0.04004931828343061 0.03858705330121737
===========>   training    <===========
Epoch: [1333][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0447 (0.0447)	
0.99998116 1.5148563e-06
===========>   testing    <===========
Epoch: [1333][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0557 (0.0557)	
0.9999902 2.4836736e-06
Epoch: [1333][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0450 (0.0597)	
0.9999918 3.0768745e-06
Epoch: [1333][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.1058 (0.0588)	
0.99999166 2.9114244e-06
loss:  0.04006661641125864 0.03858705330121737
===========>   training    <===========
Epoch: [1334][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0319 (0.0319)	
0.99999094 2.3787827e-06
===========>   testing    <===========
Epoch: [1334][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0670 (0.0670)	
0.99998975 2.098372e-06
Epoch: [1334][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0331 (0.0605)	
0.9999913 2.6993769e-06
Epoch: [1334][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0972 (0.0591)	
0.9999906 2.024041e-06
loss:  0.04046484833660147 0.03858705330121737
===========>   training    <===========
Epoch: [1335][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0344 (0.0344)	
0.9999927 2.4217568e-06
===========>   testing    <===========
Epoch: [1335][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0810 (0.0810)	
0.99998915 1.8194713e-06
Epoch: [1335][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0768 (0.0601)	
0.9999895 2.342064e-06
Epoch: [1335][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0820 (0.0582)	
0.9999865 1.6145256e-06
loss:  0.040863426337105824 0.03858705330121737
===========>   training    <===========
Epoch: [1336][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0392 (0.0392)	
0.99999094 2.268855e-06
===========>   testing    <===========
Epoch: [1336][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0663 (0.0663)	
0.9999896 1.7576457e-06
Epoch: [1336][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0652 (0.0583)	
0.9999908 2.247687e-06
Epoch: [1336][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.1045 (0.0581)	
0.9999893 1.7875191e-06
loss:  0.040464128792742415 0.03858705330121737
===========>   training    <===========
Epoch: [1337][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0364 (0.0364)	
0.999992 2.4509623e-06
===========>   testing    <===========
Epoch: [1337][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0595 (0.0595)	
0.9999908 1.7413254e-06
Epoch: [1337][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0737 (0.0581)	
0.9999883 2.300693e-06
Epoch: [1337][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.1061 (0.0578)	
0.9999877 1.7927447e-06
loss:  0.040310887505945914 0.03858705330121737
===========>   training    <===========
Epoch: [1338][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0310 (0.0310)	
0.99999344 2.277205e-06
===========>   testing    <===========
Epoch: [1338][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0558 (0.0558)	
0.9999902 1.8561002e-06
Epoch: [1338][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0469 (0.0590)	
0.9999888 2.291291e-06
Epoch: [1338][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0928 (0.0580)	
0.99998856 2.2152637e-06
loss:  0.04018116752422507 0.03858705330121737
===========>   training    <===========
Epoch: [1339][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0355 (0.0355)	
0.9999924 2.2458978e-06
===========>   testing    <===========
Epoch: [1339][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0495 (0.0495)	
0.99999106 1.9223605e-06
Epoch: [1339][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0389 (0.0602)	
0.99999094 2.649399e-06
Epoch: [1339][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.1029 (0.0585)	
0.99999106 2.3062332e-06
loss:  0.04009162972970737 0.03858705330121737
===========>   training    <===========
Epoch: [1340][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0449 (0.0449)	
0.9999958 1.6308238e-06
===========>   testing    <===========
Epoch: [1340][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0489 (0.0489)	
0.9999901 1.8071208e-06
Epoch: [1340][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0581 (0.0590)	
0.9999924 2.5687307e-06
Epoch: [1340][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0739 (0.0571)	
0.99999106 2.1541075e-06
loss:  0.04010806689206703 0.03858705330121737
===========>   training    <===========
Epoch: [1341][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0387 (0.0387)	
0.9999957 1.6252854e-06
===========>   testing    <===========
Epoch: [1341][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0451 (0.0451)	
0.99998915 1.7332699e-06
Epoch: [1341][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0454 (0.0598)	
0.9999926 2.4073947e-06
Epoch: [1341][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0841 (0.0578)	
0.9999902 1.93469e-06
loss:  0.03962666883306476 0.03858705330121737
===========>   training    <===========
Epoch: [1342][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0365 (0.0365)	
0.99999416 9.0858275e-06
===========>   testing    <===========
Epoch: [1342][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0412 (0.0412)	
0.9999894 1.7913724e-06
Epoch: [1342][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0357 (0.0582)	
0.9999919 2.241135e-06
Epoch: [1342][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.1080 (0.0574)	
0.99998593 1.6188735e-06
loss:  0.03984191925994773 0.03858705330121737
===========>   training    <===========
Epoch: [1343][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0356 (0.0356)	
0.9999938 3.1118318e-06
===========>   testing    <===========
Epoch: [1343][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0419 (0.0419)	
0.9999913 1.998618e-06
Epoch: [1343][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0300 (0.0581)	
0.99999356 2.5339425e-06
Epoch: [1343][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0769 (0.0570)	
0.99999 1.5248764e-06
loss:  0.03969561401515853 0.03858705330121737
===========>   training    <===========
Epoch: [1344][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0362 (0.0362)	
0.9999895 3.3588854e-06
===========>   testing    <===========
Epoch: [1344][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0562 (0.0562)	
0.99999034 1.9950303e-06
Epoch: [1344][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0404 (0.0597)	
0.9999907 2.458252e-06
Epoch: [1344][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0711 (0.0578)	
0.9999875 2.1579979e-06
loss:  0.040429195683847174 0.03858705330121737
===========>   training    <===========
Epoch: [1345][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0324 (0.0324)	
0.99998736 3.4575087e-06
===========>   testing    <===========
Epoch: [1345][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0509 (0.0509)	
0.99999154 2.3040018e-06
Epoch: [1345][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0322 (0.0597)	
0.9999938 2.9016285e-06
Epoch: [1345][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.1015 (0.0588)	
0.99999213 2.125161e-06
loss:  0.040635056261599356 0.03858705330121737
===========>   training    <===========
Epoch: [1346][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0341 (0.0341)	
0.9999957 3.245246e-06
===========>   testing    <===========
Epoch: [1346][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0471 (0.0471)	
0.99998903 2.079207e-06
Epoch: [1346][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0327 (0.0584)	
0.99999225 2.740349e-06
Epoch: [1346][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0910 (0.0579)	
0.99999034 1.7245396e-06
loss:  0.04036931819488143 0.03858705330121737
===========>   training    <===========
Epoch: [1347][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0407 (0.0407)	
0.99998534 1.3752039e-06
===========>   testing    <===========
Epoch: [1347][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0439 (0.0439)	
0.9999889 1.7189257e-06
Epoch: [1347][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0270 (0.0574)	
0.99998903 1.6482985e-06
Epoch: [1347][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0832 (0.0575)	
0.9999833 1.543503e-06
loss:  0.04007985177178386 0.03858705330121737
===========>   training    <===========
Epoch: [1348][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0388 (0.0388)	
0.9999938 2.5355257e-06
===========>   testing    <===========
Epoch: [1348][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0425 (0.0425)	
0.9999901 1.5505524e-06
Epoch: [1348][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0246 (0.0589)	
0.9999877 2.04171e-06
Epoch: [1348][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.1039 (0.0585)	
0.99998736 1.6086763e-06
loss:  0.040583204248878846 0.03858705330121737
===========>   training    <===========
Epoch: [1349][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0322 (0.0322)	
0.9999881 7.1493077e-06
===========>   testing    <===========
Epoch: [1349][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0337 (0.0337)	
0.9999908 1.5767283e-06
Epoch: [1349][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0248 (0.0587)	
0.9999881 2.1236458e-06
Epoch: [1349][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0933 (0.0586)	
0.99998975 1.4866478e-06
loss:  0.04026797810693328 0.03858705330121737
===========>   training    <===========
Epoch: [1350][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0370 (0.0370)	
0.99999213 3.9199394e-06
===========>   testing    <===========
Epoch: [1350][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0402 (0.0402)	
0.99999225 2.2029963e-06
Epoch: [1350][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0300 (0.0595)	
0.9999919 2.9090625e-06
Epoch: [1350][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.1204 (0.0593)	
0.9999932 2.4779906e-06
loss:  0.04047305701034687 0.03858705330121737
===========>   training    <===========
Epoch: [1351][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0350 (0.0350)	
0.9999833 1.1686922e-06
===========>   testing    <===========
Epoch: [1351][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0413 (0.0413)	
0.9999913 1.878918e-06
Epoch: [1351][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0259 (0.0588)	
0.99998903 2.266636e-06
Epoch: [1351][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.1032 (0.0588)	
0.9999896 1.4640462e-06
loss:  0.04064082042729411 0.03858705330121737
===========>   training    <===========
Epoch: [1352][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0405 (0.0405)	
0.9999887 1.2377137e-06
===========>   testing    <===========
Epoch: [1352][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0376 (0.0376)	
0.99999034 1.8913587e-06
Epoch: [1352][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0249 (0.0586)	
0.99998915 2.2242332e-06
Epoch: [1352][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.1125 (0.0594)	
0.99998903 1.238153e-06
loss:  0.040208068986914425 0.03858705330121737
===========>   training    <===========
Epoch: [1353][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0320 (0.0320)	
0.99999046 2.7577541e-06
===========>   testing    <===========
Epoch: [1353][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0432 (0.0432)	
0.9999912 1.7777539e-06
Epoch: [1353][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0294 (0.0585)	
0.99998593 2.0704063e-06
Epoch: [1353][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0832 (0.0581)	
0.9999871 1.4780752e-06
loss:  0.03980881428390026 0.03858705330121737
===========>   training    <===========
Epoch: [1354][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0416 (0.0416)	
0.9999944 2.7870462e-06
===========>   testing    <===========
Epoch: [1354][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0530 (0.0530)	
0.9999913 2.1147653e-06
Epoch: [1354][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0284 (0.0594)	
0.9999875 2.6170972e-06
Epoch: [1354][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.1071 (0.0587)	
0.99998987 1.8961845e-06
loss:  0.04018598483471314 0.03858705330121737
===========>   training    <===========
Epoch: [1355][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0374 (0.0374)	
0.9999881 2.497354e-07
===========>   testing    <===========
Epoch: [1355][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0420 (0.0420)	
0.9999908 1.8995584e-06
Epoch: [1355][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0303 (0.0580)	
0.9999869 2.4128076e-06
Epoch: [1355][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.1257 (0.0586)	
0.99998844 1.57163e-06
loss:  0.0403328263414352 0.03858705330121737
===========>   training    <===========
Epoch: [1356][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0333 (0.0333)	
0.9999889 2.296239e-06
===========>   testing    <===========
Epoch: [1356][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0514 (0.0514)	
0.99999094 2.0930038e-06
Epoch: [1356][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0262 (0.0591)	
0.99998784 2.744476e-06
Epoch: [1356][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0918 (0.0588)	
0.99999034 1.8079844e-06
loss:  0.040027711607523386 0.03858705330121737
===========>   training    <===========
Epoch: [1357][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0334 (0.0334)	
0.9999896 8.597882e-06
===========>   testing    <===========
Epoch: [1357][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0532 (0.0532)	
0.99999154 2.003316e-06
Epoch: [1357][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0306 (0.0585)	
0.9999907 2.5267223e-06
Epoch: [1357][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0861 (0.0577)	
0.9999918 1.5952016e-06
loss:  0.03969117529647048 0.03858705330121737
===========>   training    <===========
Epoch: [1358][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0412 (0.0412)	
0.99999475 2.1139667e-06
===========>   testing    <===========
Epoch: [1358][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0455 (0.0455)	
0.9999924 2.0774114e-06
Epoch: [1358][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0350 (0.0581)	
0.9999927 2.459889e-06
Epoch: [1358][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0951 (0.0578)	
0.999992 1.959014e-06
loss:  0.03972333571556974 0.03858705330121737
===========>   training    <===========
Epoch: [1359][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0318 (0.0318)	
0.999987 2.702009e-06
===========>   testing    <===========
Epoch: [1359][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0499 (0.0499)	
0.9999896 1.7495883e-06
Epoch: [1359][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0309 (0.0590)	
0.9999852 2.1226313e-06
Epoch: [1359][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0880 (0.0590)	
0.99998605 1.369554e-06
loss:  0.04066429886570433 0.03858705330121737
===========>   training    <===========
Epoch: [1360][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0356 (0.0356)	
0.9999826 5.0663184e-06
===========>   testing    <===========
Epoch: [1360][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0409 (0.0409)	
0.99999 2.0055375e-06
Epoch: [1360][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0269 (0.0586)	
0.9999895 2.3757516e-06
Epoch: [1360][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0808 (0.0590)	
0.9999895 2.0941839e-06
loss:  0.040177961851638355 0.03858705330121737
===========>   training    <===========
Epoch: [1361][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0305 (0.0305)	
0.99998724 1.8345042e-06
===========>   testing    <===========
Epoch: [1361][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0503 (0.0503)	
0.99999106 2.145513e-06
Epoch: [1361][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0306 (0.0591)	
0.99999106 2.5831534e-06
Epoch: [1361][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0920 (0.0592)	
0.9999895 1.7939693e-06
loss:  0.04068040927534422 0.03858705330121737
===========>   training    <===========
Epoch: [1362][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0362 (0.0362)	
0.999974 3.4504599e-06
===========>   testing    <===========
Epoch: [1362][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0517 (0.0517)	
0.9999896 1.9395118e-06
Epoch: [1362][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0285 (0.0588)	
0.9999912 2.4387894e-06
Epoch: [1362][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0878 (0.0586)	
0.9999907 1.7901393e-06
loss:  0.0405388612030555 0.03858705330121737
===========>   training    <===========
Epoch: [1363][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0324 (0.0324)	
0.9999912 2.0795283e-06
===========>   testing    <===========
Epoch: [1363][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0537 (0.0537)	
0.99998915 1.606127e-06
Epoch: [1363][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0330 (0.0591)	
0.99998796 1.933849e-06
Epoch: [1363][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0800 (0.0588)	
0.9999862 1.3423114e-06
loss:  0.04084703860924921 0.03858705330121737
===========>   training    <===========
Epoch: [1364][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0389 (0.0389)	
0.999992 5.5254986e-06
===========>   testing    <===========
Epoch: [1364][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0517 (0.0517)	
0.99999106 1.8804488e-06
Epoch: [1364][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0282 (0.0602)	
0.99999297 2.287025e-06
Epoch: [1364][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0919 (0.0596)	
0.9999907 1.8316931e-06
loss:  0.041398064390657074 0.03858705330121737
===========>   training    <===========
Epoch: [1365][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0425 (0.0425)	
0.99999404 2.4319309e-06
===========>   testing    <===========
Epoch: [1365][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0561 (0.0561)	
0.9999908 1.7455751e-06
Epoch: [1365][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0318 (0.0587)	
0.99999213 2.1234878e-06
Epoch: [1365][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0565 (0.0579)	
0.9999906 1.5608368e-06
loss:  0.04036918720981775 0.03858705330121737
===========>   training    <===========
Epoch: [1366][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0375 (0.0375)	
0.9999865 1.313502e-06
===========>   testing    <===========
Epoch: [1366][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0539 (0.0539)	
0.999992 1.740701e-06
Epoch: [1366][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0259 (0.0581)	
0.9999926 2.0846453e-06
Epoch: [1366][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0727 (0.0584)	
0.99999034 1.8530582e-06
loss:  0.04031151334950456 0.03858705330121737
===========>   training    <===========
Epoch: [1367][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0416 (0.0416)	
0.9999808 1.2758683e-06
===========>   testing    <===========
Epoch: [1367][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0475 (0.0475)	
0.99999 1.5421863e-06
Epoch: [1367][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0234 (0.0592)	
0.9999875 1.7879385e-06
Epoch: [1367][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0695 (0.0598)	
0.99998736 1.5358559e-06
loss:  0.04072196807870565 0.03858705330121737
===========>   training    <===========
Epoch: [1368][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0300 (0.0300)	
0.99999416 1.2073967e-06
===========>   testing    <===========
Epoch: [1368][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0593 (0.0593)	
0.9999906 1.5770381e-06
Epoch: [1368][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0305 (0.0596)	
0.9999865 1.7620916e-06
Epoch: [1368][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0914 (0.0595)	
0.9999846 1.5321518e-06
loss:  0.041066098584682464 0.03858705330121737
===========>   training    <===========
Epoch: [1369][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0341 (0.0341)	
0.99999154 1.7435353e-06
===========>   testing    <===========
Epoch: [1369][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0601 (0.0601)	
0.9999908 1.4569011e-06
Epoch: [1369][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0485 (0.0599)	
0.99998844 1.8397972e-06
Epoch: [1369][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.1006 (0.0595)	
0.9999863 1.4962513e-06
loss:  0.04126543965684648 0.03858705330121737
===========>   training    <===========
Epoch: [1370][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0384 (0.0384)	
0.99997604 8.9367893e-07
===========>   testing    <===========
Epoch: [1370][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0575 (0.0575)	
0.99999034 1.902343e-06
Epoch: [1370][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0508 (0.0608)	
0.9999907 2.4289689e-06
Epoch: [1370][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0842 (0.0590)	
0.9999901 1.967362e-06
loss:  0.040588162325549404 0.03858705330121737
===========>   training    <===========
Epoch: [1371][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0325 (0.0325)	
0.99998677 2.2419495e-06
===========>   testing    <===========
Epoch: [1371][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0478 (0.0478)	
0.99998975 1.7797709e-06
Epoch: [1371][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0419 (0.0609)	
0.9999908 2.2636095e-06
Epoch: [1371][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0903 (0.0591)	
0.99999166 1.8647106e-06
loss:  0.04043733933332605 0.03858705330121737
===========>   training    <===========
Epoch: [1372][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0256 (0.0256)	
0.99999547 3.4572713e-06
===========>   testing    <===========
Epoch: [1372][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0434 (0.0434)	
0.99999166 1.8732607e-06
Epoch: [1372][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0411 (0.0612)	
0.9999931 2.291719e-06
Epoch: [1372][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0841 (0.0594)	
0.9999925 1.983668e-06
loss:  0.04064768612591152 0.03858705330121737
===========>   training    <===========
Epoch: [1373][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0402 (0.0402)	
0.99999106 7.8089204e-07
===========>   testing    <===========
Epoch: [1373][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0470 (0.0470)	
0.9999913 1.8868153e-06
Epoch: [1373][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0591 (0.0610)	
0.9999932 2.4082237e-06
Epoch: [1373][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0737 (0.0591)	
0.99999213 2.086463e-06
loss:  0.040445240321630105 0.03858705330121737
===========>   training    <===========
Epoch: [1374][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0369 (0.0369)	
0.9999876 1.9498568e-06
===========>   testing    <===========
Epoch: [1374][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0523 (0.0523)	
0.99999106 1.7591348e-06
Epoch: [1374][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0976 (0.0617)	
0.9999937 2.2990523e-06
Epoch: [1374][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0750 (0.0595)	
0.9999913 1.9492209e-06
loss:  0.040556866424204197 0.03858705330121737
===========>   training    <===========
Epoch: [1375][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0428 (0.0428)	
0.9999894 1.6961927e-06
===========>   testing    <===========
Epoch: [1375][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0475 (0.0475)	
0.9999901 1.583307e-06
Epoch: [1375][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0593 (0.0597)	
0.9999924 1.9730626e-06
Epoch: [1375][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0807 (0.0586)	
0.9999912 1.7567575e-06
loss:  0.040187407995248337 0.03858705330121737
===========>   training    <===========
Epoch: [1376][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0290 (0.0290)	
0.9999888 7.331383e-07
===========>   testing    <===========
Epoch: [1376][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0447 (0.0447)	
0.99999297 1.8334828e-06
Epoch: [1376][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0476 (0.0586)	
0.9999945 2.5588165e-06
Epoch: [1376][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0829 (0.0583)	
0.99999297 2.0204325e-06
loss:  0.03963965147253845 0.03858705330121737
===========>   training    <===========
Epoch: [1377][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0320 (0.0320)	
0.99999106 1.3170117e-06
===========>   testing    <===========
Epoch: [1377][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0441 (0.0441)	
0.9999918 1.5839081e-06
Epoch: [1377][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0743 (0.0574)	
0.9999927 2.118249e-06
Epoch: [1377][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0724 (0.0575)	
0.9999908 1.6763099e-06
loss:  0.03996854592785115 0.03858705330121737
===========>   training    <===========
Epoch: [1378][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0383 (0.0383)	
0.9999789 1.437639e-06
===========>   testing    <===========
Epoch: [1378][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0550 (0.0550)	
0.9999902 1.4645601e-06
Epoch: [1378][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0529 (0.0586)	
0.99999166 1.7440609e-06
Epoch: [1378][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0674 (0.0579)	
0.9999895 1.5106033e-06
loss:  0.03982770208866948 0.03858705330121737
===========>   training    <===========
Epoch: [1379][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0369 (0.0369)	
0.9999943 1.4968707e-06
===========>   testing    <===========
Epoch: [1379][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0583 (0.0583)	
0.9999938 1.582522e-06
Epoch: [1379][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0456 (0.0599)	
0.9999945 1.9245817e-06
Epoch: [1379][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0740 (0.0587)	
0.9999932 1.6593832e-06
loss:  0.03982296148299125 0.03858705330121737
===========>   training    <===========
Epoch: [1380][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0347 (0.0347)	
0.99999726 3.5356647e-06
===========>   testing    <===========
Epoch: [1380][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0381 (0.0381)	
0.99999166 1.4955294e-06
Epoch: [1380][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0542 (0.0605)	
0.9999925 1.7564527e-06
Epoch: [1380][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0579 (0.0588)	
0.99999 1.2157366e-06
loss:  0.040339127684352105 0.03858705330121737
===========>   training    <===========
Epoch: [1381][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0334 (0.0334)	
0.99998295 1.1845315e-06
===========>   testing    <===========
Epoch: [1381][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0422 (0.0422)	
0.99999285 1.6335275e-06
Epoch: [1381][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0522 (0.0598)	
0.99999464 2.2461122e-06
Epoch: [1381][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0775 (0.0582)	
0.99999297 1.7521563e-06
loss:  0.039994384756765755 0.03858705330121737
===========>   training    <===========
Epoch: [1382][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0394 (0.0394)	
0.99999094 1.3989652e-06
===========>   testing    <===========
Epoch: [1382][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0521 (0.0521)	
0.99998903 1.4792964e-06
Epoch: [1382][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0770 (0.0594)	
0.9999931 1.8449083e-06
Epoch: [1382][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0833 (0.0579)	
0.99998987 1.5272093e-06
loss:  0.04055104191119785 0.03858705330121737
===========>   training    <===========
Epoch: [1383][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0354 (0.0354)	
0.99999344 1.967786e-06
===========>   testing    <===========
Epoch: [1383][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0559 (0.0559)	
0.9999912 1.5763736e-06
Epoch: [1383][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0665 (0.0603)	
0.99999166 1.9443232e-06
Epoch: [1383][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0736 (0.0587)	
0.9999902 1.685955e-06
loss:  0.040622144190743614 0.03858705330121737
===========>   training    <===========
Epoch: [1384][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0362 (0.0362)	
0.9999949 2.6264283e-06
===========>   testing    <===========
Epoch: [1384][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0535 (0.0535)	
0.9999924 2.0491284e-06
Epoch: [1384][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0404 (0.0611)	
0.9999937 2.8105264e-06
Epoch: [1384][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0736 (0.0590)	
0.999992 2.1973729e-06
loss:  0.04027732429798969 0.03858705330121737
===========>   training    <===========
Epoch: [1385][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0353 (0.0353)	
0.99999833 2.8031463e-06
===========>   testing    <===========
Epoch: [1385][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0473 (0.0473)	
0.99999166 1.7292082e-06
Epoch: [1385][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0349 (0.0591)	
0.99999356 2.2336583e-06
Epoch: [1385][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0761 (0.0585)	
0.9999918 1.5153562e-06
loss:  0.04019483771632382 0.03858705330121737
===========>   training    <===========
Epoch: [1386][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0299 (0.0299)	
0.99999344 2.0215755e-06
===========>   testing    <===========
Epoch: [1386][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0513 (0.0513)	
0.9999919 1.8415193e-06
Epoch: [1386][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0333 (0.0584)	
0.99999356 2.2905808e-06
Epoch: [1386][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0634 (0.0577)	
0.99999166 1.7605144e-06
loss:  0.039685963811390224 0.03858705330121737
===========>   training    <===========
Epoch: [1387][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0336 (0.0336)	
0.9999896 1.1599224e-06
===========>   testing    <===========
Epoch: [1387][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0553 (0.0553)	
0.9999913 1.9446124e-06
Epoch: [1387][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0473 (0.0591)	
0.9999939 2.5553002e-06
Epoch: [1387][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0691 (0.0578)	
0.9999919 2.0865148e-06
loss:  0.039740116316015484 0.03858705330121737
===========>   training    <===========
Epoch: [1388][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0332 (0.0332)	
0.99999297 1.537031e-06
===========>   testing    <===========
Epoch: [1388][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0618 (0.0618)	
0.9999895 1.7871542e-06
Epoch: [1388][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0288 (0.0591)	
0.99999154 2.426158e-06
Epoch: [1388][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0946 (0.0579)	
0.9999888 1.9750526e-06
loss:  0.04003197533286429 0.03858705330121737
===========>   training    <===========
Epoch: [1389][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0419 (0.0419)	
0.99999166 8.5954173e-07
===========>   testing    <===========
Epoch: [1389][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0541 (0.0541)	
0.9999926 1.8282725e-06
Epoch: [1389][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0571 (0.0599)	
0.9999926 2.433694e-06
Epoch: [1389][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0678 (0.0577)	
0.9999896 1.6328127e-06
loss:  0.03993904799966663 0.03858705330121737
===========>   training    <===========
Epoch: [1390][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0322 (0.0322)	
0.9999957 2.8775464e-06
===========>   testing    <===========
Epoch: [1390][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0525 (0.0525)	
0.9999926 1.8745295e-06
Epoch: [1390][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0416 (0.0592)	
0.9999933 2.6043867e-06
Epoch: [1390][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0704 (0.0577)	
0.99999106 2.0420216e-06
loss:  0.03942211611825008 0.03858705330121737
===========>   training    <===========
Epoch: [1391][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0347 (0.0347)	
0.999992 1.7689968e-06
===========>   testing    <===========
Epoch: [1391][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0492 (0.0492)	
0.99999 1.5811282e-06
Epoch: [1391][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0332 (0.0600)	
0.9999906 2.1552296e-06
Epoch: [1391][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0808 (0.0586)	
0.9999876 1.771323e-06
loss:  0.039993676209007845 0.03858705330121737
===========>   training    <===========
Epoch: [1392][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0355 (0.0355)	
0.9999957 2.4541996e-06
===========>   testing    <===========
Epoch: [1392][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0556 (0.0556)	
0.9999913 1.5531156e-06
Epoch: [1392][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0512 (0.0614)	
0.9999925 2.1330516e-06
Epoch: [1392][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0623 (0.0592)	
0.99998915 1.7017843e-06
loss:  0.04021189964756189 0.03858705330121737
===========>   training    <===========
Epoch: [1393][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0396 (0.0396)	
0.99999034 1.8396586e-06
===========>   testing    <===========
Epoch: [1393][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0562 (0.0562)	
0.99999046 1.6009046e-06
Epoch: [1393][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0490 (0.0620)	
0.99998975 2.074642e-06
Epoch: [1393][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0712 (0.0599)	
0.9999864 1.7656427e-06
loss:  0.040432686320583056 0.03858705330121737
===========>   training    <===========
Epoch: [1394][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0379 (0.0379)	
0.9999926 3.4354935e-06
===========>   testing    <===========
Epoch: [1394][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0443 (0.0443)	
0.9999908 1.6941202e-06
Epoch: [1394][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0450 (0.0603)	
0.9999888 2.0763914e-06
Epoch: [1394][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0858 (0.0591)	
0.99998856 1.8542796e-06
loss:  0.04034179902107771 0.03858705330121737
===========>   training    <===========
Epoch: [1395][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0403 (0.0403)	
0.9999912 1.0804173e-06
===========>   testing    <===========
Epoch: [1395][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0511 (0.0511)	
0.9999925 2.2440545e-06
Epoch: [1395][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1025 (0.0619)	
0.9999933 3.1783645e-06
Epoch: [1395][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0615 (0.0596)	
0.9999919 2.7169315e-06
loss:  0.040557863851484965 0.03858705330121737
===========>   training    <===========
Epoch: [1396][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0431 (0.0431)	
0.9999957 2.8256218e-06
===========>   testing    <===========
Epoch: [1396][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0447 (0.0447)	
0.99999416 1.8399674e-06
Epoch: [1396][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0872 (0.0605)	
0.9999927 2.6947316e-06
Epoch: [1396][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0771 (0.0591)	
0.9999931 1.9709846e-06
loss:  0.040555386023229056 0.03858705330121737
===========>   training    <===========
Epoch: [1397][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0328 (0.0328)	
0.9999945 2.420189e-06
===========>   testing    <===========
Epoch: [1397][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0420 (0.0420)	
0.99999046 1.7391296e-06
Epoch: [1397][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1247 (0.0602)	
0.9999881 1.931092e-06
Epoch: [1397][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0706 (0.0589)	
0.9999858 1.7685768e-06
loss:  0.04116170140144826 0.03858705330121737
===========>   training    <===========
Epoch: [1398][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0355 (0.0355)	
0.9999951 1.0383358e-06
===========>   testing    <===========
Epoch: [1398][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0316 (0.0316)	
0.9999912 1.7889311e-06
Epoch: [1398][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1083 (0.0599)	
0.99998987 2.2834638e-06
Epoch: [1398][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1060 (0.0597)	
0.9999883 1.907426e-06
loss:  0.040935145829911534 0.03858705330121737
===========>   training    <===========
Epoch: [1399][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0300 (0.0300)	
0.99999154 2.053156e-06
===========>   testing    <===========
Epoch: [1399][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0444 (0.0444)	
0.99999166 1.7611794e-06
Epoch: [1399][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1396 (0.0600)	
0.9999893 2.1284714e-06
Epoch: [1399][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1271 (0.0611)	
0.9999881 1.8576126e-06
loss:  0.04155789900736084 0.03858705330121737
===========>   training    <===========
Epoch: [1400][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0357 (0.0357)	
0.9999933 1.7081696e-06
===========>   testing    <===========
Epoch: [1400][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0535 (0.0535)	
0.999992 1.7948797e-06
Epoch: [1400][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1098 (0.0598)	
0.9999912 2.173766e-06
Epoch: [1400][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1113 (0.0603)	
0.9999895 1.8908357e-06
loss:  0.04146189527557298 0.03858705330121737
===========>   training    <===========
Epoch: [1401][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0364 (0.0364)	
0.99999714 1.3465449e-06
===========>   testing    <===========
Epoch: [1401][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0496 (0.0496)	
0.9999918 1.8279761e-06
Epoch: [1401][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1250 (0.0599)	
0.9999914 2.1775754e-06
Epoch: [1401][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0895 (0.0597)	
0.9999881 1.926025e-06
loss:  0.041511217879246165 0.03858705330121737
===========>   training    <===========
Epoch: [1402][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0355 (0.0355)	
0.99999666 3.0717435e-06
===========>   testing    <===========
Epoch: [1402][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0644 (0.0644)	
0.9999932 1.972867e-06
Epoch: [1402][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0985 (0.0615)	
0.9999933 2.695559e-06
Epoch: [1402][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0986 (0.0602)	
0.99999094 2.066723e-06
loss:  0.04136048117012836 0.03858705330121737
===========>   training    <===========
Epoch: [1403][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0315 (0.0315)	
0.9999937 2.9036195e-07
===========>   testing    <===========
Epoch: [1403][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0395 (0.0395)	
0.9999914 1.5182957e-06
Epoch: [1403][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0539 (0.0606)	
0.9999908 1.8427402e-06
Epoch: [1403][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0954 (0.0603)	
0.99998784 1.5870274e-06
loss:  0.041223055296431776 0.03858705330121737
===========>   training    <===========
Epoch: [1404][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0347 (0.0347)	
0.9999813 4.851118e-07
===========>   testing    <===========
Epoch: [1404][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0381 (0.0381)	
0.9999908 1.6042777e-06
Epoch: [1404][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0495 (0.0601)	
0.9999902 1.8361915e-06
Epoch: [1404][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1025 (0.0603)	
0.9999865 1.6096274e-06
loss:  0.040720689068977745 0.03858705330121737
===========>   training    <===========
Epoch: [1405][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0388 (0.0388)	
0.9999982 4.6216737e-06
===========>   testing    <===========
Epoch: [1405][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0414 (0.0414)	
0.99999213 1.4676978e-06
Epoch: [1405][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0496 (0.0601)	
0.99999166 1.7733852e-06
Epoch: [1405][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1107 (0.0606)	
0.9999888 1.5150644e-06
loss:  0.04076656960297298 0.03858705330121737
===========>   training    <===========
Epoch: [1406][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0357 (0.0357)	
0.9999968 1.2426552e-06
===========>   testing    <===========
Epoch: [1406][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0443 (0.0443)	
0.9999919 1.6156115e-06
Epoch: [1406][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0417 (0.0603)	
0.99999297 2.0554953e-06
Epoch: [1406][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1144 (0.0606)	
0.9999902 1.6671715e-06
loss:  0.040688618367800244 0.03858705330121737
===========>   training    <===========
Epoch: [1407][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0310 (0.0310)	
0.9999858 6.5289686e-07
===========>   testing    <===========
Epoch: [1407][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0541 (0.0541)	
0.9999924 1.5672387e-06
Epoch: [1407][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0586 (0.0606)	
0.9999926 1.9643367e-06
Epoch: [1407][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1098 (0.0599)	
0.99999 1.5980247e-06
loss:  0.041138732695191305 0.03858705330121737
===========>   training    <===========
Epoch: [1408][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0333 (0.0333)	
0.99999475 1.8809152e-06
===========>   testing    <===========
Epoch: [1408][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0486 (0.0486)	
0.9999943 1.7125574e-06
Epoch: [1408][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0456 (0.0598)	
0.9999939 2.168873e-06
Epoch: [1408][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1209 (0.0594)	
0.99999225 1.7483507e-06
loss:  0.04073654153640416 0.03858705330121737
===========>   training    <===========
Epoch: [1409][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0339 (0.0339)	
0.99999297 2.1192109e-06
===========>   testing    <===========
Epoch: [1409][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0478 (0.0478)	
0.9999937 1.6412853e-06
Epoch: [1409][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0404 (0.0590)	
0.9999926 1.9934441e-06
Epoch: [1409][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1101 (0.0598)	
0.9999895 1.1002002e-06
loss:  0.04018623366856411 0.03858705330121737
===========>   training    <===========
Epoch: [1410][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0429 (0.0429)	
0.9999945 1.8383643e-06
===========>   testing    <===========
Epoch: [1410][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0431 (0.0431)	
0.9999926 1.6246858e-06
Epoch: [1410][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0347 (0.0591)	
0.9999918 2.0288917e-06
Epoch: [1410][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1091 (0.0600)	
0.99998975 1.633096e-06
loss:  0.040568014841300015 0.03858705330121737
===========>   training    <===========
Epoch: [1411][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0366 (0.0366)	
0.9999864 7.575974e-07
===========>   testing    <===========
Epoch: [1411][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0429 (0.0429)	
0.99999344 1.732936e-06
Epoch: [1411][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0404 (0.0606)	
0.99999297 2.0042905e-06
Epoch: [1411][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0998 (0.0593)	
0.9999912 1.7183422e-06
loss:  0.04049907602033331 0.03858705330121737
===========>   training    <===========
Epoch: [1412][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0324 (0.0324)	
0.99999595 1.6550559e-06
===========>   testing    <===========
Epoch: [1412][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0383 (0.0383)	
0.9999938 1.9651684e-06
Epoch: [1412][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0307 (0.0604)	
0.9999939 2.7481112e-06
Epoch: [1412][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0915 (0.0593)	
0.99999213 1.938665e-06
loss:  0.040240018335110594 0.03858705330121737
===========>   training    <===========
Epoch: [1413][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0358 (0.0358)	
0.9999883 4.847339e-06
===========>   testing    <===========
Epoch: [1413][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0500 (0.0500)	
0.99999297 1.5184346e-06
Epoch: [1413][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0287 (0.0606)	
0.9999913 1.9909266e-06
Epoch: [1413][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1098 (0.0603)	
0.99999 1.5645567e-06
loss:  0.0403527124827463 0.03858705330121737
===========>   training    <===========
Epoch: [1414][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0340 (0.0340)	
0.9999927 5.1618936e-06
===========>   testing    <===========
Epoch: [1414][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0492 (0.0492)	
0.99999356 1.5455417e-06
Epoch: [1414][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0327 (0.0604)	
0.9999912 1.9624717e-06
Epoch: [1414][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1115 (0.0600)	
0.99999 1.5043754e-06
loss:  0.0405899030781367 0.03858705330121737
===========>   training    <===========
Epoch: [1415][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0342 (0.0342)	
0.9999882 4.8349657e-06
===========>   testing    <===========
Epoch: [1415][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0559 (0.0559)	
0.9999919 1.6827169e-06
Epoch: [1415][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0489 (0.0597)	
0.9999896 2.0727532e-06
Epoch: [1415][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1174 (0.0586)	
0.99998915 1.5981283e-06
loss:  0.04080000328420974 0.03858705330121737
===========>   training    <===========
Epoch: [1416][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0288 (0.0288)	
0.999995 2.379318e-06
===========>   testing    <===========
Epoch: [1416][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0520 (0.0520)	
0.99999046 1.5057433e-06
Epoch: [1416][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0467 (0.0595)	
0.9999863 1.8593566e-06
Epoch: [1416][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1079 (0.0586)	
0.99998677 1.3538769e-06
loss:  0.040401003382014244 0.03858705330121737
===========>   training    <===========
Epoch: [1417][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0355 (0.0355)	
0.9999939 1.6558644e-06
===========>   testing    <===========
Epoch: [1417][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0508 (0.0508)	
0.9999938 2.0099892e-06
Epoch: [1417][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0311 (0.0599)	
0.9999927 2.583848e-06
Epoch: [1417][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1029 (0.0595)	
0.99999213 1.7193684e-06
loss:  0.04007023958389422 0.03858705330121737
===========>   training    <===========
Epoch: [1418][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0311 (0.0311)	
0.99999213 1.8001305e-06
===========>   testing    <===========
Epoch: [1418][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0588 (0.0588)	
0.99999213 1.4628376e-06
Epoch: [1418][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0444 (0.0602)	
0.99998903 1.8748119e-06
Epoch: [1418][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0921 (0.0584)	
0.9999887 1.1498328e-06
loss:  0.04053114367720112 0.03858705330121737
===========>   training    <===========
Epoch: [1419][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0379 (0.0379)	
0.99998283 3.67848e-07
===========>   testing    <===========
Epoch: [1419][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0621 (0.0621)	
0.9999913 1.4389419e-06
Epoch: [1419][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0543 (0.0607)	
0.9999895 1.823877e-06
Epoch: [1419][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0664 (0.0582)	
0.9999864 1.3574245e-06
loss:  0.0408034913764751 0.03858705330121737
===========>   training    <===========
Epoch: [1420][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0349 (0.0349)	
0.99999285 2.2207064e-06
===========>   testing    <===========
Epoch: [1420][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0585 (0.0585)	
0.9999924 1.7017519e-06
Epoch: [1420][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0480 (0.0608)	
0.99999154 2.1217186e-06
Epoch: [1420][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0776 (0.0588)	
0.9999908 1.870112e-06
loss:  0.040908236403012666 0.03858705330121737
===========>   training    <===========
Epoch: [1421][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0333 (0.0333)	
0.999997 8.195534e-07
===========>   testing    <===========
Epoch: [1421][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0517 (0.0517)	
0.99999166 1.6953e-06
Epoch: [1421][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0449 (0.0597)	
0.9999908 2.1584979e-06
Epoch: [1421][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0642 (0.0581)	
0.99998903 1.9063967e-06
loss:  0.04038613612106334 0.03858705330121737
===========>   training    <===========
Epoch: [1422][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0390 (0.0390)	
0.9999927 3.0110386e-06
===========>   testing    <===========
Epoch: [1422][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0472 (0.0472)	
0.99999106 1.5871682e-06
Epoch: [1422][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0328 (0.0603)	
0.99999106 2.1992407e-06
Epoch: [1422][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0752 (0.0592)	
0.99998856 1.72488e-06
loss:  0.040458098988819136 0.03858705330121737
===========>   training    <===========
Epoch: [1423][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0352 (0.0352)	
0.99999666 2.3647342e-06
===========>   testing    <===========
Epoch: [1423][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0410 (0.0410)	
0.9999925 1.6051239e-06
Epoch: [1423][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0375 (0.0601)	
0.9999902 2.1542514e-06
Epoch: [1423][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0643 (0.0600)	
0.9999876 1.7629977e-06
loss:  0.04035831687254632 0.03858705330121737
===========>   training    <===========
Epoch: [1424][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0334 (0.0334)	
0.99999106 1.1005853e-06
===========>   testing    <===========
Epoch: [1424][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0399 (0.0399)	
0.99999213 1.568224e-06
Epoch: [1424][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0324 (0.0587)	
0.9999893 2.0244406e-06
Epoch: [1424][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0652 (0.0585)	
0.99998724 1.7054009e-06
loss:  0.03995174444227456 0.03858705330121737
===========>   training    <===========
Epoch: [1425][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0316 (0.0316)	
0.99998665 4.245468e-07
===========>   testing    <===========
Epoch: [1425][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0454 (0.0454)	
0.99999464 1.8008035e-06
Epoch: [1425][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0329 (0.0592)	
0.9999926 2.5333504e-06
Epoch: [1425][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0643 (0.0590)	
0.9999918 2.0969358e-06
loss:  0.03991374527152325 0.03858705330121737
===========>   training    <===========
Epoch: [1426][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0376 (0.0376)	
0.99998546 8.40398e-07
===========>   testing    <===========
Epoch: [1426][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0408 (0.0408)	
0.9999933 1.7640724e-06
Epoch: [1426][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0208 (0.0594)	
0.99999106 2.285189e-06
Epoch: [1426][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0675 (0.0596)	
0.9999902 1.6403981e-06
loss:  0.04009455119280325 0.03858705330121737
===========>   training    <===========
Epoch: [1427][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0327 (0.0327)	
0.99999523 1.8512212e-06
===========>   testing    <===========
Epoch: [1427][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0389 (0.0389)	
0.99999404 1.5517062e-06
Epoch: [1427][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0257 (0.0594)	
0.9999913 1.9648799e-06
Epoch: [1427][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0626 (0.0598)	
0.99999094 1.3311238e-06
loss:  0.04006704768867175 0.03858705330121737
===========>   training    <===========
Epoch: [1428][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0465 (0.0465)	
0.99999404 1.1871393e-06
===========>   testing    <===========
Epoch: [1428][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0497 (0.0497)	
0.9999937 1.4902048e-06
Epoch: [1428][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0295 (0.0592)	
0.9999908 2.0891907e-06
Epoch: [1428][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0692 (0.0593)	
0.9999907 1.4485082e-06
loss:  0.04034259921612038 0.03858705330121737
===========>   training    <===========
Epoch: [1429][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0345 (0.0345)	
0.99999106 1.4936509e-06
===========>   testing    <===========
Epoch: [1429][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0412 (0.0412)	
0.9999932 1.5447195e-06
Epoch: [1429][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0340 (0.0587)	
0.99998784 1.9972347e-06
Epoch: [1429][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0675 (0.0592)	
0.9999887 1.4771084e-06
loss:  0.04001176430517006 0.03858705330121737
===========>   training    <===========
Epoch: [1430][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0362 (0.0362)	
0.99999654 2.7407489e-06
===========>   testing    <===========
Epoch: [1430][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0411 (0.0411)	
0.9999924 1.5020073e-06
Epoch: [1430][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0312 (0.0590)	
0.9999819 1.6901955e-06
Epoch: [1430][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0693 (0.0592)	
0.99998367 1.1777729e-06
loss:  0.040401296269268805 0.03858705330121737
===========>   training    <===========
Epoch: [1431][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0354 (0.0354)	
0.99999034 1.4393414e-06
===========>   testing    <===========
Epoch: [1431][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0424 (0.0424)	
0.9999926 1.5098659e-06
Epoch: [1431][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0280 (0.0599)	
0.99998903 1.8322488e-06
Epoch: [1431][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0642 (0.0584)	
0.9999877 1.5155398e-06
loss:  0.03948702984432795 0.03858705330121737
===========>   training    <===========
Epoch: [1432][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0318 (0.0318)	
0.9999958 3.5260985e-06
===========>   testing    <===========
Epoch: [1432][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0462 (0.0462)	
0.99999166 1.4982047e-06
Epoch: [1432][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0289 (0.0609)	
0.99998736 1.8287382e-06
Epoch: [1432][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0691 (0.0590)	
0.9999857 1.6281663e-06
loss:  0.04014246886037398 0.03858705330121737
===========>   training    <===========
Epoch: [1433][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0421 (0.0421)	
0.9999937 2.3545695e-06
===========>   testing    <===========
Epoch: [1433][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0537 (0.0537)	
0.99999213 1.7013349e-06
Epoch: [1433][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0365 (0.0623)	
0.9999925 2.2053378e-06
Epoch: [1433][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0661 (0.0600)	
0.99999094 1.9563984e-06
loss:  0.04046327268040617 0.03858705330121737
===========>   training    <===========
Epoch: [1434][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0368 (0.0368)	
0.99998343 7.194794e-07
===========>   testing    <===========
Epoch: [1434][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0502 (0.0502)	
0.9999914 1.5919403e-06
Epoch: [1434][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0396 (0.0606)	
0.99998784 1.8211326e-06
Epoch: [1434][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0821 (0.0589)	
0.99998343 1.2725387e-06
loss:  0.040214734570331534 0.03858705330121737
===========>   training    <===========
Epoch: [1435][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0342 (0.0342)	
0.99999404 2.6528983e-06
===========>   testing    <===========
Epoch: [1435][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0448 (0.0448)	
0.99999285 1.5273521e-06
Epoch: [1435][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0464 (0.0610)	
0.9999924 1.9624342e-06
Epoch: [1435][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0796 (0.0592)	
0.9999906 1.3620046e-06
loss:  0.04055242232135314 0.03858705330121737
===========>   training    <===========
Epoch: [1436][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0350 (0.0350)	
0.99999356 1.7894191e-06
===========>   testing    <===========
Epoch: [1436][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0419 (0.0419)	
0.99999344 1.5253432e-06
Epoch: [1436][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0580 (0.0609)	
0.9999918 1.8944385e-06
Epoch: [1436][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0667 (0.0591)	
0.9999901 1.4257303e-06
loss:  0.0401435428025706 0.03858705330121737
===========>   training    <===========
Epoch: [1437][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0381 (0.0381)	
0.9999924 1.4849984e-06
===========>   testing    <===========
Epoch: [1437][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0400 (0.0400)	
0.9999926 1.4600083e-06
Epoch: [1437][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0661 (0.0601)	
0.9999913 1.7599269e-06
Epoch: [1437][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0671 (0.0593)	
0.99998784 1.4632116e-06
loss:  0.04067282913841752 0.03858705330121737
===========>   training    <===========
Epoch: [1438][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0377 (0.0377)	
0.99999 2.2459622e-06
===========>   testing    <===========
Epoch: [1438][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0492 (0.0492)	
0.9999932 1.2921937e-06
Epoch: [1438][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0477 (0.0604)	
0.99998915 1.4477514e-06
Epoch: [1438][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0660 (0.0596)	
0.9999862 1.2587739e-06
loss:  0.04107956916205413 0.03858705330121737
===========>   training    <===========
Epoch: [1439][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0519 (0.0519)	
0.9999765 1.0236661e-06
===========>   testing    <===========
Epoch: [1439][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0453 (0.0453)	
0.9999924 1.3527888e-06
Epoch: [1439][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0353 (0.0604)	
0.99999046 1.7603313e-06
Epoch: [1439][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0578 (0.0591)	
0.9999876 1.3820076e-06
loss:  0.04028846762181171 0.03858705330121737
===========>   training    <===========
Epoch: [1440][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0383 (0.0383)	
0.9999968 1.8387658e-06
===========>   testing    <===========
Epoch: [1440][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0371 (0.0371)	
0.99999344 1.3570517e-06
Epoch: [1440][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0301 (0.0601)	
0.99999225 1.7507732e-06
Epoch: [1440][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0595 (0.0592)	
0.99998975 1.4050742e-06
loss:  0.04044210222551303 0.03858705330121737
===========>   training    <===========
Epoch: [1441][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0308 (0.0308)	
0.99998903 1.3785666e-06
===========>   testing    <===========
Epoch: [1441][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0402 (0.0402)	
0.9999933 1.6072898e-06
Epoch: [1441][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0301 (0.0594)	
0.999992 2.0291163e-06
Epoch: [1441][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0709 (0.0591)	
0.9999881 1.1682063e-06
loss:  0.04053843671617152 0.03858705330121737
===========>   training    <===========
Epoch: [1442][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0346 (0.0346)	
0.9999877 1.2507782e-06
===========>   testing    <===========
Epoch: [1442][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0514 (0.0514)	
0.99999297 1.5841589e-06
Epoch: [1442][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0423 (0.0608)	
0.9999924 2.0054608e-06
Epoch: [1442][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0619 (0.0592)	
0.99998844 1.3606193e-06
loss:  0.04042643750550157 0.03858705330121737
===========>   training    <===========
Epoch: [1443][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0316 (0.0316)	
0.99999356 1.6583327e-06
===========>   testing    <===========
Epoch: [1443][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0327 (0.0327)	
0.9999938 1.7079677e-06
Epoch: [1443][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0300 (0.0592)	
0.9999933 2.3680584e-06
Epoch: [1443][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0657 (0.0596)	
0.99998987 1.7243932e-06
loss:  0.0400220702121894 0.03858705330121737
===========>   training    <===========
Epoch: [1444][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0271 (0.0271)	
0.9999908 1.7279771e-06
===========>   testing    <===========
Epoch: [1444][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0357 (0.0357)	
0.9999939 1.5715402e-06
Epoch: [1444][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0410 (0.0593)	
0.99999356 2.1380577e-06
Epoch: [1444][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0566 (0.0594)	
0.9999906 1.3437024e-06
loss:  0.04014952694699114 0.03858705330121737
===========>   training    <===========
Epoch: [1445][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0386 (0.0386)	
0.99999344 7.696453e-07
===========>   testing    <===========
Epoch: [1445][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0397 (0.0397)	
0.9999924 1.4689454e-06
Epoch: [1445][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0502 (0.0586)	
0.99999225 1.8201811e-06
Epoch: [1445][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0524 (0.0589)	
0.9999882 9.573657e-07
loss:  0.03964426576197155 0.03858705330121737
===========>   training    <===========
Epoch: [1446][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0372 (0.0372)	
0.9999914 1.868609e-05
===========>   testing    <===========
Epoch: [1446][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0405 (0.0405)	
0.9999933 1.526771e-06
Epoch: [1446][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0525 (0.0583)	
0.9999932 2.046744e-06
Epoch: [1446][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0490 (0.0584)	
0.9999893 1.7307492e-06
loss:  0.03957336512743115 0.03858705330121737
===========>   training    <===========
Epoch: [1447][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0383 (0.0383)	
0.99999225 2.0379089e-06
===========>   testing    <===========
Epoch: [1447][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0432 (0.0432)	
0.99999213 1.4536106e-06
Epoch: [1447][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0579 (0.0584)	
0.9999896 1.8485396e-06
Epoch: [1447][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0578 (0.0586)	
0.99998474 1.6257303e-06
loss:  0.04013565679863673 0.03858705330121737
===========>   training    <===========
Epoch: [1448][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0312 (0.0312)	
0.9999974 5.901689e-06
===========>   testing    <===========
Epoch: [1448][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0433 (0.0433)	
0.9999943 1.5899254e-06
Epoch: [1448][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0395 (0.0592)	
0.9999924 2.32843e-06
Epoch: [1448][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0739 (0.0592)	
0.99999034 1.95896e-06
loss:  0.04020276373498477 0.03858705330121737
===========>   training    <===========
Epoch: [1449][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0302 (0.0302)	
0.9999876 1.968642e-06
===========>   testing    <===========
Epoch: [1449][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0367 (0.0367)	
0.99999213 1.5138843e-06
Epoch: [1449][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0343 (0.0582)	
0.99999285 2.0124385e-06
Epoch: [1449][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0615 (0.0585)	
0.9999906 1.6813757e-06
loss:  0.03966743342877588 0.03858705330121737
===========>   training    <===========
Epoch: [1450][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0339 (0.0339)	
0.9999889 1.2059295e-06
===========>   testing    <===========
Epoch: [1450][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0369 (0.0369)	
0.9999919 1.4589505e-06
Epoch: [1450][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0342 (0.0582)	
0.99999106 1.8017759e-06
Epoch: [1450][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0608 (0.0590)	
0.9999895 1.6172331e-06
loss:  0.03988762492568543 0.03858705330121737
===========>   training    <===========
Epoch: [1451][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0346 (0.0346)	
0.99999154 5.519914e-07
===========>   testing    <===========
Epoch: [1451][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0390 (0.0390)	
0.9999925 1.5415671e-06
Epoch: [1451][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0333 (0.0588)	
0.99999106 1.8914382e-06
Epoch: [1451][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0686 (0.0598)	
0.99999 1.7093951e-06
loss:  0.040294677520427036 0.03858705330121737
===========>   training    <===========
Epoch: [1452][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0401 (0.0401)	
0.9999938 1.3556082e-06
===========>   testing    <===========
Epoch: [1452][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0374 (0.0374)	
0.9999924 1.4355016e-06
Epoch: [1452][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0305 (0.0584)	
0.99999046 1.7425613e-06
Epoch: [1452][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0616 (0.0590)	
0.99998796 1.4642487e-06
loss:  0.04028582709366524 0.03858705330121737
===========>   training    <===========
Epoch: [1453][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0306 (0.0306)	
0.9999951 2.7833382e-06
===========>   testing    <===========
Epoch: [1453][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0454 (0.0454)	
0.9999939 1.8421094e-06
Epoch: [1453][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0389 (0.0607)	
0.9999931 2.231474e-06
Epoch: [1453][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0593 (0.0594)	
0.99999213 2.0932034e-06
loss:  0.040369430661512995 0.03858705330121737
===========>   training    <===========
Epoch: [1454][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0374 (0.0374)	
0.9999912 2.9916894e-06
===========>   testing    <===========
Epoch: [1454][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0466 (0.0466)	
0.9999927 1.7134199e-06
Epoch: [1454][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0292 (0.0601)	
0.99999154 2.062604e-06
Epoch: [1454][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0618 (0.0593)	
0.9999908 1.8680479e-06
loss:  0.04009492945955151 0.03858705330121737
===========>   training    <===========
Epoch: [1455][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0466 (0.0466)	
0.9999957 6.3010093e-06
===========>   testing    <===========
Epoch: [1455][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0434 (0.0434)	
0.99999154 1.8087898e-06
Epoch: [1455][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0299 (0.0595)	
0.9999912 2.113215e-06
Epoch: [1455][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0538 (0.0589)	
0.9999907 1.8094627e-06
loss:  0.04015164322335796 0.03858705330121737
===========>   training    <===========
Epoch: [1456][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0346 (0.0346)	
0.9999702 6.417285e-07
===========>   testing    <===========
Epoch: [1456][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0397 (0.0397)	
0.999992 1.8395182e-06
Epoch: [1456][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0254 (0.0594)	
0.9999918 2.1281244e-06
Epoch: [1456][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0739 (0.0587)	
0.9999912 1.7926062e-06
loss:  0.03973929068848081 0.03858705330121737
===========>   training    <===========
Epoch: [1457][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0424 (0.0424)	
0.9999858 1.6617239e-06
===========>   testing    <===========
Epoch: [1457][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0469 (0.0469)	
0.9999949 1.5888068e-06
Epoch: [1457][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0244 (0.0596)	
0.9999943 2.1549047e-06
Epoch: [1457][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0690 (0.0586)	
0.9999933 1.7636232e-06
loss:  0.03973688485940008 0.03858705330121737
===========>   training    <===========
Epoch: [1458][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0389 (0.0389)	
0.9999924 1.8361706e-06
===========>   testing    <===========
Epoch: [1458][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0471 (0.0471)	
0.99999404 1.5885416e-06
Epoch: [1458][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0231 (0.0600)	
0.99999356 2.0746181e-06
Epoch: [1458][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0708 (0.0594)	
0.99999154 1.7335575e-06
loss:  0.039990078187943534 0.03858705330121737
===========>   training    <===========
Epoch: [1459][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0274 (0.0274)	
0.99998987 2.1852395e-06
===========>   testing    <===========
Epoch: [1459][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0501 (0.0501)	
0.9999913 1.624726e-06
Epoch: [1459][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0215 (0.0596)	
0.99999046 1.9563554e-06
Epoch: [1459][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0843 (0.0592)	
0.99998665 1.6460098e-06
loss:  0.04030536678986629 0.03858705330121737
===========>   training    <===========
Epoch: [1460][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0353 (0.0353)	
0.99999523 2.3769753e-06
===========>   testing    <===========
Epoch: [1460][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0375 (0.0375)	
0.9999913 1.495136e-06
Epoch: [1460][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0235 (0.0595)	
0.9999907 1.7904227e-06
Epoch: [1460][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0854 (0.0598)	
0.9999871 1.5264318e-06
loss:  0.040967763068060714 0.03858705330121737
===========>   training    <===========
Epoch: [1461][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0370 (0.0370)	
0.9999937 5.101738e-07
===========>   testing    <===========
Epoch: [1461][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0539 (0.0539)	
0.9999924 1.5562484e-06
Epoch: [1461][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0271 (0.0605)	
0.9999906 1.8341404e-06
Epoch: [1461][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0850 (0.0596)	
0.99998784 1.6143069e-06
loss:  0.04089507290929395 0.03858705330121737
===========>   training    <===========
Epoch: [1462][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0294 (0.0294)	
0.99999726 1.1261906e-06
===========>   testing    <===========
Epoch: [1462][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0563 (0.0563)	
0.9999919 1.5740632e-06
Epoch: [1462][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0252 (0.0606)	
0.99999106 1.9737759e-06
Epoch: [1462][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0744 (0.0591)	
0.9999889 1.7342719e-06
loss:  0.04032799384455277 0.03858705330121737
===========>   training    <===========
Epoch: [1463][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0355 (0.0355)	
0.99999106 7.515721e-07
===========>   testing    <===========
Epoch: [1463][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0431 (0.0431)	
0.99999154 1.6579154e-06
Epoch: [1463][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0242 (0.0602)	
0.99999034 2.1264425e-06
Epoch: [1463][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0658 (0.0590)	
0.9999877 1.9408144e-06
loss:  0.03973154028615744 0.03858705330121737
===========>   training    <===========
Epoch: [1464][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0447 (0.0447)	
0.9999795 9.187058e-07
===========>   testing    <===========
Epoch: [1464][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0483 (0.0483)	
0.9999925 1.5976345e-06
Epoch: [1464][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0292 (0.0601)	
0.9999914 2.044243e-06
Epoch: [1464][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0681 (0.0589)	
0.9999889 1.8085483e-06
loss:  0.03990587677361335 0.03858705330121737
===========>   training    <===========
Epoch: [1465][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0293 (0.0293)	
0.9999938 6.8362215e-06
===========>   testing    <===========
Epoch: [1465][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0436 (0.0436)	
0.9999933 1.6695773e-06
Epoch: [1465][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0230 (0.0598)	
0.9999925 2.3382051e-06
Epoch: [1465][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0751 (0.0592)	
0.9999914 2.1097273e-06
loss:  0.04017770679506927 0.03858705330121737
===========>   training    <===========
Epoch: [1466][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0335 (0.0335)	
0.99998665 7.194945e-07
===========>   testing    <===========
Epoch: [1466][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0533 (0.0533)	
0.99999225 1.6222951e-06
Epoch: [1466][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0224 (0.0602)	
0.9999931 1.99781e-06
Epoch: [1466][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0866 (0.0599)	
0.9999895 1.6863748e-06
loss:  0.04060655219866416 0.03858705330121737
===========>   training    <===========
Epoch: [1467][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0474 (0.0474)	
0.9999901 1.3825586e-06
===========>   testing    <===========
Epoch: [1467][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0458 (0.0458)	
0.9999931 1.663238e-06
Epoch: [1467][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0263 (0.0595)	
0.9999931 2.141584e-06
Epoch: [1467][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0655 (0.0596)	
0.9999912 1.8079137e-06
loss:  0.04051435740171405 0.03858705330121737
===========>   training    <===========
Epoch: [1468][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0348 (0.0348)	
0.9999962 4.1813814e-06
===========>   testing    <===========
Epoch: [1468][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0439 (0.0439)	
0.99999297 1.6686685e-06
Epoch: [1468][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0268 (0.0596)	
0.99999213 2.0259818e-06
Epoch: [1468][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0779 (0.0592)	
0.9999894 1.7611274e-06
loss:  0.04039562916002293 0.03858705330121737
===========>   training    <===========
Epoch: [1469][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0396 (0.0396)	
0.99998736 1.1500214e-06
===========>   testing    <===========
Epoch: [1469][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0449 (0.0449)	
0.99999213 1.6474106e-06
Epoch: [1469][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0232 (0.0590)	
0.9999894 1.7430731e-06
Epoch: [1469][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0816 (0.0593)	
0.9999864 1.5976057e-06
loss:  0.04024041799850886 0.03858705330121737
===========>   training    <===========
Epoch: [1470][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0415 (0.0415)	
0.9999906 1.6249027e-06
===========>   testing    <===========
Epoch: [1470][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0480 (0.0480)	
0.99999166 1.6936889e-06
Epoch: [1470][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0368 (0.0592)	
0.99999154 2.068403e-06
Epoch: [1470][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0594 (0.0584)	
0.99998856 1.825941e-06
loss:  0.04013329448823799 0.03858705330121737
===========>   training    <===========
Epoch: [1471][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0328 (0.0328)	
0.99998426 3.1790358e-07
===========>   testing    <===========
Epoch: [1471][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0478 (0.0478)	
0.9999925 1.6169602e-06
Epoch: [1471][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0288 (0.0595)	
0.9999902 1.7878394e-06
Epoch: [1471][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0772 (0.0594)	
0.9999875 1.7043343e-06
loss:  0.04076415831443281 0.03858705330121737
===========>   training    <===========
Epoch: [1472][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0324 (0.0324)	
0.99998486 9.0614e-07
===========>   testing    <===========
Epoch: [1472][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0459 (0.0459)	
0.9999924 1.7219808e-06
Epoch: [1472][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0295 (0.0590)	
0.99999034 1.9698552e-06
Epoch: [1472][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0697 (0.0587)	
0.99998784 1.7231619e-06
loss:  0.040272266638040954 0.03858705330121737
===========>   training    <===========
Epoch: [1473][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0332 (0.0332)	
0.9999927 1.7991418e-06
===========>   testing    <===========
Epoch: [1473][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0443 (0.0443)	
0.99999297 1.902753e-06
Epoch: [1473][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0289 (0.0584)	
0.99999154 2.137238e-06
Epoch: [1473][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0705 (0.0588)	
0.99998903 1.7883852e-06
loss:  0.03967493880337658 0.03858705330121737
===========>   training    <===========
Epoch: [1474][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0321 (0.0321)	
0.9999876 1.7473138e-06
===========>   testing    <===========
Epoch: [1474][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0404 (0.0404)	
0.99999297 1.8525104e-06
Epoch: [1474][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0235 (0.0588)	
0.9999912 1.9548168e-06
Epoch: [1474][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0714 (0.0592)	
0.99998844 1.8912073e-06
loss:  0.03988019533539544 0.03858705330121737
===========>   training    <===========
Epoch: [1475][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0384 (0.0384)	
0.9999882 7.342396e-07
===========>   testing    <===========
Epoch: [1475][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0489 (0.0489)	
0.9999926 1.8277774e-06
Epoch: [1475][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0231 (0.0597)	
0.99998987 1.9583883e-06
Epoch: [1475][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0573 (0.0588)	
0.9999858 1.6083602e-06
loss:  0.04043822999786151 0.03858705330121737
===========>   training    <===========
Epoch: [1476][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0348 (0.0348)	
0.99999166 1.9472106e-06
===========>   testing    <===========
Epoch: [1476][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0509 (0.0509)	
0.9999943 1.8238632e-06
Epoch: [1476][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0218 (0.0587)	
0.9999925 2.37013e-06
Epoch: [1476][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0622 (0.0590)	
0.99998915 2.0307868e-06
loss:  0.040292532515461166 0.03858705330121737
===========>   training    <===========
Epoch: [1477][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0375 (0.0375)	
0.9999927 2.850074e-06
===========>   testing    <===========
Epoch: [1477][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0504 (0.0504)	
0.99999213 1.5358456e-06
Epoch: [1477][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0247 (0.0587)	
0.9999895 1.7615356e-06
Epoch: [1477][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0800 (0.0593)	
0.99998426 1.2970484e-06
loss:  0.040456877525975155 0.03858705330121737
===========>   training    <===========
Epoch: [1478][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0315 (0.0315)	
0.9999924 1.0209878e-06
===========>   testing    <===========
Epoch: [1478][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0468 (0.0468)	
0.9999914 1.4531905e-06
Epoch: [1478][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0243 (0.0590)	
0.99998844 1.73939e-06
Epoch: [1478][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0803 (0.0591)	
0.9999831 1.4668358e-06
loss:  0.040590580646671204 0.03858705330121737
===========>   training    <===========
Epoch: [1479][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0376 (0.0376)	
0.9999914 1.5745885e-06
===========>   testing    <===========
Epoch: [1479][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0463 (0.0463)	
0.99999344 1.6026581e-06
Epoch: [1479][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0288 (0.0595)	
0.9999908 1.990904e-06
Epoch: [1479][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0747 (0.0591)	
0.99998665 1.6885054e-06
loss:  0.040166842333295705 0.03858705330121737
===========>   training    <===========
Epoch: [1480][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0386 (0.0386)	
0.9999809 1.3850185e-06
===========>   testing    <===========
Epoch: [1480][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0460 (0.0460)	
0.99999166 1.6932319e-06
Epoch: [1480][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0320 (0.0609)	
0.99999046 2.0063446e-06
Epoch: [1480][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0589 (0.0597)	
0.9999865 1.7899039e-06
loss:  0.0406437161603046 0.03858705330121737
===========>   training    <===========
Epoch: [1481][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0316 (0.0316)	
0.9999931 1.3151441e-06
===========>   testing    <===========
Epoch: [1481][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0401 (0.0401)	
0.99999285 1.7208711e-06
Epoch: [1481][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0261 (0.0609)	
0.99999166 2.0314299e-06
Epoch: [1481][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0730 (0.0608)	
0.9999887 1.8095678e-06
loss:  0.040687070364472055 0.03858705330121737
===========>   training    <===========
Epoch: [1482][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0352 (0.0352)	
0.99999356 2.1460737e-06
===========>   testing    <===========
Epoch: [1482][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0363 (0.0363)	
0.99999297 1.6882673e-06
Epoch: [1482][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0269 (0.0597)	
0.9999912 1.9497118e-06
Epoch: [1482][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0635 (0.0601)	
0.9999871 1.8428175e-06
loss:  0.04019393845156416 0.03858705330121737
===========>   training    <===========
Epoch: [1483][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0322 (0.0322)	
0.99999654 4.283812e-07
===========>   testing    <===========
Epoch: [1483][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0429 (0.0429)	
0.9999925 1.5523485e-06
Epoch: [1483][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0286 (0.0597)	
0.99998903 1.6943319e-06
Epoch: [1483][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0587 (0.0599)	
0.99998605 1.5382922e-06
loss:  0.04011882828537627 0.03858705330121737
===========>   training    <===========
Epoch: [1484][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0355 (0.0355)	
0.99999726 3.1972817e-07
===========>   testing    <===========
Epoch: [1484][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0416 (0.0416)	
0.9999919 1.6508675e-06
Epoch: [1484][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0287 (0.0605)	
0.99999034 1.9293673e-06
Epoch: [1484][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0639 (0.0609)	
0.999987 1.7282308e-06
loss:  0.04051859793624435 0.03858705330121737
===========>   training    <===========
Epoch: [1485][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0355 (0.0355)	
0.9999776 1.5517654e-06
===========>   testing    <===========
Epoch: [1485][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0423 (0.0423)	
0.99999154 1.6828579e-06
Epoch: [1485][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0275 (0.0598)	
0.99999094 2.0372054e-06
Epoch: [1485][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0558 (0.0598)	
0.99998856 1.8313614e-06
loss:  0.039765164601882286 0.03858705330121737
===========>   training    <===========
Epoch: [1486][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0331 (0.0331)	
0.9999931 7.510915e-06
===========>   testing    <===========
Epoch: [1486][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0484 (0.0484)	
0.99999213 1.8167976e-06
Epoch: [1486][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0262 (0.0600)	
0.9999919 2.401932e-06
Epoch: [1486][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0581 (0.0599)	
0.9999902 2.159165e-06
loss:  0.04038243047129009 0.03858705330121737
===========>   training    <===========
Epoch: [1487][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0328 (0.0328)	
0.99999166 1.4752178e-06
===========>   testing    <===========
Epoch: [1487][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0506 (0.0506)	
0.9999925 1.6967202e-06
Epoch: [1487][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0254 (0.0600)	
0.9999912 2.158148e-06
Epoch: [1487][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0707 (0.0602)	
0.99998856 2.0395848e-06
loss:  0.040397485109013864 0.03858705330121737
===========>   training    <===========
Epoch: [1488][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0323 (0.0323)	
0.99999654 1.360801e-06
===========>   testing    <===========
Epoch: [1488][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0500 (0.0500)	
0.9999938 1.6319191e-06
Epoch: [1488][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0249 (0.0591)	
0.99999213 1.9836377e-06
Epoch: [1488][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0724 (0.0595)	
0.9999907 1.7728811e-06
loss:  0.040275610665861716 0.03858705330121737
===========>   training    <===========
Epoch: [1489][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0335 (0.0335)	
0.9999907 1.2190013e-06
===========>   testing    <===========
Epoch: [1489][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0552 (0.0552)	
0.9999924 1.7198997e-06
Epoch: [1489][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0337 (0.0589)	
0.9999902 1.9894178e-06
Epoch: [1489][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0547 (0.0585)	
0.9999876 1.7793278e-06
loss:  0.0395513296976423 0.03858705330121737
===========>   training    <===========
Epoch: [1490][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0345 (0.0345)	
0.99998856 8.542105e-07
===========>   testing    <===========
Epoch: [1490][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0537 (0.0537)	
0.9999939 1.9789761e-06
Epoch: [1490][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0263 (0.0595)	
0.9999924 2.6265761e-06
Epoch: [1490][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0780 (0.0592)	
0.9999912 2.4189362e-06
loss:  0.040075481296035664 0.03858705330121737
===========>   training    <===========
Epoch: [1491][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0335 (0.0335)	
0.9999938 3.2083535e-05
===========>   testing    <===========
Epoch: [1491][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0566 (0.0566)	
0.9999937 1.8908646e-06
Epoch: [1491][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0282 (0.0595)	
0.9999918 2.5639629e-06
Epoch: [1491][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0821 (0.0589)	
0.99998987 2.2926197e-06
loss:  0.03987375740605614 0.03858705330121737
===========>   training    <===========
Epoch: [1492][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0329 (0.0329)	
0.9999957 3.7423456e-06
===========>   testing    <===========
Epoch: [1492][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0535 (0.0535)	
0.9999932 1.7032652e-06
Epoch: [1492][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0277 (0.0595)	
0.99999106 2.1156468e-06
Epoch: [1492][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0960 (0.0599)	
0.99998844 1.899725e-06
loss:  0.0403531090785636 0.03858705330121737
===========>   training    <===========
Epoch: [1493][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0320 (0.0320)	
0.9999949 1.9397467e-06
===========>   testing    <===========
Epoch: [1493][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0503 (0.0503)	
0.9999944 1.7560071e-06
Epoch: [1493][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0296 (0.0592)	
0.9999925 2.2970185e-06
Epoch: [1493][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0722 (0.0589)	
0.99999154 1.8831516e-06
loss:  0.040029216590343086 0.03858705330121737
===========>   training    <===========
Epoch: [1494][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0314 (0.0314)	
0.9999924 2.88936e-06
===========>   testing    <===========
Epoch: [1494][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0531 (0.0531)	
0.99999154 1.6330057e-06
Epoch: [1494][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0356 (0.0586)	
0.9999889 1.7567709e-06
Epoch: [1494][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0728 (0.0586)	
0.99998605 1.5509088e-06
loss:  0.039756464033385286 0.03858705330121737
===========>   training    <===========
Epoch: [1495][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0322 (0.0322)	
0.9999933 6.6762425e-07
===========>   testing    <===========
Epoch: [1495][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0442 (0.0442)	
0.9999925 1.643008e-06
Epoch: [1495][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0314 (0.0598)	
0.99999046 1.8514137e-06
Epoch: [1495][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0790 (0.0593)	
0.9999889 1.620687e-06
loss:  0.04040987492115111 0.03858705330121737
===========>   training    <===========
Epoch: [1496][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0359 (0.0359)	
0.9999958 5.51501e-07
===========>   testing    <===========
Epoch: [1496][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0421 (0.0421)	
0.9999927 1.6654363e-06
Epoch: [1496][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0332 (0.0594)	
0.999992 2.0132716e-06
Epoch: [1496][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0718 (0.0591)	
0.9999912 1.7686257e-06
loss:  0.03982477779476001 0.03858705330121737
===========>   training    <===========
Epoch: [1497][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0399 (0.0399)	
0.99999094 1.4835929e-06
===========>   testing    <===========
Epoch: [1497][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0418 (0.0418)	
0.9999926 1.7270759e-06
Epoch: [1497][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0399 (0.0595)	
0.999992 2.0952325e-06
Epoch: [1497][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0773 (0.0589)	
0.9999913 1.7557459e-06
loss:  0.040115289194080805 0.03858705330121737
===========>   training    <===========
Epoch: [1498][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0406 (0.0406)	
0.9999939 3.3975482e-06
===========>   testing    <===========
Epoch: [1498][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0391 (0.0391)	
0.9999913 1.7012992e-06
Epoch: [1498][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0318 (0.0586)	
0.9999906 1.9828376e-06
Epoch: [1498][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0832 (0.0581)	
0.9999889 1.699658e-06
loss:  0.039484979697315126 0.03858705330121737
===========>   training    <===========
Epoch: [1499][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0288 (0.0288)	
0.99999547 2.4662781e-06
===========>   testing    <===========
Epoch: [1499][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0405 (0.0405)	
0.9999938 1.62349e-06
Epoch: [1499][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0329 (0.0592)	
0.99999154 1.8264444e-06
Epoch: [1499][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0829 (0.0584)	
0.9999906 1.7120544e-06
loss:  0.039040466886654523 0.03858705330121737
===========>   training    <===========
Epoch: [1500][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0311 (0.0311)	
0.99999666 5.132128e-06
===========>   testing    <===========
Epoch: [1500][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0381 (0.0381)	
0.9999931 1.9946003e-06
Epoch: [1500][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0270 (0.0586)	
0.9999927 2.6559005e-06
Epoch: [1500][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0745 (0.0582)	
0.9999912 2.3014347e-06
loss:  0.03930416326413699 0.03858705330121737
===========>   training    <===========
Epoch: [1501][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0386 (0.0386)	
0.99999654 2.0740326e-06
===========>   testing    <===========
Epoch: [1501][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0314 (0.0314)	
0.99999225 1.7058043e-06
Epoch: [1501][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0277 (0.0585)	
0.9999889 1.9049354e-06
Epoch: [1501][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0726 (0.0579)	
0.9999889 1.6873256e-06
loss:  0.03913826885067462 0.03858705330121737
===========>   training    <===========
Epoch: [1502][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0360 (0.0360)	
0.99999785 2.5462798e-06
===========>   testing    <===========
Epoch: [1502][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0338 (0.0338)	
0.99999106 1.7802224e-06
Epoch: [1502][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0251 (0.0595)	
0.99998987 2.116773e-06
Epoch: [1502][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0794 (0.0581)	
0.99998844 1.9465867e-06
loss:  0.0391449288113388 0.03858705330121737
===========>   training    <===========
Epoch: [1503][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0353 (0.0353)	
0.99999845 3.9491542e-06
===========>   testing    <===========
Epoch: [1503][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0373 (0.0373)	
0.9999907 1.7356716e-06
Epoch: [1503][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0246 (0.0606)	
0.9999908 2.0464158e-06
Epoch: [1503][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0831 (0.0588)	
0.9999889 1.866723e-06
loss:  0.039359715097402215 0.03858705330121737
===========>   training    <===========
Epoch: [1504][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0355 (0.0355)	
0.9999819 1.0027675e-06
===========>   testing    <===========
Epoch: [1504][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0341 (0.0341)	
0.9999908 1.5469647e-06
Epoch: [1504][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0291 (0.0588)	
0.99998987 1.739901e-06
Epoch: [1504][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0809 (0.0583)	
0.99998784 1.5110442e-06
loss:  0.03911464356246874 0.03858705330121737
===========>   training    <===========
Epoch: [1505][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0314 (0.0314)	
0.9999852 2.8239094e-07
===========>   testing    <===========
Epoch: [1505][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0374 (0.0374)	
0.99999046 1.573919e-06
Epoch: [1505][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0334 (0.0592)	
0.9999907 1.92338e-06
Epoch: [1505][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0877 (0.0584)	
0.9999881 1.633794e-06
loss:  0.03921682807760063 0.03858705330121737
===========>   training    <===========
Epoch: [1506][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0335 (0.0335)	
0.99999547 8.6675095e-07
===========>   testing    <===========
Epoch: [1506][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0374 (0.0374)	
0.9999918 1.582735e-06
Epoch: [1506][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0392 (0.0597)	
0.9999906 1.8239172e-06
Epoch: [1506][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0997 (0.0592)	
0.99998903 1.5792581e-06
loss:  0.03984274906989205 0.03858705330121737
===========>   training    <===========
Epoch: [1507][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0336 (0.0336)	
0.9999844 1.3263603e-06
===========>   testing    <===========
Epoch: [1507][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0466 (0.0466)	
0.99999 1.7168123e-06
Epoch: [1507][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0412 (0.0597)	
0.99998605 1.7834986e-06
Epoch: [1507][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0745 (0.0583)	
0.9999863 1.7350824e-06
loss:  0.03937216494003404 0.03858705330121737
===========>   training    <===========
Epoch: [1508][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0374 (0.0374)	
0.99998987 1.2669939e-06
===========>   testing    <===========
Epoch: [1508][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0433 (0.0433)	
0.999992 1.7576843e-06
Epoch: [1508][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0394 (0.0595)	
0.9999889 1.9716142e-06
Epoch: [1508][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0682 (0.0580)	
0.99998844 1.9910995e-06
loss:  0.038773455757435404 0.03858705330121737
===========>   training    <===========
Epoch: [1509][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0309 (0.0309)	
0.9999932 1.6752168e-06
===========>   testing    <===========
Epoch: [1509][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0493 (0.0493)	
0.9999925 1.7380237e-06
Epoch: [1509][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0374 (0.0591)	
0.9999895 1.9557287e-06
Epoch: [1509][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0739 (0.0576)	
0.9999888 1.9087433e-06
loss:  0.03876192892963681 0.03858705330121737
===========>   training    <===========
Epoch: [1510][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0378 (0.0378)	
0.9999933 8.392431e-07
===========>   testing    <===========
Epoch: [1510][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0485 (0.0485)	
0.9999927 1.8196969e-06
Epoch: [1510][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0296 (0.0589)	
0.9999908 2.1098783e-06
Epoch: [1510][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0743 (0.0575)	
0.9999895 2.0220266e-06
loss:  0.03887280783805447 0.03858705330121737
===========>   training    <===========
Epoch: [1511][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0352 (0.0352)	
0.9999919 2.0760112e-06
===========>   testing    <===========
Epoch: [1511][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0475 (0.0475)	
0.9999908 1.660808e-06
Epoch: [1511][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0297 (0.0593)	
0.99998784 1.7893406e-06
Epoch: [1511][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0904 (0.0585)	
0.9999865 1.7172118e-06
loss:  0.039581096039121966 0.03858705330121737
===========>   training    <===========
Epoch: [1512][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0294 (0.0294)	
0.9999958 3.6850813e-07
===========>   testing    <===========
Epoch: [1512][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0516 (0.0516)	
0.9999927 1.6788954e-06
Epoch: [1512][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0291 (0.0593)	
0.99999034 1.8968864e-06
Epoch: [1512][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0838 (0.0582)	
0.9999888 1.7669785e-06
loss:  0.03965794901766451 0.03858705330121737
===========>   training    <===========
Epoch: [1513][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0310 (0.0310)	
0.9999927 2.8861652e-06
===========>   testing    <===========
Epoch: [1513][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0454 (0.0454)	
0.9999912 1.8059354e-06
Epoch: [1513][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0291 (0.0601)	
0.9999889 1.9031958e-06
Epoch: [1513][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0673 (0.0577)	
0.99998796 1.7606286e-06
loss:  0.03919890074620769 0.03858705330121737
===========>   training    <===========
Epoch: [1514][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0331 (0.0331)	
0.99999 8.73649e-07
===========>   testing    <===========
Epoch: [1514][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0409 (0.0409)	
0.99999034 1.7086224e-06
Epoch: [1514][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0239 (0.0589)	
0.99998796 1.7878634e-06
Epoch: [1514][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0782 (0.0581)	
0.99998605 1.5874981e-06
loss:  0.03902969742904161 0.03858705330121737
===========>   training    <===========
Epoch: [1515][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0383 (0.0383)	
0.9999894 1.8293102e-06
===========>   testing    <===========
Epoch: [1515][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0405 (0.0405)	
0.9999913 1.7968648e-06
Epoch: [1515][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0282 (0.0594)	
0.9999895 1.9493473e-06
Epoch: [1515][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0769 (0.0583)	
0.9999876 1.9274232e-06
loss:  0.03935473540688261 0.03858705330121737
===========>   training    <===========
Epoch: [1516][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0319 (0.0319)	
0.9999939 2.6214911e-06
===========>   testing    <===========
Epoch: [1516][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0450 (0.0450)	
0.99999213 1.7364117e-06
Epoch: [1516][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0310 (0.0592)	
0.9999901 2.0860894e-06
Epoch: [1516][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0854 (0.0582)	
0.9999888 1.9163235e-06
loss:  0.03908832859801192 0.03858705330121737
===========>   training    <===========
Epoch: [1517][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0341 (0.0341)	
0.9999939 1.0458799e-06
===========>   testing    <===========
Epoch: [1517][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0529 (0.0529)	
0.99999285 1.8366924e-06
Epoch: [1517][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0285 (0.0601)	
0.9999918 2.3183395e-06
Epoch: [1517][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0993 (0.0590)	
0.9999902 2.0981079e-06
loss:  0.039841791801453974 0.03858705330121737
===========>   training    <===========
Epoch: [1518][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0294 (0.0294)	
0.9999956 2.529635e-06
===========>   testing    <===========
Epoch: [1518][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0547 (0.0547)	
0.9999912 1.7162197e-06
Epoch: [1518][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0332 (0.0601)	
0.9999906 1.9712834e-06
Epoch: [1518][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0836 (0.0589)	
0.99998784 1.9008812e-06
loss:  0.03952501655308671 0.03858705330121737
===========>   training    <===========
Epoch: [1519][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0298 (0.0298)	
0.99999523 1.6073267e-06
===========>   testing    <===========
Epoch: [1519][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0436 (0.0436)	
0.9999918 1.7098777e-06
Epoch: [1519][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0253 (0.0585)	
0.99998987 1.9710428e-06
Epoch: [1519][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0844 (0.0583)	
0.9999875 1.6165994e-06
loss:  0.039750473569693856 0.03858705330121737
===========>   training    <===========
Epoch: [1520][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0325 (0.0325)	
0.9999969 4.2481024e-06
===========>   testing    <===========
Epoch: [1520][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0452 (0.0452)	
0.9999914 1.6613151e-06
Epoch: [1520][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0236 (0.0593)	
0.99998975 1.8659255e-06
Epoch: [1520][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.1044 (0.0591)	
0.999987 1.64822e-06
loss:  0.03945990759337603 0.03858705330121737
===========>   training    <===========
Epoch: [1521][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0492 (0.0492)	
0.99998856 6.7708567e-07
===========>   testing    <===========
Epoch: [1521][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0481 (0.0481)	
0.9999908 1.5351852e-06
Epoch: [1521][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0277 (0.0587)	
0.9999881 1.6431537e-06
Epoch: [1521][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0999 (0.0579)	
0.9999844 1.4636037e-06
loss:  0.03944723552786633 0.03858705330121737
===========>   training    <===========
Epoch: [1522][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0322 (0.0322)	
0.9999938 2.706277e-06
===========>   testing    <===========
Epoch: [1522][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0538 (0.0538)	
0.9999913 1.5053514e-06
Epoch: [1522][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0301 (0.0598)	
0.9999881 1.6960018e-06
Epoch: [1522][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0793 (0.0583)	
0.9999856 1.4701941e-06
loss:  0.039319486745830856 0.03858705330121737
===========>   training    <===========
Epoch: [1523][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0368 (0.0368)	
0.9999901 1.3177931e-06
===========>   testing    <===========
Epoch: [1523][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0547 (0.0547)	
0.99999106 1.6325168e-06
Epoch: [1523][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0218 (0.0605)	
0.9999901 1.8741006e-06
Epoch: [1523][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0942 (0.0593)	
0.9999875 1.8030066e-06
loss:  0.04024464532317518 0.03858705330121737
===========>   training    <===========
Epoch: [1524][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0268 (0.0268)	
0.999998 1.0396546e-06
===========>   testing    <===========
Epoch: [1524][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0440 (0.0440)	
0.99998975 1.5750031e-06
Epoch: [1524][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0246 (0.0597)	
0.9999887 1.8518215e-06
Epoch: [1524][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0885 (0.0603)	
0.9999856 1.5794222e-06
loss:  0.04060795171125542 0.03858705330121737
===========>   training    <===========
Epoch: [1525][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0441 (0.0441)	
0.9999796 9.823917e-07
===========>   testing    <===========
Epoch: [1525][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0446 (0.0446)	
0.9999918 1.5305483e-06
Epoch: [1525][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0235 (0.0598)	
0.99999034 1.808419e-06
Epoch: [1525][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0801 (0.0597)	
0.9999901 1.5711236e-06
loss:  0.04058471441202849 0.03858705330121737
===========>   training    <===========
Epoch: [1526][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0341 (0.0341)	
0.9999924 1.8761749e-06
===========>   testing    <===========
Epoch: [1526][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0402 (0.0402)	
0.9999907 1.7172872e-06
Epoch: [1526][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0275 (0.0594)	
0.99998987 1.9988734e-06
Epoch: [1526][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0789 (0.0589)	
0.99998844 1.7788358e-06
loss:  0.03988486337558439 0.03858705330121737
===========>   training    <===========
Epoch: [1527][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0383 (0.0383)	
0.99998665 3.6389616e-07
===========>   testing    <===========
Epoch: [1527][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0492 (0.0492)	
0.999992 1.6671811e-06
Epoch: [1527][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0271 (0.0597)	
0.9999901 1.98283e-06
Epoch: [1527][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0780 (0.0584)	
0.99998915 1.8135275e-06
loss:  0.039643081066342845 0.03858705330121737
===========>   training    <===========
Epoch: [1528][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0305 (0.0305)	
0.9999913 3.117963e-06
===========>   testing    <===========
Epoch: [1528][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0511 (0.0511)	
0.9999913 1.7812091e-06
Epoch: [1528][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0236 (0.0595)	
0.9999893 2.2014294e-06
Epoch: [1528][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0713 (0.0576)	
0.9999887 1.8960254e-06
loss:  0.03912341483380266 0.03858705330121737
===========>   training    <===========
Epoch: [1529][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0365 (0.0365)	
0.99999094 2.3181449e-06
===========>   testing    <===========
Epoch: [1529][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0474 (0.0474)	
0.999992 1.6804107e-06
Epoch: [1529][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0240 (0.0590)	
0.99999 2.1058938e-06
Epoch: [1529][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0852 (0.0572)	
0.99998844 1.7652841e-06
loss:  0.038643741892361194 0.03858705330121737
===========>   training    <===========
Epoch: [1530][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0327 (0.0327)	
0.99998975 1.8874451e-06
===========>   testing    <===========
Epoch: [1530][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0403 (0.0403)	
0.99999213 1.627117e-06
Epoch: [1530][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0257 (0.0573)	
0.99999213 2.1146484e-06
Epoch: [1530][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.1006 (0.0573)	
0.9999902 1.8481941e-06
loss:  0.03857940511798785 0.03858705330121737
===========>   training    <===========
Epoch: [1531][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0384 (0.0384)	
0.99998903 1.328605e-06
===========>   testing    <===========
Epoch: [1531][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0443 (0.0443)	
0.99999166 1.6460538e-06
Epoch: [1531][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0261 (0.0584)	
0.99999094 1.92369e-06
Epoch: [1531][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0753 (0.0574)	
0.99998987 1.748764e-06
loss:  0.038793857255133735 0.03857940511798785
===========>   training    <===========
Epoch: [1532][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0372 (0.0372)	
0.99998105 1.4472407e-06
===========>   testing    <===========
Epoch: [1532][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0369 (0.0369)	
0.99999034 1.6911323e-06
Epoch: [1532][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0296 (0.0583)	
0.99999106 2.0417801e-06
Epoch: [1532][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0954 (0.0574)	
0.9999902 1.8228598e-06
loss:  0.03911696289803723 0.03857940511798785
===========>   training    <===========
Epoch: [1533][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0365 (0.0365)	
0.99999297 1.9889303e-06
===========>   testing    <===========
Epoch: [1533][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0406 (0.0406)	
0.9999925 1.5218385e-06
Epoch: [1533][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0335 (0.0578)	
0.99999213 1.8554313e-06
Epoch: [1533][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0857 (0.0572)	
0.99999106 1.6701696e-06
loss:  0.03911288044242345 0.03857940511798785
===========>   training    <===========
Epoch: [1534][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0408 (0.0408)	
0.99998784 1.3904486e-06
===========>   testing    <===========
Epoch: [1534][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0425 (0.0425)	
0.9999914 1.5145471e-06
Epoch: [1534][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0323 (0.0594)	
0.99999 1.7675936e-06
Epoch: [1534][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0834 (0.0580)	
0.9999883 1.6528744e-06
loss:  0.03948078488212814 0.03857940511798785
===========>   training    <===========
Epoch: [1535][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0359 (0.0359)	
0.9999956 1.3846421e-06
===========>   testing    <===========
Epoch: [1535][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0474 (0.0474)	
0.99999106 1.6868074e-06
Epoch: [1535][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0355 (0.0603)	
0.999992 2.2807346e-06
Epoch: [1535][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0843 (0.0582)	
0.99998975 1.9072077e-06
loss:  0.039798996226549366 0.03857940511798785
===========>   training    <===========
Epoch: [1536][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0386 (0.0386)	
0.9999933 2.493951e-06
===========>   testing    <===========
Epoch: [1536][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0388 (0.0388)	
0.9999912 1.7965169e-06
Epoch: [1536][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0242 (0.0588)	
0.9999902 2.2623815e-06
Epoch: [1536][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0921 (0.0579)	
0.9999882 1.9263593e-06
loss:  0.039503458810794756 0.03857940511798785
===========>   training    <===========
Epoch: [1537][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0365 (0.0365)	
0.9999857 1.1291771e-06
===========>   testing    <===========
Epoch: [1537][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0358 (0.0358)	
0.9999926 1.7675633e-06
Epoch: [1537][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0203 (0.0593)	
0.9999927 2.2756853e-06
Epoch: [1537][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.1052 (0.0592)	
0.99999213 1.9306906e-06
loss:  0.03953848592677123 0.03857940511798785
===========>   training    <===========
Epoch: [1538][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0417 (0.0417)	
0.999995 1.2839562e-06
===========>   testing    <===========
Epoch: [1538][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0398 (0.0398)	
0.9999906 1.656632e-06
Epoch: [1538][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0231 (0.0597)	
0.99999094 2.0661928e-06
Epoch: [1538][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.1132 (0.0597)	
0.9999894 1.7644996e-06
loss:  0.03996210380916598 0.03857940511798785
===========>   training    <===========
Epoch: [1539][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0348 (0.0348)	
0.99999547 1.263809e-06
===========>   testing    <===========
Epoch: [1539][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0422 (0.0422)	
0.99999225 1.7674521e-06
Epoch: [1539][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0228 (0.0601)	
0.99999344 2.3805073e-06
Epoch: [1539][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.1087 (0.0591)	
0.9999932 2.030537e-06
loss:  0.03995369840908203 0.03857940511798785
===========>   training    <===========
Epoch: [1540][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0381 (0.0381)	
0.9999871 1.1601238e-06
===========>   testing    <===========
Epoch: [1540][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0517 (0.0517)	
0.9999919 1.8123328e-06
Epoch: [1540][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0244 (0.0594)	
0.99999213 2.3000305e-06
Epoch: [1540][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1098 (0.0578)	
0.99999154 2.0075659e-06
loss:  0.039177000043600696 0.03857940511798785
===========>   training    <===========
Epoch: [1541][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0363 (0.0363)	
0.9999877 1.211712e-06
===========>   testing    <===========
Epoch: [1541][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0491 (0.0491)	
0.9999924 1.8212768e-06
Epoch: [1541][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0238 (0.0597)	
0.999992 2.3057098e-06
Epoch: [1541][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0959 (0.0580)	
0.9999913 1.98356e-06
loss:  0.03932066198321349 0.03857940511798785
===========>   training    <===========
Epoch: [1542][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0410 (0.0410)	
0.9999862 4.168137e-07
===========>   testing    <===========
Epoch: [1542][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0431 (0.0431)	
0.9999919 1.7366816e-06
Epoch: [1542][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0244 (0.0601)	
0.99999034 2.0772113e-06
Epoch: [1542][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0783 (0.0581)	
0.9999901 1.879255e-06
loss:  0.0391434879827075 0.03857940511798785
===========>   training    <===========
Epoch: [1543][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0349 (0.0349)	
0.99999297 1.8794252e-06
===========>   testing    <===========
Epoch: [1543][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0433 (0.0433)	
0.99999166 1.6813644e-06
Epoch: [1543][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0234 (0.0607)	
0.9999901 1.8839887e-06
Epoch: [1543][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0847 (0.0583)	
0.99998975 1.847729e-06
loss:  0.039095827810703865 0.03857940511798785
===========>   training    <===========
Epoch: [1544][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0363 (0.0363)	
0.9999882 1.416717e-06
===========>   testing    <===========
Epoch: [1544][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0472 (0.0472)	
0.99999213 1.6557806e-06
Epoch: [1544][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0247 (0.0611)	
0.9999889 1.8323012e-06
Epoch: [1544][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0860 (0.0589)	
0.9999888 1.7702793e-06
loss:  0.03953998589231955 0.03857940511798785
===========>   training    <===========
Epoch: [1545][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0325 (0.0325)	
0.9999882 8.631652e-07
===========>   testing    <===========
Epoch: [1545][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0483 (0.0483)	
0.99999225 1.6983325e-06
Epoch: [1545][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0247 (0.0613)	
0.99999034 2.0954824e-06
Epoch: [1545][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1035 (0.0594)	
0.99998987 1.946962e-06
loss:  0.03971169541776998 0.03857940511798785
===========>   training    <===========
Epoch: [1546][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0383 (0.0383)	
0.9999949 1.4823355e-06
===========>   testing    <===========
Epoch: [1546][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0392 (0.0392)	
0.99999154 1.7060337e-06
Epoch: [1546][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0275 (0.0604)	
0.9999901 2.0186856e-06
Epoch: [1546][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0917 (0.0592)	
0.99998975 1.8814014e-06
loss:  0.03956135149673512 0.03857940511798785
===========>   training    <===========
Epoch: [1547][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0319 (0.0319)	
0.9999902 1.8770447e-06
===========>   testing    <===========
Epoch: [1547][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0411 (0.0411)	
0.9999919 1.6488628e-06
Epoch: [1547][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0281 (0.0602)	
0.99998915 1.8586634e-06
Epoch: [1547][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0765 (0.0591)	
0.9999883 1.7826178e-06
loss:  0.039224511163981846 0.03857940511798785
===========>   training    <===========
Epoch: [1548][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0387 (0.0387)	
0.99998784 1.1601758e-06
===========>   testing    <===========
Epoch: [1548][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0488 (0.0488)	
0.9999944 1.981794e-06
Epoch: [1548][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0258 (0.0611)	
0.9999944 2.8767836e-06
Epoch: [1548][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0801 (0.0597)	
0.99999475 2.3938346e-06
loss:  0.03983627555087155 0.03857940511798785
===========>   training    <===========
Epoch: [1549][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0452 (0.0452)	
0.9999976 3.023025e-06
===========>   testing    <===========
Epoch: [1549][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0455 (0.0455)	
0.99999166 1.6125066e-06
Epoch: [1549][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0273 (0.0603)	
0.99998987 1.8244998e-06
Epoch: [1549][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0844 (0.0597)	
0.99998784 1.6098484e-06
loss:  0.0400373571592858 0.03857940511798785
===========>   training    <===========
Epoch: [1550][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0352 (0.0352)	
0.999997 5.813618e-06
===========>   testing    <===========
Epoch: [1550][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0548 (0.0548)	
0.99999166 1.7289213e-06
Epoch: [1550][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0327 (0.0608)	
0.9999914 2.0512302e-06
Epoch: [1550][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0732 (0.0589)	
0.9999894 1.7812396e-06
loss:  0.03959762057260241 0.03857940511798785
===========>   training    <===========
Epoch: [1551][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0334 (0.0334)	
0.99999857 2.0337193e-06
===========>   testing    <===========
Epoch: [1551][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0457 (0.0457)	
0.9999918 1.9987933e-06
Epoch: [1551][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0265 (0.0605)	
0.9999927 2.2610766e-06
Epoch: [1551][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0846 (0.0588)	
0.9999919 2.084196e-06
loss:  0.039578687064728 0.03857940511798785
===========>   training    <===========
Epoch: [1552][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0322 (0.0322)	
0.9999981 1.8666179e-06
===========>   testing    <===========
Epoch: [1552][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0378 (0.0378)	
0.9999901 1.9079062e-06
Epoch: [1552][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0314 (0.0598)	
0.9999907 2.1829192e-06
Epoch: [1552][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0763 (0.0584)	
0.9999882 1.9212132e-06
loss:  0.03987325488339599 0.03857940511798785
===========>   training    <===========
Epoch: [1553][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0389 (0.0389)	
0.99999344 4.8084064e-07
===========>   testing    <===========
Epoch: [1553][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0347 (0.0347)	
0.9999913 1.788109e-06
Epoch: [1553][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0300 (0.0600)	
0.999992 2.2319591e-06
Epoch: [1553][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0762 (0.0583)	
0.9999896 1.8545892e-06
loss:  0.03900142145492247 0.03857940511798785
===========>   training    <===========
Epoch: [1554][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0321 (0.0321)	
0.99999714 2.7433925e-06
===========>   testing    <===========
Epoch: [1554][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0370 (0.0370)	
0.9999907 1.7740381e-06
Epoch: [1554][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0332 (0.0592)	
0.9999913 2.0065036e-06
Epoch: [1554][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0944 (0.0582)	
0.9999894 1.7879929e-06
loss:  0.038800346875680236 0.03857940511798785
===========>   training    <===========
Epoch: [1555][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0356 (0.0356)	
0.99999344 7.78979e-07
===========>   testing    <===========
Epoch: [1555][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0490 (0.0490)	
0.9999914 1.7166666e-06
Epoch: [1555][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0420 (0.0600)	
0.99999046 1.851705e-06
Epoch: [1555][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0776 (0.0584)	
0.9999893 1.7447113e-06
loss:  0.0397036274825362 0.03857940511798785
===========>   training    <===========
Epoch: [1556][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0321 (0.0321)	
0.9999902 1.597202e-06
===========>   testing    <===========
Epoch: [1556][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0407 (0.0407)	
0.99999225 1.7255629e-06
Epoch: [1556][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0412 (0.0611)	
0.9999918 2.107077e-06
Epoch: [1556][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0785 (0.0590)	
0.99998975 1.8618549e-06
loss:  0.03979806160417787 0.03857940511798785
===========>   training    <===========
Epoch: [1557][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0361 (0.0361)	
0.99999094 1.6069405e-06
===========>   testing    <===========
Epoch: [1557][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0391 (0.0391)	
0.9999907 1.5742193e-06
Epoch: [1557][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0298 (0.0603)	
0.9999907 1.88706e-06
Epoch: [1557][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0686 (0.0582)	
0.9999875 1.6311473e-06
loss:  0.03933874226607004 0.03857940511798785
===========>   training    <===========
Epoch: [1558][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0406 (0.0406)	
0.9999758 8.729802e-07
===========>   testing    <===========
Epoch: [1558][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0366 (0.0366)	
0.9999908 1.7872105e-06
Epoch: [1558][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0353 (0.0607)	
0.9999919 2.286639e-06
Epoch: [1558][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0521 (0.0580)	
0.99999034 1.8519557e-06
loss:  0.03908344696343102 0.03857940511798785
===========>   training    <===========
Epoch: [1559][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0258 (0.0258)	
0.9999865 4.068076e-06
===========>   testing    <===========
Epoch: [1559][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0397 (0.0397)	
0.99999 1.7965666e-06
Epoch: [1559][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0405 (0.0601)	
0.99999106 2.0255934e-06
Epoch: [1559][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0527 (0.0579)	
0.9999894 1.7612231e-06
loss:  0.03889447732184703 0.03857940511798785
===========>   training    <===========
Epoch: [1560][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0313 (0.0313)	
0.9999889 1.8009529e-06
===========>   testing    <===========
Epoch: [1560][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0356 (0.0356)	
0.99999094 1.6375611e-06
Epoch: [1560][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0362 (0.0603)	
0.99999166 1.9985685e-06
Epoch: [1560][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0660 (0.0584)	
0.9999883 1.703491e-06
loss:  0.03932779238126127 0.03857940511798785
===========>   training    <===========
Epoch: [1561][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0341 (0.0341)	
0.99998844 9.837643e-07
===========>   testing    <===========
Epoch: [1561][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0372 (0.0372)	
0.9999912 1.6382312e-06
Epoch: [1561][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0544 (0.0603)	
0.9999924 1.9633046e-06
Epoch: [1561][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0649 (0.0584)	
0.9999883 1.6701218e-06
loss:  0.03919645808209371 0.03857940511798785
===========>   training    <===========
Epoch: [1562][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0361 (0.0361)	
0.9999932 2.0953905e-06
===========>   testing    <===========
Epoch: [1562][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0379 (0.0379)	
0.99999046 1.5934227e-06
Epoch: [1562][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0359 (0.0595)	
0.9999908 1.8416492e-06
Epoch: [1562][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0614 (0.0579)	
0.9999881 1.5971624e-06
loss:  0.03887415314082798 0.03857940511798785
===========>   training    <===========
Epoch: [1563][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0360 (0.0360)	
0.9999858 1.2071158e-06
===========>   testing    <===========
Epoch: [1563][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0409 (0.0409)	
0.99999094 1.6277503e-06
Epoch: [1563][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0282 (0.0602)	
0.9999906 1.9561037e-06
Epoch: [1563][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0702 (0.0586)	
0.9999877 1.6598533e-06
loss:  0.03930257821094618 0.03857940511798785
===========>   training    <===========
Epoch: [1564][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0305 (0.0305)	
0.99999785 1.8171839e-06
===========>   testing    <===========
Epoch: [1564][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0336 (0.0336)	
0.9999912 1.5964345e-06
Epoch: [1564][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0285 (0.0599)	
0.99999094 2.0372092e-06
Epoch: [1564][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0669 (0.0583)	
0.9999883 1.6586871e-06
loss:  0.03925488340218852 0.03857940511798785
===========>   training    <===========
Epoch: [1565][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0331 (0.0331)	
0.9999858 1.4569733e-06
===========>   testing    <===========
Epoch: [1565][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0335 (0.0335)	
0.9999914 1.6271993e-06
Epoch: [1565][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0298 (0.0597)	
0.99999034 2.0807722e-06
Epoch: [1565][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0636 (0.0585)	
0.9999881 1.6771926e-06
loss:  0.03963469183547008 0.03857940511798785
===========>   training    <===========
Epoch: [1566][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0350 (0.0350)	
0.99999404 1.7211089e-06
===========>   testing    <===========
Epoch: [1566][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0335 (0.0335)	
0.99999094 1.5490567e-06
Epoch: [1566][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0311 (0.0593)	
0.99999034 1.8982146e-06
Epoch: [1566][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0588 (0.0581)	
0.99998915 1.5594383e-06
loss:  0.0395295572617651 0.03857940511798785
===========>   training    <===========
Epoch: [1567][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0425 (0.0425)	
0.9999933 2.013214e-06
===========>   testing    <===========
Epoch: [1567][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0338 (0.0338)	
0.99999154 1.5252429e-06
Epoch: [1567][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0314 (0.0598)	
0.99999106 1.873802e-06
Epoch: [1567][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0743 (0.0585)	
0.9999888 1.5469986e-06
loss:  0.03932584032290021 0.03857940511798785
===========>   training    <===========
Epoch: [1568][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0354 (0.0354)	
0.9999927 2.584363e-06
===========>   testing    <===========
Epoch: [1568][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0354 (0.0354)	
0.9999907 1.5507239e-06
Epoch: [1568][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0320 (0.0594)	
0.9999901 1.7979703e-06
Epoch: [1568][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0796 (0.0581)	
0.9999862 1.5758295e-06
loss:  0.03914941770885094 0.03857940511798785
===========>   training    <===========
Epoch: [1569][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0282 (0.0282)	
0.9999956 1.2023811e-06
===========>   testing    <===========
Epoch: [1569][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0364 (0.0364)	
0.99999166 1.7312016e-06
Epoch: [1569][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0305 (0.0596)	
0.9999925 2.1859898e-06
Epoch: [1569][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0748 (0.0581)	
0.9999894 1.8980553e-06
loss:  0.038769036385144395 0.03857940511798785
===========>   training    <===========
Epoch: [1570][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0358 (0.0358)	
0.9999969 1.2435562e-06
===========>   testing    <===========
Epoch: [1570][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0397 (0.0397)	
0.99999046 1.4582606e-06
Epoch: [1570][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0270 (0.0594)	
0.9999908 1.8024598e-06
Epoch: [1570][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0786 (0.0581)	
0.9999881 1.4921958e-06
loss:  0.03881483312742706 0.03857940511798785
===========>   training    <===========
Epoch: [1571][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0334 (0.0334)	
0.99999344 2.125149e-06
===========>   testing    <===========
Epoch: [1571][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0416 (0.0416)	
0.99999094 1.4788845e-06
Epoch: [1571][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0308 (0.0595)	
0.9999913 1.8527154e-06
Epoch: [1571][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0762 (0.0579)	
0.9999893 1.5275516e-06
loss:  0.038772233423922886 0.03857940511798785
===========>   training    <===========
Epoch: [1572][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0327 (0.0327)	
0.9999913 8.5373006e-07
===========>   testing    <===========
Epoch: [1572][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0411 (0.0411)	
0.9999907 1.612616e-06
Epoch: [1572][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0319 (0.0591)	
0.9999913 2.0477826e-06
Epoch: [1572][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0688 (0.0576)	
0.99999 1.6970455e-06
loss:  0.038285376973611895 0.03857940511798785
===========>   training    <===========
Epoch: [1573][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0314 (0.0314)	
0.9999932 1.6681801e-06
===========>   testing    <===========
Epoch: [1573][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0404 (0.0404)	
0.99999034 1.5601612e-06
Epoch: [1573][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0302 (0.0586)	
0.9999908 1.8224268e-06
Epoch: [1573][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0787 (0.0574)	
0.9999894 1.5348368e-06
loss:  0.03847133249568402 0.038285376973611895
===========>   training    <===========
Epoch: [1574][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0276 (0.0276)	
0.99999774 6.1050177e-06
===========>   testing    <===========
Epoch: [1574][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0424 (0.0424)	
0.9999907 1.6475489e-06
Epoch: [1574][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0339 (0.0594)	
0.9999919 2.076938e-06
Epoch: [1574][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0732 (0.0575)	
0.9999913 1.6736807e-06
loss:  0.03837720487918728 0.038285376973611895
===========>   training    <===========
Epoch: [1575][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0287 (0.0287)	
0.9999825 8.7422904e-07
===========>   testing    <===========
Epoch: [1575][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0376 (0.0376)	
0.9999924 1.8042656e-06
Epoch: [1575][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0369 (0.0600)	
0.99999285 2.447174e-06
Epoch: [1575][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0691 (0.0578)	
0.99999213 1.9597896e-06
loss:  0.03874750445962549 0.038285376973611895
===========>   training    <===========
Epoch: [1576][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0356 (0.0356)	
0.9999943 2.391302e-06
===========>   testing    <===========
Epoch: [1576][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0359 (0.0359)	
0.99999046 1.6049617e-06
Epoch: [1576][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0312 (0.0586)	
0.99998975 2.0864431e-06
Epoch: [1576][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0596 (0.0570)	
0.99998784 1.6820125e-06
loss:  0.03858877692876039 0.038285376973611895
===========>   training    <===========
Epoch: [1577][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0333 (0.0333)	
0.9999969 5.296488e-06
===========>   testing    <===========
Epoch: [1577][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0349 (0.0349)	
0.999992 1.6194216e-06
Epoch: [1577][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0325 (0.0586)	
0.9999913 2.1133822e-06
Epoch: [1577][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0762 (0.0573)	
0.99999046 1.6961992e-06
loss:  0.03861484908445767 0.038285376973611895
===========>   training    <===========
Epoch: [1578][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0380 (0.0380)	
0.9999831 6.3108683e-07
===========>   testing    <===========
Epoch: [1578][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0366 (0.0366)	
0.9999918 1.5086152e-06
Epoch: [1578][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0290 (0.0591)	
0.99999046 1.8511894e-06
Epoch: [1578][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0846 (0.0581)	
0.9999887 1.5867929e-06
loss:  0.03928104265880894 0.038285376973611895
===========>   training    <===========
Epoch: [1579][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0346 (0.0346)	
0.99999475 1.1775259e-06
===========>   testing    <===========
Epoch: [1579][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0385 (0.0385)	
0.9999912 1.559578e-06
Epoch: [1579][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0625 (0.0595)	
0.99998856 1.769108e-06
Epoch: [1579][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0759 (0.0581)	
0.99998665 1.5071728e-06
loss:  0.039673917106588186 0.038285376973611895
===========>   training    <===========
Epoch: [1580][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0330 (0.0330)	
0.99999654 8.0008607e-07
===========>   testing    <===========
Epoch: [1580][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0363 (0.0363)	
0.9999913 1.569656e-06
Epoch: [1580][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0333 (0.0595)	
0.9999889 1.8855741e-06
Epoch: [1580][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0911 (0.0583)	
0.999987 1.5907505e-06
loss:  0.039447608443067717 0.038285376973611895
===========>   training    <===========
Epoch: [1581][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0317 (0.0317)	
0.9999938 5.79791e-07
===========>   testing    <===========
Epoch: [1581][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0382 (0.0382)	
0.9999913 1.6742441e-06
Epoch: [1581][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0517 (0.0595)	
0.9999906 2.024064e-06
Epoch: [1581][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0722 (0.0580)	
0.9999895 1.7646327e-06
loss:  0.038979765151867185 0.038285376973611895
===========>   training    <===========
Epoch: [1582][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0337 (0.0337)	
0.9999889 4.49455e-07
===========>   testing    <===========
Epoch: [1582][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0398 (0.0398)	
0.9999902 1.5686458e-06
Epoch: [1582][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0484 (0.0595)	
0.9999887 1.8643975e-06
Epoch: [1582][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0806 (0.0581)	
0.9999869 1.5785532e-06
loss:  0.039175459364454435 0.038285376973611895
===========>   training    <===========
Epoch: [1583][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0372 (0.0372)	
0.99998796 1.6715336e-06
===========>   testing    <===========
Epoch: [1583][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0384 (0.0384)	
0.9999908 1.4098271e-06
Epoch: [1583][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0391 (0.0600)	
0.99998987 1.7293765e-06
Epoch: [1583][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0810 (0.0584)	
0.99998987 1.4554956e-06
loss:  0.039512163691424074 0.038285376973611895
===========>   training    <===========
Epoch: [1584][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0317 (0.0317)	
0.9999901 1.3581159e-06
===========>   testing    <===========
Epoch: [1584][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0402 (0.0402)	
0.9999896 1.5581776e-06
Epoch: [1584][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0422 (0.0597)	
0.99999034 2.0242244e-06
Epoch: [1584][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0723 (0.0576)	
0.99998975 1.7094277e-06
loss:  0.039073982548275654 0.038285376973611895
===========>   training    <===========
Epoch: [1585][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0348 (0.0348)	
0.9999875 2.533237e-06
===========>   testing    <===========
Epoch: [1585][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0387 (0.0387)	
0.9999908 1.5779152e-06
Epoch: [1585][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0414 (0.0596)	
0.9999912 1.9190268e-06
Epoch: [1585][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0728 (0.0579)	
0.9999895 1.7230157e-06
loss:  0.03919809274023567 0.038285376973611895
===========>   training    <===========
Epoch: [1586][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0366 (0.0366)	
0.9999944 2.8289166e-06
===========>   testing    <===========
Epoch: [1586][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0340 (0.0340)	
0.9999902 1.459059e-06
Epoch: [1586][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0354 (0.0589)	
0.9999912 1.9313534e-06
Epoch: [1586][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0779 (0.0580)	
0.9999906 1.5442275e-06
loss:  0.03925986616218835 0.038285376973611895
===========>   training    <===========
Epoch: [1587][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0507 (0.0507)	
0.99998903 1.081701e-06
===========>   testing    <===========
Epoch: [1587][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0335 (0.0335)	
0.9999913 1.3767509e-06
Epoch: [1587][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0284 (0.0596)	
0.9999907 1.5879494e-06
Epoch: [1587][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0762 (0.0582)	
0.9999902 1.3779778e-06
loss:  0.039647294351443985 0.038285376973611895
===========>   training    <===========
Epoch: [1588][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0295 (0.0295)	
0.9999846 1.5770262e-06
===========>   testing    <===========
Epoch: [1588][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0330 (0.0330)	
0.9999907 1.4576322e-06
Epoch: [1588][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0289 (0.0590)	
0.9999901 1.7862374e-06
Epoch: [1588][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0745 (0.0578)	
0.9999893 1.4811654e-06
loss:  0.039388511730452325 0.038285376973611895
===========>   training    <===========
Epoch: [1589][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0284 (0.0284)	
0.9999931 2.357769e-06
===========>   testing    <===========
Epoch: [1589][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0325 (0.0325)	
0.9999906 1.5824678e-06
Epoch: [1589][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0273 (0.0593)	
0.99999106 1.961394e-06
Epoch: [1589][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0717 (0.0581)	
0.99999034 1.6394393e-06
loss:  0.0395814698577831 0.038285376973611895
===========>   training    <===========
Epoch: [1590][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0286 (0.0286)	
0.9999963 1.1120654e-06
===========>   testing    <===========
Epoch: [1590][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0307 (0.0307)	
0.99999094 1.6295706e-06
Epoch: [1590][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0277 (0.0593)	
0.99999106 1.9666065e-06
Epoch: [1590][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0811 (0.0586)	
0.99999034 1.6481916e-06
loss:  0.03974045334318144 0.038285376973611895
===========>   training    <===========
Epoch: [1591][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0339 (0.0339)	
0.99998283 1.3347951e-06
===========>   testing    <===========
Epoch: [1591][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0317 (0.0317)	
0.99999106 1.6111571e-06
Epoch: [1591][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0287 (0.0590)	
0.99999046 1.8666198e-06
Epoch: [1591][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0725 (0.0585)	
0.9999895 1.6192981e-06
loss:  0.03967428859113575 0.038285376973611895
===========>   training    <===========
Epoch: [1592][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0362 (0.0362)	
0.99999166 1.1207756e-06
===========>   testing    <===========
Epoch: [1592][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0315 (0.0315)	
0.9999901 1.6514061e-06
Epoch: [1592][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0276 (0.0590)	
0.99999106 1.9988677e-06
Epoch: [1592][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0710 (0.0583)	
0.99999094 1.6074678e-06
loss:  0.04005260278546707 0.038285376973611895
===========>   training    <===========
Epoch: [1593][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0308 (0.0308)	
0.9999962 7.803084e-07
===========>   testing    <===========
Epoch: [1593][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0329 (0.0329)	
0.99999213 1.6357583e-06
Epoch: [1593][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0347 (0.0587)	
0.9999924 1.9965985e-06
Epoch: [1593][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0645 (0.0582)	
0.99999213 1.742425e-06
loss:  0.039375079711190475 0.038285376973611895
===========>   training    <===========
Epoch: [1594][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0341 (0.0341)	
0.9999943 5.120153e-07
===========>   testing    <===========
Epoch: [1594][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0371 (0.0371)	
0.99998975 1.5490124e-06
Epoch: [1594][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0301 (0.0588)	
0.99998975 1.6326009e-06
Epoch: [1594][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0635 (0.0580)	
0.99998975 1.1599601e-06
loss:  0.040113113885247076 0.038285376973611895
===========>   training    <===========
Epoch: [1595][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0403 (0.0403)	
0.99998283 9.183605e-06
===========>   testing    <===========
Epoch: [1595][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0313 (0.0313)	
0.99999094 1.5279988e-06
Epoch: [1595][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0284 (0.0586)	
0.99999046 1.5091174e-06
Epoch: [1595][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0777 (0.0578)	
0.99999106 1.0753405e-06
loss:  0.040012048690984514 0.038285376973611895
===========>   training    <===========
Epoch: [1596][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0317 (0.0317)	
0.9999931 8.396674e-07
===========>   testing    <===========
Epoch: [1596][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0374 (0.0374)	
0.99999106 1.6169047e-06
Epoch: [1596][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0345 (0.0589)	
0.9999919 1.7550293e-06
Epoch: [1596][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0662 (0.0576)	
0.9999924 1.4274881e-06
loss:  0.039085202968245136 0.038285376973611895
===========>   training    <===========
Epoch: [1597][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0290 (0.0290)	
0.9999963 3.5776186e-06
===========>   testing    <===========
Epoch: [1597][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0339 (0.0339)	
0.9999893 1.7779251e-06
Epoch: [1597][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0289 (0.0589)	
0.9999908 1.8062834e-06
Epoch: [1597][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0712 (0.0578)	
0.99999106 1.4394856e-06
loss:  0.03934455554763938 0.038285376973611895
===========>   training    <===========
Epoch: [1598][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0456 (0.0456)	
0.9999883 8.371391e-07
===========>   testing    <===========
Epoch: [1598][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0388 (0.0388)	
0.99999046 1.6678985e-06
Epoch: [1598][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0302 (0.0578)	
0.99999154 1.8353337e-06
Epoch: [1598][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0740 (0.0573)	
0.9999919 1.4589366e-06
loss:  0.03944117230782396 0.038285376973611895
===========>   training    <===========
Epoch: [1599][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0305 (0.0305)	
0.99998975 1.3417637e-06
===========>   testing    <===========
Epoch: [1599][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0416 (0.0416)	
0.9999913 1.7822898e-06
Epoch: [1599][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0275 (0.0589)	
0.9999926 2.115427e-06
Epoch: [1599][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0825 (0.0580)	
0.9999927 1.8708344e-06
loss:  0.03990232871795252 0.038285376973611895
===========>   training    <===========
Epoch: [1600][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0340 (0.0340)	
0.99998736 1.413567e-06
===========>   testing    <===========
Epoch: [1600][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0353 (0.0353)	
0.9999906 1.5706202e-06
Epoch: [1600][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0273 (0.0587)	
0.9999925 1.7586182e-06
Epoch: [1600][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0697 (0.0581)	
0.999992 1.4092947e-06
loss:  0.039912208474502164 0.038285376973611895
===========>   training    <===========
Epoch: [1601][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0348 (0.0348)	
0.9999887 6.632874e-06
===========>   testing    <===========
Epoch: [1601][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0383 (0.0383)	
0.99999046 1.5824376e-06
Epoch: [1601][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0276 (0.0594)	
0.999992 1.6464854e-06
Epoch: [1601][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0636 (0.0580)	
0.9999914 1.386537e-06
loss:  0.03961277652283135 0.038285376973611895
===========>   training    <===========
Epoch: [1602][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0387 (0.0387)	
0.99999416 7.503009e-07
===========>   testing    <===========
Epoch: [1602][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0376 (0.0376)	
0.9999906 1.7079757e-06
Epoch: [1602][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0249 (0.0594)	
0.99999213 1.7896581e-06
Epoch: [1602][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0810 (0.0586)	
0.9999914 1.7415477e-06
loss:  0.03978808377670451 0.038285376973611895
===========>   training    <===========
Epoch: [1603][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0341 (0.0341)	
0.9999918 1.4813236e-06
===========>   testing    <===========
Epoch: [1603][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0390 (0.0390)	
0.99999046 1.79583e-06
Epoch: [1603][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0240 (0.0594)	
0.9999926 2.1863796e-06
Epoch: [1603][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0742 (0.0583)	
0.9999925 1.9724607e-06
loss:  0.039733913040905455 0.038285376973611895
===========>   training    <===========
Epoch: [1604][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0342 (0.0342)	
0.9999933 2.4236167e-06
===========>   testing    <===========
Epoch: [1604][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0404 (0.0404)	
0.99999 1.5274394e-06
Epoch: [1604][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0240 (0.0590)	
0.99999034 1.600178e-06
Epoch: [1604][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0754 (0.0584)	
0.9999889 1.3853039e-06
loss:  0.04009540863989869 0.038285376973611895
===========>   training    <===========
Epoch: [1605][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0285 (0.0285)	
0.99999416 2.4364992e-06
===========>   testing    <===========
Epoch: [1605][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0407 (0.0407)	
0.99999034 1.5126735e-06
Epoch: [1605][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0243 (0.0590)	
0.9999906 1.6429751e-06
Epoch: [1605][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0713 (0.0584)	
0.9999889 1.560423e-06
loss:  0.03971880300998165 0.038285376973611895
===========>   training    <===========
Epoch: [1606][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0413 (0.0413)	
0.9999913 1.8682938e-06
===========>   testing    <===========
Epoch: [1606][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0389 (0.0389)	
0.99999046 1.5388263e-06
Epoch: [1606][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0257 (0.0587)	
0.99999106 1.8037633e-06
Epoch: [1606][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0710 (0.0584)	
0.99998987 1.559999e-06
loss:  0.03964192490156704 0.038285376973611895
===========>   training    <===========
Epoch: [1607][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0343 (0.0343)	
0.9999956 2.2929805e-06
===========>   testing    <===========
Epoch: [1607][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0350 (0.0350)	
0.99999046 1.4559622e-06
Epoch: [1607][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0242 (0.0585)	
0.99998987 1.6433464e-06
Epoch: [1607][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0853 (0.0588)	
0.9999889 1.5032455e-06
loss:  0.040311216310804365 0.038285376973611895
===========>   training    <===========
Epoch: [1608][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0329 (0.0329)	
0.9999949 1.9255676e-06
===========>   testing    <===========
Epoch: [1608][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0373 (0.0373)	
0.99999034 1.4073298e-06
Epoch: [1608][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0270 (0.0581)	
0.9999871 1.5380633e-06
Epoch: [1608][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0800 (0.0582)	
0.99998736 1.4200622e-06
loss:  0.03980040843575172 0.038285376973611895
===========>   training    <===========
Epoch: [1609][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0299 (0.0299)	
0.9999944 3.1229326e-06
===========>   testing    <===========
Epoch: [1609][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0329 (0.0329)	
0.99999046 1.4318375e-06
Epoch: [1609][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0247 (0.0585)	
0.9999914 1.7429768e-06
Epoch: [1609][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0900 (0.0593)	
0.9999901 1.5211101e-06
loss:  0.04014743326893977 0.038285376973611895
===========>   training    <===========
Epoch: [1610][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0377 (0.0377)	
0.9999845 6.1944746e-07
===========>   testing    <===========
Epoch: [1610][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0356 (0.0356)	
0.99999034 1.4894079e-06
Epoch: [1610][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0293 (0.0594)	
0.9999902 1.6740223e-06
Epoch: [1610][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0730 (0.0594)	
0.99999 1.2320644e-06
loss:  0.039893938041952404 0.038285376973611895
===========>   training    <===========
Epoch: [1611][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0309 (0.0309)	
0.9999833 1.4002678e-06
===========>   testing    <===========
Epoch: [1611][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0354 (0.0354)	
0.9999906 1.495732e-06
Epoch: [1611][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0383 (0.0593)	
0.99999046 1.7362776e-06
Epoch: [1611][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0712 (0.0588)	
0.99998975 1.3847425e-06
loss:  0.039887254531176364 0.038285376973611895
===========>   training    <===========
Epoch: [1612][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0446 (0.0446)	
0.9999912 1.2618111e-06
===========>   testing    <===========
Epoch: [1612][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0323 (0.0323)	
0.9999906 1.5180495e-06
Epoch: [1612][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0278 (0.0584)	
0.9999902 1.7232326e-06
Epoch: [1612][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0771 (0.0587)	
0.99998784 1.4936965e-06
loss:  0.03978568671888427 0.038285376973611895
===========>   training    <===========
Epoch: [1613][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0396 (0.0396)	
0.9999883 4.1316633e-07
===========>   testing    <===========
Epoch: [1613][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0301 (0.0301)	
0.9999914 1.4387718e-06
Epoch: [1613][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0275 (0.0584)	
0.99999166 1.5577526e-06
Epoch: [1613][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0670 (0.0588)	
0.9999902 1.2736533e-06
loss:  0.03994141062399337 0.038285376973611895
===========>   training    <===========
Epoch: [1614][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0297 (0.0297)	
0.99999464 3.844444e-06
===========>   testing    <===========
Epoch: [1614][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0376 (0.0376)	
0.9999913 1.6339965e-06
Epoch: [1614][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0286 (0.0584)	
0.9999931 2.0198488e-06
Epoch: [1614][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0651 (0.0579)	
0.99999285 1.6781095e-06
loss:  0.03914924829089894 0.038285376973611895
===========>   training    <===========
Epoch: [1615][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0290 (0.0290)	
0.9999949 5.7479156e-06
===========>   testing    <===========
Epoch: [1615][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0393 (0.0393)	
0.9999919 1.6480424e-06
Epoch: [1615][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0318 (0.0583)	
0.99999344 2.20203e-06
Epoch: [1615][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0707 (0.0584)	
0.99999297 1.8480741e-06
loss:  0.03947195905127665 0.038285376973611895
===========>   training    <===========
Epoch: [1616][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0382 (0.0382)	
0.9999877 1.7037444e-06
===========>   testing    <===========
Epoch: [1616][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0345 (0.0345)	
0.9999912 1.5614561e-06
Epoch: [1616][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0378 (0.0588)	
0.9999926 2.0152406e-06
Epoch: [1616][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0699 (0.0586)	
0.999992 1.6822867e-06
loss:  0.03991429918687295 0.038285376973611895
===========>   training    <===========
Epoch: [1617][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0312 (0.0312)	
0.9999932 2.109359e-06
===========>   testing    <===========
Epoch: [1617][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0318 (0.0318)	
0.9999901 1.4674808e-06
Epoch: [1617][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0393 (0.0594)	
0.9999907 1.7102054e-06
Epoch: [1617][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0646 (0.0590)	
0.99999034 1.5012168e-06
loss:  0.04027091835825536 0.038285376973611895
===========>   training    <===========
Epoch: [1618][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0310 (0.0310)	
0.99999356 1.8956059e-06
===========>   testing    <===========
Epoch: [1618][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0352 (0.0352)	
0.9999902 1.6805134e-06
Epoch: [1618][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0333 (0.0598)	
0.9999924 2.1815622e-06
Epoch: [1618][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0609 (0.0590)	
0.999992 1.7829034e-06
loss:  0.03975620111662004 0.038285376973611895
===========>   training    <===========
Epoch: [1619][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0391 (0.0391)	
0.9999894 2.088912e-06
===========>   testing    <===========
Epoch: [1619][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0341 (0.0341)	
0.9999895 1.4490803e-06
Epoch: [1619][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0452 (0.0595)	
0.99999094 1.7668133e-06
Epoch: [1619][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0654 (0.0584)	
0.9999901 1.4534387e-06
loss:  0.03964256957611767 0.038285376973611895
===========>   training    <===========
Epoch: [1620][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0343 (0.0343)	
0.99998975 8.004723e-07
===========>   testing    <===========
Epoch: [1620][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0341 (0.0341)	
0.99999166 1.5352146e-06
Epoch: [1620][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0382 (0.0598)	
0.9999927 1.9607842e-06
Epoch: [1620][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0634 (0.0585)	
0.99999213 1.6072868e-06
loss:  0.03957774271733949 0.038285376973611895
===========>   training    <===========
Epoch: [1621][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0432 (0.0432)	
0.99999523 3.1710981e-06
===========>   testing    <===========
Epoch: [1621][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0339 (0.0339)	
0.9999912 1.5120995e-06
Epoch: [1621][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0396 (0.0596)	
0.9999908 1.8282342e-06
Epoch: [1621][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0682 (0.0583)	
0.9999887 1.5863601e-06
loss:  0.039609443872817174 0.038285376973611895
===========>   training    <===========
Epoch: [1622][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0359 (0.0359)	
0.9999902 1.1029663e-06
===========>   testing    <===========
Epoch: [1622][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0317 (0.0317)	
0.99999213 1.6422027e-06
Epoch: [1622][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0266 (0.0593)	
0.9999927 2.2231388e-06
Epoch: [1622][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0764 (0.0581)	
0.9999918 1.8742489e-06
loss:  0.0395422604696527 0.038285376973611895
===========>   training    <===========
Epoch: [1623][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0344 (0.0344)	
0.99999225 7.348252e-07
===========>   testing    <===========
Epoch: [1623][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0324 (0.0324)	
0.9999901 1.6816547e-06
Epoch: [1623][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0302 (0.0591)	
0.9999919 2.013646e-06
Epoch: [1623][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0593 (0.0577)	
0.9999913 1.7496584e-06
loss:  0.039383167145205844 0.038285376973611895
===========>   training    <===========
Epoch: [1624][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0330 (0.0330)	
0.9999875 3.0627993e-07
===========>   testing    <===========
Epoch: [1624][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0299 (0.0299)	
0.9999914 1.8069037e-06
Epoch: [1624][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0249 (0.0581)	
0.9999933 2.2884212e-06
Epoch: [1624][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0750 (0.0580)	
0.9999926 1.9838703e-06
loss:  0.03933328941433745 0.038285376973611895
===========>   training    <===========
Epoch: [1625][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0341 (0.0341)	
0.9999869 9.660641e-07
===========>   testing    <===========
Epoch: [1625][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0373 (0.0373)	
0.99999094 1.5837646e-06
Epoch: [1625][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0305 (0.0583)	
0.9999931 1.9676415e-06
Epoch: [1625][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0678 (0.0577)	
0.9999925 1.6855209e-06
loss:  0.03970301412866761 0.038285376973611895
===========>   training    <===========
Epoch: [1626][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0333 (0.0333)	
0.9999938 6.1292167e-06
===========>   testing    <===========
Epoch: [1626][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0371 (0.0371)	
0.9999901 1.5656686e-06
Epoch: [1626][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0286 (0.0587)	
0.9999918 1.7218724e-06
Epoch: [1626][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0637 (0.0584)	
0.9999901 1.5453531e-06
loss:  0.03988474779875928 0.038285376973611895
===========>   training    <===========
Epoch: [1627][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0358 (0.0358)	
0.99998474 2.9182377e-06
===========>   testing    <===========
Epoch: [1627][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0351 (0.0351)	
0.9999901 1.4902531e-06
Epoch: [1627][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0266 (0.0587)	
0.99999094 1.6470823e-06
Epoch: [1627][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0646 (0.0583)	
0.99998903 1.5128235e-06
loss:  0.039645052130735325 0.038285376973611895
===========>   training    <===========
Epoch: [1628][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0366 (0.0366)	
0.99999595 1.9837416e-06
===========>   testing    <===========
Epoch: [1628][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0324 (0.0324)	
0.9999893 1.4821546e-06
Epoch: [1628][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0237 (0.0586)	
0.99999094 1.6222734e-06
Epoch: [1628][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0702 (0.0584)	
0.9999888 1.5329133e-06
loss:  0.03933511677862511 0.038285376973611895
===========>   training    <===========
Epoch: [1629][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0338 (0.0338)	
0.9999913 1.7696852e-06
===========>   testing    <===========
Epoch: [1629][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0328 (0.0328)	
0.9999907 1.6031917e-06
Epoch: [1629][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0233 (0.0585)	
0.99999213 1.7909897e-06
Epoch: [1629][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0801 (0.0585)	
0.99999046 1.6346012e-06
loss:  0.038999140789818365 0.038285376973611895
===========>   training    <===========
Epoch: [1630][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0327 (0.0327)	
0.99999523 1.333674e-06
===========>   testing    <===========
Epoch: [1630][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0334 (0.0334)	
0.99999034 1.5429732e-06
Epoch: [1630][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0253 (0.0581)	
0.99999213 1.7356385e-06
Epoch: [1630][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0785 (0.0581)	
0.99999046 1.6095262e-06
loss:  0.03896946507913368 0.038285376973611895
===========>   training    <===========
Epoch: [1631][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0319 (0.0319)	
0.99999726 1.1994619e-05
===========>   testing    <===========
Epoch: [1631][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0326 (0.0326)	
0.99999034 1.578901e-06
Epoch: [1631][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0247 (0.0585)	
0.99999285 1.8420883e-06
Epoch: [1631][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0771 (0.0582)	
0.9999913 1.6404418e-06
loss:  0.03936258687894112 0.038285376973611895
===========>   training    <===========
Epoch: [1632][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0297 (0.0297)	
0.9999902 1.6467147e-06
===========>   testing    <===========
Epoch: [1632][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0315 (0.0315)	
0.9999933 1.5699494e-06
Epoch: [1632][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0281 (0.0584)	
0.99999416 1.941192e-06
Epoch: [1632][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0714 (0.0578)	
0.99999297 1.7129689e-06
loss:  0.03878307168755735 0.038285376973611895
===========>   training    <===========
Epoch: [1633][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0371 (0.0371)	
0.9999919 1.1452921e-06
===========>   testing    <===========
Epoch: [1633][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0330 (0.0330)	
0.99999154 1.5839353e-06
Epoch: [1633][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0275 (0.0580)	
0.9999925 1.7738366e-06
Epoch: [1633][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0716 (0.0574)	
0.99999094 1.6661257e-06
loss:  0.0385461374992937 0.038285376973611895
===========>   training    <===========
Epoch: [1634][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0436 (0.0436)	
0.9999926 1.5874173e-05
===========>   testing    <===========
Epoch: [1634][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0339 (0.0339)	
0.9999933 1.7326038e-06
Epoch: [1634][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0260 (0.0588)	
0.99999356 2.0841405e-06
Epoch: [1634][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0737 (0.0578)	
0.9999924 1.957817e-06
loss:  0.03898098650770987 0.038285376973611895
===========>   training    <===========
Epoch: [1635][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0337 (0.0337)	
0.9999939 3.0891292e-06
===========>   testing    <===========
Epoch: [1635][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0339 (0.0339)	
0.99999213 1.5053628e-06
Epoch: [1635][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0243 (0.0590)	
0.999992 1.7299983e-06
Epoch: [1635][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0798 (0.0581)	
0.9999896 1.6017781e-06
loss:  0.03942411981304139 0.038285376973611895
===========>   training    <===========
Epoch: [1636][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0394 (0.0394)	
0.9999914 1.2616716e-06
===========>   testing    <===========
Epoch: [1636][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0316 (0.0316)	
0.9999937 1.6778966e-06
Epoch: [1636][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0290 (0.0586)	
0.99999356 2.0550563e-06
Epoch: [1636][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0722 (0.0580)	
0.9999931 1.895682e-06
loss:  0.038960872974350136 0.038285376973611895
===========>   training    <===========
Epoch: [1637][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0329 (0.0329)	
0.999992 5.1497943e-07
===========>   testing    <===========
Epoch: [1637][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0349 (0.0349)	
0.9999919 1.693697e-06
Epoch: [1637][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0279 (0.0595)	
0.9999924 2.1208689e-06
Epoch: [1637][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0729 (0.0582)	
0.99999213 1.8493365e-06
loss:  0.03934819836704706 0.038285376973611895
===========>   training    <===========
Epoch: [1638][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0363 (0.0363)	
0.9999907 1.3470074e-06
===========>   testing    <===========
Epoch: [1638][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0324 (0.0324)	
0.9999924 1.5499404e-06
Epoch: [1638][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0302 (0.0593)	
0.99999213 1.6958886e-06
Epoch: [1638][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0821 (0.0582)	
0.99999046 1.5280091e-06
loss:  0.03924876259624388 0.038285376973611895
===========>   training    <===========
Epoch: [1639][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0301 (0.0301)	
0.9999963 2.1367266e-06
===========>   testing    <===========
Epoch: [1639][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0332 (0.0332)	
0.9999932 1.7353141e-06
Epoch: [1639][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0287 (0.0593)	
0.9999931 2.2013035e-06
Epoch: [1639][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0657 (0.0579)	
0.9999925 1.9137103e-06
loss:  0.038963767181194764 0.038285376973611895
===========>   training    <===========
Epoch: [1640][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0351 (0.0351)	
0.9999869 1.3385811e-06
===========>   testing    <===========
Epoch: [1640][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0367 (0.0367)	
0.9999918 1.5110961e-06
Epoch: [1640][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0272 (0.0594)	
0.9999924 1.7978623e-06
Epoch: [1640][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0641 (0.0582)	
0.99999094 1.5694148e-06
loss:  0.03955263712802337 0.038285376973611895
===========>   training    <===========
Epoch: [1641][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0394 (0.0394)	
0.9999949 1.6130728e-06
===========>   testing    <===========
Epoch: [1641][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0325 (0.0325)	
0.99999154 1.3841654e-06
Epoch: [1641][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0294 (0.0593)	
0.999992 1.670995e-06
Epoch: [1641][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0762 (0.0583)	
0.99999106 1.4564982e-06
loss:  0.03912009679127837 0.038285376973611895
===========>   training    <===========
Epoch: [1642][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0302 (0.0302)	
0.9999945 1.77147e-06
===========>   testing    <===========
Epoch: [1642][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0331 (0.0331)	
0.9999912 1.3368079e-06
Epoch: [1642][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0347 (0.0595)	
0.99999046 1.6359049e-06
Epoch: [1642][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0667 (0.0583)	
0.9999889 1.3763203e-06
loss:  0.03957406450124201 0.038285376973611895
===========>   training    <===========
Epoch: [1643][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0392 (0.0392)	
0.99998176 8.2341336e-07
===========>   testing    <===========
Epoch: [1643][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0328 (0.0328)	
0.99999213 1.3024106e-06
Epoch: [1643][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0321 (0.0587)	
0.99999094 1.5219082e-06
Epoch: [1643][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0775 (0.0581)	
0.9999893 1.3175908e-06
loss:  0.03938175254949017 0.038285376973611895
===========>   training    <===========
Epoch: [1644][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0396 (0.0396)	
0.999992 1.7001735e-06
===========>   testing    <===========
Epoch: [1644][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0375 (0.0375)	
0.9999924 1.4239312e-06
Epoch: [1644][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0320 (0.0596)	
0.9999912 1.686161e-06
Epoch: [1644][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0703 (0.0582)	
0.99999046 1.4811795e-06
loss:  0.03954435817867907 0.038285376973611895
===========>   training    <===========
Epoch: [1645][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0333 (0.0333)	
0.9999908 2.7733256e-06
===========>   testing    <===========
Epoch: [1645][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0434 (0.0434)	
0.9999914 1.4989807e-06
Epoch: [1645][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0296 (0.0588)	
0.99999106 1.7721442e-06
Epoch: [1645][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0779 (0.0583)	
0.9999906 1.5931857e-06
loss:  0.03950013937416963 0.038285376973611895
===========>   training    <===========
Epoch: [1646][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0395 (0.0395)	
0.9999912 1.9200263e-06
===========>   testing    <===========
Epoch: [1646][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0384 (0.0384)	
0.9999937 1.6441851e-06
Epoch: [1646][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0269 (0.0587)	
0.99999297 1.982187e-06
Epoch: [1646][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0880 (0.0581)	
0.99999285 1.709206e-06
loss:  0.039174796280217916 0.038285376973611895
===========>   training    <===========
Epoch: [1647][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0363 (0.0363)	
0.99998987 1.9904308e-05
===========>   testing    <===========
Epoch: [1647][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0391 (0.0391)	
0.99999297 1.468126e-06
Epoch: [1647][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0267 (0.0596)	
0.99999285 1.7059881e-06
Epoch: [1647][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0752 (0.0588)	
0.99999166 1.5107157e-06
loss:  0.03942747602416541 0.038285376973611895
===========>   training    <===========
Epoch: [1648][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0340 (0.0340)	
0.99999404 7.850309e-07
===========>   testing    <===========
Epoch: [1648][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0341 (0.0341)	
0.99999094 1.641437e-06
Epoch: [1648][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0274 (0.0600)	
0.99999046 1.8307135e-06
Epoch: [1648][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0634 (0.0588)	
0.9999902 1.6489525e-06
loss:  0.039392632284505846 0.038285376973611895
===========>   training    <===========
Epoch: [1649][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0313 (0.0313)	
0.9999932 1.5748709e-06
===========>   testing    <===========
Epoch: [1649][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0359 (0.0359)	
0.99999213 1.5827877e-06
Epoch: [1649][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0273 (0.0591)	
0.99999225 1.8716072e-06
Epoch: [1649][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0651 (0.0587)	
0.9999908 1.7837028e-06
loss:  0.03887464556640863 0.038285376973611895
===========>   training    <===========
Epoch: [1650][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0302 (0.0302)	
0.99998224 1.1921198e-06
===========>   testing    <===========
Epoch: [1650][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0328 (0.0328)	
0.99999166 1.4942037e-06
Epoch: [1650][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0207 (0.0597)	
0.99999106 1.6668505e-06
Epoch: [1650][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0719 (0.0601)	
0.99999 1.6565782e-06
loss:  0.03984695399887517 0.038285376973611895
===========>   training    <===========
Epoch: [1651][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0312 (0.0312)	
0.99999285 1.9954184e-06
===========>   testing    <===========
Epoch: [1651][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0372 (0.0372)	
0.99999166 1.4515008e-06
Epoch: [1651][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0260 (0.0604)	
0.9999906 1.6913807e-06
Epoch: [1651][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0694 (0.0591)	
0.9999896 1.5255775e-06
loss:  0.03985188789414884 0.038285376973611895
===========>   training    <===========
Epoch: [1652][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0320 (0.0320)	
0.9999938 1.5263969e-06
===========>   testing    <===========
Epoch: [1652][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0356 (0.0356)	
0.9999912 1.4486975e-06
Epoch: [1652][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0252 (0.0604)	
0.99999046 1.7641834e-06
Epoch: [1652][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0771 (0.0598)	
0.9999893 1.5077248e-06
loss:  0.040332739556159125 0.038285376973611895
===========>   training    <===========
Epoch: [1653][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0336 (0.0336)	
0.99999547 2.8055747e-06
===========>   testing    <===========
Epoch: [1653][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0411 (0.0411)	
0.9999908 1.3470998e-06
Epoch: [1653][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0254 (0.0599)	
0.99999094 1.605496e-06
Epoch: [1653][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0680 (0.0594)	
0.9999887 1.3651124e-06
loss:  0.04004662673481829 0.038285376973611895
===========>   training    <===========
Epoch: [1654][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0381 (0.0381)	
0.9999974 5.7625857e-07
===========>   testing    <===========
Epoch: [1654][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0399 (0.0399)	
0.9999901 1.4181824e-06
Epoch: [1654][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0260 (0.0585)	
0.9999918 1.7482839e-06
Epoch: [1654][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0737 (0.0588)	
0.9999893 1.471347e-06
loss:  0.03954942477347745 0.038285376973611895
===========>   training    <===========
Epoch: [1655][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0357 (0.0357)	
0.9999908 2.131191e-06
===========>   testing    <===========
Epoch: [1655][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0379 (0.0379)	
0.99998975 1.4123138e-06
Epoch: [1655][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0260 (0.0583)	
0.9999906 1.6160999e-06
Epoch: [1655][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0726 (0.0591)	
0.99998844 1.4592289e-06
loss:  0.039429853595498 0.038285376973611895
===========>   training    <===========
Epoch: [1656][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0325 (0.0325)	
0.9999945 1.8582557e-06
===========>   testing    <===========
Epoch: [1656][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0418 (0.0418)	
0.9999924 1.3713443e-06
Epoch: [1656][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0290 (0.0587)	
0.99999285 1.6432697e-06
Epoch: [1656][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0609 (0.0590)	
0.9999913 1.5744039e-06
loss:  0.039189221461911505 0.038285376973611895
===========>   training    <===========
Epoch: [1657][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0372 (0.0372)	
0.99999523 1.0526725e-06
===========>   testing    <===========
Epoch: [1657][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0397 (0.0397)	
0.9999902 1.4275779e-06
Epoch: [1657][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0349 (0.0596)	
0.9999902 1.5851018e-06
Epoch: [1657][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0675 (0.0596)	
0.9999882 1.4026309e-06
loss:  0.03967972106471129 0.038285376973611895
===========>   training    <===========
Epoch: [1658][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0310 (0.0310)	
0.9999778 1.2109854e-06
===========>   testing    <===========
Epoch: [1658][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0415 (0.0415)	
0.9999912 1.4459342e-06
Epoch: [1658][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0291 (0.0597)	
0.9999919 1.7123874e-06
Epoch: [1658][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0672 (0.0601)	
0.9999907 1.4904848e-06
loss:  0.03957796910125444 0.038285376973611895
===========>   training    <===========
Epoch: [1659][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0317 (0.0317)	
0.9999926 2.46125e-06
===========>   testing    <===========
Epoch: [1659][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0433 (0.0433)	
0.9999908 1.5650849e-06
Epoch: [1659][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0330 (0.0599)	
0.99999166 1.8415631e-06
Epoch: [1659][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0769 (0.0602)	
0.9999902 1.5747282e-06
loss:  0.03964199272158164 0.038285376973611895
===========>   training    <===========
Epoch: [1660][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0376 (0.0376)	
0.9999957 1.7300231e-06
===========>   testing    <===========
Epoch: [1660][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0376 (0.0376)	
0.9999914 1.4658121e-06
Epoch: [1660][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0269 (0.0597)	
0.9999931 1.7463609e-06
Epoch: [1660][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0739 (0.0602)	
0.9999902 1.472373e-06
loss:  0.03972655835317784 0.038285376973611895
===========>   training    <===========
Epoch: [1661][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0407 (0.0407)	
0.9999968 2.5157967e-06
===========>   testing    <===========
Epoch: [1661][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0368 (0.0368)	
0.99999154 1.5917217e-06
Epoch: [1661][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0276 (0.0599)	
0.9999933 1.9443419e-06
Epoch: [1661][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0768 (0.0596)	
0.99999225 1.6346075e-06
loss:  0.03951112147473124 0.038285376973611895
===========>   training    <===========
Epoch: [1662][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0425 (0.0425)	
0.9999782 1.1201622e-06
===========>   testing    <===========
Epoch: [1662][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0406 (0.0406)	
0.99999094 1.4090609e-06
Epoch: [1662][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0319 (0.0596)	
0.9999924 1.6595288e-06
Epoch: [1662][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0735 (0.0596)	
0.9999907 1.4273328e-06
loss:  0.039615770274358475 0.038285376973611895
===========>   training    <===========
Epoch: [1663][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0331 (0.0331)	
0.99998224 1.0541875e-06
===========>   testing    <===========
Epoch: [1663][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0445 (0.0445)	
0.9999925 1.911514e-06
Epoch: [1663][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0309 (0.0601)	
0.9999937 2.353153e-06
Epoch: [1663][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0795 (0.0595)	
0.99999344 2.0580926e-06
loss:  0.03958045972504942 0.038285376973611895
===========>   training    <===========
Epoch: [1664][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0394 (0.0394)	
0.999995 2.1174374e-06
===========>   testing    <===========
Epoch: [1664][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0443 (0.0443)	
0.9999913 1.6985626e-06
Epoch: [1664][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0337 (0.0600)	
0.9999932 2.0882267e-06
Epoch: [1664][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0742 (0.0593)	
0.9999918 1.7627673e-06
loss:  0.03962264963125528 0.038285376973611895
===========>   training    <===========
Epoch: [1665][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0365 (0.0365)	
0.9999939 2.4419544e-06
===========>   testing    <===========
Epoch: [1665][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0424 (0.0424)	
0.9999893 1.3533244e-06
Epoch: [1665][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0358 (0.0602)	
0.9999888 1.5481559e-06
Epoch: [1665][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0770 (0.0595)	
0.9999871 1.3324726e-06
loss:  0.03994464362413852 0.038285376973611895
===========>   training    <===========
Epoch: [1666][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0315 (0.0315)	
0.9999902 1.7015977e-06
===========>   testing    <===========
Epoch: [1666][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0341 (0.0341)	
0.9999907 1.4444362e-06
Epoch: [1666][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0348 (0.0595)	
0.99998975 1.7231998e-06
Epoch: [1666][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0924 (0.0596)	
0.9999888 1.4786955e-06
loss:  0.0396533144073139 0.038285376973611895
===========>   training    <===========
Epoch: [1667][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0316 (0.0316)	
0.9999969 2.3944465e-06
===========>   testing    <===========
Epoch: [1667][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0377 (0.0377)	
0.9999914 1.7535505e-06
Epoch: [1667][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0325 (0.0593)	
0.9999927 2.0917985e-06
Epoch: [1667][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0866 (0.0594)	
0.9999925 1.8803233e-06
loss:  0.039400304474304315 0.038285376973611895
===========>   training    <===========
Epoch: [1668][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0317 (0.0317)	
0.99998283 9.3125647e-07
===========>   testing    <===========
Epoch: [1668][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0357 (0.0357)	
0.99999046 1.5240652e-06
Epoch: [1668][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0329 (0.0596)	
0.9999896 1.7448261e-06
Epoch: [1668][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0846 (0.0598)	
0.9999882 1.4985876e-06
loss:  0.03968152742758935 0.038285376973611895
===========>   training    <===========
Epoch: [1669][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0341 (0.0341)	
0.9999943 7.8268295e-07
===========>   testing    <===========
Epoch: [1669][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0355 (0.0355)	
0.9999913 1.5833464e-06
Epoch: [1669][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0288 (0.0597)	
0.9999926 1.9586273e-06
Epoch: [1669][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0853 (0.0596)	
0.99999225 1.7217853e-06
loss:  0.03978599382327119 0.038285376973611895
===========>   training    <===========
Epoch: [1670][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0328 (0.0328)	
0.9999933 1.6013764e-06
===========>   testing    <===========
Epoch: [1670][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0395 (0.0395)	
0.9999908 1.4419134e-06
Epoch: [1670][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0304 (0.0594)	
0.9999918 1.78636e-06
Epoch: [1670][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0754 (0.0590)	
0.99999 1.4632185e-06
loss:  0.03991219911427357 0.038285376973611895
===========>   training    <===========
Epoch: [1671][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0325 (0.0325)	
0.99999607 3.0069123e-06
===========>   testing    <===========
Epoch: [1671][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0361 (0.0361)	
0.9999901 1.4060313e-06
Epoch: [1671][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0273 (0.0590)	
0.99999034 1.5312695e-06
Epoch: [1671][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0812 (0.0594)	
0.9999877 1.3564267e-06
loss:  0.03966271943369093 0.038285376973611895
===========>   training    <===========
Epoch: [1672][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0357 (0.0357)	
0.9999945 1.6981966e-06
===========>   testing    <===========
Epoch: [1672][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0449 (0.0449)	
0.9999907 1.4960416e-06
Epoch: [1672][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0330 (0.0598)	
0.9999926 1.8299907e-06
Epoch: [1672][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0844 (0.0595)	
0.99999046 1.5515465e-06
loss:  0.039939373997814775 0.038285376973611895
===========>   training    <===========
Epoch: [1673][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0350 (0.0350)	
0.9999871 1.0769157e-06
===========>   testing    <===========
Epoch: [1673][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0390 (0.0390)	
0.99999106 1.5378756e-06
Epoch: [1673][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0255 (0.0595)	
0.99999285 1.8765883e-06
Epoch: [1673][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0830 (0.0593)	
0.9999907 1.6739295e-06
loss:  0.03972628343564488 0.038285376973611895
===========>   training    <===========
Epoch: [1674][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0317 (0.0317)	
0.9999889 1.5363524e-06
===========>   testing    <===========
Epoch: [1674][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0396 (0.0396)	
0.99999046 1.4245016e-06
Epoch: [1674][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0250 (0.0595)	
0.9999927 1.7589435e-06
Epoch: [1674][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0799 (0.0591)	
0.9999906 1.5600065e-06
loss:  0.039760427791919906 0.038285376973611895
===========>   training    <===========
Epoch: [1675][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0342 (0.0342)	
0.99999 1.3860188e-06
===========>   testing    <===========
Epoch: [1675][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0451 (0.0451)	
0.9999937 1.9006891e-06
Epoch: [1675][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0331 (0.0602)	
0.9999964 2.6036469e-06
Epoch: [1675][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0717 (0.0593)	
0.99999607 2.292025e-06
loss:  0.03987825477856621 0.038285376973611895
===========>   training    <===========
Epoch: [1676][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0353 (0.0353)	
0.99998903 3.8747038e-07
===========>   testing    <===========
Epoch: [1676][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0503 (0.0503)	
0.99999106 1.5933529e-06
Epoch: [1676][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0324 (0.0598)	
0.9999937 2.0745351e-06
Epoch: [1676][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0912 (0.0593)	
0.99999297 1.753094e-06
loss:  0.039918934926252425 0.038285376973611895
===========>   training    <===========
Epoch: [1677][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0327 (0.0327)	
0.99999416 1.4713021e-06
===========>   testing    <===========
Epoch: [1677][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0493 (0.0493)	
0.9999931 1.724936e-06
Epoch: [1677][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0438 (0.0593)	
0.99999523 2.2083661e-06
Epoch: [1677][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0790 (0.0588)	
0.9999944 1.910211e-06
loss:  0.0396587129268009 0.038285376973611895
===========>   training    <===========
Epoch: [1678][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0323 (0.0323)	
0.99999297 1.0676997e-06
===========>   testing    <===========
Epoch: [1678][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0505 (0.0505)	
0.99999 1.500421e-06
Epoch: [1678][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0288 (0.0592)	
0.9999925 1.919887e-06
Epoch: [1678][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0707 (0.0587)	
0.99999154 1.5954619e-06
loss:  0.039972143614622424 0.038285376973611895
===========>   training    <===========
Epoch: [1679][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0330 (0.0330)	
0.99998367 7.883733e-07
===========>   testing    <===========
Epoch: [1679][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0480 (0.0480)	
0.99999285 1.5533141e-06
Epoch: [1679][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0285 (0.0594)	
0.99999404 1.987025e-06
Epoch: [1679][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0834 (0.0595)	
0.99999344 1.6297603e-06
loss:  0.03994079583322807 0.038285376973611895
===========>   training    <===========
Epoch: [1680][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0389 (0.0389)	
0.99999094 1.8381013e-06
===========>   testing    <===========
Epoch: [1680][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0629 (0.0629)	
0.9999912 1.5080828e-06
Epoch: [1680][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0316 (0.0589)	
0.9999927 1.7437649e-06
Epoch: [1680][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0758 (0.0588)	
0.9999908 1.5180407e-06
loss:  0.03981461968458888 0.038285376973611895
===========>   training    <===========
Epoch: [1681][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0314 (0.0314)	
0.99998474 2.1038854e-07
===========>   testing    <===========
Epoch: [1681][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0492 (0.0492)	
0.99999106 1.5385813e-06
Epoch: [1681][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0261 (0.0585)	
0.99999213 1.7848497e-06
Epoch: [1681][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0773 (0.0587)	
0.9999908 1.550233e-06
loss:  0.039803260438185495 0.038285376973611895
===========>   training    <===========
Epoch: [1682][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0330 (0.0330)	
0.9999876 1.3853461e-06
===========>   testing    <===========
Epoch: [1682][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0511 (0.0511)	
0.99999034 1.4334455e-06
Epoch: [1682][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0236 (0.0594)	
0.99999094 1.5637332e-06
Epoch: [1682][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0819 (0.0600)	
0.9999877 1.4370577e-06
loss:  0.040373636207567065 0.038285376973611895
===========>   training    <===========
Epoch: [1683][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0300 (0.0300)	
0.99998796 6.1949e-07
===========>   testing    <===========
Epoch: [1683][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0508 (0.0508)	
0.999992 1.6559591e-06
Epoch: [1683][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0228 (0.0597)	
0.99999416 2.070505e-06
Epoch: [1683][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0722 (0.0599)	
0.99999297 1.7490461e-06
loss:  0.04019561772036773 0.038285376973611895
===========>   training    <===========
Epoch: [1684][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0389 (0.0389)	
0.99999774 2.9314701e-06
===========>   testing    <===========
Epoch: [1684][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0455 (0.0455)	
0.9999913 1.5289623e-06
Epoch: [1684][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0308 (0.0594)	
0.99999213 1.7328798e-06
Epoch: [1684][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0610 (0.0591)	
0.9999902 1.5426054e-06
loss:  0.040310741002260064 0.038285376973611895
===========>   training    <===========
Epoch: [1685][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0356 (0.0356)	
0.9999877 1.2480817e-06
===========>   testing    <===========
Epoch: [1685][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0452 (0.0452)	
0.999992 1.5227546e-06
Epoch: [1685][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0322 (0.0597)	
0.99999213 1.7856346e-06
Epoch: [1685][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0660 (0.0592)	
0.9999912 1.5539749e-06
loss:  0.04023332901412391 0.038285376973611895
===========>   training    <===========
Epoch: [1686][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0304 (0.0304)	
0.9999951 7.5985355e-07
===========>   testing    <===========
Epoch: [1686][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0470 (0.0470)	
0.99999106 1.5667067e-06
Epoch: [1686][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0325 (0.0602)	
0.99999154 1.7198669e-06
Epoch: [1686][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0646 (0.0593)	
0.99999046 1.5666305e-06
loss:  0.04027757656493014 0.038285376973611895
===========>   training    <===========
Epoch: [1687][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0356 (0.0356)	
0.9999957 4.964382e-06
===========>   testing    <===========
Epoch: [1687][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0490 (0.0490)	
0.99999213 1.6523306e-06
Epoch: [1687][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0317 (0.0604)	
0.9999924 2.050632e-06
Epoch: [1687][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0776 (0.0594)	
0.9999918 1.696057e-06
loss:  0.039895728171423506 0.038285376973611895
===========>   training    <===========
Epoch: [1688][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0354 (0.0354)	
0.99999297 1.6292599e-06
===========>   testing    <===========
Epoch: [1688][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0465 (0.0465)	
0.99999213 1.5887887e-06
Epoch: [1688][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0289 (0.0605)	
0.9999919 2.0896093e-06
Epoch: [1688][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0841 (0.0593)	
0.99999154 1.6666121e-06
loss:  0.04008912278892396 0.038285376973611895
===========>   training    <===========
Epoch: [1689][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0366 (0.0366)	
0.999998 1.5772968e-06
===========>   testing    <===========
Epoch: [1689][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0484 (0.0484)	
0.9999908 1.5128524e-06
Epoch: [1689][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0299 (0.0600)	
0.9999912 1.8098095e-06
Epoch: [1689][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0828 (0.0593)	
0.9999906 1.5530194e-06
loss:  0.04023527665528248 0.038285376973611895
===========>   training    <===========
Epoch: [1690][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0342 (0.0342)	
0.9999937 7.041517e-07
===========>   testing    <===========
Epoch: [1690][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0507 (0.0507)	
0.99999225 1.8447887e-06
Epoch: [1690][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0274 (0.0605)	
0.99999404 2.2741015e-06
Epoch: [1690][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0863 (0.0596)	
0.9999932 1.9080117e-06
loss:  0.0400990322377176 0.038285376973611895
===========>   training    <===========
Epoch: [1691][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0340 (0.0340)	
0.9999924 1.6465829e-06
===========>   testing    <===========
Epoch: [1691][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0453 (0.0453)	
0.9999906 1.8210214e-06
Epoch: [1691][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0304 (0.0601)	
0.9999925 2.0004525e-06
Epoch: [1691][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0902 (0.0598)	
0.9999914 1.8457177e-06
loss:  0.04033209621038514 0.038285376973611895
===========>   training    <===========
Epoch: [1692][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0401 (0.0401)	
0.9999957 3.0096235e-06
===========>   testing    <===========
Epoch: [1692][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0407 (0.0407)	
0.9999926 1.741709e-06
Epoch: [1692][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0274 (0.0597)	
0.99999344 2.1236538e-06
Epoch: [1692][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0762 (0.0593)	
0.99999213 1.8295144e-06
loss:  0.04001311358100412 0.038285376973611895
===========>   training    <===========
Epoch: [1693][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0346 (0.0346)	
0.99998415 7.7976387e-07
===========>   testing    <===========
Epoch: [1693][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0418 (0.0418)	
0.9999902 1.6614291e-06
Epoch: [1693][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0341 (0.0598)	
0.999992 1.694437e-06
Epoch: [1693][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0842 (0.0596)	
0.9999901 1.6182468e-06
loss:  0.040041206102156 0.038285376973611895
===========>   training    <===========
Epoch: [1694][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0293 (0.0293)	
0.99998796 1.3057149e-06
===========>   testing    <===========
Epoch: [1694][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0426 (0.0426)	
0.9999887 1.6890159e-06
Epoch: [1694][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0324 (0.0596)	
0.9999894 1.7282522e-06
Epoch: [1694][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0797 (0.0594)	
0.9999876 1.6753735e-06
loss:  0.0399022440822947 0.038285376973611895
===========>   training    <===========
Epoch: [1695][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0334 (0.0334)	
0.9999887 9.924298e-07
===========>   testing    <===========
Epoch: [1695][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0438 (0.0438)	
0.9999908 1.6765625e-06
Epoch: [1695][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0267 (0.0595)	
0.9999926 2.0503112e-06
Epoch: [1695][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0909 (0.0594)	
0.99999106 1.7595476e-06
loss:  0.039736245604529374 0.038285376973611895
===========>   training    <===========
Epoch: [1696][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0301 (0.0301)	
0.9999844 1.2977104e-06
===========>   testing    <===========
Epoch: [1696][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0427 (0.0427)	
0.9999896 1.6916243e-06
Epoch: [1696][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0308 (0.0591)	
0.9999931 2.1706733e-06
Epoch: [1696][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0957 (0.0588)	
0.9999918 1.8066521e-06
loss:  0.039302183010543 0.038285376973611895
===========>   training    <===========
Epoch: [1697][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0356 (0.0356)	
0.99999416 1.3417995e-06
===========>   testing    <===========
Epoch: [1697][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0471 (0.0471)	
0.9999914 1.7133284e-06
Epoch: [1697][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0362 (0.0599)	
0.9999943 2.272532e-06
Epoch: [1697][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0809 (0.0593)	
0.99999356 1.8636634e-06
loss:  0.03941837408559834 0.038285376973611895
===========>   training    <===========
Epoch: [1698][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0377 (0.0377)	
0.99998903 1.36669e-06
===========>   testing    <===========
Epoch: [1698][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0456 (0.0456)	
0.9999881 1.5712254e-06
Epoch: [1698][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0308 (0.0589)	
0.99999225 1.7280083e-06
Epoch: [1698][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0929 (0.0594)	
0.9999906 1.5958803e-06
loss:  0.040248480379878826 0.038285376973611895
===========>   training    <===========
Epoch: [1699][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0335 (0.0335)	
0.9999951 1.3525541e-06
===========>   testing    <===========
Epoch: [1699][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0447 (0.0447)	
0.9999888 1.4962056e-06
Epoch: [1699][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0301 (0.0587)	
0.999992 1.6773781e-06
Epoch: [1699][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0831 (0.0600)	
0.99999046 1.5075997e-06
loss:  0.039763349305511286 0.038285376973611895
===========>   training    <===========
Epoch: [1700][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0298 (0.0298)	
0.99999094 1.5617361e-06
===========>   testing    <===========
Epoch: [1700][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0468 (0.0468)	
0.9999895 1.651228e-06
Epoch: [1700][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0246 (0.0594)	
0.9999927 2.013329e-06
Epoch: [1700][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0926 (0.0605)	
0.9999906 1.7183193e-06
loss:  0.040077524379634744 0.038285376973611895
===========>   training    <===========
Epoch: [1701][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0352 (0.0352)	
0.99999654 1.3035661e-06
===========>   testing    <===========
Epoch: [1701][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0441 (0.0441)	
0.9999901 1.6393127e-06
Epoch: [1701][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0249 (0.0595)	
0.99999225 2.00146e-06
Epoch: [1701][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0812 (0.0606)	
0.9999907 1.7290433e-06
loss:  0.03986767995129337 0.038285376973611895
===========>   training    <===========
Epoch: [1702][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0441 (0.0441)	
0.99999094 2.513705e-07
===========>   testing    <===========
Epoch: [1702][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0407 (0.0407)	
0.9999896 1.5829205e-06
Epoch: [1702][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0255 (0.0596)	
0.9999912 1.8057908e-06
Epoch: [1702][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0839 (0.0609)	
0.9999894 1.6199731e-06
loss:  0.0402783176868734 0.038285376973611895
===========>   training    <===========
Epoch: [1703][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0340 (0.0340)	
0.9999877 1.3441713e-06
===========>   testing    <===========
Epoch: [1703][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0446 (0.0446)	
0.99998987 1.6999368e-06
Epoch: [1703][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0262 (0.0592)	
0.99999225 2.0807288e-06
Epoch: [1703][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0907 (0.0602)	
0.9999907 1.787727e-06
loss:  0.04002407927955587 0.038285376973611895
===========>   training    <===========
Epoch: [1704][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0349 (0.0349)	
0.9999957 1.7791548e-06
===========>   testing    <===========
Epoch: [1704][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0400 (0.0400)	
0.9999896 1.7146327e-06
Epoch: [1704][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0282 (0.0588)	
0.99999154 1.9900156e-06
Epoch: [1704][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0826 (0.0598)	
0.99998987 1.7488841e-06
loss:  0.03952627999010505 0.038285376973611895
===========>   training    <===========
Epoch: [1705][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0400 (0.0400)	
0.9999938 1.3320737e-06
===========>   testing    <===========
Epoch: [1705][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0450 (0.0450)	
0.99998903 1.7492662e-06
Epoch: [1705][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0240 (0.0599)	
0.9999914 2.102639e-06
Epoch: [1705][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0729 (0.0599)	
0.99999034 1.8315761e-06
loss:  0.04004708838716298 0.038285376973611895
===========>   training    <===========
Epoch: [1706][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0402 (0.0402)	
0.9999943 1.992703e-06
===========>   testing    <===========
Epoch: [1706][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0421 (0.0421)	
0.9999889 1.5988753e-06
Epoch: [1706][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0224 (0.0595)	
0.99999046 1.9690551e-06
Epoch: [1706][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0720 (0.0592)	
0.99998915 1.6801046e-06
loss:  0.0399600987213794 0.038285376973611895
===========>   training    <===========
Epoch: [1707][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0383 (0.0383)	
0.9999968 2.3076889e-07
===========>   testing    <===========
Epoch: [1707][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0423 (0.0423)	
0.99999034 1.7395624e-06
Epoch: [1707][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0234 (0.0596)	
0.9999925 2.180726e-06
Epoch: [1707][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0707 (0.0587)	
0.999992 1.986201e-06
loss:  0.03964212907761244 0.038285376973611895
===========>   training    <===========
Epoch: [1708][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0376 (0.0376)	
0.99998915 1.3054971e-06
===========>   testing    <===========
Epoch: [1708][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0439 (0.0439)	
0.99999166 1.7066749e-06
Epoch: [1708][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0268 (0.0593)	
0.99999285 2.1504459e-06
Epoch: [1708][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0778 (0.0590)	
0.9999924 1.9971278e-06
loss:  0.03969683453304329 0.038285376973611895
===========>   training    <===========
Epoch: [1709][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0323 (0.0323)	
0.99999475 1.8236441e-06
===========>   testing    <===========
Epoch: [1709][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0473 (0.0473)	
0.9999906 1.5936021e-06
Epoch: [1709][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0253 (0.0597)	
0.9999919 1.966796e-06
Epoch: [1709][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0882 (0.0599)	
0.99999106 1.7320438e-06
loss:  0.04015158682638398 0.038285376973611895
===========>   training    <===========
Epoch: [1710][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0343 (0.0343)	
0.9999902 1.5148216e-06
===========>   testing    <===========
Epoch: [1710][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0478 (0.0478)	
0.99999034 1.4428748e-06
Epoch: [1710][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0279 (0.0595)	
0.99998903 1.645688e-06
Epoch: [1710][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0731 (0.0601)	
0.9999864 1.485932e-06
loss:  0.040401165047922016 0.038285376973611895
===========>   training    <===========
Epoch: [1711][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0294 (0.0294)	
0.9999976 3.1976676e-06
===========>   testing    <===========
Epoch: [1711][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0496 (0.0496)	
0.9999927 1.7993084e-06
Epoch: [1711][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0313 (0.0599)	
0.9999931 2.2890063e-06
Epoch: [1711][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0771 (0.0604)	
0.99999225 2.1557476e-06
loss:  0.040184786564561814 0.038285376973611895
===========>   training    <===========
Epoch: [1712][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0305 (0.0305)	
0.99999774 7.51796e-06
===========>   testing    <===========
Epoch: [1712][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0438 (0.0438)	
0.99999034 1.5876178e-06
Epoch: [1712][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0290 (0.0599)	
0.9999906 1.9268737e-06
Epoch: [1712][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0824 (0.0610)	
0.99998987 1.6606814e-06
loss:  0.04070363258749732 0.038285376973611895
===========>   training    <===========
Epoch: [1713][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0354 (0.0354)	
0.99999905 2.9058738e-06
===========>   testing    <===========
Epoch: [1713][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0447 (0.0447)	
0.99999213 1.8022777e-06
Epoch: [1713][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0277 (0.0599)	
0.99999285 2.2703139e-06
Epoch: [1713][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0874 (0.0604)	
0.99999225 2.2094046e-06
loss:  0.04007371957240313 0.038285376973611895
===========>   training    <===========
Epoch: [1714][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0305 (0.0305)	
0.9999883 1.8713895e-06
===========>   testing    <===========
Epoch: [1714][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0427 (0.0427)	
0.9999914 1.6381e-06
Epoch: [1714][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0359 (0.0596)	
0.999992 2.0911561e-06
Epoch: [1714][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0751 (0.0606)	
0.9999912 2.0169268e-06
loss:  0.040146545092483055 0.038285376973611895
===========>   training    <===========
Epoch: [1715][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0302 (0.0302)	
0.9999912 2.1632645e-06
===========>   testing    <===========
Epoch: [1715][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0514 (0.0514)	
0.9999893 1.4688068e-06
Epoch: [1715][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0305 (0.0596)	
0.9999908 1.8481765e-06
Epoch: [1715][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0809 (0.0598)	
0.9999893 1.6511037e-06
loss:  0.04011740226189353 0.038285376973611895
===========>   training    <===========
Epoch: [1716][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0336 (0.0336)	
0.9999906 9.5333695e-07
===========>   testing    <===========
Epoch: [1716][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0465 (0.0465)	
0.9999912 1.6182669e-06
Epoch: [1716][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0256 (0.0593)	
0.9999924 2.05335e-06
Epoch: [1716][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0953 (0.0603)	
0.99999166 1.9003229e-06
loss:  0.04047937501126542 0.038285376973611895
===========>   training    <===========
Epoch: [1717][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0326 (0.0326)	
0.99997926 1.5122552e-06
===========>   testing    <===========
Epoch: [1717][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0461 (0.0461)	
0.99999213 1.6044261e-06
Epoch: [1717][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0287 (0.0595)	
0.99999356 2.0000211e-06
Epoch: [1717][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0877 (0.0597)	
0.99999166 1.8477397e-06
loss:  0.04030153923222901 0.038285376973611895
===========>   training    <===========
Epoch: [1718][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0322 (0.0322)	
0.99998796 1.9045431e-06
===========>   testing    <===========
Epoch: [1718][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0482 (0.0482)	
0.9999888 1.5346641e-06
Epoch: [1718][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0249 (0.0593)	
0.99998987 1.6876925e-06
Epoch: [1718][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0993 (0.0600)	
0.9999869 1.5292263e-06
loss:  0.04049009329918918 0.038285376973611895
===========>   training    <===========
Epoch: [1719][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0345 (0.0345)	
0.99998677 1.2195641e-06
===========>   testing    <===========
Epoch: [1719][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0459 (0.0459)	
0.9999913 1.5795848e-06
Epoch: [1719][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0247 (0.0590)	
0.999992 1.848046e-06
Epoch: [1719][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0964 (0.0592)	
0.9999901 1.6784694e-06
loss:  0.04018272434897863 0.038285376973611895
===========>   training    <===========
Epoch: [1720][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0344 (0.0344)	
0.9999932 1.5143623e-06
===========>   testing    <===========
Epoch: [1720][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0413 (0.0413)	
0.99999 1.5763435e-06
Epoch: [1720][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0250 (0.0592)	
0.99998903 1.6444424e-06
Epoch: [1720][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0884 (0.0600)	
0.99998796 1.5476124e-06
loss:  0.04028944869244544 0.038285376973611895
===========>   training    <===========
Epoch: [1721][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0339 (0.0339)	
0.9999968 9.614373e-07
===========>   testing    <===========
Epoch: [1721][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0373 (0.0373)	
0.9999907 1.6057471e-06
Epoch: [1721][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0239 (0.0592)	
0.9999894 1.676425e-06
Epoch: [1721][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0852 (0.0601)	
0.99998844 1.5803503e-06
loss:  0.04008605859450465 0.038285376973611895
===========>   training    <===========
Epoch: [1722][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0294 (0.0294)	
0.9999908 2.043629e-06
===========>   testing    <===========
Epoch: [1722][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0422 (0.0422)	
0.9999908 1.6228369e-06
Epoch: [1722][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0218 (0.0593)	
0.9999919 1.8997504e-06
Epoch: [1722][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1060 (0.0603)	
0.9999907 1.6576766e-06
loss:  0.04023825426056282 0.038285376973611895
===========>   training    <===========
Epoch: [1723][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0302 (0.0302)	
0.9999908 1.9150084e-06
===========>   testing    <===========
Epoch: [1723][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0382 (0.0382)	
0.99998903 1.4917547e-06
Epoch: [1723][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0230 (0.0591)	
0.9999893 1.6360984e-06
Epoch: [1723][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0994 (0.0602)	
0.9999875 1.4752839e-06
loss:  0.040301166566186986 0.038285376973611895
===========>   training    <===========
Epoch: [1724][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0336 (0.0336)	
0.9999896 2.282038e-06
===========>   testing    <===========
Epoch: [1724][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0361 (0.0361)	
0.9999912 1.5389202e-06
Epoch: [1724][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0216 (0.0597)	
0.999992 1.9314327e-06
Epoch: [1724][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0912 (0.0603)	
0.99999046 1.7347317e-06
loss:  0.04029526757504209 0.038285376973611895
===========>   training    <===========
Epoch: [1725][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0336 (0.0336)	
0.99997425 5.9797935e-07
===========>   testing    <===========
Epoch: [1725][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0373 (0.0373)	
0.9999913 1.5350564e-06
Epoch: [1725][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0216 (0.0597)	
0.99999225 1.956865e-06
Epoch: [1725][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0815 (0.0600)	
0.9999912 1.7115678e-06
loss:  0.039941010378855 0.038285376973611895
===========>   training    <===========
Epoch: [1726][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0328 (0.0328)	
0.99998224 1.7342585e-06
===========>   testing    <===========
Epoch: [1726][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0361 (0.0361)	
0.9999908 1.6523119e-06
Epoch: [1726][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0225 (0.0593)	
0.99999213 2.1196415e-06
Epoch: [1726][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0883 (0.0598)	
0.99999106 1.910867e-06
loss:  0.04004236879542189 0.038285376973611895
===========>   training    <===========
Epoch: [1727][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0337 (0.0337)	
0.99999046 5.7000852e-06
===========>   testing    <===========
Epoch: [1727][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0361 (0.0361)	
0.9999925 1.8569679e-06
Epoch: [1727][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0219 (0.0596)	
0.9999938 2.4687538e-06
Epoch: [1727][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0968 (0.0599)	
0.99999344 2.2756983e-06
loss:  0.04019837284942385 0.038285376973611895
===========>   training    <===========
Epoch: [1728][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0330 (0.0330)	
0.99999225 2.011698e-06
===========>   testing    <===========
Epoch: [1728][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0375 (0.0375)	
0.9999913 1.560746e-06
Epoch: [1728][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0243 (0.0590)	
0.99999154 2.0521811e-06
Epoch: [1728][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0858 (0.0588)	
0.99999106 1.730944e-06
loss:  0.03995686819351829 0.038285376973611895
===========>   training    <===========
Epoch: [1729][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0343 (0.0343)	
0.99999654 5.956191e-07
===========>   testing    <===========
Epoch: [1729][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0373 (0.0373)	
0.9999918 1.4159363e-06
Epoch: [1729][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0258 (0.0591)	
0.9999912 1.7038257e-06
Epoch: [1729][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0884 (0.0593)	
0.9999912 1.5100128e-06
loss:  0.03989893901650021 0.038285376973611895
===========>   training    <===========
Epoch: [1730][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0310 (0.0310)	
0.99999607 2.0070668e-07
===========>   testing    <===========
Epoch: [1730][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0389 (0.0389)	
0.9999907 1.4847604e-06
Epoch: [1730][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0252 (0.0590)	
0.9999907 1.800898e-06
Epoch: [1730][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0910 (0.0592)	
0.99999106 1.6216579e-06
loss:  0.0398238562937453 0.038285376973611895
===========>   training    <===========
Epoch: [1731][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0320 (0.0320)	
0.9999882 1.2859708e-06
===========>   testing    <===========
Epoch: [1731][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0380 (0.0380)	
0.99999225 1.4919397e-06
Epoch: [1731][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0271 (0.0581)	
0.9999918 1.8624233e-06
Epoch: [1731][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0967 (0.0585)	
0.9999918 1.6943013e-06
loss:  0.039526097129475746 0.038285376973611895
===========>   training    <===========
Epoch: [1732][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0338 (0.0338)	
0.9999963 1.993003e-06
===========>   testing    <===========
Epoch: [1732][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0400 (0.0400)	
0.9999925 1.5275502e-06
Epoch: [1732][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0319 (0.0584)	
0.99999166 1.8940159e-06
Epoch: [1732][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0736 (0.0586)	
0.99999213 1.6992204e-06
loss:  0.03957120774418543 0.038285376973611895
===========>   training    <===========
Epoch: [1733][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0414 (0.0414)	
0.99999046 1.1271642e-06
===========>   testing    <===========
Epoch: [1733][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0364 (0.0364)	
0.99999285 1.5857687e-06
Epoch: [1733][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0294 (0.0583)	
0.999992 1.9141464e-06
Epoch: [1733][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0808 (0.0589)	
0.9999924 1.7322618e-06
loss:  0.03953641329399915 0.038285376973611895
===========>   training    <===========
Epoch: [1734][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0299 (0.0299)	
0.9999926 7.903562e-07
===========>   testing    <===========
Epoch: [1734][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0358 (0.0358)	
0.99999034 1.3146775e-06
Epoch: [1734][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0286 (0.0581)	
0.9999887 1.4778497e-06
Epoch: [1734][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0772 (0.0588)	
0.99998987 1.3358929e-06
loss:  0.039575999300089815 0.038285376973611895
===========>   training    <===========
Epoch: [1735][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0351 (0.0351)	
0.9999876 1.371156e-06
===========>   testing    <===========
Epoch: [1735][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0367 (0.0367)	
0.99999154 1.5144085e-06
Epoch: [1735][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0262 (0.0580)	
0.99999154 1.7857299e-06
Epoch: [1735][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0808 (0.0592)	
0.999992 1.6544374e-06
loss:  0.03945641233752739 0.038285376973611895
===========>   training    <===========
Epoch: [1736][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0334 (0.0334)	
0.99999666 1.8325354e-06
===========>   testing    <===========
Epoch: [1736][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0413 (0.0413)	
0.99999166 1.7142993e-06
Epoch: [1736][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0286 (0.0580)	
0.9999926 1.9828187e-06
Epoch: [1736][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0807 (0.0595)	
0.9999931 1.8876846e-06
loss:  0.03977383698552084 0.038285376973611895
===========>   training    <===========
Epoch: [1737][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0504 (0.0504)	
0.9999926 1.4766296e-06
===========>   testing    <===========
Epoch: [1737][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0358 (0.0358)	
0.9999907 1.8824405e-06
Epoch: [1737][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0265 (0.0584)	
0.99999285 2.1432227e-06
Epoch: [1737][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0770 (0.0594)	
0.99999285 2.0167652e-06
loss:  0.040057222395572634 0.038285376973611895
===========>   training    <===========
Epoch: [1738][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0335 (0.0335)	
0.9999918 9.709187e-07
===========>   testing    <===========
Epoch: [1738][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0377 (0.0377)	
0.9999914 1.6444941e-06
Epoch: [1738][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0266 (0.0598)	
0.9999931 1.8347527e-06
Epoch: [1738][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0733 (0.0601)	
0.99999166 1.6884878e-06
loss:  0.0400114741596298 0.038285376973611895
===========>   training    <===========
Epoch: [1739][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0328 (0.0328)	
0.99999225 1.2529821e-06
===========>   testing    <===========
Epoch: [1739][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0414 (0.0414)	
0.9999914 1.6145163e-06
Epoch: [1739][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0237 (0.0596)	
0.9999933 1.9010299e-06
Epoch: [1739][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0767 (0.0599)	
0.9999924 1.7053993e-06
loss:  0.039881419490148895 0.038285376973611895
===========>   training    <===========
Epoch: [1740][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0301 (0.0301)	
0.99999213 9.383775e-06
===========>   testing    <===========
Epoch: [1740][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0469 (0.0469)	
0.9999893 1.5452189e-06
Epoch: [1740][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0245 (0.0595)	
0.9999913 1.848409e-06
Epoch: [1740][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0810 (0.0605)	
0.99999046 1.6318444e-06
loss:  0.040244406709454617 0.038285376973611895
===========>   training    <===========
Epoch: [1741][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0403 (0.0403)	
0.99999106 1.2949374e-06
===========>   testing    <===========
Epoch: [1741][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0406 (0.0406)	
0.99998975 1.4754133e-06
Epoch: [1741][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0258 (0.0591)	
0.99999106 1.7309968e-06
Epoch: [1741][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0772 (0.0603)	
0.9999902 1.5427142e-06
loss:  0.04001596044887723 0.038285376973611895
===========>   training    <===========
Epoch: [1742][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0327 (0.0327)	
0.99999 1.237277e-06
===========>   testing    <===========
Epoch: [1742][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0403 (0.0403)	
0.99999 1.437395e-06
Epoch: [1742][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0247 (0.0593)	
0.9999908 1.6159057e-06
Epoch: [1742][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0836 (0.0605)	
0.9999888 1.4622002e-06
loss:  0.04009587014549232 0.038285376973611895
===========>   training    <===========
Epoch: [1743][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0333 (0.0333)	
0.9999902 1.3005265e-06
===========>   testing    <===========
Epoch: [1743][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0468 (0.0468)	
0.99998975 1.6258792e-06
Epoch: [1743][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0248 (0.0593)	
0.9999919 1.943122e-06
Epoch: [1743][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0898 (0.0603)	
0.9999907 1.7008612e-06
loss:  0.03992848809611138 0.038285376973611895
===========>   training    <===========
Epoch: [1744][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0295 (0.0295)	
0.9999814 1.1353546e-06
===========>   testing    <===========
Epoch: [1744][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0475 (0.0475)	
0.99999 1.496865e-06
Epoch: [1744][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0242 (0.0589)	
0.9999912 1.5978083e-06
Epoch: [1744][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0956 (0.0606)	
0.99999046 1.5123187e-06
loss:  0.03989978935161165 0.038285376973611895
===========>   training    <===========
Epoch: [1745][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0344 (0.0344)	
0.9999882 2.360433e-06
===========>   testing    <===========
Epoch: [1745][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0448 (0.0448)	
0.99999 1.6198866e-06
Epoch: [1745][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0246 (0.0590)	
0.99999166 1.8564153e-06
Epoch: [1745][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0968 (0.0604)	
0.9999913 1.6641328e-06
loss:  0.039986837487505644 0.038285376973611895
===========>   training    <===========
Epoch: [1746][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0336 (0.0336)	
0.9999801 9.4693615e-07
===========>   testing    <===========
Epoch: [1746][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0410 (0.0410)	
0.9999893 1.3396552e-06
Epoch: [1746][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0249 (0.0589)	
0.99998784 1.3817479e-06
Epoch: [1746][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0832 (0.0603)	
0.9999871 1.3506374e-06
loss:  0.03996986778740763 0.038285376973611895
===========>   training    <===========
Epoch: [1747][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0301 (0.0301)	
0.99999535 1.9504446e-06
===========>   testing    <===========
Epoch: [1747][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0440 (0.0440)	
0.99998915 1.6367086e-06
Epoch: [1747][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0236 (0.0586)	
0.9999901 1.8329408e-06
Epoch: [1747][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0849 (0.0603)	
0.9999893 1.6561643e-06
loss:  0.03991077917867425 0.038285376973611895
===========>   training    <===========
Epoch: [1748][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0446 (0.0446)	
0.999992 1.121677e-06
===========>   testing    <===========
Epoch: [1748][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0465 (0.0465)	
0.9999914 1.6760638e-06
Epoch: [1748][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0234 (0.0591)	
0.9999927 1.989748e-06
Epoch: [1748][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0831 (0.0599)	
0.9999926 1.8740219e-06
loss:  0.03955279720203697 0.038285376973611895
===========>   training    <===========
Epoch: [1749][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0344 (0.0344)	
0.99999046 3.801536e-07
===========>   testing    <===========
Epoch: [1749][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0473 (0.0473)	
0.9999895 1.5268787e-06
Epoch: [1749][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0268 (0.0592)	
0.9999913 1.7696143e-06
Epoch: [1749][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0797 (0.0601)	
0.9999906 1.5801664e-06
loss:  0.03984632251467013 0.038285376973611895
===========>   training    <===========
Epoch: [1750][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0307 (0.0307)	
0.9999963 5.959122e-06
===========>   testing    <===========
Epoch: [1750][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0411 (0.0411)	
0.99999 1.5384902e-06
Epoch: [1750][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0245 (0.0592)	
0.99999213 1.7036454e-06
Epoch: [1750][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0902 (0.0606)	
0.99999154 1.5803896e-06
loss:  0.03981970065182927 0.038285376973611895
===========>   training    <===========
Epoch: [1751][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0326 (0.0326)	
0.99999285 3.0386625e-06
===========>   testing    <===========
Epoch: [1751][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0478 (0.0478)	
0.9999908 1.7200801e-06
Epoch: [1751][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0238 (0.0593)	
0.99999344 2.0280638e-06
Epoch: [1751][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.1017 (0.0603)	
0.9999927 1.7970841e-06
loss:  0.040079000875246074 0.038285376973611895
===========>   training    <===========
Epoch: [1752][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0308 (0.0308)	
0.9999914 2.0454677e-06
===========>   testing    <===========
Epoch: [1752][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0420 (0.0420)	
0.99999 1.476945e-06
Epoch: [1752][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0279 (0.0591)	
0.99999154 1.7173215e-06
Epoch: [1752][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0925 (0.0595)	
0.9999913 1.5571021e-06
loss:  0.0400182351761561 0.038285376973611895
===========>   training    <===========
Epoch: [1753][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0323 (0.0323)	
0.9999931 2.962989e-06
===========>   testing    <===========
Epoch: [1753][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0429 (0.0429)	
0.9999895 1.5834248e-06
Epoch: [1753][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0271 (0.0587)	
0.99999166 1.8734002e-06
Epoch: [1753][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0807 (0.0593)	
0.99999154 1.6401791e-06
loss:  0.039547668689541515 0.038285376973611895
===========>   training    <===========
Epoch: [1754][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0324 (0.0324)	
0.9999858 1.7096136e-06
===========>   testing    <===========
Epoch: [1754][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0450 (0.0450)	
0.9999893 1.5727067e-06
Epoch: [1754][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0287 (0.0588)	
0.99999154 1.8354843e-06
Epoch: [1754][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0861 (0.0597)	
0.999992 1.6285267e-06
loss:  0.03974672382288791 0.038285376973611895
===========>   training    <===========
Epoch: [1755][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0314 (0.0314)	
0.9999896 2.3896557e-06
===========>   testing    <===========
Epoch: [1755][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0438 (0.0438)	
0.9999896 1.5307089e-06
Epoch: [1755][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0249 (0.0592)	
0.99999166 1.7560909e-06
Epoch: [1755][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0817 (0.0603)	
0.99999213 1.5648044e-06
loss:  0.039915213601240285 0.038285376973611895
===========>   training    <===========
Epoch: [1756][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0348 (0.0348)	
0.9999949 1.2875735e-06
===========>   testing    <===========
Epoch: [1756][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0432 (0.0432)	
0.99999 1.5572209e-06
Epoch: [1756][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0243 (0.0589)	
0.99999213 1.7327707e-06
Epoch: [1756][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0834 (0.0605)	
0.9999919 1.5964268e-06
loss:  0.039523556489860945 0.038285376973611895
===========>   training    <===========
Epoch: [1757][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0365 (0.0365)	
0.9999939 2.280926e-06
===========>   testing    <===========
Epoch: [1757][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0443 (0.0443)	
0.99998915 1.588928e-06
Epoch: [1757][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0237 (0.0586)	
0.9999912 1.7906704e-06
Epoch: [1757][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0870 (0.0602)	
0.99999106 1.6385e-06
loss:  0.03957893865864026 0.038285376973611895
===========>   training    <===========
Epoch: [1758][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0299 (0.0299)	
0.9999918 1.5870835e-06
===========>   testing    <===========
Epoch: [1758][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0496 (0.0496)	
0.99998975 1.5455564e-06
Epoch: [1758][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0218 (0.0590)	
0.9999907 1.7182733e-06
Epoch: [1758][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0920 (0.0607)	
0.9999906 1.5755394e-06
loss:  0.03987781796243195 0.038285376973611895
===========>   training    <===========
Epoch: [1759][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0314 (0.0314)	
0.99999213 1.1619309e-06
===========>   testing    <===========
Epoch: [1759][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0470 (0.0470)	
0.99999094 1.5648461e-06
Epoch: [1759][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0238 (0.0585)	
0.99999213 1.7927636e-06
Epoch: [1759][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0857 (0.0601)	
0.9999925 1.6777749e-06
loss:  0.03954801978142641 0.038285376973611895
===========>   training    <===========
Epoch: [1760][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0330 (0.0330)	
0.9999989 3.3427318e-06
===========>   testing    <===========
Epoch: [1760][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0414 (0.0414)	
0.9999906 1.8229206e-06
Epoch: [1760][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0255 (0.0585)	
0.9999926 2.1294438e-06
Epoch: [1760][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0864 (0.0600)	
0.99999297 1.964518e-06
loss:  0.03941943269229331 0.038285376973611895
===========>   training    <===========
Epoch: [1761][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0362 (0.0362)	
0.99998724 1.3506876e-06
===========>   testing    <===========
Epoch: [1761][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0442 (0.0442)	
0.99999 1.4663826e-06
Epoch: [1761][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0303 (0.0585)	
0.99998975 1.6232331e-06
Epoch: [1761][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0825 (0.0599)	
0.99998915 1.4780892e-06
loss:  0.03972651154665885 0.038285376973611895
===========>   training    <===========
Epoch: [1762][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0294 (0.0294)	
0.9999918 1.4335427e-06
===========>   testing    <===========
Epoch: [1762][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0470 (0.0470)	
0.99999046 1.569129e-06
Epoch: [1762][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0298 (0.0586)	
0.99999225 1.8422218e-06
Epoch: [1762][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0854 (0.0599)	
0.9999918 1.6438246e-06
loss:  0.039282964214852 0.038285376973611895
===========>   training    <===========
Epoch: [1763][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0440 (0.0440)	
0.9999981 6.0073894e-06
===========>   testing    <===========
Epoch: [1763][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0460 (0.0460)	
0.99999154 1.4488274e-06
Epoch: [1763][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0284 (0.0586)	
0.9999931 1.7913383e-06
Epoch: [1763][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0836 (0.0595)	
0.9999931 1.5722027e-06
loss:  0.039355309810853334 0.038285376973611895
===========>   training    <===========
Epoch: [1764][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0360 (0.0360)	
0.9999918 7.221851e-07
===========>   testing    <===========
Epoch: [1764][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0445 (0.0445)	
0.9999906 1.3567334e-06
Epoch: [1764][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0282 (0.0581)	
0.9999908 1.5446429e-06
Epoch: [1764][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0834 (0.0593)	
0.9999908 1.3893259e-06
loss:  0.0394715415158966 0.038285376973611895
===========>   training    <===========
Epoch: [1765][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0276 (0.0276)	
0.9999931 1.4876944e-06
===========>   testing    <===========
Epoch: [1765][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0423 (0.0423)	
0.9999907 1.4763339e-06
Epoch: [1765][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0243 (0.0587)	
0.9999918 1.7434987e-06
Epoch: [1765][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0900 (0.0600)	
0.9999913 1.5181059e-06
loss:  0.03978181896463118 0.038285376973611895
===========>   training    <===========
Epoch: [1766][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0313 (0.0313)	
0.99999547 1.7913349e-06
===========>   testing    <===========
Epoch: [1766][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0505 (0.0505)	
0.99999285 1.8243554e-06
Epoch: [1766][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0314 (0.0590)	
0.9999938 2.2263043e-06
Epoch: [1766][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0897 (0.0589)	
0.99999464 2.0102557e-06
loss:  0.03964430106243433 0.038285376973611895
===========>   training    <===========
Epoch: [1767][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0320 (0.0320)	
0.99998677 6.4935983e-07
===========>   testing    <===========
Epoch: [1767][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0443 (0.0443)	
0.9999918 1.7459131e-06
Epoch: [1767][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0265 (0.0586)	
0.9999932 2.1110375e-06
Epoch: [1767][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0912 (0.0588)	
0.9999938 1.8263643e-06
loss:  0.03975983977384456 0.038285376973611895
===========>   training    <===========
Epoch: [1768][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0310 (0.0310)	
0.99999464 1.4150427e-06
===========>   testing    <===========
Epoch: [1768][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0464 (0.0464)	
0.99999225 1.4761931e-06
Epoch: [1768][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0252 (0.0586)	
0.99999297 1.7972966e-06
Epoch: [1768][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0833 (0.0587)	
0.9999932 1.5420906e-06
loss:  0.039690264391089025 0.038285376973611895
===========>   training    <===========
Epoch: [1769][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0346 (0.0346)	
0.9999938 1.9396043e-06
===========>   testing    <===========
Epoch: [1769][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0476 (0.0476)	
0.9999918 1.4591287e-06
Epoch: [1769][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0233 (0.0592)	
0.9999925 1.7101371e-06
Epoch: [1769][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0818 (0.0588)	
0.9999927 1.4907179e-06
loss:  0.03978800024446871 0.038285376973611895
===========>   training    <===========
Epoch: [1770][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0324 (0.0324)	
0.99998987 6.679911e-07
===========>   testing    <===========
Epoch: [1770][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0435 (0.0435)	
0.9999925 1.4747578e-06
Epoch: [1770][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0218 (0.0591)	
0.9999931 1.6760525e-06
Epoch: [1770][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0914 (0.0589)	
0.9999932 1.5396395e-06
loss:  0.03951720093417199 0.038285376973611895
===========>   training    <===========
Epoch: [1771][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0428 (0.0428)	
0.99999213 1.6539988e-06
===========>   testing    <===========
Epoch: [1771][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0459 (0.0459)	
0.999992 1.4882748e-06
Epoch: [1771][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0212 (0.0594)	
0.9999931 1.7605144e-06
Epoch: [1771][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0838 (0.0586)	
0.9999933 1.5474e-06
loss:  0.039729234957159076 0.038285376973611895
===========>   training    <===========
Epoch: [1772][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0303 (0.0303)	
0.99999845 2.3551465e-06
===========>   testing    <===========
Epoch: [1772][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0409 (0.0409)	
0.9999906 1.3614435e-06
Epoch: [1772][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0257 (0.0588)	
0.99999046 1.5252008e-06
Epoch: [1772][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0743 (0.0583)	
0.9999893 1.3804901e-06
loss:  0.03960035857544575 0.038285376973611895
===========>   training    <===========
Epoch: [1773][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0404 (0.0404)	
0.9999908 9.573421e-07
===========>   testing    <===========
Epoch: [1773][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0414 (0.0414)	
0.99999106 1.4522138e-06
Epoch: [1773][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0277 (0.0587)	
0.9999925 1.7668436e-06
Epoch: [1773][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0771 (0.0581)	
0.99999166 1.4848554e-06
loss:  0.03943184413496015 0.038285376973611895
===========>   training    <===========
Epoch: [1774][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0353 (0.0353)	
0.9999914 1.2871806e-06
===========>   testing    <===========
Epoch: [1774][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0407 (0.0407)	
0.9999908 1.4692578e-06
Epoch: [1774][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0248 (0.0583)	
0.9999924 1.8093764e-06
Epoch: [1774][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0861 (0.0580)	
0.9999914 1.4834882e-06
loss:  0.03959837809341449 0.038285376973611895
===========>   training    <===========
Epoch: [1775][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0306 (0.0306)	
0.99998415 1.1562138e-06
===========>   testing    <===========
Epoch: [1775][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0362 (0.0362)	
0.9999926 1.7372034e-06
Epoch: [1775][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0243 (0.0581)	
0.99999416 2.3105458e-06
Epoch: [1775][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0831 (0.0577)	
0.9999944 1.8476198e-06
loss:  0.03918324316176536 0.038285376973611895
===========>   training    <===========
Epoch: [1776][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0350 (0.0350)	
0.9999931 1.7149109e-06
===========>   testing    <===========
Epoch: [1776][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0416 (0.0416)	
0.9999908 1.5980277e-06
Epoch: [1776][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0217 (0.0586)	
0.9999925 1.910282e-06
Epoch: [1776][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0884 (0.0588)	
0.99999225 1.6453004e-06
loss:  0.03985431797430783 0.038285376973611895
===========>   training    <===========
Epoch: [1777][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0349 (0.0349)	
0.99998784 1.1997705e-06
===========>   testing    <===========
Epoch: [1777][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0415 (0.0415)	
0.99999166 1.5225877e-06
Epoch: [1777][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0247 (0.0590)	
0.9999932 1.9343802e-06
Epoch: [1777][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0774 (0.0586)	
0.9999933 1.6471483e-06
loss:  0.03968799705931292 0.038285376973611895
===========>   training    <===========
Epoch: [1778][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0328 (0.0328)	
0.9999958 2.0290252e-06
===========>   testing    <===========
Epoch: [1778][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0395 (0.0395)	
0.9999907 1.5248895e-06
Epoch: [1778][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0307 (0.0586)	
0.999992 1.8422342e-06
Epoch: [1778][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0764 (0.0579)	
0.9999919 1.5940307e-06
loss:  0.03937601940815327 0.038285376973611895
===========>   training    <===========
Epoch: [1779][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0413 (0.0413)	
0.9999968 1.4739536e-06
===========>   testing    <===========
Epoch: [1779][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0429 (0.0429)	
0.99999034 1.4795249e-06
Epoch: [1779][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0321 (0.0588)	
0.999992 1.7739078e-06
Epoch: [1779][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0701 (0.0576)	
0.9999919 1.5483419e-06
loss:  0.03916893968100432 0.038285376973611895
===========>   training    <===========
Epoch: [1780][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0355 (0.0355)	
0.9999913 3.5851326e-06
===========>   testing    <===========
Epoch: [1780][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0378 (0.0378)	
0.999992 1.4949563e-06
Epoch: [1780][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0239 (0.0591)	
0.9999932 1.8126647e-06
Epoch: [1780][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0757 (0.0582)	
0.99999356 1.5902029e-06
loss:  0.03920166019804283 0.038285376973611895
===========>   training    <===========
Epoch: [1781][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0327 (0.0327)	
0.99999475 1.6206313e-06
===========>   testing    <===========
Epoch: [1781][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0394 (0.0394)	
0.9999912 1.5511248e-06
Epoch: [1781][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0283 (0.0586)	
0.9999924 1.8483775e-06
Epoch: [1781][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0826 (0.0579)	
0.9999925 1.6409269e-06
loss:  0.0393280389860754 0.038285376973611895
===========>   training    <===========
Epoch: [1782][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0355 (0.0355)	
0.99999225 1.9032684e-06
===========>   testing    <===========
Epoch: [1782][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0415 (0.0415)	
0.9999914 1.5940261e-06
Epoch: [1782][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0317 (0.0586)	
0.99999344 2.1062956e-06
Epoch: [1782][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0668 (0.0575)	
0.99999404 1.7980767e-06
loss:  0.03887067013131307 0.038285376973611895
===========>   training    <===========
Epoch: [1783][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0334 (0.0334)	
0.9999931 2.942295e-06
===========>   testing    <===========
Epoch: [1783][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0408 (0.0408)	
0.9999907 1.3991746e-06
Epoch: [1783][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0272 (0.0588)	
0.99999154 1.6531976e-06
Epoch: [1783][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0771 (0.0583)	
0.99999106 1.4228262e-06
loss:  0.03938005918564491 0.038285376973611895
===========>   training    <===========
Epoch: [1784][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0327 (0.0327)	
0.9999914 9.3445556e-07
===========>   testing    <===========
Epoch: [1784][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0401 (0.0401)	
0.9999913 1.533485e-06
Epoch: [1784][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0255 (0.0592)	
0.9999932 1.8712735e-06
Epoch: [1784][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0796 (0.0585)	
0.9999932 1.6717025e-06
loss:  0.039365353611349296 0.038285376973611895
===========>   training    <===========
Epoch: [1785][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0397 (0.0397)	
0.9999851 9.62687e-07
===========>   testing    <===========
Epoch: [1785][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0438 (0.0438)	
0.99999213 1.6555201e-06
Epoch: [1785][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0235 (0.0591)	
0.9999943 2.091663e-06
Epoch: [1785][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0789 (0.0588)	
0.99999464 1.8802301e-06
loss:  0.0393182776886879 0.038285376973611895
===========>   training    <===========
Epoch: [1786][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0327 (0.0327)	
0.99999416 1.6207488e-06
===========>   testing    <===========
Epoch: [1786][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0485 (0.0485)	
0.99999166 1.6502331e-06
Epoch: [1786][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0271 (0.0589)	
0.99999416 2.103369e-06
Epoch: [1786][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0806 (0.0585)	
0.99999356 1.8273661e-06
loss:  0.0391464838367791 0.038285376973611895
===========>   training    <===========
Epoch: [1787][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0353 (0.0353)	
0.99999654 3.3279919e-06
===========>   testing    <===========
Epoch: [1787][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0538 (0.0538)	
0.99999106 1.6524284e-06
Epoch: [1787][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0251 (0.0585)	
0.99999344 2.0539396e-06
Epoch: [1787][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0782 (0.0585)	
0.9999938 1.7993701e-06
loss:  0.039038906644868865 0.038285376973611895
===========>   training    <===========
Epoch: [1788][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0398 (0.0398)	
0.99999404 2.7944798e-06
===========>   testing    <===========
Epoch: [1788][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0501 (0.0501)	
0.9999912 1.495812e-06
Epoch: [1788][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0225 (0.0584)	
0.9999927 1.793983e-06
Epoch: [1788][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0781 (0.0588)	
0.9999924 1.5803398e-06
loss:  0.03923835908162676 0.038285376973611895
===========>   training    <===========
Epoch: [1789][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0328 (0.0328)	
0.99999356 9.823973e-07
===========>   testing    <===========
Epoch: [1789][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0518 (0.0518)	
0.99999106 1.6304567e-06
Epoch: [1789][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0225 (0.0586)	
0.9999927 1.9469767e-06
Epoch: [1789][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0866 (0.0585)	
0.9999927 1.7373774e-06
loss:  0.03908503382412509 0.038285376973611895
===========>   training    <===========
Epoch: [1790][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0269 (0.0269)	
0.9999932 1.2226222e-06
===========>   testing    <===========
Epoch: [1790][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0513 (0.0513)	
0.99999046 1.6279754e-06
Epoch: [1790][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0223 (0.0590)	
0.9999927 1.9575032e-06
Epoch: [1790][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0752 (0.0584)	
0.9999924 1.7648953e-06
loss:  0.03928618211229207 0.038285376973611895
===========>   training    <===========
Epoch: [1791][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0350 (0.0350)	
0.9999888 2.2225113e-06
===========>   testing    <===========
Epoch: [1791][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0487 (0.0487)	
0.99998975 1.5268364e-06
Epoch: [1791][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0194 (0.0593)	
0.9999919 1.7926114e-06
Epoch: [1791][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0790 (0.0596)	
0.9999919 1.5786752e-06
loss:  0.03967262218758005 0.038285376973611895
===========>   training    <===========
Epoch: [1792][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0338 (0.0338)	
0.9999939 2.3546502e-06
===========>   testing    <===========
Epoch: [1792][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0446 (0.0446)	
0.99999 1.5237875e-06
Epoch: [1792][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0199 (0.0593)	
0.99999225 1.8111166e-06
Epoch: [1792][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0810 (0.0589)	
0.9999919 1.5947224e-06
loss:  0.03934112778931431 0.038285376973611895
===========>   training    <===========
Epoch: [1793][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0317 (0.0317)	
0.99999344 1.9359527e-06
===========>   testing    <===========
Epoch: [1793][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0477 (0.0477)	
0.999992 1.6397021e-06
Epoch: [1793][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0250 (0.0595)	
0.9999938 2.10299e-06
Epoch: [1793][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0823 (0.0585)	
0.9999937 1.8433079e-06
loss:  0.039010557402544555 0.038285376973611895
===========>   training    <===========
Epoch: [1794][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0316 (0.0316)	
0.99998796 7.0699e-07
===========>   testing    <===========
Epoch: [1794][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0473 (0.0473)	
0.9999913 1.5146627e-06
Epoch: [1794][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0248 (0.0590)	
0.99999285 1.9383506e-06
Epoch: [1794][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0867 (0.0584)	
0.99999297 1.683622e-06
loss:  0.0389336491772585 0.038285376973611895
===========>   training    <===========
Epoch: [1795][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0329 (0.0329)	
0.9999876 1.1866663e-06
===========>   testing    <===========
Epoch: [1795][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0487 (0.0487)	
0.99999034 1.3516604e-06
Epoch: [1795][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0224 (0.0585)	
0.99999166 1.6950382e-06
Epoch: [1795][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0896 (0.0584)	
0.99999166 1.4329685e-06
loss:  0.03920781134729623 0.038285376973611895
===========>   training    <===========
Epoch: [1796][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0269 (0.0269)	
0.99999404 1.668253e-06
===========>   testing    <===========
Epoch: [1796][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0422 (0.0422)	
0.9999901 1.4170251e-06
Epoch: [1796][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0224 (0.0584)	
0.9999913 1.7116137e-06
Epoch: [1796][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0956 (0.0586)	
0.9999913 1.518685e-06
loss:  0.03911071843113345 0.038285376973611895
===========>   training    <===========
Epoch: [1797][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0380 (0.0380)	
0.99999547 3.1948205e-06
===========>   testing    <===========
Epoch: [1797][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0432 (0.0432)	
0.9999889 1.4078078e-06
Epoch: [1797][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0242 (0.0587)	
0.9999901 1.6163435e-06
Epoch: [1797][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0808 (0.0590)	
0.9999912 1.4495074e-06
loss:  0.03954917018608706 0.038285376973611895
===========>   training    <===========
Epoch: [1798][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0366 (0.0366)	
0.9999958 1.8018857e-06
===========>   testing    <===========
Epoch: [1798][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0401 (0.0401)	
0.9999918 1.5526269e-06
Epoch: [1798][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0294 (0.0588)	
0.9999927 1.8878376e-06
Epoch: [1798][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0809 (0.0589)	
0.9999938 1.7104061e-06
loss:  0.039028552586862 0.038285376973611895
===========>   training    <===========
Epoch: [1799][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0333 (0.0333)	
0.99998975 1.261218e-06
===========>   testing    <===========
Epoch: [1799][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0418 (0.0418)	
0.99999046 1.5255964e-06
Epoch: [1799][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0265 (0.0591)	
0.99999213 1.7596985e-06
Epoch: [1799][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0845 (0.0591)	
0.9999933 1.5616171e-06
loss:  0.039482444669381 0.038285376973611895
===========>   training    <===========
Epoch: [1800][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0358 (0.0358)	
0.9999974 1.4102654e-06
===========>   testing    <===========
Epoch: [1800][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0419 (0.0419)	
0.99998915 1.4362699e-06
Epoch: [1800][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0242 (0.0584)	
0.9999914 1.691192e-06
Epoch: [1800][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0819 (0.0587)	
0.9999926 1.492422e-06
loss:  0.03920845052296229 0.038285376973611895
===========>   training    <===========
Epoch: [1801][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0333 (0.0333)	
0.9999951 2.8419233e-06
===========>   testing    <===========
Epoch: [1801][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0434 (0.0434)	
0.9999893 1.4313296e-06
Epoch: [1801][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0228 (0.0588)	
0.9999918 1.6544564e-06
Epoch: [1801][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0859 (0.0593)	
0.999992 1.4871952e-06
loss:  0.039762599675255084 0.038285376973611895
===========>   training    <===========
Epoch: [1802][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0323 (0.0323)	
0.9999871 2.5285808e-06
===========>   testing    <===========
Epoch: [1802][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0409 (0.0409)	
0.9999902 1.480369e-06
Epoch: [1802][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0250 (0.0584)	
0.9999927 1.7360193e-06
Epoch: [1802][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0793 (0.0583)	
0.99999344 1.597403e-06
loss:  0.03917461659706012 0.038285376973611895
===========>   training    <===========
Epoch: [1803][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0275 (0.0275)	
0.9999896 1.9648967e-06
===========>   testing    <===========
Epoch: [1803][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0418 (0.0418)	
0.9999882 1.3808759e-06
Epoch: [1803][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0238 (0.0585)	
0.9999907 1.5177917e-06
Epoch: [1803][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0934 (0.0585)	
0.9999907 1.3840388e-06
loss:  0.03931577411741005 0.038285376973611895
===========>   training    <===========
Epoch: [1804][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0393 (0.0393)	
0.99998665 1.7340585e-06
===========>   testing    <===========
Epoch: [1804][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0427 (0.0427)	
0.9999914 1.4848994e-06
Epoch: [1804][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0320 (0.0582)	
0.99999356 1.7337923e-06
Epoch: [1804][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0949 (0.0585)	
0.9999939 1.586466e-06
loss:  0.03920051035585692 0.038285376973611895
===========>   training    <===========
Epoch: [1805][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0374 (0.0374)	
0.9999926 2.0025404e-06
===========>   testing    <===========
Epoch: [1805][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0424 (0.0424)	
0.99998915 1.3722548e-06
Epoch: [1805][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0332 (0.0581)	
0.99999166 1.5287948e-06
Epoch: [1805][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0981 (0.0585)	
0.9999907 1.3638996e-06
loss:  0.0396478463763722 0.038285376973611895
===========>   training    <===========
Epoch: [1806][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0381 (0.0381)	
0.99999416 1.6634982e-06
===========>   testing    <===========
Epoch: [1806][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0402 (0.0402)	
0.99998975 1.3455489e-06
Epoch: [1806][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0284 (0.0582)	
0.9999919 1.4887802e-06
Epoch: [1806][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0991 (0.0588)	
0.99999094 1.3545563e-06
loss:  0.03929645068954957 0.038285376973611895
===========>   training    <===========
Epoch: [1807][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0353 (0.0353)	
0.9999945 7.307315e-07
===========>   testing    <===========
Epoch: [1807][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0423 (0.0423)	
0.9999895 1.452883e-06
Epoch: [1807][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0309 (0.0587)	
0.9999925 1.624585e-06
Epoch: [1807][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0981 (0.0593)	
0.9999914 1.5121225e-06
loss:  0.039430045091154886 0.038285376973611895
===========>   training    <===========
Epoch: [1808][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0324 (0.0324)	
0.99999225 1.2933107e-06
===========>   testing    <===========
Epoch: [1808][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0434 (0.0434)	
0.99999034 1.4512433e-06
Epoch: [1808][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0312 (0.0579)	
0.99999285 1.6446917e-06
Epoch: [1808][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1072 (0.0594)	
0.9999918 1.4730795e-06
loss:  0.03960585307411146 0.038285376973611895
===========>   training    <===========
Epoch: [1809][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0425 (0.0425)	
0.9999931 1.3261542e-06
===========>   testing    <===========
Epoch: [1809][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0492 (0.0492)	
0.99998987 1.4235619e-06
Epoch: [1809][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0342 (0.0583)	
0.999992 1.512261e-06
Epoch: [1809][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0850 (0.0586)	
0.99999094 1.3866891e-06
loss:  0.039524388576637204 0.038285376973611895
===========>   training    <===========
Epoch: [1810][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0329 (0.0329)	
0.9999949 2.5524116e-06
===========>   testing    <===========
Epoch: [1810][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0495 (0.0495)	
0.99999154 1.5762713e-06
Epoch: [1810][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0353 (0.0584)	
0.9999933 1.8105605e-06
Epoch: [1810][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0885 (0.0586)	
0.99999356 1.6011e-06
loss:  0.03953949561123604 0.038285376973611895
===========>   training    <===========
Epoch: [1811][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0347 (0.0347)	
0.9999893 1.0701627e-06
===========>   testing    <===========
Epoch: [1811][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0475 (0.0475)	
0.99998903 1.4136128e-06
Epoch: [1811][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0267 (0.0581)	
0.99999154 1.6462359e-06
Epoch: [1811][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0838 (0.0588)	
0.9999912 1.4135536e-06
loss:  0.0396988238930952 0.038285376973611895
===========>   training    <===========
Epoch: [1812][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0381 (0.0381)	
0.9999912 1.2179044e-06
===========>   testing    <===========
Epoch: [1812][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0501 (0.0501)	
0.9999894 1.4154638e-06
Epoch: [1812][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0237 (0.0583)	
0.9999912 1.5980247e-06
Epoch: [1812][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0809 (0.0591)	
0.99999046 1.4289891e-06
loss:  0.03945529999568065 0.038285376973611895
===========>   training    <===========
Epoch: [1813][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0403 (0.0403)	
0.99999166 1.1139621e-06
===========>   testing    <===========
Epoch: [1813][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0524 (0.0524)	
0.99999046 1.5571095e-06
Epoch: [1813][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0249 (0.0587)	
0.99999297 1.9224337e-06
Epoch: [1813][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0830 (0.0590)	
0.9999931 1.7099103e-06
loss:  0.03951466241676527 0.038285376973611895
===========>   training    <===========
Epoch: [1814][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0306 (0.0306)	
0.9999888 1.0409543e-06
===========>   testing    <===========
Epoch: [1814][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0474 (0.0474)	
0.9999901 1.5191241e-06
Epoch: [1814][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0268 (0.0587)	
0.99999213 1.8231779e-06
Epoch: [1814][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0773 (0.0589)	
0.9999913 1.5820874e-06
loss:  0.039358887329456915 0.038285376973611895
===========>   training    <===========
Epoch: [1815][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0293 (0.0293)	
0.9999862 2.2448787e-06
===========>   testing    <===========
Epoch: [1815][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0483 (0.0483)	
0.99999094 1.5316053e-06
Epoch: [1815][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0324 (0.0588)	
0.9999925 1.8252186e-06
Epoch: [1815][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0706 (0.0587)	
0.99999154 1.6099375e-06
loss:  0.039330946740941175 0.038285376973611895
===========>   training    <===========
Epoch: [1816][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0283 (0.0283)	
0.9999925 2.491317e-06
===========>   testing    <===========
Epoch: [1816][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0494 (0.0494)	
0.99999034 1.6216409e-06
Epoch: [1816][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0279 (0.0591)	
0.9999926 2.0249793e-06
Epoch: [1816][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0788 (0.0590)	
0.9999924 1.7787986e-06
loss:  0.039335264700669836 0.038285376973611895
===========>   training    <===========
Epoch: [1817][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0320 (0.0320)	
0.9999937 9.223313e-07
===========>   testing    <===========
Epoch: [1817][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0488 (0.0488)	
0.9999906 1.5030275e-06
Epoch: [1817][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0254 (0.0587)	
0.9999924 1.8024598e-06
Epoch: [1817][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0802 (0.0590)	
0.99999154 1.578755e-06
loss:  0.03920762476554707 0.038285376973611895
===========>   training    <===========
Epoch: [1818][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0316 (0.0316)	
0.99999714 3.304645e-06
===========>   testing    <===========
Epoch: [1818][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0488 (0.0488)	
0.9999908 1.544151e-06
Epoch: [1818][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0254 (0.0586)	
0.99999285 1.9708266e-06
Epoch: [1818][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0839 (0.0590)	
0.99999225 1.6440785e-06
loss:  0.03933740834923194 0.038285376973611895
===========>   training    <===========
Epoch: [1819][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0329 (0.0329)	
0.99999475 3.3788979e-06
===========>   testing    <===========
Epoch: [1819][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0500 (0.0500)	
0.9999895 1.5276594e-06
Epoch: [1819][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0243 (0.0584)	
0.99999213 1.8719605e-06
Epoch: [1819][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0883 (0.0599)	
0.9999912 1.6467509e-06
loss:  0.039636918311165115 0.038285376973611895
===========>   training    <===========
Epoch: [1820][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0333 (0.0333)	
0.99998045 8.546228e-07
===========>   testing    <===========
Epoch: [1820][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0540 (0.0540)	
0.99999106 1.4085718e-06
Epoch: [1820][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0271 (0.0586)	
0.9999927 1.71732e-06
Epoch: [1820][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0825 (0.0595)	
0.99999154 1.5165069e-06
loss:  0.03957821563849595 0.038285376973611895
===========>   training    <===========
Epoch: [1821][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0356 (0.0356)	
0.9999887 1.6104934e-06
===========>   testing    <===========
Epoch: [1821][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0517 (0.0517)	
0.999992 1.6705185e-06
Epoch: [1821][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0316 (0.0585)	
0.9999938 2.1322523e-06
Epoch: [1821][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0842 (0.0591)	
0.9999932 1.9463566e-06
loss:  0.03937546708423001 0.038285376973611895
===========>   training    <===========
Epoch: [1822][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0358 (0.0358)	
0.99998546 1.371551e-06
===========>   testing    <===========
Epoch: [1822][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0469 (0.0469)	
0.9999902 1.4690869e-06
Epoch: [1822][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0264 (0.0585)	
0.999992 1.8255703e-06
Epoch: [1822][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0929 (0.0590)	
0.99999154 1.5864175e-06
loss:  0.039868674115845826 0.038285376973611895
===========>   training    <===========
Epoch: [1823][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0325 (0.0325)	
0.9999764 7.8244267e-07
===========>   testing    <===========
Epoch: [1823][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0488 (0.0488)	
0.9999907 1.39924e-06
Epoch: [1823][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0271 (0.0585)	
0.9999914 1.7275519e-06
Epoch: [1823][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0883 (0.0590)	
0.99999094 1.4955409e-06
loss:  0.039653947068958195 0.038285376973611895
===========>   training    <===========
Epoch: [1824][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0393 (0.0393)	
0.999985 7.953284e-07
===========>   testing    <===========
Epoch: [1824][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0527 (0.0527)	
0.9999912 1.6893656e-06
Epoch: [1824][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0351 (0.0582)	
0.99999213 2.1252422e-06
Epoch: [1824][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0799 (0.0585)	
0.9999925 1.8567836e-06
loss:  0.03948399182722839 0.038285376973611895
===========>   training    <===========
Epoch: [1825][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0339 (0.0339)	
0.9999919 6.822784e-07
===========>   testing    <===========
Epoch: [1825][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0469 (0.0469)	
0.99999166 1.486404e-06
Epoch: [1825][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0274 (0.0578)	
0.9999927 1.8228493e-06
Epoch: [1825][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0905 (0.0589)	
0.9999919 1.5694284e-06
loss:  0.03947869694438022 0.038285376973611895
===========>   training    <===========
Epoch: [1826][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0364 (0.0364)	
0.9999944 1.5698984e-06
===========>   testing    <===========
Epoch: [1826][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0512 (0.0512)	
0.9999895 1.5486371e-06
Epoch: [1826][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0268 (0.0583)	
0.9999912 1.822865e-06
Epoch: [1826][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0853 (0.0592)	
0.99999034 1.5799162e-06
loss:  0.040029838045939514 0.038285376973611895
===========>   training    <===========
Epoch: [1827][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0311 (0.0311)	
0.99999464 2.1637577e-06
===========>   testing    <===========
Epoch: [1827][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0527 (0.0527)	
0.99998987 1.6290951e-06
Epoch: [1827][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0289 (0.0581)	
0.99999225 1.917574e-06
Epoch: [1827][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0865 (0.0591)	
0.9999913 1.6853153e-06
loss:  0.03980858805402632 0.038285376973611895
===========>   training    <===========
Epoch: [1828][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0343 (0.0343)	
0.9999914 2.5913823e-06
===========>   testing    <===========
Epoch: [1828][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0468 (0.0468)	
0.9999896 1.6340401e-06
Epoch: [1828][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0265 (0.0587)	
0.9999918 1.9030506e-06
Epoch: [1828][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0828 (0.0593)	
0.9999902 1.6908501e-06
loss:  0.039803738494514684 0.038285376973611895
===========>   training    <===========
Epoch: [1829][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0292 (0.0292)	
0.99999464 2.8773295e-06
===========>   testing    <===========
Epoch: [1829][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0532 (0.0532)	
0.9999902 1.4326077e-06
Epoch: [1829][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0231 (0.0587)	
0.99999154 1.747124e-06
Epoch: [1829][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0822 (0.0593)	
0.99999046 1.4761227e-06
loss:  0.03975416024401979 0.038285376973611895
===========>   training    <===========
Epoch: [1830][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0358 (0.0358)	
0.9999956 1.6965001e-06
===========>   testing    <===========
Epoch: [1830][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0479 (0.0479)	
0.9999895 1.4101753e-06
Epoch: [1830][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0272 (0.0585)	
0.9999918 1.7198505e-06
Epoch: [1830][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0836 (0.0586)	
0.9999902 1.4552097e-06
loss:  0.03957481526226381 0.038285376973611895
===========>   training    <===========
Epoch: [1831][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0357 (0.0357)	
0.9999957 1.8583141e-06
===========>   testing    <===========
Epoch: [1831][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0419 (0.0419)	
0.9999908 1.5957615e-06
Epoch: [1831][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0293 (0.0585)	
0.99999297 2.0004525e-06
Epoch: [1831][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0873 (0.0588)	
0.9999927 1.7077526e-06
loss:  0.03967751388067131 0.038285376973611895
===========>   training    <===========
Epoch: [1832][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0347 (0.0347)	
0.9999889 1.5239067e-06
===========>   testing    <===========
Epoch: [1832][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0446 (0.0446)	
0.99999034 1.4504587e-06
Epoch: [1832][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0269 (0.0586)	
0.99999213 1.7516167e-06
Epoch: [1832][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0969 (0.0588)	
0.9999912 1.5083144e-06
loss:  0.039622345418418026 0.038285376973611895
===========>   training    <===========
Epoch: [1833][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0314 (0.0314)	
0.99998856 1.1884375e-06
===========>   testing    <===========
Epoch: [1833][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0480 (0.0480)	
0.9999907 1.5157724e-06
Epoch: [1833][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0254 (0.0584)	
0.9999931 1.9122563e-06
Epoch: [1833][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0938 (0.0584)	
0.9999924 1.6201817e-06
loss:  0.039343189380015464 0.038285376973611895
===========>   training    <===========
Epoch: [1834][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0328 (0.0328)	
0.99999774 3.5554353e-06
===========>   testing    <===========
Epoch: [1834][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0489 (0.0489)	
0.99999 1.4290531e-06
Epoch: [1834][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0243 (0.0586)	
0.9999925 1.8076965e-06
Epoch: [1834][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0950 (0.0588)	
0.9999912 1.5256676e-06
loss:  0.039459851033238236 0.038285376973611895
===========>   training    <===========
Epoch: [1835][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0400 (0.0400)	
0.99998343 7.1203976e-07
===========>   testing    <===========
Epoch: [1835][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0522 (0.0522)	
0.99999034 1.7057262e-06
Epoch: [1835][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0240 (0.0591)	
0.9999933 2.1424828e-06
Epoch: [1835][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0925 (0.0590)	
0.9999927 1.8198218e-06
loss:  0.039455320021854146 0.038285376973611895
===========>   training    <===========
Epoch: [1836][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0292 (0.0292)	
0.99999523 1.9461934e-06
===========>   testing    <===========
Epoch: [1836][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0469 (0.0469)	
0.99998975 1.4082898e-06
Epoch: [1836][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0254 (0.0590)	
0.999992 1.6071214e-06
Epoch: [1836][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0881 (0.0595)	
0.9999906 1.430257e-06
loss:  0.03992368767058707 0.038285376973611895
===========>   training    <===========
Epoch: [1837][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0368 (0.0368)	
0.9999938 2.0812565e-06
===========>   testing    <===========
Epoch: [1837][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0481 (0.0481)	
0.9999902 1.437639e-06
Epoch: [1837][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0262 (0.0591)	
0.9999926 1.6773766e-06
Epoch: [1837][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0947 (0.0593)	
0.99999154 1.4774522e-06
loss:  0.039854993849345655 0.038285376973611895
===========>   training    <===========
Epoch: [1838][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0329 (0.0329)	
0.9999937 2.0954762e-06
===========>   testing    <===========
Epoch: [1838][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0439 (0.0439)	
0.9999906 1.5778835e-06
Epoch: [1838][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0243 (0.0590)	
0.9999931 1.854094e-06
Epoch: [1838][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0919 (0.0597)	
0.999992 1.6169834e-06
loss:  0.03987356782884832 0.038285376973611895
===========>   training    <===========
Epoch: [1839][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0289 (0.0289)	
0.9999893 2.6634414e-06
===========>   testing    <===========
Epoch: [1839][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0436 (0.0436)	
0.99999034 1.4977347e-06
Epoch: [1839][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0313 (0.0585)	
0.9999927 1.7588077e-06
Epoch: [1839][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0791 (0.0591)	
0.99999166 1.5310519e-06
loss:  0.03949448674004774 0.038285376973611895
===========>   training    <===========
Epoch: [1840][0/23]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0327 (0.0327)	
0.99999475 4.6019563e-06
===========>   testing    <===========
Epoch: [1840][0/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0425 (0.0425)	
0.99999106 1.6188334e-06
Epoch: [1840][100/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0258 (0.0589)	
0.99999344 1.966271e-06
Epoch: [1840][200/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0820 (0.0598)	
0.99999225 1.6872838e-06
loss:  0.039996057352199355 0.038285376973611895
===========>   training    <===========
Epoch: [1841][0/23]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0303 (0.0303)	
0.9999925 1.6843802e-06
===========>   testing    <===========
Epoch: [1841][0/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0454 (0.0454)	
0.99999046 1.6195869e-06
Epoch: [1841][100/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0238 (0.0591)	
0.9999932 1.9632055e-06
Epoch: [1841][200/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0809 (0.0595)	
0.9999924 1.726539e-06
loss:  0.039599267757050804 0.038285376973611895
===========>   training    <===========
Epoch: [1842][0/23]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0321 (0.0321)	
0.9999964 2.0851246e-06
===========>   testing    <===========
Epoch: [1842][0/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0438 (0.0438)	
0.99999034 1.4994655e-06
Epoch: [1842][100/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0266 (0.0585)	
0.9999925 1.7342486e-06
Epoch: [1842][200/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0749 (0.0591)	
0.9999914 1.5114996e-06
loss:  0.03955589752555244 0.038285376973611895
===========>   training    <===========
Epoch: [1843][0/23]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0290 (0.0290)	
0.9999907 2.8019972e-06
===========>   testing    <===========
Epoch: [1843][0/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0473 (0.0473)	
0.9999896 1.4421211e-06
Epoch: [1843][100/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0261 (0.0583)	
0.99999106 1.6307678e-06
Epoch: [1843][200/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0764 (0.0589)	
0.9999902 1.4551654e-06
loss:  0.03966210294914374 0.038285376973611895
===========>   training    <===========
Epoch: [1844][0/23]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0371 (0.0371)	
0.9999924 1.2351975e-06
===========>   testing    <===========
Epoch: [1844][0/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0434 (0.0434)	
0.9999896 1.5324849e-06
Epoch: [1844][100/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0273 (0.0585)	
0.99999154 1.6421245e-06
Epoch: [1844][200/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0794 (0.0593)	
0.9999907 1.5293926e-06
loss:  0.03968528192353149 0.038285376973611895
===========>   training    <===========
Epoch: [1845][0/23]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0304 (0.0304)	
0.9999951 1.5200761e-06
===========>   testing    <===========
Epoch: [1845][0/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0466 (0.0466)	
0.99998987 1.6988623e-06
Epoch: [1845][100/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0361 (0.0586)	
0.99999213 1.9064329e-06
Epoch: [1845][200/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0716 (0.0589)	
0.99999106 1.7066553e-06
loss:  0.039606002490479186 0.038285376973611895
===========>   training    <===========
Epoch: [1846][0/23]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0369 (0.0369)	
0.9999949 3.799224e-07
===========>   testing    <===========
Epoch: [1846][0/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0452 (0.0452)	
0.9999913 1.7920661e-06
Epoch: [1846][100/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0331 (0.0586)	
0.99999344 2.1467595e-06
Epoch: [1846][200/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0747 (0.0590)	
0.9999927 1.8801996e-06
loss:  0.039570694520900784 0.038285376973611895
===========>   training    <===========
Epoch: [1847][0/23]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0299 (0.0299)	
0.99999213 1.3995123e-06
===========>   testing    <===========
Epoch: [1847][0/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0473 (0.0473)	
0.9999907 1.559694e-06
Epoch: [1847][100/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0248 (0.0587)	
0.9999919 1.8151661e-06
Epoch: [1847][200/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0870 (0.0593)	
0.9999908 1.5733967e-06
loss:  0.039635355585728504 0.038285376973611895
===========>   training    <===========
Epoch: [1848][0/23]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0328 (0.0328)	
0.9999827 1.0523071e-06
===========>   testing    <===========
Epoch: [1848][0/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0519 (0.0519)	
0.9999919 1.7502023e-06
Epoch: [1848][100/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0266 (0.0590)	
0.9999933 2.1251205e-06
Epoch: [1848][200/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0848 (0.0591)	
0.99999297 1.8331751e-06
loss:  0.03949394011951557 0.038285376973611895
===========>   training    <===========
Epoch: [1849][0/23]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0282 (0.0282)	
0.9999907 3.4545553e-06
===========>   testing    <===========
Epoch: [1849][0/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0498 (0.0498)	
0.99999106 1.6276726e-06
Epoch: [1849][100/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0284 (0.0587)	
0.9999932 1.8733357e-06
Epoch: [1849][200/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0705 (0.0589)	
0.9999925 1.6595177e-06
loss:  0.039389625970639885 0.038285376973611895
===========>   training    <===========
Epoch: [1850][0/23]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0407 (0.0407)	
0.9999907 1.5405001e-06
===========>   testing    <===========
Epoch: [1850][0/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0510 (0.0510)	
0.9999907 1.5749099e-06
Epoch: [1850][100/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0271 (0.0589)	
0.99999297 1.9422623e-06
Epoch: [1850][200/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0784 (0.0592)	
0.99999213 1.6517258e-06
loss:  0.039716932120898885 0.038285376973611895
===========>   training    <===========
Epoch: [1851][0/23]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0311 (0.0311)	
0.99999607 2.554603e-06
===========>   testing    <===========
Epoch: [1851][0/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0462 (0.0462)	
0.9999902 1.6421417e-06
Epoch: [1851][100/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0271 (0.0590)	
0.99999225 1.7891068e-06
Epoch: [1851][200/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0839 (0.0597)	
0.9999919 1.6430723e-06
loss:  0.03982218320695674 0.038285376973611895
===========>   training    <===========
Epoch: [1852][0/23]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0368 (0.0368)	
0.9999902 1.0533583e-06
===========>   testing    <===========
Epoch: [1852][0/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0474 (0.0474)	
0.9999914 1.8017861e-06
Epoch: [1852][100/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0310 (0.0588)	
0.9999939 2.2189618e-06
Epoch: [1852][200/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0850 (0.0593)	
0.99999356 1.9370239e-06
loss:  0.039372901371379165 0.038285376973611895
===========>   training    <===========
Epoch: [1853][0/23]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0342 (0.0342)	
0.9999906 7.725736e-07
===========>   testing    <===========
Epoch: [1853][0/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0491 (0.0491)	
0.99999166 1.6890127e-06
Epoch: [1853][100/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0293 (0.0586)	
0.99999356 2.0345262e-06
Epoch: [1853][200/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0881 (0.0594)	
0.9999926 1.7779302e-06
loss:  0.03945790805037519 0.038285376973611895
===========>   training    <===========
Epoch: [1854][0/23]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0412 (0.0412)	
0.9999943 2.9241212e-06
===========>   testing    <===========
Epoch: [1854][0/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0492 (0.0492)	
0.99999094 1.4344371e-06
Epoch: [1854][100/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0362 (0.0581)	
0.9999913 1.5955943e-06
Epoch: [1854][200/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0828 (0.0587)	
0.9999908 1.4451581e-06
loss:  0.03921667022464992 0.038285376973611895
===========>   training    <===========
Epoch: [1855][0/23]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0372 (0.0372)	
0.99999404 2.4320143e-06
===========>   testing    <===========
Epoch: [1855][0/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0512 (0.0512)	
0.9999906 1.3822475e-06
Epoch: [1855][100/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0362 (0.0582)	
0.999992 1.6941153e-06
Epoch: [1855][200/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0844 (0.0588)	
0.9999913 1.4262961e-06
loss:  0.03925741966656959 0.038285376973611895
===========>   training    <===========
Epoch: [1856][0/23]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0312 (0.0312)	
0.99998903 2.1965914e-06
===========>   testing    <===========
Epoch: [1856][0/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0480 (0.0480)	
0.99999154 1.5537955e-06
Epoch: [1856][100/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0422 (0.0584)	
0.99999285 1.9099177e-06
Epoch: [1856][200/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0845 (0.0585)	
0.99999154 1.6182468e-06
loss:  0.039085440596949295 0.038285376973611895
===========>   training    <===========
Epoch: [1857][0/23]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0359 (0.0359)	
0.99999547 1.5242657e-06
===========>   testing    <===========
Epoch: [1857][0/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0513 (0.0513)	
0.99999225 1.6408111e-06
Epoch: [1857][100/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0424 (0.0589)	
0.9999939 2.1811961e-06
Epoch: [1857][200/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0805 (0.0587)	
0.9999932 1.8701174e-06
loss:  0.03930290312788931 0.038285376973611895
===========>   training    <===========
Epoch: [1858][0/23]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0319 (0.0319)	
0.99999785 1.7605211e-06
===========>   testing    <===========
Epoch: [1858][0/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0525 (0.0525)	
0.9999902 1.5855102e-06
Epoch: [1858][100/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0407 (0.0585)	
0.9999925 1.9568051e-06
Epoch: [1858][200/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0742 (0.0584)	
0.9999914 1.6697921e-06
loss:  0.039388853267615764 0.038285376973611895
===========>   training    <===========
Epoch: [1859][0/23]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0319 (0.0319)	
0.99999475 2.0473412e-06
===========>   testing    <===========
Epoch: [1859][0/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0492 (0.0492)	
0.9999914 1.5967557e-06
Epoch: [1859][100/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0363 (0.0585)	
0.9999932 1.9642896e-06
Epoch: [1859][200/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0648 (0.0584)	
0.99999225 1.6677886e-06
loss:  0.03924961898580792 0.038285376973611895
===========>   training    <===========
Epoch: [1860][0/23]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0316 (0.0316)	
0.9999907 1.8655536e-06
===========>   testing    <===========
Epoch: [1860][0/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0472 (0.0472)	
0.99999034 1.3620071e-06
Epoch: [1860][100/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0325 (0.0585)	
0.9999912 1.6054239e-06
Epoch: [1860][200/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0693 (0.0587)	
0.9999902 1.3827326e-06
loss:  0.03936320349875422 0.038285376973611895
===========>   training    <===========
Epoch: [1861][0/23]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0328 (0.0328)	
0.99998975 1.5287482e-06
===========>   testing    <===========
Epoch: [1861][0/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0464 (0.0464)	
0.99998975 1.425404e-06
Epoch: [1861][100/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0305 (0.0580)	
0.99999166 1.692825e-06
Epoch: [1861][200/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0755 (0.0588)	
0.9999907 1.4566899e-06
loss:  0.03937378831073801 0.038285376973611895
===========>   training    <===========
Epoch: [1862][0/23]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0314 (0.0314)	
0.9999907 1.5923928e-06
===========>   testing    <===========
Epoch: [1862][0/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0450 (0.0450)	
0.99999225 1.656406e-06
Epoch: [1862][100/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0488 (0.0586)	
0.9999931 2.0999455e-06
Epoch: [1862][200/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0737 (0.0586)	
0.9999925 1.7637005e-06
loss:  0.039471667571216784 0.038285376973611895
===========>   training    <===========
Epoch: [1863][0/23]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0346 (0.0346)	
0.99998593 7.544122e-07
===========>   testing    <===========
Epoch: [1863][0/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0415 (0.0415)	
0.9999901 1.4037093e-06
Epoch: [1863][100/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0293 (0.0586)	
0.9999906 1.7022064e-06
Epoch: [1863][200/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0818 (0.0593)	
0.9999893 1.4252328e-06
loss:  0.03967952915420392 0.038285376973611895
===========>   training    <===========
Epoch: [1864][0/23]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0320 (0.0320)	
0.9999914 2.1525427e-06
===========>   testing    <===========
Epoch: [1864][0/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0416 (0.0416)	
0.9999919 1.6734459e-06
Epoch: [1864][100/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0415 (0.0588)	
0.9999931 2.0368443e-06
Epoch: [1864][200/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0716 (0.0586)	
0.9999925 1.786091e-06
loss:  0.03927167396677034 0.038285376973611895
===========>   training    <===========
Epoch: [1865][0/23]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0316 (0.0316)	
0.99998975 1.969348e-06
===========>   testing    <===========
Epoch: [1865][0/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0421 (0.0421)	
0.99999225 1.5535675e-06
Epoch: [1865][100/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0368 (0.0584)	
0.9999933 2.0089697e-06
Epoch: [1865][200/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0736 (0.0588)	
0.9999927 1.7067172e-06
loss:  0.03963105736655681 0.038285376973611895
===========>   training    <===========
Epoch: [1866][0/23]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0310 (0.0310)	
0.9999931 1.0236691e-06
===========>   testing    <===========
Epoch: [1866][0/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0436 (0.0436)	
0.9999913 1.5136013e-06
Epoch: [1866][100/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0362 (0.0584)	
0.9999931 1.92606e-06
Epoch: [1866][200/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0767 (0.0588)	
0.9999926 1.6524568e-06
loss:  0.0395455222215324 0.038285376973611895
===========>   training    <===========
Epoch: [1867][0/23]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0281 (0.0281)	
0.999997 4.0208733e-06
===========>   testing    <===========
Epoch: [1867][0/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0393 (0.0393)	
0.9999894 1.3520523e-06
Epoch: [1867][100/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0291 (0.0586)	
0.9999893 1.4026763e-06
Epoch: [1867][200/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0939 (0.0601)	
0.9999889 1.3121111e-06
loss:  0.04005997056611754 0.038285376973611895
===========>   training    <===========
Epoch: [1868][0/23]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0280 (0.0280)	
0.9999951 2.7243962e-06
===========>   testing    <===========
Epoch: [1868][0/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0457 (0.0457)	
0.9999912 1.6256746e-06
Epoch: [1868][100/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0349 (0.0587)	
0.99999297 1.949788e-06
Epoch: [1868][200/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0880 (0.0595)	
0.99999297 1.7625639e-06
loss:  0.03972574075298918 0.038285376973611895
===========>   training    <===========
Epoch: [1869][0/23]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0349 (0.0349)	
0.9999809 8.431419e-07
===========>   testing    <===========
Epoch: [1869][0/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0448 (0.0448)	
0.9999902 1.4015758e-06
Epoch: [1869][100/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0327 (0.0587)	
0.99999154 1.6252994e-06
Epoch: [1869][200/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0834 (0.0590)	
0.99999046 1.402251e-06
loss:  0.03988338720863993 0.038285376973611895
===========>   training    <===========
Epoch: [1870][0/23]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0326 (0.0326)	
0.99999857 3.1770765e-06
===========>   testing    <===========
Epoch: [1870][0/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0411 (0.0411)	
0.9999914 1.4109893e-06
Epoch: [1870][100/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0377 (0.0582)	
0.9999919 1.6796865e-06
Epoch: [1870][200/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0883 (0.0587)	
0.9999906 1.4464653e-06
loss:  0.039470546935025164 0.038285376973611895
===========>   training    <===========
Epoch: [1871][0/23]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0363 (0.0363)	
0.9999932 1.252356e-06
===========>   testing    <===========
Epoch: [1871][0/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0418 (0.0418)	
0.9999896 1.4413909e-06
Epoch: [1871][100/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0407 (0.0581)	
0.99998915 1.5877072e-06
Epoch: [1871][200/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0820 (0.0590)	
0.9999888 1.4237017e-06
loss:  0.03969232076013918 0.038285376973611895
===========>   training    <===========
Epoch: [1872][0/23]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0299 (0.0299)	
0.99999774 2.1385797e-06
===========>   testing    <===========
Epoch: [1872][0/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0418 (0.0418)	
0.99998903 1.4028221e-06
Epoch: [1872][100/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0359 (0.0583)	
0.9999894 1.6108191e-06
Epoch: [1872][200/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0909 (0.0594)	
0.9999887 1.4187667e-06
loss:  0.03979590543959999 0.038285376973611895
===========>   training    <===========
Epoch: [1873][0/23]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0340 (0.0340)	
0.99999344 1.357449e-06
===========>   testing    <===========
Epoch: [1873][0/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0445 (0.0445)	
0.99999106 1.5312783e-06
Epoch: [1873][100/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0524 (0.0587)	
0.9999924 1.81064e-06
Epoch: [1873][200/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0863 (0.0591)	
0.99999154 1.6009581e-06
loss:  0.039718509090323706 0.038285376973611895
===========>   training    <===========
Epoch: [1874][0/23]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0342 (0.0342)	
0.99998844 1.2841717e-06
===========>   testing    <===========
Epoch: [1874][0/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0456 (0.0456)	
0.99999106 1.5477882e-06
Epoch: [1874][100/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0420 (0.0583)	
0.9999924 1.8842654e-06
Epoch: [1874][200/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0901 (0.0590)	
0.9999918 1.692586e-06
loss:  0.039875062817114726 0.038285376973611895
===========>   training    <===========
Epoch: [1875][0/23]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0299 (0.0299)	
0.9999889 9.4869876e-07
===========>   testing    <===========
Epoch: [1875][0/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0430 (0.0430)	
0.9999902 1.3685564e-06
Epoch: [1875][100/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0406 (0.0584)	
0.99999046 1.6011336e-06
Epoch: [1875][200/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0835 (0.0587)	
0.99999 1.4119046e-06
loss:  0.039625679598872976 0.038285376973611895
===========>   training    <===========
Epoch: [1876][0/23]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0391 (0.0391)	
0.99998975 1.135634e-06
===========>   testing    <===========
Epoch: [1876][0/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0442 (0.0442)	
0.99999166 1.7476656e-06
Epoch: [1876][100/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0425 (0.0587)	
0.99999344 2.3639564e-06
Epoch: [1876][200/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0825 (0.0586)	
0.99999356 2.1294904e-06
loss:  0.039291595825684644 0.038285376973611895
===========>   training    <===========
Epoch: [1877][0/23]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0352 (0.0352)	
0.9999865 1.0796861e-06
===========>   testing    <===========
Epoch: [1877][0/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0408 (0.0408)	
0.9999894 1.4217384e-06
Epoch: [1877][100/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0355 (0.0579)	
0.99998987 1.71857e-06
Epoch: [1877][200/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0790 (0.0586)	
0.9999887 1.4626256e-06
loss:  0.03943838748883988 0.038285376973611895
===========>   training    <===========
Epoch: [1878][0/23]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0315 (0.0315)	
0.9999957 1.685275e-06
===========>   testing    <===========
Epoch: [1878][0/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0408 (0.0408)	
0.9999914 1.6608906e-06
Epoch: [1878][100/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0406 (0.0579)	
0.9999925 2.1241683e-06
Epoch: [1878][200/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0732 (0.0580)	
0.99999166 1.8055875e-06
loss:  0.03914646407671096 0.038285376973611895
===========>   training    <===========
Epoch: [1879][0/23]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0296 (0.0296)	
0.99999285 6.361494e-07
===========>   testing    <===========
Epoch: [1879][0/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0403 (0.0403)	
0.9999926 1.6326335e-06
Epoch: [1879][100/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0427 (0.0581)	
0.99999356 2.0811137e-06
Epoch: [1879][200/289]	Lr-deconv: [0.0]	Lr-other: [8.478036692943842e-06]	Loss 0.0715 (0.0583)	
0.99999297 1.8410767e-06
loss:  0.03907195325786461 0.038285376973611895
===========>   training    <===========
Epoch: [1880][0/23]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0313 (0.0313)	
0.9999933 1.2293684e-06
===========>   testing    <===========
Epoch: [1880][0/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0403 (0.0403)	
0.999992 1.7307227e-06
Epoch: [1880][100/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0431 (0.0584)	
0.99999344 2.213855e-06
Epoch: [1880][200/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0775 (0.0588)	
0.9999931 1.9577049e-06
loss:  0.03921935065968574 0.038285376973611895
===========>   training    <===========
Epoch: [1881][0/23]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0305 (0.0305)	
0.99999547 1.7278419e-06
===========>   testing    <===========
Epoch: [1881][0/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0398 (0.0398)	
0.9999901 1.4842508e-06
Epoch: [1881][100/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0339 (0.0582)	
0.99999106 1.7593059e-06
Epoch: [1881][200/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0742 (0.0584)	
0.99998975 1.5682823e-06
loss:  0.039156068148274326 0.038285376973611895
===========>   training    <===========
Epoch: [1882][0/23]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0361 (0.0361)	
0.99999094 1.2555872e-06
===========>   testing    <===========
Epoch: [1882][0/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0372 (0.0372)	
0.99999106 1.5509546e-06
Epoch: [1882][100/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0360 (0.0585)	
0.999992 1.8259099e-06
Epoch: [1882][200/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0714 (0.0585)	
0.9999906 1.6291045e-06
loss:  0.03927806360062436 0.038285376973611895
===========>   training    <===========
Epoch: [1883][0/23]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0320 (0.0320)	
0.9999964 9.3238503e-07
===========>   testing    <===========
Epoch: [1883][0/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0363 (0.0363)	
0.9999908 1.558882e-06
Epoch: [1883][100/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0315 (0.0582)	
0.9999918 1.8981096e-06
Epoch: [1883][200/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0726 (0.0586)	
0.9999907 1.6294774e-06
loss:  0.0394885661603821 0.038285376973611895
===========>   training    <===========
Epoch: [1884][0/23]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0291 (0.0291)	
0.99999285 1.5662197e-06
===========>   testing    <===========
Epoch: [1884][0/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0415 (0.0415)	
0.99999154 1.4947196e-06
Epoch: [1884][100/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0297 (0.0584)	
0.9999918 1.9332922e-06
Epoch: [1884][200/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0792 (0.0590)	
0.99999094 1.6206561e-06
loss:  0.039591895128325394 0.038285376973611895
===========>   training    <===========
Epoch: [1885][0/23]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0308 (0.0308)	
0.99998665 2.106409e-07
===========>   testing    <===========
Epoch: [1885][0/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0444 (0.0444)	
0.9999924 1.4832377e-06
Epoch: [1885][100/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0353 (0.0584)	
0.9999925 1.8573434e-06
Epoch: [1885][200/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0777 (0.0585)	
0.99999166 1.5500113e-06
loss:  0.03931322826948669 0.038285376973611895
===========>   training    <===========
Epoch: [1886][0/23]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0326 (0.0326)	
0.9999943 1.405483e-06
===========>   testing    <===========
Epoch: [1886][0/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0399 (0.0399)	
0.9999919 1.4983905e-06
Epoch: [1886][100/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0342 (0.0585)	
0.9999924 1.9066366e-06
Epoch: [1886][200/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0805 (0.0586)	
0.9999913 1.5774968e-06
loss:  0.03922729407909398 0.038285376973611895
===========>   training    <===========
Epoch: [1887][0/23]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0334 (0.0334)	
0.9999926 1.2175699e-06
===========>   testing    <===========
Epoch: [1887][0/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0421 (0.0421)	
0.9999907 1.230072e-06
Epoch: [1887][100/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0347 (0.0580)	
0.9999889 1.5288064e-06
Epoch: [1887][200/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0852 (0.0583)	
0.9999888 1.2606108e-06
loss:  0.0393185137376566 0.038285376973611895
===========>   training    <===========
Epoch: [1888][0/23]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0313 (0.0313)	
0.99998844 1.9989343e-06
===========>   testing    <===========
Epoch: [1888][0/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0383 (0.0383)	
0.9999914 1.460532e-06
Epoch: [1888][100/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0350 (0.0582)	
0.9999918 1.8831192e-06
Epoch: [1888][200/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0794 (0.0583)	
0.9999908 1.5780822e-06
loss:  0.0391483775677286 0.038285376973611895
===========>   training    <===========
Epoch: [1889][0/23]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0316 (0.0316)	
0.99999464 3.9018278e-06
===========>   testing    <===========
Epoch: [1889][0/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0393 (0.0393)	
0.9999927 1.3836204e-06
Epoch: [1889][100/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0259 (0.0584)	
0.9999925 1.7248323e-06
Epoch: [1889][200/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0884 (0.0588)	
0.99999166 1.4643227e-06
loss:  0.03939853250946579 0.038285376973611895
===========>   training    <===========
Epoch: [1890][0/23]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0322 (0.0322)	
0.99999523 1.1632791e-06
===========>   testing    <===========
Epoch: [1890][0/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0391 (0.0391)	
0.99999166 1.2983999e-06
Epoch: [1890][100/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0328 (0.0586)	
0.9999914 1.6021447e-06
Epoch: [1890][200/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0802 (0.0585)	
0.9999908 1.31573e-06
loss:  0.03919653179420901 0.038285376973611895
===========>   training    <===========
Epoch: [1891][0/23]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0333 (0.0333)	
0.99999475 1.3736139e-06
===========>   testing    <===========
Epoch: [1891][0/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0417 (0.0417)	
0.9999932 1.4615003e-06
Epoch: [1891][100/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0301 (0.0588)	
0.9999931 1.9467277e-06
Epoch: [1891][200/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0852 (0.0585)	
0.99999285 1.5746276e-06
loss:  0.03902274932397687 0.038285376973611895
===========>   training    <===========
Epoch: [1892][0/23]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0299 (0.0299)	
0.9999907 1.0041723e-06
===========>   testing    <===========
Epoch: [1892][0/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0429 (0.0429)	
0.99999297 1.7317631e-06
Epoch: [1892][100/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0390 (0.0590)	
0.9999937 2.197683e-06
Epoch: [1892][200/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0831 (0.0584)	
0.9999933 1.9363977e-06
loss:  0.03910727115757684 0.038285376973611895
===========>   training    <===========
Epoch: [1893][0/23]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0334 (0.0334)	
0.99999154 1.5545515e-06
===========>   testing    <===========
Epoch: [1893][0/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0397 (0.0397)	
0.9999937 1.584035e-06
Epoch: [1893][100/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0410 (0.0585)	
0.9999937 2.067839e-06
Epoch: [1893][200/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0934 (0.0586)	
0.99999344 1.8036704e-06
loss:  0.039339742543189726 0.038285376973611895
===========>   training    <===========
Epoch: [1894][0/23]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0332 (0.0332)	
0.9999809 1.1455784e-06
===========>   testing    <===========
Epoch: [1894][0/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0431 (0.0431)	
0.9999913 1.3964898e-06
Epoch: [1894][100/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0319 (0.0584)	
0.9999901 1.6597219e-06
Epoch: [1894][200/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.1009 (0.0586)	
0.9999907 1.4099642e-06
loss:  0.03935118476212662 0.038285376973611895
===========>   training    <===========
Epoch: [1895][0/23]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0384 (0.0384)	
0.9999895 8.1755815e-07
===========>   testing    <===========
Epoch: [1895][0/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0385 (0.0385)	
0.99999297 1.4709204e-06
Epoch: [1895][100/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0322 (0.0583)	
0.99999285 1.8198115e-06
Epoch: [1895][200/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0920 (0.0586)	
0.99999225 1.5702458e-06
loss:  0.039317274757710186 0.038285376973611895
===========>   training    <===========
Epoch: [1896][0/23]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0283 (0.0283)	
0.9999943 1.4766662e-06
===========>   testing    <===========
Epoch: [1896][0/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0437 (0.0437)	
0.9999914 1.4352581e-06
Epoch: [1896][100/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0297 (0.0587)	
0.9999918 1.6567662e-06
Epoch: [1896][200/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0890 (0.0587)	
0.9999912 1.4772789e-06
loss:  0.03960005603732519 0.038285376973611895
===========>   training    <===========
Epoch: [1897][0/23]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0268 (0.0268)	
0.99999404 1.8000515e-06
===========>   testing    <===========
Epoch: [1897][0/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0432 (0.0432)	
0.9999912 1.4530825e-06
Epoch: [1897][100/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0300 (0.0585)	
0.99999225 1.7511658e-06
Epoch: [1897][200/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0956 (0.0587)	
0.9999912 1.5892039e-06
loss:  0.03963316698087027 0.038285376973611895
===========>   training    <===========
Epoch: [1898][0/23]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0328 (0.0328)	
0.9999968 2.5059571e-06
===========>   testing    <===========
Epoch: [1898][0/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0429 (0.0429)	
0.9999913 1.5069055e-06
Epoch: [1898][100/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0354 (0.0583)	
0.99999166 1.7991625e-06
Epoch: [1898][200/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0797 (0.0583)	
0.9999901 1.616086e-06
loss:  0.039590297274786246 0.038285376973611895
===========>   training    <===========
Epoch: [1899][0/23]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0359 (0.0359)	
0.999992 1.6622818e-06
===========>   testing    <===========
Epoch: [1899][0/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0451 (0.0451)	
0.99999213 1.4541638e-06
Epoch: [1899][100/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0340 (0.0583)	
0.99999154 1.7460912e-06
Epoch: [1899][200/289]	Lr-deconv: [0.0]	Lr-other: [8.054134858296648e-06]	Loss 0.0904 (0.0589)	
0.9999914 1.4951787e-06
loss:  0.039771039396361174 0.038285376973611895
===========>   training    <===========
Epoch: [1900][0/23]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0308 (0.0308)	
0.99998987 1.6373409e-06
===========>   testing    <===========
Epoch: [1900][0/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0410 (0.0410)	
0.9999908 1.4203696e-06
Epoch: [1900][100/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0303 (0.0579)	
0.9999896 1.6720788e-06
Epoch: [1900][200/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0786 (0.0582)	
0.99999034 1.4275099e-06
loss:  0.039225445538322745 0.038285376973611895
===========>   training    <===========
Epoch: [1901][0/23]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0355 (0.0355)	
0.99999654 1.7735069e-06
===========>   testing    <===========
Epoch: [1901][0/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0462 (0.0462)	
0.9999907 1.3133819e-06
Epoch: [1901][100/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0314 (0.0583)	
0.99999 1.580789e-06
Epoch: [1901][200/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0897 (0.0582)	
0.99999046 1.3764936e-06
loss:  0.03927600735051129 0.038285376973611895
===========>   training    <===========
Epoch: [1902][0/23]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0347 (0.0347)	
0.99999475 1.2550796e-06
===========>   testing    <===========
Epoch: [1902][0/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0446 (0.0446)	
0.99999213 1.3570608e-06
Epoch: [1902][100/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0290 (0.0583)	
0.99999225 1.7025847e-06
Epoch: [1902][200/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0853 (0.0583)	
0.99999225 1.5068307e-06
loss:  0.03912217188267009 0.038285376973611895
===========>   training    <===========
Epoch: [1903][0/23]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0364 (0.0364)	
0.9999932 4.935069e-07
===========>   testing    <===========
Epoch: [1903][0/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0485 (0.0485)	
0.99999154 1.4301235e-06
Epoch: [1903][100/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0315 (0.0582)	
0.99999225 1.8173487e-06
Epoch: [1903][200/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0819 (0.0581)	
0.999992 1.6138098e-06
loss:  0.03906039537514361 0.038285376973611895
===========>   training    <===========
Epoch: [1904][0/23]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0334 (0.0334)	
0.99999034 1.4806387e-06
===========>   testing    <===========
Epoch: [1904][0/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0540 (0.0540)	
0.999992 1.4365891e-06
Epoch: [1904][100/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0297 (0.0586)	
0.99999225 1.791991e-06
Epoch: [1904][200/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0957 (0.0587)	
0.9999918 1.5739686e-06
loss:  0.039332209256320416 0.038285376973611895
===========>   training    <===========
Epoch: [1905][0/23]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0323 (0.0323)	
0.99999535 8.944266e-07
===========>   testing    <===========
Epoch: [1905][0/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0468 (0.0468)	
0.9999924 1.5088051e-06
Epoch: [1905][100/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0327 (0.0583)	
0.9999924 1.862782e-06
Epoch: [1905][200/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0946 (0.0586)	
0.9999914 1.6883138e-06
loss:  0.03933182608583774 0.038285376973611895
===========>   training    <===========
Epoch: [1906][0/23]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0362 (0.0362)	
0.999997 1.7250084e-06
===========>   testing    <===========
Epoch: [1906][0/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0450 (0.0450)	
0.99999166 1.4758524e-06
Epoch: [1906][100/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0288 (0.0587)	
0.99999166 1.7106116e-06
Epoch: [1906][200/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0869 (0.0592)	
0.9999907 1.5454017e-06
loss:  0.039812299544766505 0.038285376973611895
===========>   training    <===========
Epoch: [1907][0/23]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0353 (0.0353)	
0.99999523 1.6420273e-06
===========>   testing    <===========
Epoch: [1907][0/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0406 (0.0406)	
0.99999213 1.4411751e-06
Epoch: [1907][100/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0335 (0.0592)	
0.9999919 1.7113002e-06
Epoch: [1907][200/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0877 (0.0589)	
0.9999912 1.5329995e-06
loss:  0.03943247039018949 0.038285376973611895
===========>   training    <===========
Epoch: [1908][0/23]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0297 (0.0297)	
0.9999913 1.4402902e-06
===========>   testing    <===========
Epoch: [1908][0/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0433 (0.0433)	
0.9999907 1.2584522e-06
Epoch: [1908][100/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0288 (0.0589)	
0.9999888 1.3786693e-06
Epoch: [1908][200/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0895 (0.0589)	
0.9999888 1.2663885e-06
loss:  0.03959210404061164 0.038285376973611895
===========>   training    <===========
Epoch: [1909][0/23]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0311 (0.0311)	
0.99999845 6.05103e-06
===========>   testing    <===========
Epoch: [1909][0/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0449 (0.0449)	
0.9999908 1.428158e-06
Epoch: [1909][100/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0250 (0.0587)	
0.9999914 1.7003747e-06
Epoch: [1909][200/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0960 (0.0592)	
0.99999166 1.5507536e-06
loss:  0.039640093493815476 0.038285376973611895
===========>   training    <===========
Epoch: [1910][0/23]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0307 (0.0307)	
0.9999945 1.404912e-06
===========>   testing    <===========
Epoch: [1910][0/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0448 (0.0448)	
0.99999225 1.4175549e-06
Epoch: [1910][100/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0265 (0.0588)	
0.9999924 1.7429768e-06
Epoch: [1910][200/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0899 (0.0591)	
0.9999918 1.5994792e-06
loss:  0.03943206827027079 0.038285376973611895
===========>   training    <===========
Epoch: [1911][0/23]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0298 (0.0298)	
0.99999595 1.5083518e-06
===========>   testing    <===========
Epoch: [1911][0/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0455 (0.0455)	
0.9999925 1.5448431e-06
Epoch: [1911][100/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0302 (0.0588)	
0.9999927 1.867656e-06
Epoch: [1911][200/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0904 (0.0592)	
0.999992 1.7125312e-06
loss:  0.03950582590634533 0.038285376973611895
===========>   training    <===========
Epoch: [1912][0/23]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0329 (0.0329)	
0.9999963 1.3919703e-06
===========>   testing    <===========
Epoch: [1912][0/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0451 (0.0451)	
0.9999913 1.4162874e-06
Epoch: [1912][100/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0301 (0.0584)	
0.99999106 1.6470007e-06
Epoch: [1912][200/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0858 (0.0587)	
0.9999906 1.4892431e-06
loss:  0.03956145357983942 0.038285376973611895
===========>   training    <===========
Epoch: [1913][0/23]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0302 (0.0302)	
0.9999945 2.4330907e-06
===========>   testing    <===========
Epoch: [1913][0/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0487 (0.0487)	
0.99999094 1.2764013e-06
Epoch: [1913][100/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0280 (0.0584)	
0.9999908 1.524872e-06
Epoch: [1913][200/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0899 (0.0586)	
0.9999907 1.3670119e-06
loss:  0.039605447914617065 0.038285376973611895
===========>   training    <===========
Epoch: [1914][0/23]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0314 (0.0314)	
0.99999285 1.2547374e-06
===========>   testing    <===========
Epoch: [1914][0/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0530 (0.0530)	
0.99999225 1.486798e-06
Epoch: [1914][100/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0259 (0.0583)	
0.9999927 1.8416439e-06
Epoch: [1914][200/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.1005 (0.0586)	
0.9999919 1.6619473e-06
loss:  0.039543918624033836 0.038285376973611895
===========>   training    <===========
Epoch: [1915][0/23]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0335 (0.0335)	
0.99999285 7.5521336e-07
===========>   testing    <===========
Epoch: [1915][0/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0564 (0.0564)	
0.9999925 1.5235318e-06
Epoch: [1915][100/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0418 (0.0584)	
0.9999937 2.013091e-06
Epoch: [1915][200/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0883 (0.0584)	
0.99999356 1.8101116e-06
loss:  0.03936671172526873 0.038285376973611895
===========>   training    <===========
Epoch: [1916][0/23]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0344 (0.0344)	
0.99998486 2.0409373e-06
===========>   testing    <===========
Epoch: [1916][0/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0482 (0.0482)	
0.99999213 1.5170423e-06
Epoch: [1916][100/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0327 (0.0580)	
0.9999933 1.8859517e-06
Epoch: [1916][200/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0970 (0.0584)	
0.9999927 1.6696362e-06
loss:  0.03931143305895235 0.038285376973611895
===========>   training    <===========
Epoch: [1917][0/23]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0274 (0.0274)	
0.99999666 6.9409947e-07
===========>   testing    <===========
Epoch: [1917][0/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0535 (0.0535)	
0.9999913 1.3578102e-06
Epoch: [1917][100/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0409 (0.0578)	
0.9999919 1.6282378e-06
Epoch: [1917][200/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0763 (0.0578)	
0.9999918 1.4589087e-06
loss:  0.03928693754265966 0.038285376973611895
===========>   training    <===========
Epoch: [1918][0/23]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0303 (0.0303)	
0.9999957 1.5860803e-06
===========>   testing    <===========
Epoch: [1918][0/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0549 (0.0549)	
0.9999927 1.4457481e-06
Epoch: [1918][100/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0364 (0.0583)	
0.99999225 1.6735274e-06
Epoch: [1918][200/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0821 (0.0583)	
0.99999213 1.6006146e-06
loss:  0.039342394231980826 0.038285376973611895
===========>   training    <===========
Epoch: [1919][0/23]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0310 (0.0310)	
0.9999932 1.3753481e-06
===========>   testing    <===========
Epoch: [1919][0/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0558 (0.0558)	
0.99999225 1.4819736e-06
Epoch: [1919][100/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0359 (0.0584)	
0.9999924 1.6890257e-06
Epoch: [1919][200/289]	Lr-deconv: [0.0]	Lr-other: [7.651428115381816e-06]	Loss 0.0780 (0.0579)	
0.99999154 1.5660644e-06
loss:  0.038918881054476495 0.038285376973611895
===========>   training    <===========
Epoch: [1920][0/23]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0361 (0.0361)	
0.99999046 1.3837299e-06
===========>   testing    <===========
Epoch: [1920][0/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0545 (0.0545)	
0.99999285 1.5380867e-06
Epoch: [1920][100/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0297 (0.0582)	
0.9999931 1.957449e-06
Epoch: [1920][200/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0846 (0.0579)	
0.99999285 1.7577764e-06
loss:  0.038932668021233297 0.038285376973611895
===========>   training    <===========
Epoch: [1921][0/23]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0337 (0.0337)	
0.9999925 3.8713205e-07
===========>   testing    <===========
Epoch: [1921][0/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0528 (0.0528)	
0.9999927 1.5599485e-06
Epoch: [1921][100/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0354 (0.0583)	
0.9999931 1.8674707e-06
Epoch: [1921][200/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0837 (0.0581)	
0.9999927 1.687781e-06
loss:  0.03888946521857661 0.038285376973611895
===========>   training    <===========
Epoch: [1922][0/23]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0305 (0.0305)	
0.99999535 1.5615128e-06
===========>   testing    <===========
Epoch: [1922][0/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0546 (0.0546)	
0.9999924 1.4096348e-06
Epoch: [1922][100/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0318 (0.0580)	
0.9999918 1.6911081e-06
Epoch: [1922][200/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0891 (0.0582)	
0.99999154 1.5206169e-06
loss:  0.038985496431188316 0.038285376973611895
===========>   training    <===========
Epoch: [1923][0/23]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0360 (0.0360)	
0.9999896 7.286703e-07
===========>   testing    <===========
Epoch: [1923][0/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0540 (0.0540)	
0.9999926 1.4976162e-06
Epoch: [1923][100/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0338 (0.0578)	
0.9999926 1.8234945e-06
Epoch: [1923][200/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0844 (0.0580)	
0.9999927 1.6469817e-06
loss:  0.03879229211195223 0.038285376973611895
===========>   training    <===========
Epoch: [1924][0/23]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0294 (0.0294)	
0.9999956 1.9949541e-06
===========>   testing    <===========
Epoch: [1924][0/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0549 (0.0549)	
0.9999906 1.3578207e-06
Epoch: [1924][100/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0280 (0.0581)	
0.9999908 1.5813062e-06
Epoch: [1924][200/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0787 (0.0582)	
0.99999046 1.4185475e-06
loss:  0.039118054742767305 0.038285376973611895
===========>   training    <===========
Epoch: [1925][0/23]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0276 (0.0276)	
0.9999925 1.0146146e-06
===========>   testing    <===========
Epoch: [1925][0/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0535 (0.0535)	
0.9999939 1.8475248e-06
Epoch: [1925][100/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0333 (0.0583)	
0.999995 2.4413139e-06
Epoch: [1925][200/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0902 (0.0583)	
0.99999535 2.3191114e-06
loss:  0.03860577506565577 0.038285376973611895
===========>   training    <===========
Epoch: [1926][0/23]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0324 (0.0324)	
0.9999937 1.8097854e-06
===========>   testing    <===========
Epoch: [1926][0/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0564 (0.0564)	
0.99999166 1.5215802e-06
Epoch: [1926][100/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0354 (0.0583)	
0.9999924 1.8071898e-06
Epoch: [1926][200/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0847 (0.0582)	
0.99999225 1.6655428e-06
loss:  0.03908036446456298 0.038285376973611895
===========>   training    <===========
Epoch: [1927][0/23]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0331 (0.0331)	
0.99998605 1.2827738e-06
===========>   testing    <===========
Epoch: [1927][0/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0533 (0.0533)	
0.9999913 1.5279159e-06
Epoch: [1927][100/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0313 (0.0583)	
0.999992 1.7894838e-06
Epoch: [1927][200/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0805 (0.0581)	
0.99999154 1.6271434e-06
loss:  0.039092679422639054 0.038285376973611895
===========>   training    <===========
Epoch: [1928][0/23]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0300 (0.0300)	
0.9999894 2.3779955e-06
===========>   testing    <===========
Epoch: [1928][0/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0545 (0.0545)	
0.9999919 1.5066727e-06
Epoch: [1928][100/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0261 (0.0584)	
0.99999213 1.9410736e-06
Epoch: [1928][200/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0788 (0.0582)	
0.9999924 1.7748841e-06
loss:  0.039042176236616766 0.038285376973611895
===========>   training    <===========
Epoch: [1929][0/23]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0369 (0.0369)	
0.99999034 1.5075537e-06
===========>   testing    <===========
Epoch: [1929][0/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0517 (0.0517)	
0.9999913 1.4145663e-06
Epoch: [1929][100/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0301 (0.0582)	
0.99999225 1.7008643e-06
Epoch: [1929][200/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0810 (0.0580)	
0.9999918 1.4731048e-06
loss:  0.038879431289061905 0.038285376973611895
===========>   training    <===========
Epoch: [1930][0/23]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0343 (0.0343)	
0.99999547 1.3255777e-06
===========>   testing    <===========
Epoch: [1930][0/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0560 (0.0560)	
0.9999912 1.3754714e-06
Epoch: [1930][100/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0279 (0.0585)	
0.99999166 1.6782326e-06
Epoch: [1930][200/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0825 (0.0585)	
0.9999913 1.4379023e-06
loss:  0.03911300246635818 0.038285376973611895
===========>   training    <===========
Epoch: [1931][0/23]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0370 (0.0370)	
0.99999464 1.455765e-06
===========>   testing    <===========
Epoch: [1931][0/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0525 (0.0525)	
0.9999912 1.4167387e-06
Epoch: [1931][100/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0288 (0.0581)	
0.999992 1.8166e-06
Epoch: [1931][200/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0805 (0.0585)	
0.99999166 1.5970191e-06
loss:  0.039377359068172524 0.038285376973611895
===========>   training    <===========
Epoch: [1932][0/23]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0341 (0.0341)	
0.9999956 2.0079547e-06
===========>   testing    <===========
Epoch: [1932][0/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0508 (0.0508)	
0.9999914 1.3632156e-06
Epoch: [1932][100/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0303 (0.0583)	
0.99999166 1.6600147e-06
Epoch: [1932][200/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0764 (0.0584)	
0.99999166 1.4810638e-06
loss:  0.03911254325967117 0.038285376973611895
===========>   training    <===========
Epoch: [1933][0/23]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0305 (0.0305)	
0.99998605 1.7585845e-06
===========>   testing    <===========
Epoch: [1933][0/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0492 (0.0492)	
0.99999094 1.3631766e-06
Epoch: [1933][100/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0304 (0.0582)	
0.99999106 1.5940246e-06
Epoch: [1933][200/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0742 (0.0587)	
0.9999914 1.3878388e-06
loss:  0.039246807813585805 0.038285376973611895
===========>   training    <===========
Epoch: [1934][0/23]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0318 (0.0318)	
0.9999964 5.586559e-06
===========>   testing    <===========
Epoch: [1934][0/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0519 (0.0519)	
0.999992 1.4917305e-06
Epoch: [1934][100/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0283 (0.0577)	
0.9999931 1.9554545e-06
Epoch: [1934][200/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0838 (0.0584)	
0.9999932 1.702773e-06
loss:  0.03903043988996391 0.038285376973611895
===========>   training    <===========
Epoch: [1935][0/23]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0305 (0.0305)	
0.9999968 2.2834267e-06
===========>   testing    <===========
Epoch: [1935][0/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0496 (0.0496)	
0.9999919 1.3958439e-06
Epoch: [1935][100/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0275 (0.0577)	
0.99999285 1.7996601e-06
Epoch: [1935][200/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0842 (0.0587)	
0.9999925 1.5645866e-06
loss:  0.03913760711691294 0.038285376973611895
===========>   training    <===========
Epoch: [1936][0/23]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0388 (0.0388)	
0.9999956 1.7129804e-06
===========>   testing    <===========
Epoch: [1936][0/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0505 (0.0505)	
0.99999213 1.5552055e-06
Epoch: [1936][100/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0265 (0.0580)	
0.99999285 2.1028795e-06
Epoch: [1936][200/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0831 (0.0587)	
0.99999285 1.8163506e-06
loss:  0.03902598164944626 0.038285376973611895
===========>   training    <===========
Epoch: [1937][0/23]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0364 (0.0364)	
0.9999937 2.485664e-06
===========>   testing    <===========
Epoch: [1937][0/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0511 (0.0511)	
0.9999918 1.4466998e-06
Epoch: [1937][100/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0321 (0.0578)	
0.9999924 1.8464432e-06
Epoch: [1937][200/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0787 (0.0587)	
0.99999225 1.5934196e-06
loss:  0.03891910869596393 0.038285376973611895
===========>   training    <===========
Epoch: [1938][0/23]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0281 (0.0281)	
0.9999968 2.6836988e-06
===========>   testing    <===========
Epoch: [1938][0/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0529 (0.0529)	
0.9999924 1.4508005e-06
Epoch: [1938][100/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0338 (0.0581)	
0.9999931 1.860247e-06
Epoch: [1938][200/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0859 (0.0584)	
0.99999297 1.6081761e-06
loss:  0.038931774279522435 0.038285376973611895
===========>   training    <===========
Epoch: [1939][0/23]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0302 (0.0302)	
0.9999939 1.1604646e-06
===========>   testing    <===========
Epoch: [1939][0/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0473 (0.0473)	
0.9999914 1.3709978e-06
Epoch: [1939][100/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0307 (0.0584)	
0.999992 1.7386653e-06
Epoch: [1939][200/289]	Lr-deconv: [0.0]	Lr-other: [7.2688567096127245e-06]	Loss 0.0865 (0.0589)	
0.9999914 1.4507617e-06
loss:  0.03929616080679854 0.038285376973611895
===========>   training    <===========
Epoch: [1940][0/23]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0261 (0.0261)	
0.99999416 1.6998832e-06
===========>   testing    <===========
Epoch: [1940][0/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0492 (0.0492)	
0.9999918 1.3092749e-06
Epoch: [1940][100/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0383 (0.0587)	
0.99999213 1.7171169e-06
Epoch: [1940][200/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0878 (0.0588)	
0.99999166 1.424715e-06
loss:  0.039290577061427134 0.038285376973611895
===========>   training    <===========
Epoch: [1941][0/23]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0331 (0.0331)	
0.99999297 1.0505544e-06
===========>   testing    <===========
Epoch: [1941][0/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0489 (0.0489)	
0.9999918 1.260386e-06
Epoch: [1941][100/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0335 (0.0583)	
0.9999914 1.5764757e-06
Epoch: [1941][200/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0953 (0.0591)	
0.9999908 1.323852e-06
loss:  0.03938340484876979 0.038285376973611895
===========>   training    <===========
Epoch: [1942][0/23]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0365 (0.0365)	
0.9999962 7.3320615e-07
===========>   testing    <===========
Epoch: [1942][0/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0525 (0.0525)	
0.9999918 1.2615476e-06
Epoch: [1942][100/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0312 (0.0585)	
0.9999918 1.7276426e-06
Epoch: [1942][200/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0971 (0.0590)	
0.99999106 1.3976929e-06
loss:  0.03937080063640186 0.038285376973611895
===========>   training    <===========
Epoch: [1943][0/23]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0331 (0.0331)	
0.99999416 4.871563e-07
===========>   testing    <===========
Epoch: [1943][0/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0550 (0.0550)	
0.99999166 1.3652557e-06
Epoch: [1943][100/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0256 (0.0583)	
0.99999166 1.8334513e-06
Epoch: [1943][200/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.1080 (0.0590)	
0.99999106 1.4885914e-06
loss:  0.03945058309530636 0.038285376973611895
===========>   training    <===========
Epoch: [1944][0/23]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0309 (0.0309)	
0.99999 1.8386448e-06
===========>   testing    <===========
Epoch: [1944][0/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0487 (0.0487)	
0.999992 1.4658066e-06
Epoch: [1944][100/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0285 (0.0585)	
0.99999225 1.9312834e-06
Epoch: [1944][200/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0810 (0.0589)	
0.999992 1.6626401e-06
loss:  0.03916591397701019 0.038285376973611895
===========>   training    <===========
Epoch: [1945][0/23]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0337 (0.0337)	
0.99998856 1.1375776e-06
===========>   testing    <===========
Epoch: [1945][0/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0517 (0.0517)	
0.9999924 1.4575431e-06
Epoch: [1945][100/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0268 (0.0586)	
0.99999225 1.8049953e-06
Epoch: [1945][200/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0922 (0.0593)	
0.9999919 1.5576902e-06
loss:  0.03948976547121119 0.038285376973611895
===========>   training    <===========
Epoch: [1946][0/23]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0365 (0.0365)	
0.99999094 5.990678e-06
===========>   testing    <===========
Epoch: [1946][0/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0507 (0.0507)	
0.9999913 1.3455077e-06
Epoch: [1946][100/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0333 (0.0586)	
0.9999912 1.7329195e-06
Epoch: [1946][200/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0818 (0.0588)	
0.99999106 1.4198225e-06
loss:  0.03944058525998606 0.038285376973611895
===========>   training    <===========
Epoch: [1947][0/23]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0318 (0.0318)	
0.9999962 1.5188748e-06
===========>   testing    <===========
Epoch: [1947][0/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0487 (0.0487)	
0.99999213 1.4174806e-06
Epoch: [1947][100/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0336 (0.0585)	
0.99999225 1.8526395e-06
Epoch: [1947][200/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0911 (0.0587)	
0.99999225 1.5409042e-06
loss:  0.03943740968947529 0.038285376973611895
===========>   training    <===========
Epoch: [1948][0/23]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0319 (0.0319)	
0.99998045 1.5237177e-06
===========>   testing    <===========
Epoch: [1948][0/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0467 (0.0467)	
0.9999927 1.5889916e-06
Epoch: [1948][100/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0285 (0.0586)	
0.99999356 2.096246e-06
Epoch: [1948][200/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.1010 (0.0588)	
0.9999938 1.7904365e-06
loss:  0.03921734605805782 0.038285376973611895
===========>   training    <===========
Epoch: [1949][0/23]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0289 (0.0289)	
0.9999895 9.714382e-07
===========>   testing    <===========
Epoch: [1949][0/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0504 (0.0504)	
0.9999927 1.4521543e-06
Epoch: [1949][100/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0295 (0.0583)	
0.9999931 1.8589701e-06
Epoch: [1949][200/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0935 (0.0589)	
0.9999932 1.586112e-06
loss:  0.039110550226929996 0.038285376973611895
===========>   training    <===========
Epoch: [1950][0/23]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0342 (0.0342)	
0.99998903 1.9551974e-06
===========>   testing    <===========
Epoch: [1950][0/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0524 (0.0524)	
0.9999924 1.4495669e-06
Epoch: [1950][100/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0299 (0.0582)	
0.99999213 1.7484173e-06
Epoch: [1950][200/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0950 (0.0591)	
0.9999919 1.5781018e-06
loss:  0.03933407379445131 0.038285376973611895
===========>   training    <===========
Epoch: [1951][0/23]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0329 (0.0329)	
0.999987 8.933875e-07
===========>   testing    <===========
Epoch: [1951][0/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0547 (0.0547)	
0.9999919 1.4194069e-06
Epoch: [1951][100/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0336 (0.0583)	
0.999992 1.6986695e-06
Epoch: [1951][200/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0908 (0.0591)	
0.99999225 1.5730186e-06
loss:  0.039297901471134766 0.038285376973611895
===========>   training    <===========
Epoch: [1952][0/23]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0306 (0.0306)	
0.99999106 1.0807668e-06
===========>   testing    <===========
Epoch: [1952][0/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0507 (0.0507)	
0.99999106 1.2702133e-06
Epoch: [1952][100/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0302 (0.0586)	
0.99999046 1.4732719e-06
Epoch: [1952][200/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0910 (0.0590)	
0.99999094 1.3199527e-06
loss:  0.03951166894301239 0.038285376973611895
===========>   training    <===========
Epoch: [1953][0/23]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0309 (0.0309)	
0.9999958 1.2284988e-06
===========>   testing    <===========
Epoch: [1953][0/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0492 (0.0492)	
0.9999925 1.4480387e-06
Epoch: [1953][100/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0336 (0.0581)	
0.9999919 1.7194798e-06
Epoch: [1953][200/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0820 (0.0583)	
0.9999913 1.512887e-06
loss:  0.03902334755890591 0.038285376973611895
===========>   training    <===========
Epoch: [1954][0/23]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0315 (0.0315)	
0.9999913 1.2306846e-06
===========>   testing    <===========
Epoch: [1954][0/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0529 (0.0529)	
0.99999225 1.5413407e-06
Epoch: [1954][100/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0350 (0.0588)	
0.9999926 1.97841e-06
Epoch: [1954][200/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0794 (0.0588)	
0.9999925 1.7008822e-06
loss:  0.03914262814020186 0.038285376973611895
===========>   training    <===========
Epoch: [1955][0/23]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0319 (0.0319)	
0.99999213 1.642007e-06
===========>   testing    <===========
Epoch: [1955][0/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0489 (0.0489)	
0.99999213 1.4202559e-06
Epoch: [1955][100/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0342 (0.0585)	
0.9999919 1.770151e-06
Epoch: [1955][200/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0866 (0.0590)	
0.9999919 1.5177802e-06
loss:  0.039380660697282965 0.038285376973611895
===========>   training    <===========
Epoch: [1956][0/23]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0315 (0.0315)	
0.9999926 2.6353052e-06
===========>   testing    <===========
Epoch: [1956][0/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0438 (0.0438)	
0.99999285 1.6047383e-06
Epoch: [1956][100/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0319 (0.0588)	
0.9999931 2.139004e-06
Epoch: [1956][200/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0947 (0.0593)	
0.99999344 1.794998e-06
loss:  0.03936883634074784 0.038285376973611895
===========>   training    <===========
Epoch: [1957][0/23]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0270 (0.0270)	
0.9999912 1.7713062e-06
===========>   testing    <===========
Epoch: [1957][0/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0473 (0.0473)	
0.99999285 1.64614e-06
Epoch: [1957][100/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0418 (0.0592)	
0.9999932 2.186728e-06
Epoch: [1957][200/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0844 (0.0589)	
0.99999356 1.8756848e-06
loss:  0.03941109888356753 0.038285376973611895
===========>   training    <===========
Epoch: [1958][0/23]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0310 (0.0310)	
0.99999213 1.3752077e-06
===========>   testing    <===========
Epoch: [1958][0/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0471 (0.0471)	
0.9999926 1.4238539e-06
Epoch: [1958][100/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0341 (0.0591)	
0.9999927 1.8785328e-06
Epoch: [1958][200/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0830 (0.0594)	
0.99999297 1.6276975e-06
loss:  0.03952850813559716 0.038285376973611895
===========>   training    <===========
Epoch: [1959][0/23]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0298 (0.0298)	
0.9999949 1.4029184e-06
===========>   testing    <===========
Epoch: [1959][0/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0460 (0.0460)	
0.999992 1.3899011e-06
Epoch: [1959][100/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0365 (0.0588)	
0.9999919 1.7544821e-06
Epoch: [1959][200/289]	Lr-deconv: [0.0]	Lr-other: [6.905413874132088e-06]	Loss 0.0793 (0.0592)	
0.99999166 1.5467391e-06
loss:  0.03942585476145555 0.038285376973611895
===========>   training    <===========
Epoch: [1960][0/23]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0327 (0.0327)	
0.9999976 3.867796e-06
===========>   testing    <===========
Epoch: [1960][0/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0462 (0.0462)	
0.9999914 1.3261442e-06
Epoch: [1960][100/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0353 (0.0587)	
0.9999908 1.6190974e-06
Epoch: [1960][200/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0928 (0.0593)	
0.99999034 1.394951e-06
loss:  0.03977436588917427 0.038285376973611895
===========>   training    <===========
Epoch: [1961][0/23]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0306 (0.0306)	
0.9999914 1.113172e-06
===========>   testing    <===========
Epoch: [1961][0/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0451 (0.0451)	
0.99999213 1.3895975e-06
Epoch: [1961][100/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0369 (0.0585)	
0.999992 1.7763608e-06
Epoch: [1961][200/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0871 (0.0593)	
0.999992 1.5432264e-06
loss:  0.03948590727242807 0.038285376973611895
===========>   training    <===========
Epoch: [1962][0/23]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0296 (0.0296)	
0.99999714 4.9431565e-06
===========>   testing    <===========
Epoch: [1962][0/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0479 (0.0479)	
0.9999918 1.3611475e-06
Epoch: [1962][100/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0364 (0.0585)	
0.99999166 1.6752393e-06
Epoch: [1962][200/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0820 (0.0593)	
0.99999154 1.4367768e-06
loss:  0.039517354193278176 0.038285376973611895
===========>   training    <===========
Epoch: [1963][0/23]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0310 (0.0310)	
0.999995 7.0518527e-06
===========>   testing    <===========
Epoch: [1963][0/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0472 (0.0472)	
0.999992 1.3835439e-06
Epoch: [1963][100/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0405 (0.0582)	
0.9999925 1.761606e-06
Epoch: [1963][200/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0974 (0.0596)	
0.99999213 1.5282262e-06
loss:  0.03976099258824484 0.038285376973611895
===========>   training    <===========
Epoch: [1964][0/23]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0380 (0.0380)	
0.999992 1.8010492e-06
===========>   testing    <===========
Epoch: [1964][0/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0483 (0.0483)	
0.9999927 1.5414937e-06
Epoch: [1964][100/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0403 (0.0584)	
0.99999344 2.0845362e-06
Epoch: [1964][200/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0841 (0.0596)	
0.9999933 1.8349259e-06
loss:  0.03965733198912269 0.038285376973611895
===========>   training    <===========
Epoch: [1965][0/23]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0362 (0.0362)	
0.9999931 1.7355921e-06
===========>   testing    <===========
Epoch: [1965][0/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0482 (0.0482)	
0.99999166 1.3719434e-06
Epoch: [1965][100/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0349 (0.0578)	
0.99999213 1.7902554e-06
Epoch: [1965][200/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0793 (0.0589)	
0.9999914 1.553886e-06
loss:  0.039299384009306326 0.038285376973611895
===========>   training    <===========
Epoch: [1966][0/23]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0321 (0.0321)	
0.99997354 9.937984e-07
===========>   testing    <===========
Epoch: [1966][0/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0444 (0.0444)	
0.99999213 1.4352307e-06
Epoch: [1966][100/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0260 (0.0582)	
0.9999926 1.9217446e-06
Epoch: [1966][200/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0939 (0.0602)	
0.9999924 1.6923424e-06
loss:  0.03999064073329772 0.038285376973611895
===========>   training    <===========
Epoch: [1967][0/23]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0314 (0.0314)	
0.99999714 2.0500881e-06
===========>   testing    <===========
Epoch: [1967][0/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0456 (0.0456)	
0.9999908 1.2763112e-06
Epoch: [1967][100/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0261 (0.0584)	
0.9999912 1.6420446e-06
Epoch: [1967][200/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0914 (0.0600)	
0.9999901 1.4359398e-06
loss:  0.039839659696891516 0.038285376973611895
===========>   training    <===========
Epoch: [1968][0/23]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0294 (0.0294)	
0.9999912 3.5718163e-06
===========>   testing    <===========
Epoch: [1968][0/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0447 (0.0447)	
0.9999926 1.4798551e-06
Epoch: [1968][100/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0301 (0.0581)	
0.99999297 1.9562285e-06
Epoch: [1968][200/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0804 (0.0593)	
0.99999285 1.6671175e-06
loss:  0.03941138457618654 0.038285376973611895
===========>   training    <===========
Epoch: [1969][0/23]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0343 (0.0343)	
0.99999666 2.1372095e-06
===========>   testing    <===========
Epoch: [1969][0/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0475 (0.0475)	
0.99999106 1.3332327e-06
Epoch: [1969][100/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0317 (0.0581)	
0.99999106 1.6842516e-06
Epoch: [1969][200/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0681 (0.0594)	
0.9999908 1.468846e-06
loss:  0.0397803936537362 0.038285376973611895
===========>   training    <===========
Epoch: [1970][0/23]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0319 (0.0319)	
0.99999356 3.4830914e-06
===========>   testing    <===========
Epoch: [1970][0/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0428 (0.0428)	
0.9999919 1.4563926e-06
Epoch: [1970][100/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0321 (0.0581)	
0.99999225 1.8459958e-06
Epoch: [1970][200/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0730 (0.0594)	
0.999992 1.6345919e-06
loss:  0.03964108430917934 0.038285376973611895
===========>   training    <===========
Epoch: [1971][0/23]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0334 (0.0334)	
0.99999726 3.4779132e-06
===========>   testing    <===========
Epoch: [1971][0/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0462 (0.0462)	
0.99999154 1.3677812e-06
Epoch: [1971][100/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0333 (0.0584)	
0.99999213 1.7553642e-06
Epoch: [1971][200/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0789 (0.0597)	
0.99999213 1.5145081e-06
loss:  0.039824510514103295 0.038285376973611895
===========>   training    <===========
Epoch: [1972][0/23]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0302 (0.0302)	
0.9999896 4.365764e-06
===========>   testing    <===========
Epoch: [1972][0/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0427 (0.0427)	
0.9999925 1.4198496e-06
Epoch: [1972][100/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0390 (0.0584)	
0.9999927 1.827387e-06
Epoch: [1972][200/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0869 (0.0594)	
0.9999925 1.5760023e-06
loss:  0.03980401209316631 0.038285376973611895
===========>   training    <===========
Epoch: [1973][0/23]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0316 (0.0316)	
0.9999944 1.4695661e-06
===========>   testing    <===========
Epoch: [1973][0/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0473 (0.0473)	
0.99999094 1.3141774e-06
Epoch: [1973][100/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0372 (0.0585)	
0.9999914 1.6689469e-06
Epoch: [1973][200/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0948 (0.0597)	
0.9999913 1.4331175e-06
loss:  0.03977358731900027 0.038285376973611895
===========>   training    <===========
Epoch: [1974][0/23]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0320 (0.0320)	
0.99999595 7.899372e-07
===========>   testing    <===========
Epoch: [1974][0/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0441 (0.0441)	
0.9999912 1.3305324e-06
Epoch: [1974][100/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0301 (0.0587)	
0.9999918 1.719839e-06
Epoch: [1974][200/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0892 (0.0600)	
0.9999918 1.5079261e-06
loss:  0.039701793364752436 0.038285376973611895
===========>   training    <===========
Epoch: [1975][0/23]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0300 (0.0300)	
0.9999993 1.1915212e-05
===========>   testing    <===========
Epoch: [1975][0/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0431 (0.0431)	
0.9999907 1.2789211e-06
Epoch: [1975][100/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0277 (0.0587)	
0.9999913 1.5765644e-06
Epoch: [1975][200/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0847 (0.0598)	
0.9999913 1.4303648e-06
loss:  0.0397110840777416 0.038285376973611895
===========>   training    <===========
Epoch: [1976][0/23]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0342 (0.0342)	
0.99999845 3.0998062e-06
===========>   testing    <===========
Epoch: [1976][0/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0429 (0.0429)	
0.9999908 1.4243468e-06
Epoch: [1976][100/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0341 (0.0586)	
0.9999912 1.7573976e-06
Epoch: [1976][200/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0866 (0.0593)	
0.9999912 1.5230872e-06
loss:  0.03955401472148956 0.038285376973611895
===========>   training    <===========
Epoch: [1977][0/23]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0387 (0.0387)	
0.99999213 7.816685e-07
===========>   testing    <===========
Epoch: [1977][0/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0481 (0.0481)	
0.9999912 1.3999554e-06
Epoch: [1977][100/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0309 (0.0588)	
0.9999919 1.796803e-06
Epoch: [1977][200/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0911 (0.0595)	
0.9999925 1.5688806e-06
loss:  0.039711423376308175 0.038285376973611895
===========>   training    <===========
Epoch: [1978][0/23]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0288 (0.0288)	
0.99999 1.272892e-06
===========>   testing    <===========
Epoch: [1978][0/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0430 (0.0430)	
0.9999919 1.623041e-06
Epoch: [1978][100/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0318 (0.0583)	
0.99999285 2.1684532e-06
Epoch: [1978][200/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0804 (0.0592)	
0.99999344 1.9034263e-06
loss:  0.03950994291376375 0.038285376973611895
===========>   training    <===========
Epoch: [1979][0/23]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0355 (0.0355)	
0.99999666 2.3877878e-06
===========>   testing    <===========
Epoch: [1979][0/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0439 (0.0439)	
0.9999907 1.3441047e-06
Epoch: [1979][100/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0268 (0.0587)	
0.9999913 1.6643089e-06
Epoch: [1979][200/289]	Lr-deconv: [0.0]	Lr-other: [6.560143180425483e-06]	Loss 0.0804 (0.0599)	
0.99999166 1.4765536e-06
loss:  0.03982567112769664 0.038285376973611895
===========>   training    <===========
Epoch: [1980][0/23]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0285 (0.0285)	
0.99999547 1.3713927e-06
===========>   testing    <===========
Epoch: [1980][0/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0451 (0.0451)	
0.9999918 1.3729199e-06
Epoch: [1980][100/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0388 (0.0590)	
0.99999225 1.8331174e-06
Epoch: [1980][200/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0766 (0.0593)	
0.99999285 1.5847936e-06
loss:  0.0397044492391081 0.038285376973611895
===========>   training    <===========
Epoch: [1981][0/23]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0321 (0.0321)	
0.99999857 3.2210507e-06
===========>   testing    <===========
Epoch: [1981][0/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0440 (0.0440)	
0.99999213 1.348695e-06
Epoch: [1981][100/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0282 (0.0586)	
0.9999924 1.7868304e-06
Epoch: [1981][200/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0871 (0.0600)	
0.99999285 1.5581122e-06
loss:  0.03975827096986251 0.038285376973611895
===========>   training    <===========
Epoch: [1982][0/23]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0401 (0.0401)	
0.9999933 1.3568718e-06
===========>   testing    <===========
Epoch: [1982][0/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0415 (0.0415)	
0.9999924 1.3071565e-06
Epoch: [1982][100/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0303 (0.0587)	
0.9999925 1.8067141e-06
Epoch: [1982][200/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0783 (0.0597)	
0.99999297 1.549234e-06
loss:  0.03959380199488205 0.038285376973611895
===========>   training    <===========
Epoch: [1983][0/23]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0337 (0.0337)	
0.99999535 1.1619353e-06
===========>   testing    <===========
Epoch: [1983][0/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0397 (0.0397)	
0.99999046 1.2151895e-06
Epoch: [1983][100/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0290 (0.0588)	
0.99999 1.4986877e-06
Epoch: [1983][200/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0762 (0.0599)	
0.99999094 1.2853062e-06
loss:  0.03972012171489536 0.038285376973611895
===========>   training    <===========
Epoch: [1984][0/23]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0359 (0.0359)	
0.99998784 1.2551562e-06
===========>   testing    <===========
Epoch: [1984][0/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0420 (0.0420)	
0.9999913 1.3805468e-06
Epoch: [1984][100/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0305 (0.0587)	
0.9999914 1.7454952e-06
Epoch: [1984][200/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0725 (0.0591)	
0.999992 1.4981133e-06
loss:  0.03940481087887526 0.038285376973611895
===========>   training    <===========
Epoch: [1985][0/23]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0380 (0.0380)	
0.9999809 4.2919683e-06
===========>   testing    <===========
Epoch: [1985][0/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0417 (0.0417)	
0.99999094 1.3003578e-06
Epoch: [1985][100/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0237 (0.0591)	
0.9999906 1.5626763e-06
Epoch: [1985][200/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0795 (0.0602)	
0.99999154 1.358901e-06
loss:  0.03977578193375353 0.038285376973611895
===========>   training    <===========
Epoch: [1986][0/23]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0312 (0.0312)	
0.9999963 3.198735e-06
===========>   testing    <===========
Epoch: [1986][0/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0412 (0.0412)	
0.9999914 1.3612772e-06
Epoch: [1986][100/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0304 (0.0592)	
0.9999913 1.7372614e-06
Epoch: [1986][200/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0726 (0.0592)	
0.999992 1.5142352e-06
loss:  0.03959860771652457 0.038285376973611895
===========>   training    <===========
Epoch: [1987][0/23]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0313 (0.0313)	
0.9999962 1.7227215e-06
===========>   testing    <===========
Epoch: [1987][0/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0405 (0.0405)	
0.9999914 1.2853847e-06
Epoch: [1987][100/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0282 (0.0592)	
0.9999908 1.6291449e-06
Epoch: [1987][200/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0763 (0.0593)	
0.99999154 1.4348775e-06
loss:  0.03960349223871795 0.038285376973611895
===========>   training    <===========
Epoch: [1988][0/23]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0404 (0.0404)	
0.9999964 5.016898e-07
===========>   testing    <===========
Epoch: [1988][0/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0391 (0.0391)	
0.9999919 1.2946065e-06
Epoch: [1988][100/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0255 (0.0588)	
0.9999908 1.6146579e-06
Epoch: [1988][200/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0842 (0.0592)	
0.99999166 1.3916517e-06
loss:  0.03971741442537158 0.038285376973611895
===========>   training    <===========
Epoch: [1989][0/23]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0352 (0.0352)	
0.99998724 1.0050096e-06
===========>   testing    <===========
Epoch: [1989][0/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0431 (0.0431)	
0.99999 1.3373026e-06
Epoch: [1989][100/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0292 (0.0585)	
0.99998975 1.5814463e-06
Epoch: [1989][200/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0822 (0.0589)	
0.99999106 1.3694037e-06
loss:  0.03978116819578725 0.038285376973611895
===========>   training    <===========
Epoch: [1990][0/23]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0374 (0.0374)	
0.999992 2.3115952e-06
===========>   testing    <===========
Epoch: [1990][0/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0432 (0.0432)	
0.9999913 1.316178e-06
Epoch: [1990][100/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0306 (0.0588)	
0.9999913 1.6074141e-06
Epoch: [1990][200/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0910 (0.0594)	
0.99999213 1.3987384e-06
loss:  0.03975175952525767 0.038285376973611895
===========>   training    <===========
Epoch: [1991][0/23]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0369 (0.0369)	
0.99998665 9.093387e-07
===========>   testing    <===========
Epoch: [1991][0/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0461 (0.0461)	
0.9999912 1.3051447e-06
Epoch: [1991][100/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0266 (0.0589)	
0.9999914 1.6005245e-06
Epoch: [1991][200/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0960 (0.0592)	
0.999992 1.391316e-06
loss:  0.039869271083930125 0.038285376973611895
===========>   training    <===========
Epoch: [1992][0/23]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0322 (0.0322)	
0.99998593 1.6403199e-06
===========>   testing    <===========
Epoch: [1992][0/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0445 (0.0445)	
0.99999154 1.3646985e-06
Epoch: [1992][100/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0283 (0.0593)	
0.999992 1.7529635e-06
Epoch: [1992][200/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0875 (0.0590)	
0.99999285 1.5201153e-06
loss:  0.03957839849030409 0.038285376973611895
===========>   training    <===========
Epoch: [1993][0/23]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0360 (0.0360)	
0.999997 1.9851611e-06
===========>   testing    <===========
Epoch: [1993][0/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0425 (0.0425)	
0.99999106 1.301133e-06
Epoch: [1993][100/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0277 (0.0587)	
0.99999106 1.5815988e-06
Epoch: [1993][200/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0865 (0.0589)	
0.99999213 1.3546362e-06
loss:  0.03966399434093926 0.038285376973611895
===========>   training    <===========
Epoch: [1994][0/23]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0352 (0.0352)	
0.9999908 1.5377949e-06
===========>   testing    <===========
Epoch: [1994][0/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0450 (0.0450)	
0.99999213 1.4013392e-06
Epoch: [1994][100/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0323 (0.0588)	
0.9999924 1.757582e-06
Epoch: [1994][200/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0838 (0.0585)	
0.9999932 1.5238719e-06
loss:  0.03927924807351779 0.038285376973611895
===========>   training    <===========
Epoch: [1995][0/23]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0395 (0.0395)	
0.9999925 1.827692e-06
===========>   testing    <===========
Epoch: [1995][0/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0413 (0.0413)	
0.9999925 1.5149429e-06
Epoch: [1995][100/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0284 (0.0586)	
0.9999932 1.9595727e-06
Epoch: [1995][200/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0914 (0.0587)	
0.9999938 1.6699594e-06
loss:  0.03921062673687459 0.038285376973611895
===========>   training    <===========
Epoch: [1996][0/23]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0378 (0.0378)	
0.9999908 1.1101803e-06
===========>   testing    <===========
Epoch: [1996][0/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0393 (0.0393)	
0.99999213 1.3715392e-06
Epoch: [1996][100/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0281 (0.0583)	
0.999992 1.6854664e-06
Epoch: [1996][200/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0903 (0.0586)	
0.9999924 1.4691961e-06
loss:  0.03940802583366709 0.038285376973611895
===========>   training    <===========
Epoch: [1997][0/23]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0284 (0.0284)	
0.9999906 1.4244446e-06
===========>   testing    <===========
Epoch: [1997][0/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0422 (0.0422)	
0.99999213 1.4490845e-06
Epoch: [1997][100/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0341 (0.0582)	
0.9999925 1.7845858e-06
Epoch: [1997][200/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0821 (0.0583)	
0.9999933 1.5703866e-06
loss:  0.039337181918018604 0.038285376973611895
===========>   training    <===========
Epoch: [1998][0/23]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0301 (0.0301)	
0.9999893 1.5312256e-06
===========>   testing    <===========
Epoch: [1998][0/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0432 (0.0432)	
0.9999913 1.2761142e-06
Epoch: [1998][100/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0301 (0.0581)	
0.9999906 1.5587409e-06
Epoch: [1998][200/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0868 (0.0585)	
0.9999918 1.3375296e-06
loss:  0.039577660931990444 0.038285376973611895
===========>   training    <===========
Epoch: [1999][0/23]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0331 (0.0331)	
0.99998677 1.607299e-06
===========>   testing    <===========
Epoch: [1999][0/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0494 (0.0494)	
0.99999034 1.2183215e-06
Epoch: [1999][100/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0289 (0.0586)	
0.99999034 1.4957235e-06
Epoch: [1999][200/289]	Lr-deconv: [0.0]	Lr-other: [6.2321360214042085e-06]	Loss 0.0815 (0.0587)	
0.9999913 1.2669987e-06
loss:  0.039628106450191436 0.038285376973611895
