2022-12-04 14:56:01.043463: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-04 14:56:01.192820: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2022-12-04 14:56:01.776800: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/zhanchao/anaconda3/envs/portraitnet/lib/python3.8/site-packages/cv2/../../lib64:/usr/local/cuda-11.1/lib64
2022-12-04 14:56:01.776889: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/zhanchao/anaconda3/envs/portraitnet/lib/python3.8/site-packages/cv2/../../lib64:/usr/local/cuda-11.1/lib64
2022-12-04 14:56:01.776902: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2022-12-04 14:56:02.381895: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/zhanchao/anaconda3/envs/portraitnet/lib/python3.8/site-packages/cv2/../../lib64:/usr/local/cuda-11.1/lib64
2022-12-04 14:56:02.381943: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2022-12-04 14:56:02.382280: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
===========> loading config <============
config path:  /home/zhanchao/github/cv_assignment3/config/model_mobilenetv2_without_auxiliary_losses.yaml
b"data_root: /data/zhanchao/ #\xe9\x9c\x80\xe8\xa6\x81\xe8\xbf\x9b\xe8\xa1\x8c\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84dataset root\xe5\x9c\xb0\xe5\x9d\x80\nfile_root: /home/zhanchao/github/cv_assignment3/data/select_data/\nmodel_root: /home/zhanchao/github/cv_assignment3/myexp/mobilenetv2_eg1800/single_224_single_gpu_2/\n\nistrain: True\ntask: 'seg'\ndatasetlist: ['EG1800'] # 'support: [EG1800, supervisely_face_easy, ATR, MscocoBackground]'\n# datasetlist: ['supervisely_face_easy'] # 'support: [EG1800, supervisely_face_easy, ATR, MscocoBackground]'\n\ninput_height: 224 # the height of input images\ninput_width: 224 # the width of input images\n\nvideo: False # if exp_args.video=True, add prior channel for input images\nprior_prob: 0.5 # the probability to set empty prior channel\n\naddEdge: False # whether to add boundary auxiliary loss \nedgeRatio: 0.1 # the weight of boundary auxiliary loss\nstability: False # whether to add consistency constraint loss\nuse_kl: True # whether to use KL loss in consistency constraint loss\ntemperature: 1 # temperature in consistency constraint loss\nalpha: 2 # the weight of consistency constraint loss\n\n# input normalization parameters\npadding_color: 128\nimg_scale: 1\nimg_mean: [103.94, 116.78, 123.68] # BGR order, image mean\nimg_val: [0.017, 0.017, 0.017] # BGR order, image val\n\ninit: True # whether to use pretian model to init portraitnet\nresume: False # whether to continue training\n\nuseUpsample: False # if exp_args.useUpsample==True, use nn.Upsample in decoder, else use nn.ConvTranspose2d\nuseDeconvGroup: False # if exp_args.useDeconvGroup==True, set groups=input_channel in nn.ConvTranspose2d\n\n\n"
===========> loading data <===========
image number in training:  1447
image number in testing:  289
finish load dataset ...
===========> loading model <===========
finish load PortraitNet ...
pretrain keys:  260
netmodel keys:  468
init model stage0.0.weight from pretrained stage0.0.weight
init model stage0.1.weight from pretrained stage0.1.weight
init model stage0.1.bias from pretrained stage0.1.bias
init model stage0.1.running_mean from pretrained stage0.1.running_mean
init model stage0.1.running_var from pretrained stage0.1.running_var
init len is: 5
load model init finish...
===========>   training    <===========
/home/zhanchao/github/cv_assignment3/myTrain/../model/model_mobilenetv2_seg_small.py:257: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.
  nn.init.kaiming_normal(m.weight.data)
Epoch: [0][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.8402 (0.8402)	
0.9964683 0.0004231544
===========>   testing    <===========
Epoch: [0][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.6851 (0.6851)	
0.76789457 0.08454264
Epoch: [0][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.7078 (0.6871)	
0.778958 0.0804825
Epoch: [0][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.6885 (0.6872)	
0.88736826 0.0823615
loss:  0.578698428465119 10000
===========>   training    <===========
Epoch: [1][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.6935 (0.6935)	
0.8956591 0.01816157
===========>   testing    <===========
Epoch: [1][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.6339 (0.6339)	
0.8114755 0.023831911
Epoch: [1][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.6368 (0.6736)	
0.8223478 0.025624508
Epoch: [1][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.7267 (0.6760)	
0.8689854 0.026079403
loss:  0.7346541074300814 0.578698428465119
===========>   training    <===========
Epoch: [2][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.5484 (0.5484)	
0.8968701 0.009750274
===========>   testing    <===========
Epoch: [2][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.4447 (0.4447)	
0.9513573 0.005784638
Epoch: [2][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.6332 (0.4305)	
0.95024395 0.0050802953
Epoch: [2][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.4431 (0.4266)	
0.9649044 0.006839115
loss:  0.3957049238552407 0.578698428465119
===========>   training    <===========
Epoch: [3][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3822 (0.3822)	
0.97300637 0.0050542043
===========>   testing    <===========
Epoch: [3][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3347 (0.3347)	
0.9805623 0.0005963865
Epoch: [3][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.4771 (0.3334)	
0.95303476 0.00038630195
Epoch: [3][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2809 (0.3383)	
0.9809249 0.0005985795
loss:  0.25812368904174343 0.3957049238552407
===========>   training    <===========
Epoch: [4][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2982 (0.2982)	
0.97615075 0.0004939683
===========>   testing    <===========
Epoch: [4][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.4077 (0.4077)	
0.978637 0.0014221206
Epoch: [4][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3873 (0.3273)	
0.94542706 0.0015592345
Epoch: [4][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3267 (0.3272)	
0.97747886 0.0011952166
loss:  0.2590224035735337 0.25812368904174343
===========>   training    <===========
Epoch: [5][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3340 (0.3340)	
0.9768386 0.00044930752
===========>   testing    <===========
Epoch: [5][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3716 (0.3716)	
0.98235345 0.00087156997
Epoch: [5][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.6280 (0.3175)	
0.9717881 0.0026061274
Epoch: [5][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2705 (0.3209)	
0.9827192 0.0008965109
loss:  0.24979162919418085 0.25812368904174343
===========>   training    <===========
Epoch: [6][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3190 (0.3190)	
0.98553574 0.00057639193
===========>   testing    <===========
Epoch: [6][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3306 (0.3306)	
0.99048764 0.00091405824
Epoch: [6][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.6709 (0.3190)	
0.98509765 0.0010328641
Epoch: [6][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2670 (0.3284)	
0.9902366 0.0010825399
loss:  0.23909647542263568 0.24979162919418085
===========>   training    <===========
Epoch: [7][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2928 (0.2928)	
0.9894721 0.0004814735
===========>   testing    <===========
Epoch: [7][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2947 (0.2947)	
0.9883603 0.0010445333
Epoch: [7][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.4756 (0.3012)	
0.9617255 0.0017393543
Epoch: [7][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2630 (0.3061)	
0.9868133 0.00077898067
loss:  0.22977840039737207 0.23909647542263568
===========>   training    <===========
Epoch: [8][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2884 (0.2884)	
0.9927884 0.0003024349
===========>   testing    <===========
Epoch: [8][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3021 (0.3021)	
0.98924786 0.0010332229
Epoch: [8][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.5123 (0.3026)	
0.98205316 0.0011713388
Epoch: [8][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2607 (0.3101)	
0.9898662 0.0007834818
loss:  0.2323074516911139 0.22977840039737207
===========>   training    <===========
Epoch: [9][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3061 (0.3061)	
0.9913566 0.0001582825
===========>   testing    <===========
Epoch: [9][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3095 (0.3095)	
0.99164915 0.00027550463
Epoch: [9][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.4750 (0.2836)	
0.98116875 0.00031497685
Epoch: [9][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2749 (0.2817)	
0.99183124 0.0002606266
loss:  0.21518637250261163 0.22977840039737207
===========>   training    <===========
Epoch: [10][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2990 (0.2990)	
0.99246585 0.00023287482
===========>   testing    <===========
Epoch: [10][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3332 (0.3332)	
0.99392843 0.0015686348
Epoch: [10][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.6052 (0.2913)	
0.9882443 0.0017654559
Epoch: [10][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2639 (0.2942)	
0.99342394 0.0014752417
loss:  0.2180575698535817 0.21518637250261163
===========>   training    <===========
Epoch: [11][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2689 (0.2689)	
0.9942334 0.00030591304
===========>   testing    <===========
Epoch: [11][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3556 (0.3556)	
0.9910567 0.00079822703
Epoch: [11][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3579 (0.2868)	
0.97648025 0.0009032178
Epoch: [11][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2697 (0.2811)	
0.9921583 0.00087273633
loss:  0.22230561546879146 0.21518637250261163
===========>   training    <===========
Epoch: [12][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.3046 (0.3046)	
0.99321496 7.614131e-05
===========>   testing    <===========
Epoch: [12][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2695 (0.2695)	
0.99329513 0.00039969652
Epoch: [12][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.6808 (0.2610)	
0.9875875 0.0018242255
Epoch: [12][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2276 (0.2566)	
0.993166 0.00033039018
loss:  0.19596118633702064 0.21518637250261163
===========>   training    <===========
Epoch: [13][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2651 (0.2651)	
0.9931317 0.00010728305
===========>   testing    <===========
Epoch: [13][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2852 (0.2852)	
0.99472636 0.0005449248
Epoch: [13][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.5746 (0.2663)	
0.9786628 0.000676524
Epoch: [13][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2244 (0.2646)	
0.99525684 0.0004262735
loss:  0.20287353486430737 0.19596118633702064
===========>   training    <===========
Epoch: [14][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2389 (0.2389)	
0.99648947 0.0012891049
===========>   testing    <===========
Epoch: [14][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2636 (0.2636)	
0.9932996 0.00035986048
Epoch: [14][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.7957 (0.2639)	
0.99182796 0.00047700878
Epoch: [14][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2102 (0.2626)	
0.99388075 0.00033360842
loss:  0.2013082039440487 0.19596118633702064
===========>   training    <===========
Epoch: [15][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2770 (0.2770)	
0.9934981 0.00010025924
===========>   testing    <===========
Epoch: [15][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2554 (0.2554)	
0.9947478 0.0002956593
Epoch: [15][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.6207 (0.2649)	
0.988196 0.00042945173
Epoch: [15][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.1938 (0.2650)	
0.9948265 0.00022943539
loss:  0.19810810388314815 0.19596118633702064
===========>   training    <===========
Epoch: [16][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2474 (0.2474)	
0.99503785 0.0004918414
===========>   testing    <===========
Epoch: [16][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2222 (0.2222)	
0.9939283 0.00022739063
Epoch: [16][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.5743 (0.2568)	
0.9812228 0.00057713327
Epoch: [16][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2320 (0.2571)	
0.99382967 0.00031022815
loss:  0.19364547633989093 0.19596118633702064
===========>   training    <===========
Epoch: [17][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2179 (0.2179)	
0.9942954 0.000100771744
===========>   testing    <===========
Epoch: [17][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2742 (0.2742)	
0.99486417 7.058089e-05
Epoch: [17][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.4432 (0.2310)	
0.9706336 0.00032379408
Epoch: [17][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2213 (0.2243)	
0.99494535 9.941119e-05
loss:  0.1741620495067785 0.19364547633989093
===========>   training    <===========
Epoch: [18][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2587 (0.2587)	
0.995743 4.6417088e-05
===========>   testing    <===========
Epoch: [18][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2000 (0.2000)	
0.9962794 0.00010694863
Epoch: [18][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.6319 (0.2334)	
0.9847727 0.00021530283
Epoch: [18][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2237 (0.2302)	
0.99600405 0.00015606033
loss:  0.1814745119843445 0.1741620495067785
===========>   training    <===========
Epoch: [19][0/23]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2396 (0.2396)	
0.9960628 5.771998e-05
===========>   testing    <===========
Epoch: [19][0/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2691 (0.2691)	
0.99492234 0.00011363027
Epoch: [19][100/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.6126 (0.2269)	
0.9822227 0.00016284864
Epoch: [19][200/289]	Lr-deconv: [0.0]	Lr-other: [0.001]	Loss 0.2058 (0.2220)	
0.9947625 7.2834606e-05
loss:  0.168855201058566 0.1741620495067785
===========>   training    <===========
Epoch: [20][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2523 (0.2523)	
0.99568117 1.40326665e-05
===========>   testing    <===========
Epoch: [20][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.3002 (0.3002)	
0.99601585 0.00014269368
Epoch: [20][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.5522 (0.2285)	
0.9825608 0.00017943863
Epoch: [20][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1730 (0.2248)	
0.9960551 9.23223e-05
loss:  0.17238011458466496 0.168855201058566
===========>   training    <===========
Epoch: [21][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2515 (0.2515)	
0.99529195 2.817708e-05
===========>   testing    <===========
Epoch: [21][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.3779 (0.3779)	
0.9961964 2.1582493e-05
Epoch: [21][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.4452 (0.2669)	
0.97077686 5.68011e-05
Epoch: [21][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.3240 (0.2528)	
0.99363774 1.3549951e-05
loss:  0.21230069912082195 0.168855201058566
===========>   training    <===========
Epoch: [22][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2349 (0.2349)	
0.99644864 5.1310864e-05
===========>   testing    <===========
Epoch: [22][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2249 (0.2249)	
0.9971359 4.7259655e-05
Epoch: [22][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.7108 (0.2271)	
0.99219877 0.00014096344
Epoch: [22][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1735 (0.2203)	
0.9974511 3.4928096e-05
loss:  0.1693983565620757 0.168855201058566
===========>   training    <===========
Epoch: [23][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2206 (0.2206)	
0.99648356 3.971214e-05
===========>   testing    <===========
Epoch: [23][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2091 (0.2091)	
0.99658066 7.304592e-05
Epoch: [23][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.4404 (0.2061)	
0.9791428 0.000110072884
Epoch: [23][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1832 (0.2034)	
0.9967908 2.4687968e-05
loss:  0.1592919946376251 0.168855201058566
===========>   training    <===========
Epoch: [24][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2152 (0.2152)	
0.9967691 0.0001875703
===========>   testing    <===========
Epoch: [24][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1943 (0.1943)	
0.9974221 4.9499722e-05
Epoch: [24][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.4152 (0.2019)	
0.9667517 5.1902007e-05
Epoch: [24][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1954 (0.1958)	
0.99754936 2.98117e-05
loss:  0.14777306022683745 0.1592919946376251
===========>   training    <===========
Epoch: [25][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2290 (0.2290)	
0.99772626 9.675139e-06
===========>   testing    <===========
Epoch: [25][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1843 (0.1843)	
0.99614894 0.00011477742
Epoch: [25][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.3727 (0.1938)	
0.9861813 0.0001862769
Epoch: [25][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1846 (0.1868)	
0.99632484 7.07777e-05
loss:  0.14619025241306527 0.14777306022683745
===========>   training    <===========
Epoch: [26][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2021 (0.2021)	
0.996888 0.0002144728
===========>   testing    <===========
Epoch: [26][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2496 (0.2496)	
0.997141 0.00017329016
Epoch: [26][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.7764 (0.2226)	
0.9944759 0.00022270472
Epoch: [26][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2088 (0.2188)	
0.99726856 8.590254e-05
loss:  0.17204513356660345 0.14619025241306527
===========>   training    <===========
Epoch: [27][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2151 (0.2151)	
0.9979614 0.00017136699
===========>   testing    <===========
Epoch: [27][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1756 (0.1756)	
0.997224 3.9898445e-05
Epoch: [27][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2550 (0.2068)	
0.9596397 0.00010218219
Epoch: [27][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2154 (0.1988)	
0.99724174 7.356025e-05
loss:  0.1560611534047237 0.14619025241306527
===========>   training    <===========
Epoch: [28][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2130 (0.2130)	
0.99687356 6.7425506e-05
===========>   testing    <===========
Epoch: [28][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1710 (0.1710)	
0.9964857 6.446637e-05
Epoch: [28][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.5178 (0.2068)	
0.98937607 0.00023394347
Epoch: [28][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1945 (0.2099)	
0.99694073 6.285719e-05
loss:  0.15881235958732887 0.14619025241306527
===========>   training    <===========
Epoch: [29][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2006 (0.2006)	
0.99706584 2.16992e-06
===========>   testing    <===========
Epoch: [29][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1945 (0.1945)	
0.9974299 5.389059e-05
Epoch: [29][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2341 (0.1844)	
0.98857087 0.0001732026
Epoch: [29][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1313 (0.1809)	
0.99738246 3.1708794e-05
loss:  0.139845043190704 0.14619025241306527
===========>   training    <===========
Epoch: [30][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1919 (0.1919)	
0.99755645 2.0299678e-06
===========>   testing    <===========
Epoch: [30][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1959 (0.1959)	
0.9968845 5.9729315e-05
Epoch: [30][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2969 (0.1814)	
0.9939501 0.00017346523
Epoch: [30][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1726 (0.1778)	
0.99686205 3.5470126e-05
loss:  0.13313816729881112 0.139845043190704
===========>   training    <===========
Epoch: [31][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2245 (0.2245)	
0.99703985 8.558824e-06
===========>   testing    <===========
Epoch: [31][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1681 (0.1681)	
0.99818665 8.570682e-05
Epoch: [31][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.4450 (0.1967)	
0.9962442 0.00013420689
Epoch: [31][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1695 (0.1983)	
0.99822456 5.0904244e-05
loss:  0.15282674876097513 0.13313816729881112
===========>   training    <===========
Epoch: [32][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1753 (0.1753)	
0.99857724 4.715588e-05
===========>   testing    <===========
Epoch: [32][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1637 (0.1637)	
0.9978047 0.00021248784
Epoch: [32][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2395 (0.1898)	
0.992957 0.0003115551
Epoch: [32][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1735 (0.1863)	
0.9977858 0.00011419793
loss:  0.14098028750365232 0.13313816729881112
===========>   training    <===========
Epoch: [33][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1311 (0.1311)	
0.9978072 9.9332565e-06
===========>   testing    <===========
Epoch: [33][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2275 (0.2275)	
0.998212 6.1501574e-05
Epoch: [33][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2117 (0.1768)	
0.9908806 8.103971e-05
Epoch: [33][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1728 (0.1721)	
0.9983058 3.6422327e-05
loss:  0.1349482335421126 0.13313816729881112
===========>   training    <===========
Epoch: [34][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1562 (0.1562)	
0.99873346 2.8893214e-06
===========>   testing    <===========
Epoch: [34][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1451 (0.1451)	
0.99830747 0.00018409641
Epoch: [34][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2798 (0.1609)	
0.995436 0.0001615301
Epoch: [34][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1508 (0.1641)	
0.99850935 7.322781e-05
loss:  0.12314865749668191 0.13313816729881112
===========>   training    <===========
Epoch: [35][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1761 (0.1761)	
0.99883837 9.450422e-06
===========>   testing    <===========
Epoch: [35][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1592 (0.1592)	
0.9981951 3.137563e-05
Epoch: [35][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2689 (0.1688)	
0.99710745 6.43223e-05
Epoch: [35][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1278 (0.1734)	
0.9981963 2.3334505e-05
loss:  0.1338049069906575 0.12314865749668191
===========>   training    <===========
Epoch: [36][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1509 (0.1509)	
0.99860066 1.0896194e-06
===========>   testing    <===========
Epoch: [36][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2014 (0.2014)	
0.9977533 2.7394255e-05
Epoch: [36][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1380 (0.1629)	
0.9969289 0.0001366496
Epoch: [36][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1461 (0.1602)	
0.9978891 1.5169022e-05
loss:  0.1270851838697763 0.12314865749668191
===========>   training    <===========
Epoch: [37][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1947 (0.1947)	
0.99837863 2.1673293e-07
===========>   testing    <===========
Epoch: [37][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1325 (0.1325)	
0.998589 8.410873e-05
Epoch: [37][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2747 (0.1554)	
0.9963581 9.2511335e-05
Epoch: [37][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1265 (0.1541)	
0.9986726 3.864382e-05
loss:  0.1199645986670429 0.12314865749668191
===========>   training    <===========
Epoch: [38][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1501 (0.1501)	
0.99893564 2.4332152e-05
===========>   testing    <===========
Epoch: [38][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2673 (0.2673)	
0.9982968 0.00010272724
Epoch: [38][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.5262 (0.1840)	
0.99346477 0.00011496976
Epoch: [38][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1179 (0.1833)	
0.9983261 7.003453e-05
loss:  0.14163923292827274 0.1199645986670429
===========>   training    <===========
Epoch: [39][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.2146 (0.2146)	
0.9985708 0.0006126536
===========>   testing    <===========
Epoch: [39][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1903 (0.1903)	
0.9983292 3.2229873e-05
Epoch: [39][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1662 (0.1573)	
0.99659234 3.7426566e-05
Epoch: [39][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00095]	Loss 0.1529 (0.1555)	
0.9984693 1.9245696e-05
loss:  0.12107479205841265 0.1199645986670429
===========>   training    <===========
Epoch: [40][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1502 (0.1502)	
0.99861157 6.165575e-06
===========>   testing    <===========
Epoch: [40][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1297 (0.1297)	
0.99894243 6.955771e-05
Epoch: [40][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.2683 (0.1632)	
0.99802256 0.00012411561
Epoch: [40][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1625 (0.1586)	
0.9989176 6.678986e-05
loss:  0.12172480695560528 0.1199645986670429
===========>   training    <===========
Epoch: [41][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1660 (0.1660)	
0.99934715 2.231058e-05
===========>   testing    <===========
Epoch: [41][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1492 (0.1492)	
0.9986582 2.9430581e-05
Epoch: [41][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.2799 (0.1503)	
0.97632766 9.5899544e-05
Epoch: [41][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1200 (0.1456)	
0.9986534 1.8534438e-05
loss:  0.11539587435743082 0.1199645986670429
===========>   training    <===========
Epoch: [42][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1695 (0.1695)	
0.9990772 4.023693e-06
===========>   testing    <===========
Epoch: [42][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1565 (0.1565)	
0.9988207 2.6071873e-05
Epoch: [42][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.2587 (0.1479)	
0.99552506 5.860311e-05
Epoch: [42][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1365 (0.1457)	
0.99870694 1.3232915e-05
loss:  0.11349649605324641 0.11539587435743082
===========>   training    <===========
Epoch: [43][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1485 (0.1485)	
0.9989982 3.9973665e-06
===========>   testing    <===========
Epoch: [43][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1388 (0.1388)	
0.998912 4.9535796e-05
Epoch: [43][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.2643 (0.1467)	
0.9971576 7.551986e-05
Epoch: [43][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1270 (0.1427)	
0.99892396 2.8655943e-05
loss:  0.11022704900126745 0.11349649605324641
===========>   training    <===========
Epoch: [44][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1230 (0.1230)	
0.99916625 1.5733676e-05
===========>   testing    <===========
Epoch: [44][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1761 (0.1761)	
0.99874425 1.3180974e-05
Epoch: [44][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1391 (0.1414)	
0.9978058 3.140233e-05
Epoch: [44][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1355 (0.1401)	
0.99880946 2.2493301e-05
loss:  0.10723241935123184 0.11022704900126745
===========>   training    <===========
Epoch: [45][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1331 (0.1331)	
0.99881893 0.0001374031
===========>   testing    <===========
Epoch: [45][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1678 (0.1678)	
0.9989423 1.9225168e-05
Epoch: [45][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.2032 (0.1526)	
0.99596393 7.696886e-05
Epoch: [45][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.0866 (0.1478)	
0.9989353 2.7799886e-05
loss:  0.12063022449538574 0.10723241935123184
===========>   training    <===========
Epoch: [46][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1691 (0.1691)	
0.9990877 1.4986682e-05
===========>   testing    <===========
Epoch: [46][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1428 (0.1428)	
0.9989505 3.678146e-05
Epoch: [46][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.2020 (0.1352)	
0.9952036 0.00014182537
Epoch: [46][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1086 (0.1316)	
0.9990722 4.0042225e-05
loss:  0.10630336569177556 0.10723241935123184
===========>   training    <===========
Epoch: [47][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1468 (0.1468)	
0.99900216 0.00030714573
===========>   testing    <===========
Epoch: [47][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1466 (0.1466)	
0.99903107 4.627967e-05
Epoch: [47][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1597 (0.1414)	
0.99529356 0.00015426481
Epoch: [47][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1559 (0.1538)	
0.99902403 4.09142e-05
loss:  0.1156181348668407 0.10630336569177556
===========>   training    <===========
Epoch: [48][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1790 (0.1790)	
0.9991049 4.5086326e-06
===========>   testing    <===========
Epoch: [48][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1203 (0.1203)	
0.99920434 4.1419564e-05
Epoch: [48][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1046 (0.1304)	
0.9976866 7.061388e-05
Epoch: [48][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1516 (0.1329)	
0.99923646 2.5110454e-05
loss:  0.10359404099071345 0.10630336569177556
===========>   training    <===========
Epoch: [49][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1992 (0.1992)	
0.9992587 8.563527e-06
===========>   testing    <===========
Epoch: [49][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1659 (0.1659)	
0.99897516 9.130692e-06
Epoch: [49][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1485 (0.1317)	
0.99257904 1.4998062e-05
Epoch: [49][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1162 (0.1374)	
0.999141 6.1733185e-06
loss:  0.10456781208610655 0.10359404099071345
===========>   training    <===========
Epoch: [50][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1197 (0.1197)	
0.99890065 1.532786e-05
===========>   testing    <===========
Epoch: [50][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1523 (0.1523)	
0.99910754 2.5706307e-05
Epoch: [50][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.0924 (0.1213)	
0.99819165 4.958405e-05
Epoch: [50][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1169 (0.1210)	
0.9992003 1.8807874e-05
loss:  0.09309072817048158 0.10359404099071345
===========>   training    <===========
Epoch: [51][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1213 (0.1213)	
0.9993787 3.1245413e-06
===========>   testing    <===========
Epoch: [51][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1266 (0.1266)	
0.999233 2.0688525e-05
Epoch: [51][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1246 (0.1221)	
0.9977235 2.0199192e-05
Epoch: [51][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1107 (0.1228)	
0.9992112 1.2667035e-05
loss:  0.09589849645484816 0.09309072817048158
===========>   training    <===========
Epoch: [52][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1586 (0.1586)	
0.9985019 9.750425e-06
===========>   testing    <===========
Epoch: [52][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1163 (0.1163)	
0.9992079 2.489011e-05
Epoch: [52][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.2284 (0.1228)	
0.99778014 2.7128146e-05
Epoch: [52][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1351 (0.1215)	
0.9992268 2.416413e-05
loss:  0.09558536411079321 0.09309072817048158
===========>   training    <===========
Epoch: [53][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1476 (0.1476)	
0.9989241 1.6561768e-05
===========>   testing    <===========
Epoch: [53][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1156 (0.1156)	
0.999175 2.7077229e-05
Epoch: [53][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1449 (0.1345)	
0.9983941 3.3776243e-05
Epoch: [53][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1306 (0.1342)	
0.99923563 1.9635534e-05
loss:  0.1049988613854621 0.09309072817048158
===========>   training    <===========
Epoch: [54][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1322 (0.1322)	
0.99912685 8.227696e-06
===========>   testing    <===========
Epoch: [54][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1643 (0.1643)	
0.9992986 9.628903e-06
Epoch: [54][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1221 (0.1219)	
0.99543095 1.1281727e-05
Epoch: [54][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1001 (0.1204)	
0.99937785 6.437699e-06
loss:  0.09683203910893656 0.09309072817048158
===========>   training    <===========
Epoch: [55][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1509 (0.1509)	
0.9994254 8.61129e-06
===========>   testing    <===========
Epoch: [55][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1895 (0.1895)	
0.99942255 7.809316e-06
Epoch: [55][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.2984 (0.1298)	
0.9978599 9.983685e-06
Epoch: [55][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.0955 (0.1239)	
0.99946064 7.285116e-06
loss:  0.09912070541806206 0.09309072817048158
===========>   training    <===========
Epoch: [56][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1362 (0.1362)	
0.99935144 2.4342897e-05
===========>   testing    <===========
Epoch: [56][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1557 (0.1557)	
0.9992811 4.831633e-06
Epoch: [56][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.0871 (0.1265)	
0.99569243 5.109941e-06
Epoch: [56][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1473 (0.1266)	
0.999199 2.8924146e-06
loss:  0.09955307032976157 0.09309072817048158
===========>   training    <===========
Epoch: [57][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1273 (0.1273)	
0.9994752 0.00015598325
===========>   testing    <===========
Epoch: [57][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.2141 (0.2141)	
0.99934345 6.782799e-05
Epoch: [57][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.2707 (0.1229)	
0.9988896 4.840511e-05
Epoch: [57][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1403 (0.1257)	
0.99935764 4.9263508e-05
loss:  0.09987040004826842 0.09309072817048158
===========>   training    <===========
Epoch: [58][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1531 (0.1531)	
0.99950993 1.8358924e-05
===========>   testing    <===========
Epoch: [58][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1412 (0.1412)	
0.99926096 2.5903475e-05
Epoch: [58][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.2407 (0.1301)	
0.9982451 1.231228e-05
Epoch: [58][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.2466 (0.1313)	
0.99935514 1.0540714e-05
loss:  0.10070353733054915 0.09309072817048158
===========>   training    <===========
Epoch: [59][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1357 (0.1357)	
0.9995401 1.2235902e-05
===========>   testing    <===========
Epoch: [59][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1942 (0.1942)	
0.99928266 1.0640541e-05
Epoch: [59][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.2397 (0.1244)	
0.9983772 3.6818452e-05
Epoch: [59][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0009025]	Loss 0.1064 (0.1249)	
0.99932945 1.9606981e-05
loss:  0.09604808726008451 0.09309072817048158
===========>   training    <===========
Epoch: [60][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1227 (0.1227)	
0.99933547 1.1660875e-05
===========>   testing    <===========
Epoch: [60][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.3584 (0.3584)	
0.99932754 6.0331193e-05
Epoch: [60][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1546 (0.1331)	
0.99897003 0.00022565527
Epoch: [60][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1851 (0.1350)	
0.9994041 0.000114875635
loss:  0.10332389095833983 0.09309072817048158
===========>   training    <===========
Epoch: [61][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1338 (0.1338)	
0.9994856 1.5701838e-05
===========>   testing    <===========
Epoch: [61][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1095 (0.1095)	
0.999546 3.3814234e-05
Epoch: [61][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1660 (0.1090)	
0.9970599 5.0358463e-05
Epoch: [61][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1201 (0.1121)	
0.99955803 3.2519933e-05
loss:  0.08719410641832903 0.09309072817048158
===========>   training    <===========
Epoch: [62][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1268 (0.1268)	
0.99977416 5.3681884e-05
===========>   testing    <===========
Epoch: [62][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1251 (0.1251)	
0.9995516 1.718736e-05
Epoch: [62][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.2118 (0.1158)	
0.9989791 3.1029038e-05
Epoch: [62][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1007 (0.1141)	
0.99955493 2.2081824e-05
loss:  0.090653184009446 0.08719410641832903
===========>   training    <===========
Epoch: [63][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1478 (0.1478)	
0.99968195 2.8017224e-05
===========>   testing    <===========
Epoch: [63][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1034 (0.1034)	
0.9994165 2.762185e-05
Epoch: [63][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.2394 (0.1100)	
0.99842995 4.7651734e-05
Epoch: [63][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1099 (0.1061)	
0.99945205 2.461835e-05
loss:  0.08380331332919932 0.08719410641832903
===========>   training    <===========
Epoch: [64][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1027 (0.1027)	
0.9994566 0.00015181545
===========>   testing    <===========
Epoch: [64][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1386 (0.1386)	
0.99931705 3.280569e-05
Epoch: [64][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.2159 (0.1225)	
0.99701273 4.4353677e-05
Epoch: [64][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1186 (0.1219)	
0.9993838 3.7459242e-05
loss:  0.09540639188120725 0.08380331332919932
===========>   training    <===========
Epoch: [65][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1159 (0.1159)	
0.9994972 1.0694108e-06
===========>   testing    <===========
Epoch: [65][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1143 (0.1143)	
0.99956745 4.0504863e-05
Epoch: [65][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1927 (0.1112)	
0.9991968 2.3829902e-05
Epoch: [65][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1427 (0.1107)	
0.9996056 3.1144926e-05
loss:  0.0886963677085213 0.08380331332919932
===========>   training    <===========
Epoch: [66][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1445 (0.1445)	
0.9995221 4.4961558e-05
===========>   testing    <===========
Epoch: [66][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1114 (0.1114)	
0.9995499 2.0647865e-05
Epoch: [66][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.2369 (0.1236)	
0.99920315 4.3949858e-05
Epoch: [66][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1087 (0.1185)	
0.9995807 2.6375244e-05
loss:  0.0930653237264949 0.08380331332919932
===========>   training    <===========
Epoch: [67][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1362 (0.1362)	
0.9996207 1.10788305e-05
===========>   testing    <===========
Epoch: [67][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1078 (0.1078)	
0.99954337 3.189391e-05
Epoch: [67][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.2090 (0.1060)	
0.9992318 4.819503e-05
Epoch: [67][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.0748 (0.1105)	
0.99955004 3.1246847e-05
loss:  0.08802917287421541 0.08380331332919932
===========>   training    <===========
Epoch: [68][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1442 (0.1442)	
0.9994855 4.5467885e-05
===========>   testing    <===========
Epoch: [68][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1444 (0.1444)	
0.99950194 2.833066e-05
Epoch: [68][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.0852 (0.1201)	
0.9989448 5.8071608e-05
Epoch: [68][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1979 (0.1207)	
0.9994941 2.5041676e-05
loss:  0.0936849464062195 0.08380331332919932
===========>   training    <===========
Epoch: [69][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1060 (0.1060)	
0.9994313 4.6560253e-06
===========>   testing    <===========
Epoch: [69][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1460 (0.1460)	
0.99959666 2.046664e-05
Epoch: [69][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1078 (0.1513)	
0.9992455 5.4367185e-05
Epoch: [69][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1636 (0.1534)	
0.9995759 2.2535643e-05
loss:  0.11456281584949013 0.08380331332919932
===========>   training    <===========
Epoch: [70][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1243 (0.1243)	
0.9995454 5.7630496e-05
===========>   testing    <===========
Epoch: [70][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1106 (0.1106)	
0.99962616 1.1535964e-05
Epoch: [70][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1803 (0.1061)	
0.99880314 4.9178732e-05
Epoch: [70][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.0953 (0.1023)	
0.99966407 1.0863596e-05
loss:  0.08137825868983439 0.08380331332919932
===========>   training    <===========
Epoch: [71][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1229 (0.1229)	
0.9997743 6.2412523e-06
===========>   testing    <===========
Epoch: [71][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1278 (0.1278)	
0.999572 1.6014868e-05
Epoch: [71][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.0712 (0.1223)	
0.9992612 2.2062355e-05
Epoch: [71][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1057 (0.1174)	
0.99965036 1.1190368e-05
loss:  0.08968412435338591 0.08137825868983439
===========>   training    <===========
Epoch: [72][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1373 (0.1373)	
0.99966276 3.8432895e-06
===========>   testing    <===========
Epoch: [72][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1383 (0.1383)	
0.99960214 1.0416602e-05
Epoch: [72][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1807 (0.1307)	
0.9985512 9.461036e-06
Epoch: [72][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.0861 (0.1187)	
0.9996306 1.5139121e-05
loss:  0.09346441325981758 0.08137825868983439
===========>   training    <===========
Epoch: [73][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.0959 (0.0959)	
0.9997037 1.3867724e-06
===========>   testing    <===========
Epoch: [73][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1266 (0.1266)	
0.9995053 9.738762e-06
Epoch: [73][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.2076 (0.1103)	
0.99905604 1.8740591e-05
Epoch: [73][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.0723 (0.1080)	
0.99961334 1.7637543e-05
loss:  0.08850195190029886 0.08137825868983439
===========>   training    <===========
Epoch: [74][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1203 (0.1203)	
0.9997154 9.4698655e-05
===========>   testing    <===========
Epoch: [74][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1112 (0.1112)	
0.9994966 1.3320978e-05
Epoch: [74][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.0740 (0.1018)	
0.99894506 1.5692556e-05
Epoch: [74][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.0982 (0.1002)	
0.9996088 1.1067595e-05
loss:  0.07787435007856103 0.08137825868983439
===========>   training    <===========
Epoch: [75][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1104 (0.1104)	
0.9997925 3.3719384e-06
===========>   testing    <===========
Epoch: [75][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.2188 (0.2188)	
0.9996582 2.0512522e-05
Epoch: [75][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1277 (0.1129)	
0.99919516 1.2877679e-05
Epoch: [75][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1068 (0.1110)	
0.9997086 1.1342064e-05
loss:  0.08833516124043816 0.07787435007856103
===========>   training    <===========
Epoch: [76][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1318 (0.1318)	
0.99956065 6.004033e-06
===========>   testing    <===========
Epoch: [76][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.2066 (0.2066)	
0.99960166 0.00010637621
Epoch: [76][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.2105 (0.1140)	
0.9990509 2.4618726e-05
Epoch: [76][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1529 (0.1161)	
0.9996018 4.1823423e-05
loss:  0.09024456463371078 0.07787435007856103
===========>   training    <===========
Epoch: [77][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1058 (0.1058)	
0.99963176 1.3556935e-06
===========>   testing    <===========
Epoch: [77][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1169 (0.1169)	
0.999684 1.9872046e-05
Epoch: [77][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.0969 (0.1089)	
0.99928504 1.587755e-05
Epoch: [77][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1876 (0.1038)	
0.99969625 3.499888e-05
loss:  0.08009364804527774 0.07787435007856103
===========>   training    <===========
Epoch: [78][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1270 (0.1270)	
0.9997509 1.08339855e-05
===========>   testing    <===========
Epoch: [78][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1042 (0.1042)	
0.9996215 2.9661993e-05
Epoch: [78][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.0648 (0.1054)	
0.99918026 4.1247193e-05
Epoch: [78][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1516 (0.1013)	
0.9996432 0.00010738899
loss:  0.07959322411559944 0.07787435007856103
===========>   training    <===========
Epoch: [79][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.0989 (0.0989)	
0.9995901 5.5537994e-06
===========>   testing    <===========
Epoch: [79][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1591 (0.1591)	
0.9996531 2.7172164e-05
Epoch: [79][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.3300 (0.1246)	
0.99914134 3.048856e-05
Epoch: [79][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000857375]	Loss 0.1819 (0.1272)	
0.99968743 4.474606e-05
loss:  0.097185212240807 0.07787435007856103
===========>   training    <===========
Epoch: [80][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1120 (0.1120)	
0.9997131 8.599801e-06
===========>   testing    <===========
Epoch: [80][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1537 (0.1537)	
0.99955016 3.3809432e-05
Epoch: [80][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1561 (0.1074)	
0.9992244 7.5398326e-05
Epoch: [80][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1251 (0.1014)	
0.9996044 5.9720485e-05
loss:  0.08189697449680333 0.07787435007856103
===========>   training    <===========
Epoch: [81][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1510 (0.1510)	
0.9996778 6.9859334e-06
===========>   testing    <===========
Epoch: [81][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.2789 (0.2789)	
0.9995524 7.1087397e-06
Epoch: [81][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.2050 (0.0985)	
0.99910045 1.3421881e-05
Epoch: [81][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0947 (0.0935)	
0.9996762 1.4241012e-05
loss:  0.07771362290554229 0.07787435007856103
===========>   training    <===========
Epoch: [82][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0919 (0.0919)	
0.9997913 6.939526e-06
===========>   testing    <===========
Epoch: [82][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1169 (0.1169)	
0.99959046 2.3452387e-05
Epoch: [82][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1351 (0.0997)	
0.9989147 3.597495e-05
Epoch: [82][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0677 (0.0972)	
0.9996032 2.7466953e-05
loss:  0.07875552024563448 0.07771362290554229
===========>   training    <===========
Epoch: [83][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0869 (0.0869)	
0.9997787 1.9119607e-06
===========>   testing    <===========
Epoch: [83][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1518 (0.1518)	
0.99966276 3.5127716e-05
Epoch: [83][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0650 (0.1078)	
0.9990564 6.0518058e-05
Epoch: [83][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1164 (0.1056)	
0.99962866 5.2409763e-05
loss:  0.08236255686822846 0.07771362290554229
===========>   training    <===========
Epoch: [84][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1217 (0.1217)	
0.9997354 5.7113095e-05
===========>   testing    <===========
Epoch: [84][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1132 (0.1132)	
0.999526 1.1707699e-05
Epoch: [84][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1822 (0.0985)	
0.9987847 8.335278e-06
Epoch: [84][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1092 (0.0947)	
0.99956304 1.2484848e-05
loss:  0.07442041126166776 0.07771362290554229
===========>   training    <===========
Epoch: [85][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0999 (0.0999)	
0.99974304 1.5911275e-05
===========>   testing    <===========
Epoch: [85][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1034 (0.1034)	
0.9996803 3.8560105e-05
Epoch: [85][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.2454 (0.0989)	
0.9994066 1.20134055e-05
Epoch: [85][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0803 (0.0976)	
0.9996538 2.084671e-05
loss:  0.07539538108811161 0.07442041126166776
===========>   training    <===========
Epoch: [86][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1100 (0.1100)	
0.99975735 1.2784792e-05
===========>   testing    <===========
Epoch: [86][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1906 (0.1906)	
0.9995491 1.635024e-05
Epoch: [86][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0590 (0.1314)	
0.9993604 3.785458e-05
Epoch: [86][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.2216 (0.1254)	
0.99950135 2.3025232e-05
loss:  0.0909933382763578 0.07442041126166776
===========>   training    <===========
Epoch: [87][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0994 (0.0994)	
0.99968326 5.6307135e-06
===========>   testing    <===========
Epoch: [87][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.2165 (0.2165)	
0.9994425 1.332958e-05
Epoch: [87][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.4987 (0.1109)	
0.9991683 2.1386824e-05
Epoch: [87][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1233 (0.1079)	
0.99954116 1.795336e-05
loss:  0.0828121873930937 0.07442041126166776
===========>   training    <===========
Epoch: [88][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1031 (0.1031)	
0.9993724 5.484722e-06
===========>   testing    <===========
Epoch: [88][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0908 (0.0908)	
0.9995295 1.6608728e-05
Epoch: [88][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1488 (0.0961)	
0.99926704 2.963793e-05
Epoch: [88][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0983 (0.0930)	
0.9995328 3.1551426e-05
loss:  0.07312866383210503 0.07442041126166776
===========>   training    <===========
Epoch: [89][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0857 (0.0857)	
0.9996081 1.6505874e-05
===========>   testing    <===========
Epoch: [89][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0966 (0.0966)	
0.9994973 2.0564306e-05
Epoch: [89][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0675 (0.1027)	
0.99928457 1.515465e-05
Epoch: [89][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1673 (0.1002)	
0.9995431 2.6146048e-05
loss:  0.07730189977689839 0.07312866383210503
===========>   training    <===========
Epoch: [90][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1170 (0.1170)	
0.9995647 5.806164e-05
===========>   testing    <===========
Epoch: [90][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0907 (0.0907)	
0.9996507 2.8134278e-05
Epoch: [90][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0741 (0.0946)	
0.9994081 1.8798764e-05
Epoch: [90][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0750 (0.0915)	
0.9996221 1.3076404e-05
loss:  0.07316639077871134 0.07312866383210503
===========>   training    <===========
Epoch: [91][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0945 (0.0945)	
0.99965954 0.000102806225
===========>   testing    <===========
Epoch: [91][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1135 (0.1135)	
0.9996325 2.4127567e-05
Epoch: [91][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0563 (0.0962)	
0.9992895 2.7973969e-05
Epoch: [91][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0936 (0.0906)	
0.9996057 6.9655175e-06
loss:  0.0712875497155373 0.07312866383210503
===========>   training    <===========
Epoch: [92][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1309 (0.1309)	
0.99969125 1.0996789e-05
===========>   testing    <===========
Epoch: [92][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1233 (0.1233)	
0.9995426 2.9838748e-05
Epoch: [92][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0534 (0.1063)	
0.9982559 2.270981e-05
Epoch: [92][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0958 (0.1027)	
0.99950576 2.0003965e-05
loss:  0.08555742914110032 0.0712875497155373
===========>   training    <===========
Epoch: [93][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0966 (0.0966)	
0.9994696 8.825343e-05
===========>   testing    <===========
Epoch: [93][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0901 (0.0901)	
0.999634 2.3061228e-05
Epoch: [93][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0596 (0.0988)	
0.9991929 3.0665797e-05
Epoch: [93][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1083 (0.0963)	
0.9996468 1.2310261e-05
loss:  0.07448086600555348 0.0712875497155373
===========>   training    <===========
Epoch: [94][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1143 (0.1143)	
0.999476 9.785094e-07
===========>   testing    <===========
Epoch: [94][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1439 (0.1439)	
0.999567 1.8300958e-05
Epoch: [94][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0634 (0.1061)	
0.9989899 1.3790302e-05
Epoch: [94][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1109 (0.1037)	
0.999671 1.4490121e-05
loss:  0.08480544499315479 0.0712875497155373
===========>   training    <===========
Epoch: [95][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1022 (0.1022)	
0.9997904 2.1462809e-05
===========>   testing    <===========
Epoch: [95][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1030 (0.1030)	
0.9996941 2.1350612e-05
Epoch: [95][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0543 (0.1075)	
0.9992681 3.1353196e-05
Epoch: [95][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1363 (0.1059)	
0.9996729 4.10263e-05
loss:  0.07971399667805845 0.0712875497155373
===========>   training    <===========
Epoch: [96][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1036 (0.1036)	
0.9997204 1.7270037e-05
===========>   testing    <===========
Epoch: [96][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1154 (0.1154)	
0.9997749 1.758348e-05
Epoch: [96][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.5078 (0.1125)	
0.99941933 3.0691543e-05
Epoch: [96][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0799 (0.1086)	
0.9997578 2.2511027e-05
loss:  0.08159156400769063 0.0712875497155373
===========>   training    <===========
Epoch: [97][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0855 (0.0855)	
0.99963677 4.3282425e-06
===========>   testing    <===========
Epoch: [97][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0826 (0.0826)	
0.99970657 1.2303923e-05
Epoch: [97][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0417 (0.0939)	
0.99948704 3.132543e-05
Epoch: [97][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1117 (0.0935)	
0.99972826 1.9027138e-05
loss:  0.07180847957163972 0.0712875497155373
===========>   training    <===========
Epoch: [98][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0968 (0.0968)	
0.99949265 4.8381116e-06
===========>   testing    <===========
Epoch: [98][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0826 (0.0826)	
0.9997533 2.528819e-05
Epoch: [98][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1983 (0.1236)	
0.9996382 1.21154335e-05
Epoch: [98][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1522 (0.1196)	
0.99975306 4.1379448e-05
loss:  0.08896113906705383 0.0712875497155373
===========>   training    <===========
Epoch: [99][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0874 (0.0874)	
0.9998172 1.3669252e-05
===========>   testing    <===========
Epoch: [99][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0930 (0.0930)	
0.99972016 1.4493729e-05
Epoch: [99][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.1419 (0.0924)	
0.9995963 6.319063e-06
Epoch: [99][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0008145062499999999]	Loss 0.0572 (0.0878)	
0.9997104 1.2424072e-05
loss:  0.06886164512122661 0.0712875497155373
===========>   training    <===========
Epoch: [100][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0963 (0.0963)	
0.99969006 1.0953374e-05
===========>   testing    <===========
Epoch: [100][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1504 (0.1504)	
0.9996319 1.5656508e-06
Epoch: [100][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0690 (0.0994)	
0.9994467 1.6430283e-06
Epoch: [100][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0867 (0.0976)	
0.99963164 1.9887993e-06
loss:  0.07430540407551811 0.06886164512122661
===========>   training    <===========
Epoch: [101][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1442 (0.1442)	
0.9996455 4.0345863e-06
===========>   testing    <===========
Epoch: [101][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1376 (0.1376)	
0.99965703 1.7661883e-05
Epoch: [101][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0576 (0.0985)	
0.999587 1.2825529e-05
Epoch: [101][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0681 (0.0913)	
0.999655 2.520181e-05
loss:  0.07188233622121765 0.06886164512122661
===========>   training    <===========
Epoch: [102][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0821 (0.0821)	
0.9996196 1.632626e-05
===========>   testing    <===========
Epoch: [102][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1299 (0.1299)	
0.9996458 7.938257e-06
Epoch: [102][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0568 (0.0946)	
0.9995573 8.854923e-06
Epoch: [102][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0662 (0.0887)	
0.99969316 1.7071296e-05
loss:  0.07215258007144787 0.06886164512122661
===========>   training    <===========
Epoch: [103][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1054 (0.1054)	
0.99973625 4.6991304e-06
===========>   testing    <===========
Epoch: [103][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1200 (0.1200)	
0.9997044 1.6724645e-05
Epoch: [103][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.3285 (0.0965)	
0.99969697 1.41891305e-05
Epoch: [103][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0762 (0.0897)	
0.99971205 2.4389623e-05
loss:  0.07003759255245168 0.06886164512122661
===========>   training    <===========
Epoch: [104][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0891 (0.0891)	
0.99971217 3.5128073e-06
===========>   testing    <===========
Epoch: [104][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0920 (0.0920)	
0.9996704 1.8113746e-05
Epoch: [104][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.3271 (0.0948)	
0.9995005 1.4151643e-05
Epoch: [104][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0776 (0.0909)	
0.9997265 2.4268327e-05
loss:  0.07239648304543189 0.06886164512122661
===========>   training    <===========
Epoch: [105][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1135 (0.1135)	
0.99974185 1.5872212e-07
===========>   testing    <===========
Epoch: [105][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0820 (0.0820)	
0.9996014 2.7435799e-05
Epoch: [105][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0586 (0.0973)	
0.999141 5.6966877e-05
Epoch: [105][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1587 (0.0976)	
0.99967706 2.9948302e-05
loss:  0.07465046387838947 0.06886164512122661
===========>   training    <===========
Epoch: [106][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0854 (0.0854)	
0.99975115 6.2018667e-06
===========>   testing    <===========
Epoch: [106][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0870 (0.0870)	
0.99960786 1.31646175e-05
Epoch: [106][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0622 (0.0933)	
0.99957603 2.6242546e-05
Epoch: [106][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1127 (0.0897)	
0.99965453 1.7467259e-05
loss:  0.07023731954581902 0.06886164512122661
===========>   training    <===========
Epoch: [107][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0972 (0.0972)	
0.99951935 7.1571475e-07
===========>   testing    <===========
Epoch: [107][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0896 (0.0896)	
0.99960476 1.0296346e-05
Epoch: [107][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1990 (0.0949)	
0.9992466 7.68404e-06
Epoch: [107][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1171 (0.0894)	
0.9996062 1.5887395e-05
loss:  0.07093395557894899 0.06886164512122661
===========>   training    <===========
Epoch: [108][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1234 (0.1234)	
0.9996805 9.1266185e-07
===========>   testing    <===========
Epoch: [108][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0645 (0.0645)	
0.9997509 1.0358857e-05
Epoch: [108][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1099 (0.0981)	
0.9995301 5.3912696e-05
Epoch: [108][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0986 (0.0993)	
0.9997352 4.986843e-05
loss:  0.07569306498829675 0.06886164512122661
===========>   training    <===========
Epoch: [109][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0878 (0.0878)	
0.99977607 4.9137856e-07
===========>   testing    <===========
Epoch: [109][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0829 (0.0829)	
0.9996823 1.461345e-05
Epoch: [109][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0594 (0.0961)	
0.9991479 1.4236626e-05
Epoch: [109][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1095 (0.0927)	
0.99965334 2.746072e-05
loss:  0.07267817143960964 0.06886164512122661
===========>   training    <===========
Epoch: [110][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0863 (0.0863)	
0.9997764 5.1705842e-06
===========>   testing    <===========
Epoch: [110][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0781 (0.0781)	
0.9995704 2.9511389e-06
Epoch: [110][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0411 (0.0985)	
0.99875355 4.6809846e-06
Epoch: [110][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1488 (0.0967)	
0.99956673 1.1025268e-05
loss:  0.07320238297229897 0.06886164512122661
===========>   training    <===========
Epoch: [111][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0947 (0.0947)	
0.9996568 1.7519342e-05
===========>   testing    <===========
Epoch: [111][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0616 (0.0616)	
0.999624 2.4278928e-05
Epoch: [111][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1870 (0.0971)	
0.9992823 2.3387642e-05
Epoch: [111][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0850 (0.0970)	
0.9996517 4.2694184e-05
loss:  0.07120328061020575 0.06886164512122661
===========>   training    <===========
Epoch: [112][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1277 (0.1277)	
0.9996506 1.3520005e-05
===========>   testing    <===========
Epoch: [112][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0999 (0.0999)	
0.9996145 7.749328e-06
Epoch: [112][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0948 (0.1016)	
0.99906904 1.0445958e-05
Epoch: [112][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0843 (0.0933)	
0.99956876 1.1727735e-05
loss:  0.07337003960036337 0.06886164512122661
===========>   training    <===========
Epoch: [113][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0932 (0.0932)	
0.9996915 8.917965e-06
===========>   testing    <===========
Epoch: [113][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0916 (0.0916)	
0.9997986 1.14229e-05
Epoch: [113][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0573 (0.0924)	
0.999451 8.361853e-06
Epoch: [113][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0652 (0.0876)	
0.9997507 1.0583725e-05
loss:  0.0676199008438807 0.06886164512122661
===========>   training    <===========
Epoch: [114][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0810 (0.0810)	
0.99975306 4.2220216e-07
===========>   testing    <===========
Epoch: [114][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1434 (0.1434)	
0.9997702 2.164059e-05
Epoch: [114][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.2738 (0.0999)	
0.9996018 3.3163387e-06
Epoch: [114][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0837 (0.0934)	
0.9997372 3.8956073e-06
loss:  0.07348665234667884 0.0676199008438807
===========>   training    <===========
Epoch: [115][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0911 (0.0911)	
0.9997043 1.5871501e-06
===========>   testing    <===========
Epoch: [115][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0999 (0.0999)	
0.99977845 2.0652513e-05
Epoch: [115][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1473 (0.0988)	
0.99969375 1.7657183e-05
Epoch: [115][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0593 (0.0913)	
0.9997825 4.7707617e-05
loss:  0.07051944923047415 0.0676199008438807
===========>   training    <===========
Epoch: [116][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1378 (0.1378)	
0.9997359 6.3017965e-06
===========>   testing    <===========
Epoch: [116][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0752 (0.0752)	
0.999571 1.461957e-05
Epoch: [116][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.6324 (0.0984)	
0.9994836 1.6224458e-05
Epoch: [116][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0582 (0.0913)	
0.99960524 1.3768134e-05
loss:  0.06921112660997775 0.0676199008438807
===========>   training    <===========
Epoch: [117][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0795 (0.0795)	
0.99965274 1.229923e-05
===========>   testing    <===========
Epoch: [117][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0823 (0.0823)	
0.99962056 1.307138e-05
Epoch: [117][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1231 (0.0875)	
0.99920505 2.1653163e-05
Epoch: [117][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1282 (0.0872)	
0.999683 2.1726057e-05
loss:  0.06765442828995782 0.0676199008438807
===========>   training    <===========
Epoch: [118][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1211 (0.1211)	
0.99965465 5.798131e-07
===========>   testing    <===========
Epoch: [118][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0764 (0.0764)	
0.9997669 3.201946e-06
Epoch: [118][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0546 (0.0977)	
0.99957937 5.755881e-06
Epoch: [118][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0930 (0.0940)	
0.9997191 3.5625867e-06
loss:  0.07171678591775066 0.0676199008438807
===========>   training    <===========
Epoch: [119][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0845 (0.0845)	
0.99982846 1.6431992e-05
===========>   testing    <===========
Epoch: [119][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.0757 (0.0757)	
0.9996667 1.469623e-05
Epoch: [119][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1204 (0.0851)	
0.9990276 1.1213304e-05
Epoch: [119][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007737809374999998]	Loss 0.1432 (0.0812)	
0.99965334 1.20328295e-05
loss:  0.06312064780614124 0.0676199008438807
===========>   training    <===========
Epoch: [120][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1048 (0.1048)	
0.9997322 1.8001536e-05
===========>   testing    <===========
Epoch: [120][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1040 (0.1040)	
0.99970335 1.194265e-05
Epoch: [120][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.3844 (0.1112)	
0.99961096 1.0740289e-05
Epoch: [120][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0745 (0.1009)	
0.9997383 1.7473323e-05
loss:  0.08124379862510189 0.06312064780614124
===========>   training    <===========
Epoch: [121][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0896 (0.0896)	
0.9997974 4.8508487e-06
===========>   testing    <===========
Epoch: [121][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1325 (0.1325)	
0.9997507 1.188193e-05
Epoch: [121][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0475 (0.0939)	
0.9995803 1.4129742e-05
Epoch: [121][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1849 (0.0874)	
0.9997551 8.592684e-06
loss:  0.06891880417797391 0.06312064780614124
===========>   training    <===========
Epoch: [122][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0835 (0.0835)	
0.9998124 8.632409e-07
===========>   testing    <===========
Epoch: [122][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0948 (0.0948)	
0.99970055 1.2754115e-05
Epoch: [122][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0513 (0.0939)	
0.99912685 2.1151278e-05
Epoch: [122][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1376 (0.0872)	
0.9996921 8.237424e-06
loss:  0.06492929928917635 0.06312064780614124
===========>   training    <===========
Epoch: [123][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0867 (0.0867)	
0.9996817 1.8273626e-06
===========>   testing    <===========
Epoch: [123][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0731 (0.0731)	
0.9997701 2.5395853e-05
Epoch: [123][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0936 (0.0851)	
0.9995005 1.3892322e-05
Epoch: [123][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1607 (0.0830)	
0.99971503 1.6421212e-05
loss:  0.06499401458816312 0.06312064780614124
===========>   training    <===========
Epoch: [124][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0975 (0.0975)	
0.99979776 8.6321415e-06
===========>   testing    <===========
Epoch: [124][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1059 (0.1059)	
0.99896157 9.933806e-06
Epoch: [124][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0704 (0.0906)	
0.9989324 6.397184e-06
Epoch: [124][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1330 (0.0871)	
0.9995189 2.2789995e-06
loss:  0.06614692828931323 0.06312064780614124
===========>   training    <===========
Epoch: [125][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0881 (0.0881)	
0.9996377 1.3932864e-06
===========>   testing    <===========
Epoch: [125][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1166 (0.1166)	
0.9997321 3.090651e-05
Epoch: [125][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0957 (0.0922)	
0.999729 4.392346e-05
Epoch: [125][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0884 (0.0853)	
0.9997328 2.0213063e-05
loss:  0.06561469751690407 0.06312064780614124
===========>   training    <===========
Epoch: [126][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0835 (0.0835)	
0.9997204 1.3054859e-06
===========>   testing    <===========
Epoch: [126][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1327 (0.1327)	
0.999683 1.3960269e-05
Epoch: [126][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0629 (0.0938)	
0.99962926 3.4961502e-06
Epoch: [126][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1080 (0.0927)	
0.9997385 1.8219578e-06
loss:  0.07016617281985704 0.06312064780614124
===========>   training    <===========
Epoch: [127][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0803 (0.0803)	
0.99979776 6.311907e-06
===========>   testing    <===========
Epoch: [127][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0968 (0.0968)	
0.9997396 7.752204e-06
Epoch: [127][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0620 (0.0848)	
0.9996648 4.338504e-06
Epoch: [127][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1304 (0.0815)	
0.999778 1.9824122e-06
loss:  0.06260102389898847 0.06312064780614124
===========>   training    <===========
Epoch: [128][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0930 (0.0930)	
0.9996817 1.3450546e-07
===========>   testing    <===========
Epoch: [128][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1095 (0.1095)	
0.9997938 7.407747e-06
Epoch: [128][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0622 (0.0871)	
0.99960464 3.030357e-06
Epoch: [128][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0997 (0.0817)	
0.9997881 3.5485723e-06
loss:  0.06419678941059781 0.06260102389898847
===========>   training    <===========
Epoch: [129][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1051 (0.1051)	
0.9998313 1.5634272e-05
===========>   testing    <===========
Epoch: [129][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1234 (0.1234)	
0.99976224 2.1788155e-05
Epoch: [129][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0469 (0.1087)	
0.99961805 1.7444851e-06
Epoch: [129][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1612 (0.1032)	
0.99981946 4.796215e-06
loss:  0.08269565897553666 0.06260102389898847
===========>   training    <===========
Epoch: [130][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0878 (0.0878)	
0.9998254 8.901235e-06
===========>   testing    <===========
Epoch: [130][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1243 (0.1243)	
0.9997396 5.683833e-06
Epoch: [130][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.2110 (0.0930)	
0.9996376 6.545529e-06
Epoch: [130][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0858 (0.0845)	
0.99976414 5.043545e-06
loss:  0.06771892159987714 0.06260102389898847
===========>   training    <===========
Epoch: [131][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0784 (0.0784)	
0.9997857 1.3805684e-05
===========>   testing    <===========
Epoch: [131][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1095 (0.1095)	
0.99978334 3.4798562e-05
Epoch: [131][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0625 (0.0960)	
0.9996125 9.075428e-06
Epoch: [131][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0977 (0.0887)	
0.9997961 8.004899e-06
loss:  0.06785023499618792 0.06260102389898847
===========>   training    <===========
Epoch: [132][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0780 (0.0780)	
0.999765 1.4990893e-07
===========>   testing    <===========
Epoch: [132][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0685 (0.0685)	
0.99967563 4.301852e-06
Epoch: [132][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0418 (0.0870)	
0.99958116 5.2894866e-06
Epoch: [132][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1661 (0.0835)	
0.9996923 5.702097e-06
loss:  0.0636391883924744 0.06260102389898847
===========>   training    <===========
Epoch: [133][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0875 (0.0875)	
0.999637 1.4495309e-06
===========>   testing    <===========
Epoch: [133][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0898 (0.0898)	
0.9996966 3.2960652e-06
Epoch: [133][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0426 (0.0853)	
0.9996296 2.1702863e-06
Epoch: [133][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1234 (0.0797)	
0.999731 2.711307e-06
loss:  0.06291313667121579 0.06260102389898847
===========>   training    <===========
Epoch: [134][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0817 (0.0817)	
0.9998441 1.9273226e-05
===========>   testing    <===========
Epoch: [134][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1224 (0.1224)	
0.9997725 2.3285445e-05
Epoch: [134][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0891 (0.0913)	
0.9997975 1.3452149e-05
Epoch: [134][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0425 (0.0878)	
0.99978536 1.0701335e-05
loss:  0.06679936884657334 0.06260102389898847
===========>   training    <===========
Epoch: [135][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0966 (0.0966)	
0.99977714 1.2189514e-05
===========>   testing    <===========
Epoch: [135][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1119 (0.1119)	
0.9998547 1.5127546e-05
Epoch: [135][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1608 (0.0999)	
0.99987257 8.397224e-06
Epoch: [135][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0794 (0.0971)	
0.9998282 1.0208915e-05
loss:  0.07248093711042358 0.06260102389898847
===========>   training    <===========
Epoch: [136][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0855 (0.0855)	
0.9998147 1.2625114e-05
===========>   testing    <===========
Epoch: [136][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0778 (0.0778)	
0.99978465 7.466444e-06
Epoch: [136][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0338 (0.0891)	
0.9997223 8.908139e-06
Epoch: [136][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0892 (0.0818)	
0.99979883 6.72359e-06
loss:  0.06394469252152912 0.06260102389898847
===========>   training    <===========
Epoch: [137][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0937 (0.0937)	
0.99983823 1.5983378e-05
===========>   testing    <===========
Epoch: [137][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0780 (0.0780)	
0.9997751 5.2732084e-06
Epoch: [137][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1354 (0.0888)	
0.99983513 6.0797906e-06
Epoch: [137][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0729 (0.0828)	
0.9997929 3.276009e-06
loss:  0.06619695699223793 0.06260102389898847
===========>   training    <===========
Epoch: [138][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0783 (0.0783)	
0.9998473 8.881994e-07
===========>   testing    <===========
Epoch: [138][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0903 (0.0903)	
0.99968934 2.7816932e-06
Epoch: [138][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0645 (0.0889)	
0.9992737 8.6012074e-07
Epoch: [138][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1767 (0.0850)	
0.99970824 1.0908765e-06
loss:  0.06806653820465458 0.06260102389898847
===========>   training    <===========
Epoch: [139][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.0872 (0.0872)	
0.9996878 1.3049988e-07
===========>   testing    <===========
Epoch: [139][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1339 (0.1339)	
0.99967265 2.1083656e-06
Epoch: [139][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.4721 (0.0965)	
0.99973494 1.9610964e-06
Epoch: [139][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0007350918906249999]	Loss 0.1050 (0.0892)	
0.99976355 1.3841233e-06
loss:  0.06928327859909833 0.06260102389898847
===========>   training    <===========
Epoch: [140][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0857 (0.0857)	
0.99976546 1.3230871e-06
===========>   testing    <===========
Epoch: [140][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1783 (0.1783)	
0.99982786 1.9487064e-05
Epoch: [140][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0370 (0.1043)	
0.9997702 1.230918e-05
Epoch: [140][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.2050 (0.0968)	
0.9998266 8.338831e-06
loss:  0.06889790785853289 0.06260102389898847
===========>   training    <===========
Epoch: [141][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0909 (0.0909)	
0.9998235 8.885492e-05
===========>   testing    <===========
Epoch: [141][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0855 (0.0855)	
0.9997969 2.5036688e-06
Epoch: [141][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.3053 (0.0902)	
0.99980956 7.302338e-06
Epoch: [141][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0977 (0.0872)	
0.9997862 3.3763918e-06
loss:  0.0673556961426881 0.06260102389898847
===========>   training    <===========
Epoch: [142][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0820 (0.0820)	
0.9997837 2.4737358e-06
===========>   testing    <===========
Epoch: [142][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0920 (0.0920)	
0.9997445 2.1541735e-05
Epoch: [142][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.4138 (0.0822)	
0.99969184 7.5070125e-06
Epoch: [142][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0868 (0.0773)	
0.9997569 1.1800726e-05
loss:  0.05953973386098543 0.06260102389898847
===========>   training    <===========
Epoch: [143][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0957 (0.0957)	
0.9996704 1.5304431e-06
===========>   testing    <===========
Epoch: [143][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0841 (0.0841)	
0.9997267 9.931343e-06
Epoch: [143][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0409 (0.0858)	
0.9998087 6.3811713e-06
Epoch: [143][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0926 (0.0797)	
0.99976116 3.0732203e-06
loss:  0.06175063806442793 0.05953973386098543
===========>   training    <===========
Epoch: [144][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0806 (0.0806)	
0.9998294 2.0707596e-06
===========>   testing    <===========
Epoch: [144][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1186 (0.1186)	
0.9996507 1.22485235e-05
Epoch: [144][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0427 (0.0864)	
0.9995777 3.033873e-06
Epoch: [144][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.2161 (0.0854)	
0.9997203 1.9383783e-06
loss:  0.06576555817983232 0.05953973386098543
===========>   training    <===========
Epoch: [145][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0888 (0.0888)	
0.9998275 5.382415e-06
===========>   testing    <===========
Epoch: [145][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0948 (0.0948)	
0.9997824 4.680654e-06
Epoch: [145][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.2468 (0.0881)	
0.9997893 1.8810084e-06
Epoch: [145][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0876 (0.0856)	
0.9997799 1.2021115e-06
loss:  0.06653507833333117 0.05953973386098543
===========>   training    <===========
Epoch: [146][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0858 (0.0858)	
0.9996823 2.3120492e-06
===========>   testing    <===========
Epoch: [146][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0600 (0.0600)	
0.99968314 5.553588e-06
Epoch: [146][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0445 (0.0856)	
0.999438 4.8312413e-06
Epoch: [146][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.2524 (0.0836)	
0.99968684 1.8420567e-06
loss:  0.06568394405101463 0.05953973386098543
===========>   training    <===========
Epoch: [147][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0626 (0.0626)	
0.9997782 1.3050739e-06
===========>   testing    <===========
Epoch: [147][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0873 (0.0873)	
0.9996673 5.9133845e-06
Epoch: [147][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0383 (0.0866)	
0.9997224 2.705766e-06
Epoch: [147][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1505 (0.0837)	
0.99970406 2.0888801e-06
loss:  0.06508143423533985 0.05953973386098543
===========>   training    <===========
Epoch: [148][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1000 (0.1000)	
0.9997619 4.308372e-06
===========>   testing    <===========
Epoch: [148][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0610 (0.0610)	
0.99976987 9.1567745e-06
Epoch: [148][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0556 (0.0852)	
0.9997826 6.926825e-06
Epoch: [148][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1960 (0.0811)	
0.99977154 6.1989813e-06
loss:  0.06271747923743465 0.05953973386098543
===========>   training    <===========
Epoch: [149][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0779 (0.0779)	
0.9997986 6.74863e-07
===========>   testing    <===========
Epoch: [149][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0929 (0.0929)	
0.9997558 5.5346172e-06
Epoch: [149][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0535 (0.0944)	
0.9997794 3.860827e-06
Epoch: [149][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1910 (0.0916)	
0.9997696 2.4031947e-06
loss:  0.06804638018002052 0.05953973386098543
===========>   training    <===========
Epoch: [150][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0827 (0.0827)	
0.9997774 1.4203562e-06
===========>   testing    <===========
Epoch: [150][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0971 (0.0971)	
0.9998116 3.4982168e-05
Epoch: [150][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0391 (0.0818)	
0.9997222 2.025965e-05
Epoch: [150][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0619 (0.0776)	
0.99980706 2.2414055e-05
loss:  0.05919798146732724 0.05953973386098543
===========>   training    <===========
Epoch: [151][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0811 (0.0811)	
0.99983764 1.9377408e-06
===========>   testing    <===========
Epoch: [151][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1151 (0.1151)	
0.9997758 3.2668179e-06
Epoch: [151][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0770 (0.0902)	
0.9996822 4.070055e-06
Epoch: [151][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0729 (0.0809)	
0.99980253 1.9531249e-06
loss:  0.06269742633145425 0.05919798146732724
===========>   training    <===========
Epoch: [152][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0916 (0.0916)	
0.99986994 7.5245302e-06
===========>   testing    <===========
Epoch: [152][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0749 (0.0749)	
0.999708 3.505216e-05
Epoch: [152][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0778 (0.0872)	
0.9997367 2.027258e-05
Epoch: [152][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1527 (0.0829)	
0.99980515 3.4901856e-05
loss:  0.060899545038520575 0.05919798146732724
===========>   training    <===========
Epoch: [153][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0687 (0.0687)	
0.99982435 7.4223743e-07
===========>   testing    <===========
Epoch: [153][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0787 (0.0787)	
0.99974865 5.597054e-06
Epoch: [153][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0416 (0.0818)	
0.9995639 5.9641648e-06
Epoch: [153][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1647 (0.0818)	
0.9997136 6.1275505e-06
loss:  0.06325534362610852 0.05919798146732724
===========>   training    <===========
Epoch: [154][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0759 (0.0759)	
0.9997806 8.347364e-07
===========>   testing    <===========
Epoch: [154][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0848 (0.0848)	
0.9997886 1.4387389e-06
Epoch: [154][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0598 (0.0800)	
0.9995474 4.1010185e-06
Epoch: [154][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1301 (0.0751)	
0.9997873 2.3214725e-06
loss:  0.05872529907271107 0.05919798146732724
===========>   training    <===========
Epoch: [155][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0857 (0.0857)	
0.9998036 2.2621758e-07
===========>   testing    <===========
Epoch: [155][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1757 (0.1757)	
0.99956197 3.4479497e-06
Epoch: [155][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0408 (0.0872)	
0.9996766 2.2705974e-06
Epoch: [155][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1599 (0.0849)	
0.99980277 4.544475e-06
loss:  0.065884430147092 0.05872529907271107
===========>   training    <===========
Epoch: [156][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0883 (0.0883)	
0.99971765 1.7387576e-08
===========>   testing    <===========
Epoch: [156][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0743 (0.0743)	
0.99952805 4.1135954e-06
Epoch: [156][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0524 (0.0855)	
0.99949896 1.697455e-06
Epoch: [156][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1649 (0.0805)	
0.99973184 1.9705053e-06
loss:  0.061861895166151926 0.05872529907271107
===========>   training    <===========
Epoch: [157][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0639 (0.0639)	
0.9997384 5.393305e-07
===========>   testing    <===========
Epoch: [157][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1062 (0.1062)	
0.99972004 7.704048e-06
Epoch: [157][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.2208 (0.0890)	
0.99963844 2.585031e-06
Epoch: [157][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0831 (0.0814)	
0.9997594 5.1489924e-06
loss:  0.06464409666014204 0.05872529907271107
===========>   training    <===========
Epoch: [158][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0682 (0.0682)	
0.99968696 2.3790459e-05
===========>   testing    <===========
Epoch: [158][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0767 (0.0767)	
0.99971706 1.03686125e-05
Epoch: [158][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1256 (0.0825)	
0.9995591 4.229427e-06
Epoch: [158][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1249 (0.0753)	
0.99980766 5.3037106e-06
loss:  0.05959546288867057 0.05872529907271107
===========>   training    <===========
Epoch: [159][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.0712 (0.0712)	
0.9997892 9.0231896e-07
===========>   testing    <===========
Epoch: [159][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1171 (0.1171)	
0.99980277 6.7695028e-06
Epoch: [159][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1579 (0.0810)	
0.99952877 4.099396e-06
Epoch: [159][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006983372960937497]	Loss 0.1383 (0.0763)	
0.9997451 4.5120005e-06
loss:  0.05996631150498799 0.05872529907271107
===========>   training    <===========
Epoch: [160][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0736 (0.0736)	
0.99984396 6.165825e-07
===========>   testing    <===========
Epoch: [160][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1104 (0.1104)	
0.99988663 7.373211e-06
Epoch: [160][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0508 (0.0819)	
0.99981934 1.01657115e-05
Epoch: [160][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0936 (0.0798)	
0.9998815 5.8193923e-06
loss:  0.05962394864634224 0.05872529907271107
===========>   training    <===========
Epoch: [161][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0717 (0.0717)	
0.9998703 1.5580528e-07
===========>   testing    <===========
Epoch: [161][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1020 (0.1020)	
0.9998697 3.6451409e-06
Epoch: [161][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0623 (0.0891)	
0.99972314 2.0127495e-06
Epoch: [161][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1335 (0.0820)	
0.99984825 4.2737356e-06
loss:  0.062414256027831905 0.05872529907271107
===========>   training    <===========
Epoch: [162][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0661 (0.0661)	
0.999866 2.8687891e-06
===========>   testing    <===========
Epoch: [162][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0740 (0.0740)	
0.999782 2.1997087e-06
Epoch: [162][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0451 (0.0872)	
0.99955946 2.7807646e-06
Epoch: [162][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1237 (0.0784)	
0.99980193 2.2848799e-06
loss:  0.061786316047873324 0.05872529907271107
===========>   training    <===========
Epoch: [163][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0907 (0.0907)	
0.9998252 2.1743174e-06
===========>   testing    <===========
Epoch: [163][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0831 (0.0831)	
0.9997521 2.575071e-06
Epoch: [163][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0384 (0.0869)	
0.9996191 1.4853638e-06
Epoch: [163][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1200 (0.0790)	
0.99978215 2.4840194e-06
loss:  0.061463079946718624 0.05872529907271107
===========>   training    <===========
Epoch: [164][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0688 (0.0688)	
0.9997632 3.1917023e-06
===========>   testing    <===========
Epoch: [164][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1237 (0.1237)	
0.9997842 7.945574e-06
Epoch: [164][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0326 (0.0918)	
0.9997305 4.3354885e-06
Epoch: [164][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0896 (0.0833)	
0.9998074 5.9010586e-06
loss:  0.061563900298389096 0.05872529907271107
===========>   training    <===========
Epoch: [165][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0783 (0.0783)	
0.99984145 7.7215755e-06
===========>   testing    <===========
Epoch: [165][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0948 (0.0948)	
0.9996867 9.132242e-06
Epoch: [165][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0335 (0.0944)	
0.99969184 6.0208445e-06
Epoch: [165][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1778 (0.0891)	
0.9998222 2.8536995e-06
loss:  0.07011129357923518 0.05872529907271107
===========>   training    <===========
Epoch: [166][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0698 (0.0698)	
0.99983263 1.1831354e-05
===========>   testing    <===========
Epoch: [166][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1013 (0.1013)	
0.999775 2.2117279e-06
Epoch: [166][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0339 (0.0954)	
0.99961877 2.2672155e-06
Epoch: [166][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1510 (0.0899)	
0.99980587 2.6773616e-06
loss:  0.06798066975115424 0.05872529907271107
===========>   training    <===========
Epoch: [167][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0795 (0.0795)	
0.9997502 7.642125e-07
===========>   testing    <===========
Epoch: [167][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0687 (0.0687)	
0.9998135 2.757762e-06
Epoch: [167][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0419 (0.0858)	
0.9993599 2.3531775e-06
Epoch: [167][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1666 (0.0799)	
0.9997917 3.2378857e-06
loss:  0.061747003660182265 0.05872529907271107
===========>   training    <===========
Epoch: [168][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1389 (0.1389)	
0.99978787 7.447574e-07
===========>   testing    <===========
Epoch: [168][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0598 (0.0598)	
0.99972063 2.3819655e-06
Epoch: [168][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1049 (0.0779)	
0.9995864 1.275794e-06
Epoch: [168][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1917 (0.0713)	
0.9998247 1.8654647e-06
loss:  0.05575283549353016 0.05872529907271107
===========>   training    <===========
Epoch: [169][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0772 (0.0772)	
0.99984443 3.756409e-05
===========>   testing    <===========
Epoch: [169][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0803 (0.0803)	
0.99977523 9.669299e-06
Epoch: [169][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0556 (0.0817)	
0.9997178 6.9951266e-06
Epoch: [169][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0972 (0.0755)	
0.99981385 1.2795929e-05
loss:  0.05645244386270942 0.05575283549353016
===========>   training    <===========
Epoch: [170][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1150 (0.1150)	
0.99974734 3.0785122e-06
===========>   testing    <===========
Epoch: [170][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0868 (0.0868)	
0.9996014 1.0680155e-06
Epoch: [170][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0415 (0.0865)	
0.99930716 6.845204e-07
Epoch: [170][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1481 (0.0800)	
0.9997471 1.1052817e-06
loss:  0.06159480081630142 0.05575283549353016
===========>   training    <===========
Epoch: [171][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0929 (0.0929)	
0.9998272 1.8120495e-06
===========>   testing    <===========
Epoch: [171][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1168 (0.1168)	
0.99965894 4.2779357e-06
Epoch: [171][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0546 (0.0787)	
0.9997806 2.5748477e-06
Epoch: [171][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0530 (0.0740)	
0.9997881 4.2852116e-06
loss:  0.057052419405060784 0.05575283549353016
===========>   training    <===========
Epoch: [172][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0853 (0.0853)	
0.99978405 2.6614214e-05
===========>   testing    <===========
Epoch: [172][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0999 (0.0999)	
0.99950767 4.71258e-06
Epoch: [172][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0583 (0.0857)	
0.99885774 1.4118991e-06
Epoch: [172][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1191 (0.0790)	
0.99964786 6.21142e-06
loss:  0.058491541081534204 0.05575283549353016
===========>   training    <===========
Epoch: [173][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0886 (0.0886)	
0.999793 2.1341789e-06
===========>   testing    <===========
Epoch: [173][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0775 (0.0775)	
0.9998011 7.332498e-06
Epoch: [173][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1049 (0.0857)	
0.9997392 4.5837664e-06
Epoch: [173][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1186 (0.0784)	
0.9998307 1.1405896e-05
loss:  0.05896528495980491 0.05575283549353016
===========>   training    <===========
Epoch: [174][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0634 (0.0634)	
0.9998318 9.69039e-07
===========>   testing    <===========
Epoch: [174][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0914 (0.0914)	
0.99977 3.16051e-06
Epoch: [174][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0541 (0.0827)	
0.9995189 3.3711797e-06
Epoch: [174][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0546 (0.0751)	
0.9997596 1.7287829e-06
loss:  0.05955068883127901 0.05575283549353016
===========>   training    <===========
Epoch: [175][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0811 (0.0811)	
0.999785 9.972628e-06
===========>   testing    <===========
Epoch: [175][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0978 (0.0978)	
0.9998049 1.4892224e-05
Epoch: [175][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.2204 (0.0841)	
0.999699 1.365798e-05
Epoch: [175][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0579 (0.0764)	
0.9998043 7.7575505e-06
loss:  0.06058843931185087 0.05575283549353016
===========>   training    <===========
Epoch: [176][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0681 (0.0681)	
0.999734 8.8233026e-07
===========>   testing    <===========
Epoch: [176][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0833 (0.0833)	
0.9998074 9.26175e-06
Epoch: [176][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0489 (0.0789)	
0.9996699 1.745765e-05
Epoch: [176][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1989 (0.0753)	
0.99975485 1.4043579e-05
loss:  0.057488988245144146 0.05575283549353016
===========>   training    <===========
Epoch: [177][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0634 (0.0634)	
0.99978095 1.7198357e-06
===========>   testing    <===========
Epoch: [177][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0735 (0.0735)	
0.9998204 7.0449696e-06
Epoch: [177][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0434 (0.0820)	
0.99973565 6.8513245e-06
Epoch: [177][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1464 (0.0784)	
0.9998018 1.4156596e-05
loss:  0.05835802906160259 0.05575283549353016
===========>   training    <===========
Epoch: [178][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0648 (0.0648)	
0.99985826 2.3338723e-06
===========>   testing    <===========
Epoch: [178][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1033 (0.1033)	
0.9998258 6.9831226e-06
Epoch: [178][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0369 (0.0885)	
0.99975866 1.1245861e-05
Epoch: [178][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1178 (0.0802)	
0.99982136 8.656162e-06
loss:  0.06115193429752508 0.05575283549353016
===========>   training    <===========
Epoch: [179][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0653 (0.0653)	
0.9998029 9.766311e-06
===========>   testing    <===========
Epoch: [179][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0863 (0.0863)	
0.9998691 3.8832445e-06
Epoch: [179][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.0455 (0.0851)	
0.9997271 5.935544e-06
Epoch: [179][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006634204312890623]	Loss 0.1286 (0.0799)	
0.9998522 5.7760058e-06
loss:  0.06106031684480906 0.05575283549353016
===========>   training    <===========
Epoch: [180][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0743 (0.0743)	
0.99984586 1.9636173e-06
===========>   testing    <===========
Epoch: [180][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0732 (0.0732)	
0.99979216 2.4474493e-06
Epoch: [180][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0408 (0.0812)	
0.9997435 6.442723e-06
Epoch: [180][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1354 (0.0755)	
0.99979204 1.058271e-06
loss:  0.057612683147364674 0.05575283549353016
===========>   training    <===========
Epoch: [181][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0760 (0.0760)	
0.99988794 1.097077e-05
===========>   testing    <===========
Epoch: [181][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0924 (0.0924)	
0.99981433 4.657082e-06
Epoch: [181][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0307 (0.0794)	
0.9997124 8.4959875e-06
Epoch: [181][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1377 (0.0746)	
0.9998165 3.229023e-06
loss:  0.05652533825726058 0.05575283549353016
===========>   training    <===========
Epoch: [182][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0758 (0.0758)	
0.9998271 1.1346142e-05
===========>   testing    <===========
Epoch: [182][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0854 (0.0854)	
0.9997825 4.828639e-06
Epoch: [182][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0392 (0.0781)	
0.99958307 7.3991755e-06
Epoch: [182][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0726 (0.0721)	
0.9997718 3.5242224e-06
loss:  0.05455085111298075 0.05575283549353016
===========>   training    <===========
Epoch: [183][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0812 (0.0812)	
0.99972504 3.4852403e-07
===========>   testing    <===========
Epoch: [183][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0728 (0.0728)	
0.9998416 3.8699177e-06
Epoch: [183][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0402 (0.0885)	
0.999749 5.569818e-06
Epoch: [183][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1896 (0.0815)	
0.99979657 4.1121916e-06
loss:  0.06022270219491499 0.05455085111298075
===========>   training    <===========
Epoch: [184][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0823 (0.0823)	
0.9998735 2.2488239e-05
===========>   testing    <===========
Epoch: [184][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0655 (0.0655)	
0.99987686 2.2162506e-06
Epoch: [184][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0512 (0.0790)	
0.9998049 1.5028684e-06
Epoch: [184][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0930 (0.0731)	
0.9998863 1.588216e-06
loss:  0.05468000076166901 0.05455085111298075
===========>   training    <===========
Epoch: [185][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0722 (0.0722)	
0.9998518 1.924312e-06
===========>   testing    <===========
Epoch: [185][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0915 (0.0915)	
0.9998084 4.2015404e-07
Epoch: [185][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0261 (0.0831)	
0.9996724 3.409246e-06
Epoch: [185][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1398 (0.0766)	
0.9997943 1.0229322e-06
loss:  0.059997162636781565 0.05455085111298075
===========>   training    <===========
Epoch: [186][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0700 (0.0700)	
0.99988973 4.1713724e-06
===========>   testing    <===========
Epoch: [186][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0563 (0.0563)	
0.9998963 1.1470495e-05
Epoch: [186][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0428 (0.0821)	
0.99980074 2.611395e-05
Epoch: [186][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0588 (0.0751)	
0.99989784 6.6060575e-06
loss:  0.057503227394463896 0.05455085111298075
===========>   training    <===========
Epoch: [187][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0708 (0.0708)	
0.9998524 5.2062396e-06
===========>   testing    <===========
Epoch: [187][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0950 (0.0950)	
0.99984086 1.3705449e-05
Epoch: [187][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0487 (0.0819)	
0.9998305 2.459402e-05
Epoch: [187][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1188 (0.0800)	
0.99986386 5.6339577e-06
loss:  0.06120734232745095 0.05455085111298075
===========>   training    <===========
Epoch: [188][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0726 (0.0726)	
0.9999279 2.3203922e-06
===========>   testing    <===========
Epoch: [188][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0623 (0.0623)	
0.9998629 3.4813777e-06
Epoch: [188][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0449 (0.0926)	
0.99966264 1.4764423e-06
Epoch: [188][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1972 (0.0846)	
0.9998498 1.8640135e-06
loss:  0.06591813371280542 0.05455085111298075
===========>   training    <===========
Epoch: [189][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0737 (0.0737)	
0.9998523 1.1204379e-06
===========>   testing    <===========
Epoch: [189][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0535 (0.0535)	
0.99988437 9.48797e-06
Epoch: [189][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0501 (0.0806)	
0.99963343 9.3282515e-06
Epoch: [189][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1296 (0.0740)	
0.9998549 7.835038e-06
loss:  0.05602594263983118 0.05455085111298075
===========>   training    <===========
Epoch: [190][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0689 (0.0689)	
0.9998797 1.2191653e-05
===========>   testing    <===========
Epoch: [190][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0681 (0.0681)	
0.9998596 3.5940811e-06
Epoch: [190][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1137 (0.0813)	
0.99970883 8.13738e-06
Epoch: [190][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0536 (0.0742)	
0.9998443 1.8272162e-06
loss:  0.05532588041873754 0.05455085111298075
===========>   training    <===========
Epoch: [191][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0673 (0.0673)	
0.99989116 3.7302343e-06
===========>   testing    <===========
Epoch: [191][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0714 (0.0714)	
0.9998553 7.947181e-06
Epoch: [191][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0268 (0.0848)	
0.99974924 9.886804e-06
Epoch: [191][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1667 (0.0777)	
0.9998267 1.7987816e-06
loss:  0.057452102876893285 0.05455085111298075
===========>   training    <===========
Epoch: [192][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0570 (0.0570)	
0.99982506 1.8635585e-05
===========>   testing    <===========
Epoch: [192][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1073 (0.1073)	
0.9998758 8.672622e-06
Epoch: [192][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0478 (0.0850)	
0.99976414 5.1497686e-06
Epoch: [192][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1272 (0.0768)	
0.99983644 2.0610269e-06
loss:  0.05732398606225453 0.05455085111298075
===========>   training    <===========
Epoch: [193][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0817 (0.0817)	
0.9998381 7.2703904e-07
===========>   testing    <===========
Epoch: [193][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0760 (0.0760)	
0.99987566 2.2797498e-05
Epoch: [193][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0473 (0.0792)	
0.9997439 1.620502e-05
Epoch: [193][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1219 (0.0752)	
0.9998652 9.218142e-06
loss:  0.056074927732940316 0.05455085111298075
===========>   training    <===========
Epoch: [194][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0649 (0.0649)	
0.9998553 4.892649e-06
===========>   testing    <===========
Epoch: [194][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0834 (0.0834)	
0.9997913 1.561279e-06
Epoch: [194][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1287 (0.0786)	
0.9996871 1.5222654e-06
Epoch: [194][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1693 (0.0759)	
0.9997414 2.2038093e-06
loss:  0.061023905324060435 0.05455085111298075
===========>   training    <===========
Epoch: [195][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0761 (0.0761)	
0.9998671 2.7490942e-06
===========>   testing    <===========
Epoch: [195][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0945 (0.0945)	
0.9998447 1.4352403e-06
Epoch: [195][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0880 (0.0831)	
0.99967945 2.0215255e-06
Epoch: [195][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0546 (0.0759)	
0.9998487 1.9411143e-06
loss:  0.05961804317595043 0.05455085111298075
===========>   training    <===========
Epoch: [196][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1089 (0.1089)	
0.9997677 8.485951e-07
===========>   testing    <===========
Epoch: [196][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0942 (0.0942)	
0.99985814 1.2418506e-05
Epoch: [196][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0422 (0.0839)	
0.99970406 1.50480355e-05
Epoch: [196][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1592 (0.0772)	
0.99984133 1.18201e-05
loss:  0.06027139444828877 0.05455085111298075
===========>   training    <===========
Epoch: [197][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0748 (0.0748)	
0.9999225 4.4464823e-06
===========>   testing    <===========
Epoch: [197][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.2224 (0.2224)	
0.9998982 2.7740211e-06
Epoch: [197][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0426 (0.0839)	
0.99976474 5.6073386e-06
Epoch: [197][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1423 (0.0791)	
0.99989724 7.598738e-07
loss:  0.059550214063138096 0.05455085111298075
===========>   training    <===========
Epoch: [198][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0635 (0.0635)	
0.99991596 6.4176766e-07
===========>   testing    <===========
Epoch: [198][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0782 (0.0782)	
0.9998987 1.5934561e-06
Epoch: [198][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0399 (0.0833)	
0.99976057 1.8797282e-06
Epoch: [198][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1244 (0.0758)	
0.999884 2.0154885e-06
loss:  0.056833233194234944 0.05455085111298075
===========>   training    <===========
Epoch: [199][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0789 (0.0789)	
0.9998956 5.048449e-06
===========>   testing    <===========
Epoch: [199][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0843 (0.0843)	
0.99987936 3.4062368e-06
Epoch: [199][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.0449 (0.0794)	
0.999741 3.9660636e-06
Epoch: [199][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0006302494097246091]	Loss 0.1267 (0.0743)	
0.9998815 4.0582454e-06
loss:  0.05627481661303202 0.05455085111298075
===========>   training    <===========
Epoch: [200][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0783 (0.0783)	
0.9998839 4.6714053e-06
===========>   testing    <===========
Epoch: [200][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0667 (0.0667)	
0.99987483 1.9183753e-06
Epoch: [200][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0299 (0.0792)	
0.9995751 3.4477757e-06
Epoch: [200][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1195 (0.0740)	
0.9998692 1.3490848e-06
loss:  0.05470496541304515 0.05455085111298075
===========>   training    <===========
Epoch: [201][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0767 (0.0767)	
0.999877 1.3333294e-06
===========>   testing    <===========
Epoch: [201][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0610 (0.0610)	
0.9997297 1.0794215e-06
Epoch: [201][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0418 (0.0830)	
0.99940693 1.0629055e-06
Epoch: [201][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1257 (0.0754)	
0.9997664 9.254345e-07
loss:  0.05853054617721032 0.05455085111298075
===========>   training    <===========
Epoch: [202][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0705 (0.0705)	
0.9998503 2.6756845e-06
===========>   testing    <===========
Epoch: [202][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0659 (0.0659)	
0.99990904 2.2071492e-06
Epoch: [202][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0464 (0.0786)	
0.9997507 4.5142947e-06
Epoch: [202][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1458 (0.0765)	
0.999882 1.51732e-06
loss:  0.05877544958981684 0.05455085111298075
===========>   training    <===========
Epoch: [203][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0796 (0.0796)	
0.99988055 1.07052765e-05
===========>   testing    <===========
Epoch: [203][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0883 (0.0883)	
0.99987745 2.1113879e-06
Epoch: [203][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0676 (0.0786)	
0.9998338 8.794295e-07
Epoch: [203][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0872 (0.0724)	
0.999856 1.6173489e-06
loss:  0.05478633255144927 0.05455085111298075
===========>   training    <===========
Epoch: [204][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0805 (0.0805)	
0.9998622 1.6860258e-06
===========>   testing    <===========
Epoch: [204][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0615 (0.0615)	
0.9998653 3.9293936e-06
Epoch: [204][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0409 (0.0821)	
0.99975795 1.2508541e-05
Epoch: [204][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1226 (0.0748)	
0.9998449 7.9156325e-06
loss:  0.05575361786745725 0.05455085111298075
===========>   training    <===========
Epoch: [205][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0630 (0.0630)	
0.9998728 6.427785e-06
===========>   testing    <===========
Epoch: [205][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0664 (0.0664)	
0.99982774 1.7937143e-06
Epoch: [205][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0510 (0.0768)	
0.99963164 2.2552515e-06
Epoch: [205][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0962 (0.0707)	
0.9998062 2.007319e-06
loss:  0.056240486946807056 0.05455085111298075
===========>   training    <===========
Epoch: [206][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0692 (0.0692)	
0.99989843 5.648455e-07
===========>   testing    <===========
Epoch: [206][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0863 (0.0863)	
0.9998517 1.4866251e-06
Epoch: [206][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0374 (0.0768)	
0.9996996 1.2444673e-06
Epoch: [206][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0656 (0.0715)	
0.9998344 1.7171562e-06
loss:  0.05594208594082861 0.05455085111298075
===========>   training    <===========
Epoch: [207][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0668 (0.0668)	
0.99984956 6.753729e-07
===========>   testing    <===========
Epoch: [207][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0568 (0.0568)	
0.99986386 4.0354456e-07
Epoch: [207][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0294 (0.0793)	
0.9996594 8.4377086e-07
Epoch: [207][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1772 (0.0732)	
0.99984324 5.8818046e-07
loss:  0.05498607958814583 0.05455085111298075
===========>   training    <===========
Epoch: [208][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0661 (0.0661)	
0.9999049 9.543981e-06
===========>   testing    <===========
Epoch: [208][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0633 (0.0633)	
0.9998417 1.2917421e-05
Epoch: [208][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1680 (0.0804)	
0.9996972 1.6822383e-05
Epoch: [208][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0788 (0.0724)	
0.99985635 8.384676e-06
loss:  0.0580571001307687 0.05455085111298075
===========>   training    <===========
Epoch: [209][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0673 (0.0673)	
0.99991775 1.0744793e-06
===========>   testing    <===========
Epoch: [209][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0514 (0.0514)	
0.99986184 1.9758909e-06
Epoch: [209][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.2086 (0.0738)	
0.9996954 2.4609471e-06
Epoch: [209][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0543 (0.0705)	
0.99986434 3.2231467e-06
loss:  0.05442217610840161 0.05455085111298075
===========>   training    <===========
Epoch: [210][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0646 (0.0646)	
0.9998691 2.548945e-06
===========>   testing    <===========
Epoch: [210][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0586 (0.0586)	
0.99992704 4.9205e-06
Epoch: [210][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1593 (0.0797)	
0.9998417 5.356126e-06
Epoch: [210][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1229 (0.0736)	
0.99991775 3.783571e-06
loss:  0.05350688142198223 0.05442217610840161
===========>   training    <===========
Epoch: [211][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0618 (0.0618)	
0.9999002 1.6408753e-06
===========>   testing    <===========
Epoch: [211][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1475 (0.1475)	
0.9997875 1.6841071e-06
Epoch: [211][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0492 (0.0828)	
0.9996934 3.8787507e-06
Epoch: [211][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1463 (0.0765)	
0.9998099 3.3221443e-06
loss:  0.05773394736453297 0.05350688142198223
===========>   training    <===========
Epoch: [212][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0665 (0.0665)	
0.99987435 2.4800613e-07
===========>   testing    <===========
Epoch: [212][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0561 (0.0561)	
0.99985754 8.364126e-06
Epoch: [212][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0668 (0.0748)	
0.9997521 4.923063e-06
Epoch: [212][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0959 (0.0701)	
0.99988055 7.877024e-06
loss:  0.053885319096076634 0.05350688142198223
===========>   training    <===========
Epoch: [213][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0640 (0.0640)	
0.99985814 3.489495e-06
===========>   testing    <===========
Epoch: [213][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0678 (0.0678)	
0.9998766 7.076841e-06
Epoch: [213][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0339 (0.0745)	
0.9997552 9.757523e-06
Epoch: [213][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1115 (0.0693)	
0.9998568 4.7290305e-06
loss:  0.053656707267856874 0.05350688142198223
===========>   training    <===========
Epoch: [214][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0692 (0.0692)	
0.9999188 8.303296e-06
===========>   testing    <===========
Epoch: [214][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0492 (0.0492)	
0.99986494 2.1132353e-06
Epoch: [214][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1593 (0.0707)	
0.9997023 3.6641322e-06
Epoch: [214][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1027 (0.0668)	
0.99983144 3.2216224e-06
loss:  0.052993821273584096 0.05350688142198223
===========>   training    <===========
Epoch: [215][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0690 (0.0690)	
0.99986565 7.3890988e-06
===========>   testing    <===========
Epoch: [215][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0505 (0.0505)	
0.9998944 1.021887e-05
Epoch: [215][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0819 (0.0763)	
0.9997893 7.5199323e-06
Epoch: [215][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.2253 (0.0720)	
0.9998838 7.547197e-06
loss:  0.05404582472299824 0.052993821273584096
===========>   training    <===========
Epoch: [216][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0749 (0.0749)	
0.9999467 8.32391e-06
===========>   testing    <===========
Epoch: [216][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0723 (0.0723)	
0.9998728 3.2924959e-06
Epoch: [216][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0499 (0.0706)	
0.99976104 2.600525e-06
Epoch: [216][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1281 (0.0675)	
0.9998673 4.0969494e-06
loss:  0.05324435496119051 0.052993821273584096
===========>   training    <===========
Epoch: [217][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0460 (0.0460)	
0.9999013 2.2575092e-05
===========>   testing    <===========
Epoch: [217][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0960 (0.0960)	
0.999926 1.4499042e-06
Epoch: [217][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0474 (0.0755)	
0.9997727 1.6926313e-06
Epoch: [217][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1021 (0.0689)	
0.99991703 1.5561922e-06
loss:  0.05321845253654256 0.052993821273584096
===========>   training    <===========
Epoch: [218][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0770 (0.0770)	
0.99993134 7.561307e-07
===========>   testing    <===========
Epoch: [218][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0662 (0.0662)	
0.99991655 3.5452774e-06
Epoch: [218][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0284 (0.0746)	
0.99988866 6.4468045e-06
Epoch: [218][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1896 (0.0743)	
0.99990404 2.0943735e-06
loss:  0.05384916232495984 0.052993821273584096
===========>   training    <===========
Epoch: [219][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0683 (0.0683)	
0.9999405 6.5362283e-06
===========>   testing    <===========
Epoch: [219][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0995 (0.0995)	
0.99991834 3.0644699e-06
Epoch: [219][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.0322 (0.0740)	
0.99987185 2.5732766e-06
Epoch: [219][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005987369392383787]	Loss 0.1038 (0.0709)	
0.9999138 7.6712377e-07
loss:  0.053090387144368756 0.052993821273584096
===========>   training    <===========
Epoch: [220][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0736 (0.0736)	
0.9999269 4.7483817e-07
===========>   testing    <===========
Epoch: [220][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0960 (0.0960)	
0.99985516 4.3456844e-06
Epoch: [220][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0364 (0.0757)	
0.9997769 4.832656e-06
Epoch: [220][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1378 (0.0737)	
0.9998493 3.5895357e-06
loss:  0.05566591838888424 0.052993821273584096
===========>   training    <===========
Epoch: [221][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0602 (0.0602)	
0.9998869 4.843171e-06
===========>   testing    <===========
Epoch: [221][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0681 (0.0681)	
0.9998925 6.7551844e-07
Epoch: [221][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0499 (0.0846)	
0.9995714 1.2372924e-06
Epoch: [221][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.2337 (0.0824)	
0.9998785 6.00727e-07
loss:  0.06182566882186791 0.052993821273584096
===========>   training    <===========
Epoch: [222][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0690 (0.0690)	
0.99993145 1.9285264e-06
===========>   testing    <===========
Epoch: [222][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0649 (0.0649)	
0.9998896 7.5881945e-07
Epoch: [222][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0521 (0.0778)	
0.9997662 1.495498e-06
Epoch: [222][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1552 (0.0728)	
0.9998673 8.1974724e-07
loss:  0.05578620634932274 0.052993821273584096
===========>   training    <===========
Epoch: [223][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0693 (0.0693)	
0.99986565 3.0438482e-06
===========>   testing    <===========
Epoch: [223][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0827 (0.0827)	
0.9998752 1.1518424e-06
Epoch: [223][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0304 (0.0722)	
0.99952924 1.7834017e-06
Epoch: [223][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1101 (0.0707)	
0.9998561 1.279026e-06
loss:  0.054891974459856385 0.052993821273584096
===========>   training    <===========
Epoch: [224][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0742 (0.0742)	
0.9998627 1.4272593e-06
===========>   testing    <===========
Epoch: [224][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0799 (0.0799)	
0.9998585 2.9663306e-06
Epoch: [224][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0661 (0.0856)	
0.99979717 2.2826146e-06
Epoch: [224][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1987 (0.0834)	
0.99985063 2.6694097e-06
loss:  0.06059053871575215 0.052993821273584096
===========>   training    <===========
Epoch: [225][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0791 (0.0791)	
0.99991465 5.189079e-06
===========>   testing    <===========
Epoch: [225][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0554 (0.0554)	
0.9998845 2.814021e-06
Epoch: [225][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0515 (0.0788)	
0.99976414 4.929349e-06
Epoch: [225][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.2016 (0.0760)	
0.99987113 5.059612e-06
loss:  0.057664239235144854 0.052993821273584096
===========>   training    <===========
Epoch: [226][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0682 (0.0682)	
0.99988055 3.5662274e-06
===========>   testing    <===========
Epoch: [226][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0667 (0.0667)	
0.9998746 1.5929365e-06
Epoch: [226][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0779 (0.0765)	
0.9997621 2.2195268e-06
Epoch: [226][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1076 (0.0708)	
0.99983466 1.7013608e-06
loss:  0.05553915912923424 0.052993821273584096
===========>   training    <===========
Epoch: [227][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0722 (0.0722)	
0.9998915 1.930742e-06
===========>   testing    <===========
Epoch: [227][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0434 (0.0434)	
0.9998728 1.8958428e-06
Epoch: [227][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0286 (0.0723)	
0.9997366 1.2931849e-06
Epoch: [227][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1616 (0.0675)	
0.9998591 1.7509636e-06
loss:  0.050953800269220695 0.052993821273584096
===========>   training    <===========
Epoch: [228][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0600 (0.0600)	
0.999905 2.6113205e-06
===========>   testing    <===========
Epoch: [228][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0677 (0.0677)	
0.9998921 4.7400886e-06
Epoch: [228][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0292 (0.0748)	
0.9998578 4.4491208e-06
Epoch: [228][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1710 (0.0721)	
0.99986935 4.9047676e-06
loss:  0.05491111400585447 0.050953800269220695
===========>   training    <===========
Epoch: [229][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0874 (0.0874)	
0.9998349 7.450884e-07
===========>   testing    <===========
Epoch: [229][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0646 (0.0646)	
0.99986184 1.4871724e-06
Epoch: [229][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0293 (0.0835)	
0.9997774 1.4695661e-06
Epoch: [229][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.2233 (0.0801)	
0.9998604 1.3689714e-06
loss:  0.0595415675170502 0.050953800269220695
===========>   training    <===========
Epoch: [230][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0626 (0.0626)	
0.9999157 2.7270762e-06
===========>   testing    <===========
Epoch: [230][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0603 (0.0603)	
0.9998776 2.7014446e-06
Epoch: [230][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0556 (0.0720)	
0.9997564 3.7357593e-06
Epoch: [230][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1178 (0.0689)	
0.9998771 2.683146e-06
loss:  0.05286830050970737 0.050953800269220695
===========>   training    <===========
Epoch: [231][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0608 (0.0608)	
0.99981254 2.3101868e-06
===========>   testing    <===========
Epoch: [231][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0925 (0.0925)	
0.9998661 4.4879425e-06
Epoch: [231][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0271 (0.0769)	
0.99969494 4.5728552e-06
Epoch: [231][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1809 (0.0744)	
0.99988735 6.521416e-06
loss:  0.05403383042122012 0.050953800269220695
===========>   training    <===========
Epoch: [232][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0725 (0.0725)	
0.99993956 1.2602994e-06
===========>   testing    <===========
Epoch: [232][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0866 (0.0866)	
0.9998456 1.3753914e-06
Epoch: [232][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1109 (0.0739)	
0.9997776 1.3249811e-06
Epoch: [232][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0483 (0.0685)	
0.9998497 1.1746343e-06
loss:  0.05379813116521337 0.050953800269220695
===========>   training    <===========
Epoch: [233][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0643 (0.0643)	
0.9998983 3.2464254e-06
===========>   testing    <===========
Epoch: [233][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0759 (0.0759)	
0.9998826 9.672569e-07
Epoch: [233][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0380 (0.0722)	
0.999765 1.2797386e-06
Epoch: [233][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1336 (0.0706)	
0.999858 1.4335563e-06
loss:  0.05307624175618564 0.050953800269220695
===========>   training    <===========
Epoch: [234][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0626 (0.0626)	
0.9999051 4.042181e-06
===========>   testing    <===========
Epoch: [234][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0752 (0.0752)	
0.99986696 1.5283166e-06
Epoch: [234][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0760 (0.0763)	
0.9996618 3.3604522e-06
Epoch: [234][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1363 (0.0696)	
0.9998481 2.6035625e-06
loss:  0.05401506233908615 0.050953800269220695
===========>   training    <===========
Epoch: [235][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0735 (0.0735)	
0.9997683 2.467779e-06
===========>   testing    <===========
Epoch: [235][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0751 (0.0751)	
0.9999112 3.4620413e-07
Epoch: [235][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1297 (0.0702)	
0.99971277 1.0801156e-06
Epoch: [235][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1360 (0.0656)	
0.9999026 6.221465e-07
loss:  0.05114439632618295 0.050953800269220695
===========>   training    <===========
Epoch: [236][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0681 (0.0681)	
0.9999281 2.2206207e-07
===========>   testing    <===========
Epoch: [236][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0912 (0.0912)	
0.99990284 2.1738986e-06
Epoch: [236][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1123 (0.0723)	
0.99985397 4.4990584e-06
Epoch: [236][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0750 (0.0664)	
0.9999076 2.5920817e-06
loss:  0.05141310228615681 0.050953800269220695
===========>   training    <===========
Epoch: [237][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0629 (0.0629)	
0.99993956 5.0749786e-06
===========>   testing    <===========
Epoch: [237][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0596 (0.0596)	
0.9998648 5.3222143e-06
Epoch: [237][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.3940 (0.0789)	
0.9996915 6.533343e-06
Epoch: [237][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1034 (0.0728)	
0.9998499 7.1202744e-06
loss:  0.05601133440037931 0.050953800269220695
===========>   training    <===========
Epoch: [238][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0756 (0.0756)	
0.9999045 1.7155782e-06
===========>   testing    <===========
Epoch: [238][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0876 (0.0876)	
0.99984384 1.6469913e-07
Epoch: [238][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0445 (0.0796)	
0.99955744 3.3577118e-07
Epoch: [238][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0964 (0.0710)	
0.9998375 3.4055245e-07
loss:  0.05451456393718601 0.050953800269220695
===========>   training    <===========
Epoch: [239][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0647 (0.0647)	
0.9999027 5.4051475e-07
===========>   testing    <===========
Epoch: [239][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.1004 (0.1004)	
0.9998845 1.6552785e-06
Epoch: [239][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0363 (0.0770)	
0.9997706 1.2596867e-06
Epoch: [239][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005688000922764596]	Loss 0.0401 (0.0675)	
0.99987376 1.8105536e-06
loss:  0.053783074338117576 0.050953800269220695
===========>   training    <===========
Epoch: [240][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0780 (0.0780)	
0.9997938 2.6687198e-07
===========>   testing    <===========
Epoch: [240][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0636 (0.0636)	
0.9998703 5.612837e-07
Epoch: [240][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0409 (0.0754)	
0.9998056 9.551069e-07
Epoch: [240][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1668 (0.0719)	
0.99987745 9.553446e-07
loss:  0.05417626330086667 0.050953800269220695
===========>   training    <===========
Epoch: [241][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0704 (0.0704)	
0.99985945 2.7957196e-07
===========>   testing    <===========
Epoch: [241][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1345 (0.1345)	
0.9998393 3.2254297e-07
Epoch: [241][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0661 (0.0817)	
0.99954444 8.9519637e-07
Epoch: [241][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0997 (0.0747)	
0.9998215 4.41426e-07
loss:  0.0554684093217056 0.050953800269220695
===========>   training    <===========
Epoch: [242][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0785 (0.0785)	
0.99991035 5.652227e-07
===========>   testing    <===========
Epoch: [242][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0800 (0.0800)	
0.99987423 5.7951786e-07
Epoch: [242][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0283 (0.0700)	
0.9997881 6.618743e-07
Epoch: [242][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1818 (0.0656)	
0.99985456 1.0520723e-06
loss:  0.05143882909764663 0.050953800269220695
===========>   training    <===========
Epoch: [243][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0807 (0.0807)	
0.9998802 6.898102e-07
===========>   testing    <===========
Epoch: [243][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1311 (0.1311)	
0.9998832 1.1406366e-06
Epoch: [243][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0383 (0.0794)	
0.9997651 1.944798e-06
Epoch: [243][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1565 (0.0729)	
0.9998565 2.542834e-06
loss:  0.05527691747776475 0.050953800269220695
===========>   training    <===========
Epoch: [244][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0647 (0.0647)	
0.9999039 1.9157353e-06
===========>   testing    <===========
Epoch: [244][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0880 (0.0880)	
0.9999099 1.4503757e-06
Epoch: [244][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0704 (0.0697)	
0.99979275 1.5690184e-06
Epoch: [244][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0799 (0.0667)	
0.99988294 3.0311314e-06
loss:  0.04931653209264475 0.050953800269220695
===========>   training    <===========
Epoch: [245][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0652 (0.0652)	
0.9999083 2.871039e-06
===========>   testing    <===========
Epoch: [245][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1008 (0.1008)	
0.9998996 7.218856e-07
Epoch: [245][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0424 (0.0709)	
0.99982613 6.281519e-07
Epoch: [245][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1456 (0.0673)	
0.999874 1.3830478e-06
loss:  0.05105745664853689 0.04931653209264475
===========>   training    <===========
Epoch: [246][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0613 (0.0613)	
0.9999517 3.6334345e-06
===========>   testing    <===========
Epoch: [246][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0477 (0.0477)	
0.9998795 1.2003176e-06
Epoch: [246][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0358 (0.0708)	
0.99965703 1.3950481e-06
Epoch: [246][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1312 (0.0678)	
0.9998822 1.519324e-06
loss:  0.05161379274357758 0.04931653209264475
===========>   training    <===========
Epoch: [247][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0659 (0.0659)	
0.9999099 9.770839e-06
===========>   testing    <===========
Epoch: [247][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0653 (0.0653)	
0.99988675 5.3211334e-06
Epoch: [247][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0293 (0.0744)	
0.99978286 7.181439e-06
Epoch: [247][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0880 (0.0695)	
0.9998765 6.8515453e-07
loss:  0.05207521846600971 0.04931653209264475
===========>   training    <===========
Epoch: [248][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0668 (0.0668)	
0.9998925 1.5205503e-06
===========>   testing    <===========
Epoch: [248][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1060 (0.1060)	
0.99988437 3.1592895e-06
Epoch: [248][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.3769 (0.0859)	
0.9997652 1.3797426e-06
Epoch: [248][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0794 (0.0780)	
0.9998884 1.3154778e-06
loss:  0.05877490972801602 0.04931653209264475
===========>   training    <===========
Epoch: [249][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0694 (0.0694)	
0.9998617 1.7476339e-06
===========>   testing    <===========
Epoch: [249][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0832 (0.0832)	
0.9999113 1.5566433e-06
Epoch: [249][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0362 (0.0728)	
0.99986553 2.000067e-06
Epoch: [249][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1527 (0.0685)	
0.9999076 1.6370225e-06
loss:  0.052786237882872955 0.04931653209264475
===========>   training    <===========
Epoch: [250][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0696 (0.0696)	
0.99992824 4.802302e-07
===========>   testing    <===========
Epoch: [250][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0863 (0.0863)	
0.9998772 6.074373e-07
Epoch: [250][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0363 (0.0738)	
0.99981207 5.402525e-07
Epoch: [250][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1141 (0.0693)	
0.999895 6.5911286e-07
loss:  0.053096212452021896 0.04931653209264475
===========>   training    <===========
Epoch: [251][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0662 (0.0662)	
0.9998722 4.4255395e-07
===========>   testing    <===========
Epoch: [251][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0765 (0.0765)	
0.99988663 4.1649264e-07
Epoch: [251][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0428 (0.0784)	
0.9997899 1.0817442e-06
Epoch: [251][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0540 (0.0715)	
0.9998555 6.573514e-07
loss:  0.053668211892966 0.04931653209264475
===========>   training    <===========
Epoch: [252][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0637 (0.0637)	
0.99982697 2.1625496e-07
===========>   testing    <===========
Epoch: [252][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0652 (0.0652)	
0.99987614 7.6589714e-07
Epoch: [252][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0367 (0.0743)	
0.9998148 6.7463003e-07
Epoch: [252][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1082 (0.0701)	
0.9998723 7.0754845e-07
loss:  0.053417297304271694 0.04931653209264475
===========>   training    <===========
Epoch: [253][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0590 (0.0590)	
0.9998863 8.539531e-07
===========>   testing    <===========
Epoch: [253][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0574 (0.0574)	
0.9998642 3.166174e-07
Epoch: [253][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0348 (0.0710)	
0.99960786 6.597669e-07
Epoch: [253][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1392 (0.0683)	
0.9998535 3.4701895e-07
loss:  0.051686337317649045 0.04931653209264475
===========>   training    <===========
Epoch: [254][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0623 (0.0623)	
0.9998498 9.4944636e-07
===========>   testing    <===========
Epoch: [254][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0705 (0.0705)	
0.9998895 2.2757633e-06
Epoch: [254][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0948 (0.0786)	
0.9997446 3.8424173e-06
Epoch: [254][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0624 (0.0721)	
0.9998616 3.2014389e-06
loss:  0.056990856398665524 0.04931653209264475
===========>   training    <===========
Epoch: [255][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0740 (0.0740)	
0.99990857 9.494701e-08
===========>   testing    <===========
Epoch: [255][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0837 (0.0837)	
0.9998622 6.566121e-07
Epoch: [255][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0493 (0.0748)	
0.99974245 9.4674016e-07
Epoch: [255][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0835 (0.0678)	
0.9998603 8.602487e-07
loss:  0.051301040157893496 0.04931653209264475
===========>   training    <===========
Epoch: [256][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0712 (0.0712)	
0.99981517 4.5813047e-07
===========>   testing    <===========
Epoch: [256][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0464 (0.0464)	
0.99986756 6.146925e-07
Epoch: [256][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0281 (0.0707)	
0.99982244 1.887384e-06
Epoch: [256][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1274 (0.0650)	
0.9998677 1.0598133e-06
loss:  0.05070335209150456 0.04931653209264475
===========>   training    <===========
Epoch: [257][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0704 (0.0704)	
0.9998591 2.6804196e-07
===========>   testing    <===========
Epoch: [257][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0912 (0.0912)	
0.99990416 7.349683e-08
Epoch: [257][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0437 (0.0728)	
0.9997712 2.4928852e-07
Epoch: [257][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1301 (0.0660)	
0.9998871 2.2366845e-07
loss:  0.050529939746035146 0.04931653209264475
===========>   training    <===========
Epoch: [258][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0648 (0.0648)	
0.9998235 2.1900829e-07
===========>   testing    <===========
Epoch: [258][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0662 (0.0662)	
0.9999094 1.3196504e-07
Epoch: [258][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0352 (0.0828)	
0.99981064 1.7456154e-07
Epoch: [258][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0679 (0.0736)	
0.9998989 1.383491e-07
loss:  0.0559484981954419 0.04931653209264475
===========>   training    <===========
Epoch: [259][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0862 (0.0862)	
0.99986947 1.7280267e-07
===========>   testing    <===========
Epoch: [259][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0856 (0.0856)	
0.99988914 2.6860494e-06
Epoch: [259][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.0748 (0.0738)	
0.9998522 6.6565867e-06
Epoch: [259][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005403600876626366]	Loss 0.1472 (0.0692)	
0.9998684 4.5609395e-06
loss:  0.052516136945293 0.04931653209264475
===========>   training    <===========
Epoch: [260][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0550 (0.0550)	
0.99990046 3.0115444e-07
===========>   testing    <===========
Epoch: [260][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0883 (0.0883)	
0.9998468 5.907061e-07
Epoch: [260][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0815 (0.0738)	
0.9997497 1.3432744e-06
Epoch: [260][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1903 (0.0665)	
0.99984336 6.1026503e-07
loss:  0.051815002678162525 0.04931653209264475
===========>   training    <===========
Epoch: [261][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0762 (0.0762)	
0.99985576 3.8106398e-07
===========>   testing    <===========
Epoch: [261][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0651 (0.0651)	
0.99987483 2.0873904e-06
Epoch: [261][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0392 (0.0743)	
0.99974614 3.402464e-06
Epoch: [261][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1830 (0.0691)	
0.99984455 2.5558388e-06
loss:  0.05449055404878722 0.04931653209264475
===========>   training    <===========
Epoch: [262][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0520 (0.0520)	
0.9999045 2.5089798e-06
===========>   testing    <===========
Epoch: [262][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0644 (0.0644)	
0.99988437 2.0448533e-06
Epoch: [262][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0312 (0.0695)	
0.99973327 2.716996e-06
Epoch: [262][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.2051 (0.0665)	
0.9998605 4.024833e-06
loss:  0.04959095583132489 0.04931653209264475
===========>   training    <===========
Epoch: [263][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0682 (0.0682)	
0.99992836 1.1101295e-06
===========>   testing    <===========
Epoch: [263][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0733 (0.0733)	
0.999908 7.1752297e-06
Epoch: [263][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0374 (0.0726)	
0.9998714 7.2016505e-06
Epoch: [263][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.2420 (0.0681)	
0.99989784 7.24811e-06
loss:  0.05403519816394586 0.04931653209264475
===========>   training    <===========
Epoch: [264][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0653 (0.0653)	
0.9999374 2.2634347e-06
===========>   testing    <===========
Epoch: [264][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0626 (0.0626)	
0.99991477 6.8530744e-07
Epoch: [264][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0260 (0.0809)	
0.9998666 1.9339948e-06
Epoch: [264][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1464 (0.0724)	
0.99989235 1.1309457e-06
loss:  0.0587201623213085 0.04931653209264475
===========>   training    <===========
Epoch: [265][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0608 (0.0608)	
0.9999161 1.5075293e-06
===========>   testing    <===========
Epoch: [265][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0655 (0.0655)	
0.9999083 2.7022153e-07
Epoch: [265][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0402 (0.0651)	
0.99978834 7.921423e-07
Epoch: [265][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1268 (0.0620)	
0.99987924 4.34914e-07
loss:  0.048683702738901435 0.04931653209264475
===========>   training    <===========
Epoch: [266][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0681 (0.0681)	
0.9999014 1.1829466e-06
===========>   testing    <===========
Epoch: [266][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0883 (0.0883)	
0.99988866 2.35527e-06
Epoch: [266][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0581 (0.0817)	
0.999813 3.161363e-06
Epoch: [266][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1068 (0.0740)	
0.9998778 2.3959128e-06
loss:  0.055068583551116546 0.048683702738901435
===========>   training    <===========
Epoch: [267][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0666 (0.0666)	
0.9999181 1.7841536e-06
===========>   testing    <===========
Epoch: [267][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0462 (0.0462)	
0.9998975 7.649227e-07
Epoch: [267][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0329 (0.0705)	
0.99968004 6.56941e-07
Epoch: [267][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1715 (0.0679)	
0.99986947 5.8366e-07
loss:  0.05434321523553631 0.048683702738901435
===========>   training    <===========
Epoch: [268][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0672 (0.0672)	
0.9997731 1.8118906e-06
===========>   testing    <===========
Epoch: [268][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1319 (0.1319)	
0.9998746 3.3891608e-06
Epoch: [268][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0857 (0.0724)	
0.9998048 4.305324e-06
Epoch: [268][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0436 (0.0682)	
0.99986684 4.02805e-06
loss:  0.05251741392907039 0.048683702738901435
===========>   training    <===========
Epoch: [269][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0673 (0.0673)	
0.9998908 5.7846046e-07
===========>   testing    <===========
Epoch: [269][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1076 (0.1076)	
0.99989474 2.66886e-06
Epoch: [269][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0327 (0.0748)	
0.9998467 4.635985e-06
Epoch: [269][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1625 (0.0684)	
0.99986935 8.119869e-06
loss:  0.05175365786357844 0.048683702738901435
===========>   training    <===========
Epoch: [270][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0725 (0.0725)	
0.9998611 4.3345977e-07
===========>   testing    <===========
Epoch: [270][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1150 (0.1150)	
0.9999069 6.21624e-07
Epoch: [270][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0594 (0.0731)	
0.9998448 7.191474e-07
Epoch: [270][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1114 (0.0699)	
0.99989426 8.977912e-07
loss:  0.05424235281770551 0.048683702738901435
===========>   training    <===========
Epoch: [271][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0646 (0.0646)	
0.999926 1.6840383e-07
===========>   testing    <===========
Epoch: [271][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0760 (0.0760)	
0.99990773 5.353688e-07
Epoch: [271][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0296 (0.0703)	
0.9998185 1.1491816e-06
Epoch: [271][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0480 (0.0634)	
0.99988604 1.0112695e-06
loss:  0.05085936420750137 0.048683702738901435
===========>   training    <===========
Epoch: [272][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0595 (0.0595)	
0.9999461 3.7315004e-07
===========>   testing    <===========
Epoch: [272][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0908 (0.0908)	
0.99990475 1.9130005e-06
Epoch: [272][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0306 (0.0744)	
0.999818 3.4282702e-06
Epoch: [272][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1552 (0.0687)	
0.9998876 2.7329654e-06
loss:  0.05273905746221674 0.048683702738901435
===========>   training    <===========
Epoch: [273][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0698 (0.0698)	
0.9998791 1.304557e-07
===========>   testing    <===========
Epoch: [273][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0572 (0.0572)	
0.9999268 6.796904e-07
Epoch: [273][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0290 (0.0762)	
0.9998815 8.993122e-07
Epoch: [273][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0888 (0.0708)	
0.9999062 4.208727e-07
loss:  0.05429218936905533 0.048683702738901435
===========>   training    <===========
Epoch: [274][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0539 (0.0539)	
0.99995065 2.6250486e-06
===========>   testing    <===========
Epoch: [274][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0675 (0.0675)	
0.99990284 2.096128e-06
Epoch: [274][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0435 (0.0694)	
0.9998373 2.6692492e-06
Epoch: [274][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0955 (0.0664)	
0.9999056 2.337737e-06
loss:  0.04918576615052073 0.048683702738901435
===========>   training    <===========
Epoch: [275][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0666 (0.0666)	
0.9999201 3.099419e-06
===========>   testing    <===========
Epoch: [275][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0685 (0.0685)	
0.99990416 2.3841608e-06
Epoch: [275][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0313 (0.0696)	
0.9998758 2.2072902e-06
Epoch: [275][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1789 (0.0665)	
0.9998944 2.8884176e-06
loss:  0.05021456580140993 0.048683702738901435
===========>   training    <===========
Epoch: [276][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0702 (0.0702)	
0.9999335 3.979088e-06
===========>   testing    <===========
Epoch: [276][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0596 (0.0596)	
0.99990165 4.083392e-07
Epoch: [276][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0552 (0.0784)	
0.9997179 5.2630725e-07
Epoch: [276][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1579 (0.0717)	
0.99988174 4.4332785e-07
loss:  0.05524738189661782 0.048683702738901435
===========>   training    <===========
Epoch: [277][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0625 (0.0625)	
0.9999274 4.72441e-07
===========>   testing    <===========
Epoch: [277][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0859 (0.0859)	
0.99991405 1.7300032e-06
Epoch: [277][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0820 (0.0737)	
0.9998746 2.755354e-06
Epoch: [277][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0542 (0.0659)	
0.999908 2.3461234e-06
loss:  0.051279051329282344 0.048683702738901435
===========>   training    <===========
Epoch: [278][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0619 (0.0619)	
0.9999262 9.77051e-07
===========>   testing    <===========
Epoch: [278][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0597 (0.0597)	
0.99993014 1.2372228e-06
Epoch: [278][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0327 (0.0761)	
0.99985003 1.3450305e-06
Epoch: [278][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.1190 (0.0684)	
0.99991274 9.696917e-07
loss:  0.051299947837675 0.048683702738901435
===========>   training    <===========
Epoch: [279][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0616 (0.0616)	
0.99994457 3.4134882e-06
===========>   testing    <===========
Epoch: [279][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0719 (0.0719)	
0.99994266 6.8563565e-07
Epoch: [279][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0356 (0.0683)	
0.99988985 7.168494e-07
Epoch: [279][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0005133420832795048]	Loss 0.0863 (0.0647)	
0.99992585 9.483251e-07
loss:  0.050307216316613834 0.048683702738901435
===========>   training    <===========
Epoch: [280][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0911 (0.0911)	
0.9999535 3.0809413e-06
===========>   testing    <===========
Epoch: [280][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0486 (0.0486)	
0.9999503 1.081734e-06
Epoch: [280][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0281 (0.0714)	
0.99984634 2.4659769e-06
Epoch: [280][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1230 (0.0656)	
0.9999294 2.3949033e-06
loss:  0.050711083059204354 0.048683702738901435
===========>   training    <===========
Epoch: [281][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0512 (0.0512)	
0.9999324 1.6423704e-06
===========>   testing    <===========
Epoch: [281][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0626 (0.0626)	
0.9999465 4.7254238e-07
Epoch: [281][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0493 (0.0650)	
0.99990356 1.3253249e-06
Epoch: [281][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0788 (0.0609)	
0.9999201 1.2494859e-06
loss:  0.04789572829482813 0.048683702738901435
===========>   training    <===========
Epoch: [282][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0655 (0.0655)	
0.9999347 4.835372e-07
===========>   testing    <===========
Epoch: [282][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0795 (0.0795)	
0.9999329 7.705855e-06
Epoch: [282][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0507 (0.0775)	
0.9998661 9.598445e-06
Epoch: [282][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1121 (0.0716)	
0.9999206 1.05514855e-05
loss:  0.05375456846247928 0.04789572829482813
===========>   training    <===========
Epoch: [283][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0587 (0.0587)	
0.99994195 4.937611e-06
===========>   testing    <===========
Epoch: [283][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0547 (0.0547)	
0.9999474 1.0398599e-06
Epoch: [283][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0275 (0.0738)	
0.9998826 2.5190784e-06
Epoch: [283][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1503 (0.0670)	
0.9999198 1.1975095e-06
loss:  0.05221708720744411 0.04789572829482813
===========>   training    <===========
Epoch: [284][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0730 (0.0730)	
0.9999509 3.1579493e-06
===========>   testing    <===========
Epoch: [284][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0861 (0.0861)	
0.99993145 4.4359427e-07
Epoch: [284][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0391 (0.0710)	
0.9998797 9.722576e-07
Epoch: [284][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0874 (0.0656)	
0.9999105 9.951119e-07
loss:  0.05208151886671586 0.04789572829482813
===========>   training    <===========
Epoch: [285][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0683 (0.0683)	
0.9999422 2.8490692e-07
===========>   testing    <===========
Epoch: [285][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0505 (0.0505)	
0.99992657 2.6100957e-07
Epoch: [285][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1919 (0.0712)	
0.9998591 6.4648776e-07
Epoch: [285][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1233 (0.0649)	
0.99991655 6.5636476e-07
loss:  0.05040881494019067 0.04789572829482813
===========>   training    <===========
Epoch: [286][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0695 (0.0695)	
0.999964 6.2767676e-06
===========>   testing    <===========
Epoch: [286][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0770 (0.0770)	
0.9999285 6.1028487e-07
Epoch: [286][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1122 (0.0683)	
0.9998235 7.548548e-07
Epoch: [286][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0741 (0.0623)	
0.9998888 8.2761505e-07
loss:  0.04866856166631606 0.04789572829482813
===========>   training    <===========
Epoch: [287][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0654 (0.0654)	
0.9999411 1.5123244e-06
===========>   testing    <===========
Epoch: [287][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0494 (0.0494)	
0.9999491 2.1023571e-07
Epoch: [287][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0329 (0.0767)	
0.99989223 5.149996e-07
Epoch: [287][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1363 (0.0691)	
0.9999356 4.952504e-07
loss:  0.0515295769134837 0.04789572829482813
===========>   training    <===========
Epoch: [288][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0794 (0.0794)	
0.9999646 1.9392473e-06
===========>   testing    <===========
Epoch: [288][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0511 (0.0511)	
0.99994814 1.078407e-06
Epoch: [288][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0517 (0.0797)	
0.9999 2.241892e-06
Epoch: [288][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1410 (0.0721)	
0.9999373 3.9397164e-06
loss:  0.055507705538333174 0.04789572829482813
===========>   training    <===========
Epoch: [289][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0573 (0.0573)	
0.99994373 3.503616e-07
===========>   testing    <===========
Epoch: [289][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0817 (0.0817)	
0.99995136 3.2900823e-06
Epoch: [289][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0484 (0.0725)	
0.99990034 1.8652619e-06
Epoch: [289][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0687 (0.0657)	
0.99993753 3.942035e-06
loss:  0.04999611901967138 0.04789572829482813
===========>   training    <===========
Epoch: [290][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0990 (0.0990)	
0.9999193 9.23812e-09
===========>   testing    <===========
Epoch: [290][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0870 (0.0870)	
0.99995816 1.2856543e-06
Epoch: [290][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.2858 (0.0850)	
0.99992716 6.7234987e-07
Epoch: [290][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0595 (0.0721)	
0.99992025 1.7869224e-06
loss:  0.054892384551469386 0.04789572829482813
===========>   training    <===========
Epoch: [291][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0641 (0.0641)	
0.9999504 2.1048307e-07
===========>   testing    <===========
Epoch: [291][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0784 (0.0784)	
0.99990845 2.280878e-06
Epoch: [291][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0772 (0.0798)	
0.99989367 4.163134e-06
Epoch: [291][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.2153 (0.0741)	
0.9999238 5.560169e-06
loss:  0.05605300301100946 0.04789572829482813
===========>   training    <===========
Epoch: [292][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0683 (0.0683)	
0.9999294 2.161963e-06
===========>   testing    <===========
Epoch: [292][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0525 (0.0525)	
0.9999125 3.136585e-06
Epoch: [292][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0248 (0.0743)	
0.99987555 1.5324324e-06
Epoch: [292][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.2170 (0.0710)	
0.999912 1.4617874e-06
loss:  0.05369825984760834 0.04789572829482813
===========>   training    <===========
Epoch: [293][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0623 (0.0623)	
0.9999409 7.956667e-07
===========>   testing    <===========
Epoch: [293][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0984 (0.0984)	
0.99991095 5.155544e-07
Epoch: [293][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0988 (0.0737)	
0.9998424 8.930647e-07
Epoch: [293][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1401 (0.0693)	
0.9998987 4.826103e-07
loss:  0.05264985320954496 0.04789572829482813
===========>   training    <===========
Epoch: [294][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0675 (0.0675)	
0.9999281 1.0611842e-05
===========>   testing    <===========
Epoch: [294][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0499 (0.0499)	
0.9999044 5.406256e-07
Epoch: [294][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0301 (0.0719)	
0.999894 5.4298283e-07
Epoch: [294][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1558 (0.0674)	
0.99990225 7.752276e-07
loss:  0.0505193192506217 0.04789572829482813
===========>   training    <===========
Epoch: [295][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0607 (0.0607)	
0.9998271 1.1209648e-06
===========>   testing    <===========
Epoch: [295][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0708 (0.0708)	
0.9999126 1.5964314e-06
Epoch: [295][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0360 (0.0704)	
0.9998591 1.5899345e-06
Epoch: [295][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1476 (0.0662)	
0.999881 2.4143176e-06
loss:  0.05096431077341956 0.04789572829482813
===========>   training    <===========
Epoch: [296][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0634 (0.0634)	
0.9999231 1.4801839e-07
===========>   testing    <===========
Epoch: [296][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0788 (0.0788)	
0.99992156 1.1774922e-06
Epoch: [296][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0364 (0.0703)	
0.9998073 2.0677799e-06
Epoch: [296][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0962 (0.0637)	
0.9999081 3.888974e-06
loss:  0.04863438012799148 0.04789572829482813
===========>   training    <===========
Epoch: [297][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0595 (0.0595)	
0.9998833 7.7617614e-08
===========>   testing    <===========
Epoch: [297][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0759 (0.0759)	
0.9998945 2.8203354e-07
Epoch: [297][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0441 (0.0749)	
0.9998516 4.5857635e-07
Epoch: [297][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1798 (0.0710)	
0.9999018 6.010903e-07
loss:  0.05364400111873291 0.04789572829482813
===========>   training    <===========
Epoch: [298][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0580 (0.0580)	
0.9999391 1.47391e-06
===========>   testing    <===========
Epoch: [298][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0896 (0.0896)	
0.99993074 2.2827453e-06
Epoch: [298][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.2852 (0.0822)	
0.9998952 2.1295232e-06
Epoch: [298][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.1423 (0.0744)	
0.9999343 4.3162677e-06
loss:  0.05633716781717191 0.04789572829482813
===========>   training    <===========
Epoch: [299][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0647 (0.0647)	
0.9999349 1.4786362e-06
===========>   testing    <===========
Epoch: [299][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0704 (0.0704)	
0.9999229 2.5242824e-07
Epoch: [299][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.2370 (0.0779)	
0.9998981 2.2484879e-07
Epoch: [299][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00048767497911552955]	Loss 0.0951 (0.0711)	
0.9999243 3.4446785e-07
loss:  0.05359611276398413 0.04789572829482813
===========>   training    <===========
Epoch: [300][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0558 (0.0558)	
0.99991083 1.6032391e-06
===========>   testing    <===========
Epoch: [300][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0479 (0.0479)	
0.99990034 5.335258e-07
Epoch: [300][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0374 (0.0738)	
0.9998209 5.7885177e-07
Epoch: [300][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1531 (0.0699)	
0.9998977 4.3349866e-07
loss:  0.053795574810021285 0.04789572829482813
===========>   training    <===========
Epoch: [301][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0624 (0.0624)	
0.9999399 8.238939e-06
===========>   testing    <===========
Epoch: [301][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0646 (0.0646)	
0.99991524 1.08568244e-07
Epoch: [301][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0378 (0.0730)	
0.9998233 1.4915214e-07
Epoch: [301][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1277 (0.0670)	
0.9999198 3.0305944e-07
loss:  0.049932959567364654 0.04789572829482813
===========>   training    <===========
Epoch: [302][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0622 (0.0622)	
0.999881 2.7294442e-07
===========>   testing    <===========
Epoch: [302][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0818 (0.0818)	
0.9999057 1.1296592e-07
Epoch: [302][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1560 (0.0779)	
0.9998085 1.498712e-07
Epoch: [302][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1303 (0.0714)	
0.99991345 1.4266945e-07
loss:  0.052405143517783914 0.04789572829482813
===========>   training    <===========
Epoch: [303][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0719 (0.0719)	
0.99990654 3.4266972e-07
===========>   testing    <===========
Epoch: [303][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0723 (0.0723)	
0.99992466 8.292378e-07
Epoch: [303][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0696 (0.0731)	
0.99987364 1.3163436e-06
Epoch: [303][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1356 (0.0682)	
0.9999124 1.8202453e-06
loss:  0.05034005969115607 0.04789572829482813
===========>   training    <===========
Epoch: [304][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0537 (0.0537)	
0.999931 4.4601603e-07
===========>   testing    <===========
Epoch: [304][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0679 (0.0679)	
0.9999263 2.52229e-06
Epoch: [304][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0619 (0.0704)	
0.9998635 2.1845747e-06
Epoch: [304][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0963 (0.0642)	
0.9999087 2.3491818e-06
loss:  0.04850710437503902 0.04789572829482813
===========>   training    <===========
Epoch: [305][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0695 (0.0695)	
0.9999182 1.4656556e-06
===========>   testing    <===========
Epoch: [305][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0522 (0.0522)	
0.9999211 2.811331e-07
Epoch: [305][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0303 (0.0685)	
0.999879 3.9890244e-07
Epoch: [305][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1153 (0.0644)	
0.9999175 4.114194e-07
loss:  0.0484876919251902 0.04789572829482813
===========>   training    <===========
Epoch: [306][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0624 (0.0624)	
0.9999379 4.748934e-07
===========>   testing    <===========
Epoch: [306][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0500 (0.0500)	
0.9999206 2.3076655e-06
Epoch: [306][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0318 (0.0674)	
0.999864 1.8517138e-06
Epoch: [306][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0848 (0.0630)	
0.9999033 2.501392e-06
loss:  0.047955075499952926 0.04789572829482813
===========>   training    <===========
Epoch: [307][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0664 (0.0664)	
0.9999403 6.8196806e-07
===========>   testing    <===========
Epoch: [307][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0711 (0.0711)	
0.9999237 4.369828e-07
Epoch: [307][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0573 (0.0648)	
0.99987245 7.9133366e-07
Epoch: [307][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1150 (0.0640)	
0.9999132 1.5072346e-06
loss:  0.050278946499657806 0.04789572829482813
===========>   training    <===========
Epoch: [308][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0732 (0.0732)	
0.9999467 7.0936727e-07
===========>   testing    <===========
Epoch: [308][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0898 (0.0898)	
0.9999298 6.82512e-07
Epoch: [308][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0563 (0.0681)	
0.99988806 1.026187e-06
Epoch: [308][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1130 (0.0612)	
0.99990356 1.3996137e-06
loss:  0.046958838078881904 0.04789572829482813
===========>   training    <===========
Epoch: [309][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0591 (0.0591)	
0.99992514 1.0717806e-06
===========>   testing    <===========
Epoch: [309][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0767 (0.0767)	
0.9999347 5.699829e-07
Epoch: [309][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0334 (0.0670)	
0.99987316 3.1605654e-07
Epoch: [309][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0712 (0.0613)	
0.9999107 9.572224e-07
loss:  0.04718376934193458 0.046958838078881904
===========>   training    <===========
Epoch: [310][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0601 (0.0601)	
0.9999342 3.430392e-07
===========>   testing    <===========
Epoch: [310][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0557 (0.0557)	
0.9999391 4.2725677e-07
Epoch: [310][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.2859 (0.0758)	
0.9998393 6.54162e-07
Epoch: [310][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1355 (0.0654)	
0.9999206 6.769023e-07
loss:  0.04796647231237916 0.046958838078881904
===========>   training    <===========
Epoch: [311][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0570 (0.0570)	
0.9999343 6.592499e-07
===========>   testing    <===========
Epoch: [311][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0606 (0.0606)	
0.9999354 1.6498412e-06
Epoch: [311][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0769 (0.0726)	
0.99990666 2.1490825e-06
Epoch: [311][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1312 (0.0665)	
0.9999249 5.181395e-06
loss:  0.0500418262237583 0.046958838078881904
===========>   training    <===========
Epoch: [312][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0595 (0.0595)	
0.9999666 2.7189145e-07
===========>   testing    <===========
Epoch: [312][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0852 (0.0852)	
0.9998318 1.1074986e-06
Epoch: [312][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0572 (0.0678)	
0.9998611 1.8477782e-06
Epoch: [312][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1035 (0.0631)	
0.99990404 1.17099546e-07
loss:  0.04922832734542559 0.046958838078881904
===========>   training    <===========
Epoch: [313][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0630 (0.0630)	
0.9999316 9.166456e-07
===========>   testing    <===========
Epoch: [313][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0489 (0.0489)	
0.99995124 1.0507047e-06
Epoch: [313][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0493 (0.0701)	
0.9999043 1.0842292e-06
Epoch: [313][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0901 (0.0659)	
0.99993825 2.010156e-06
loss:  0.048962402420539286 0.046958838078881904
===========>   training    <===========
Epoch: [314][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0536 (0.0536)	
0.9999665 3.294167e-06
===========>   testing    <===========
Epoch: [314][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0415 (0.0415)	
0.99993455 2.7856356e-07
Epoch: [314][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0436 (0.0665)	
0.9998591 4.4045586e-07
Epoch: [314][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1397 (0.0624)	
0.9999064 4.6939923e-07
loss:  0.048906670756563075 0.046958838078881904
===========>   training    <===========
Epoch: [315][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0592 (0.0592)	
0.9999496 6.3279964e-07
===========>   testing    <===========
Epoch: [315][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0573 (0.0573)	
0.9999335 1.0994082e-06
Epoch: [315][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0380 (0.0724)	
0.9998733 1.0062104e-06
Epoch: [315][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1399 (0.0656)	
0.99993217 1.6561486e-06
loss:  0.0494569801492325 0.046958838078881904
===========>   training    <===========
Epoch: [316][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0573 (0.0573)	
0.9999416 1.280186e-05
===========>   testing    <===========
Epoch: [316][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1157 (0.1157)	
0.9999275 1.8189682e-07
Epoch: [316][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0277 (0.0771)	
0.9998362 2.6955337e-07
Epoch: [316][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0760 (0.0710)	
0.99991286 2.6693536e-07
loss:  0.052724212116963765 0.046958838078881904
===========>   training    <===========
Epoch: [317][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0613 (0.0613)	
0.99995327 2.1450426e-06
===========>   testing    <===========
Epoch: [317][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0909 (0.0909)	
0.9999361 4.8792765e-07
Epoch: [317][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0519 (0.0694)	
0.9997584 5.112419e-07
Epoch: [317][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0898 (0.0640)	
0.9999143 2.7019676e-06
loss:  0.04803975859654519 0.046958838078881904
===========>   training    <===========
Epoch: [318][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0505 (0.0505)	
0.9999541 6.7525565e-07
===========>   testing    <===========
Epoch: [318][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0652 (0.0652)	
0.9999511 2.8523806e-07
Epoch: [318][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0527 (0.0713)	
0.9998722 4.6972525e-07
Epoch: [318][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1742 (0.0679)	
0.99993277 5.5013885e-07
loss:  0.05224714310409273 0.046958838078881904
===========>   training    <===========
Epoch: [319][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0633 (0.0633)	
0.99995136 4.6601476e-06
===========>   testing    <===========
Epoch: [319][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1016 (0.1016)	
0.9999368 4.416458e-07
Epoch: [319][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.0340 (0.0708)	
0.9998542 4.911021e-07
Epoch: [319][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000463291230159753]	Loss 0.1681 (0.0641)	
0.99992526 7.381108e-07
loss:  0.04868102344806147 0.046958838078881904
===========>   training    <===========
Epoch: [320][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0711 (0.0711)	
0.9999548 1.3351006e-06
===========>   testing    <===========
Epoch: [320][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0709 (0.0709)	
0.99994504 3.0787365e-07
Epoch: [320][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0288 (0.0620)	
0.99984 5.203745e-07
Epoch: [320][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0946 (0.0592)	
0.99991035 4.7005864e-07
loss:  0.04586845850410293 0.046958838078881904
===========>   training    <===========
Epoch: [321][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0567 (0.0567)	
0.9999342 1.61604e-07
===========>   testing    <===========
Epoch: [321][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0821 (0.0821)	
0.99994457 7.5242906e-07
Epoch: [321][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0307 (0.0661)	
0.99988997 8.4990063e-07
Epoch: [321][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1893 (0.0625)	
0.99991965 9.80014e-07
loss:  0.047354937244322604 0.04586845850410293
===========>   training    <===========
Epoch: [322][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0547 (0.0547)	
0.99994206 6.6717104e-07
===========>   testing    <===========
Epoch: [322][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0688 (0.0688)	
0.99995065 1.6389314e-06
Epoch: [322][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0374 (0.0680)	
0.9998783 1.9725924e-06
Epoch: [322][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0769 (0.0625)	
0.9999231 2.520453e-06
loss:  0.04878548200752619 0.04586845850410293
===========>   training    <===========
Epoch: [323][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0930 (0.0930)	
0.9999645 1.1000459e-06
===========>   testing    <===========
Epoch: [323][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0768 (0.0768)	
0.9999367 2.358374e-06
Epoch: [323][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0268 (0.0720)	
0.9999229 1.2716773e-06
Epoch: [323][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1448 (0.0640)	
0.99993634 4.3555506e-06
loss:  0.04783936870932204 0.04586845850410293
===========>   training    <===========
Epoch: [324][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0776 (0.0776)	
0.9999608 3.22024e-06
===========>   testing    <===========
Epoch: [324][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0836 (0.0836)	
0.99994814 4.3824147e-07
Epoch: [324][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0339 (0.0713)	
0.99987364 3.3300097e-07
Epoch: [324][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1637 (0.0654)	
0.99993515 1.0939686e-06
loss:  0.0500980523565796 0.04586845850410293
===========>   training    <===========
Epoch: [325][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0808 (0.0808)	
0.999889 4.3345275e-07
===========>   testing    <===========
Epoch: [325][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0870 (0.0870)	
0.99994457 3.3501536e-07
Epoch: [325][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0489 (0.0672)	
0.99988353 3.2360595e-07
Epoch: [325][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1979 (0.0628)	
0.9999311 6.0404403e-07
loss:  0.047755851398249005 0.04586845850410293
===========>   training    <===========
Epoch: [326][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0553 (0.0553)	
0.99993265 4.0761898e-07
===========>   testing    <===========
Epoch: [326][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0911 (0.0911)	
0.9999405 5.806531e-07
Epoch: [326][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.2359 (0.0761)	
0.9999063 6.799899e-07
Epoch: [326][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0917 (0.0678)	
0.99994564 7.794048e-07
loss:  0.053469598298177656 0.04586845850410293
===========>   training    <===========
Epoch: [327][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0638 (0.0638)	
0.9999261 9.729449e-07
===========>   testing    <===========
Epoch: [327][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0457 (0.0457)	
0.9999404 4.2074294e-06
Epoch: [327][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0288 (0.0680)	
0.9999132 4.154931e-06
Epoch: [327][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1441 (0.0629)	
0.99993753 2.3238558e-06
loss:  0.04809629549224803 0.04586845850410293
===========>   training    <===========
Epoch: [328][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0553 (0.0553)	
0.9999534 2.8420595e-07
===========>   testing    <===========
Epoch: [328][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0777 (0.0777)	
0.99994063 3.7532143e-07
Epoch: [328][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1077 (0.0762)	
0.99987733 3.437164e-07
Epoch: [328][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1279 (0.0678)	
0.99991727 7.3678586e-07
loss:  0.0510276248516931 0.04586845850410293
===========>   training    <===========
Epoch: [329][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0479 (0.0479)	
0.9999651 2.129121e-06
===========>   testing    <===========
Epoch: [329][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0748 (0.0748)	
0.99994373 4.2670501e-07
Epoch: [329][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0999 (0.0719)	
0.99987364 5.457322e-07
Epoch: [329][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0539 (0.0674)	
0.99991 7.8956816e-07
loss:  0.050374028413812555 0.04586845850410293
===========>   training    <===========
Epoch: [330][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0631 (0.0631)	
0.999964 5.865918e-07
===========>   testing    <===========
Epoch: [330][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0417 (0.0417)	
0.9999397 2.1170051e-06
Epoch: [330][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0500 (0.0705)	
0.9998963 5.7109132e-06
Epoch: [330][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1646 (0.0685)	
0.9999232 5.1646907e-06
loss:  0.05074603820502532 0.04586845850410293
===========>   training    <===========
Epoch: [331][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0644 (0.0644)	
0.99995935 5.315174e-06
===========>   testing    <===========
Epoch: [331][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0522 (0.0522)	
0.9999447 8.30105e-07
Epoch: [331][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1054 (0.0670)	
0.9999198 8.005471e-07
Epoch: [331][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1169 (0.0616)	
0.9999343 1.1585107e-06
loss:  0.04779218451472289 0.04586845850410293
===========>   training    <===========
Epoch: [332][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0543 (0.0543)	
0.99995875 3.4344347e-07
===========>   testing    <===========
Epoch: [332][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0417 (0.0417)	
0.99993527 6.828017e-07
Epoch: [332][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1099 (0.0709)	
0.9998945 9.3755307e-07
Epoch: [332][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1101 (0.0642)	
0.99993575 9.2543087e-07
loss:  0.04916314909277153 0.04586845850410293
===========>   training    <===========
Epoch: [333][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0652 (0.0652)	
0.9999604 1.8142091e-06
===========>   testing    <===========
Epoch: [333][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0634 (0.0634)	
0.999948 4.3182587e-07
Epoch: [333][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0653 (0.0794)	
0.9999 6.3763264e-07
Epoch: [333][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1124 (0.0724)	
0.9999218 8.6407033e-07
loss:  0.0541455306933426 0.04586845850410293
===========>   training    <===========
Epoch: [334][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0629 (0.0629)	
0.9999472 6.770986e-07
===========>   testing    <===========
Epoch: [334][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0648 (0.0648)	
0.9999422 6.073881e-07
Epoch: [334][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1017 (0.0684)	
0.999928 1.1468048e-06
Epoch: [334][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1657 (0.0635)	
0.99992883 6.5842994e-07
loss:  0.049291133626664374 0.04586845850410293
===========>   training    <===========
Epoch: [335][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0607 (0.0607)	
0.99996114 1.4205309e-06
===========>   testing    <===========
Epoch: [335][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0734 (0.0734)	
0.99995935 1.7810872e-07
Epoch: [335][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0300 (0.0678)	
0.9999229 2.0439454e-07
Epoch: [335][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0964 (0.0621)	
0.9999324 2.119792e-07
loss:  0.04719263888935088 0.04586845850410293
===========>   training    <===========
Epoch: [336][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0540 (0.0540)	
0.99996734 2.1466838e-06
===========>   testing    <===========
Epoch: [336][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0497 (0.0497)	
0.9999442 1.4516999e-07
Epoch: [336][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0350 (0.0672)	
0.99985373 2.0524382e-07
Epoch: [336][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.2065 (0.0642)	
0.9999187 2.1709846e-07
loss:  0.049620540603112495 0.04586845850410293
===========>   training    <===========
Epoch: [337][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0605 (0.0605)	
0.9999647 6.2201184e-07
===========>   testing    <===========
Epoch: [337][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0559 (0.0559)	
0.99992764 1.9648048e-06
Epoch: [337][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0352 (0.0751)	
0.9998337 2.047107e-06
Epoch: [337][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0717 (0.0693)	
0.9999349 3.4899874e-06
loss:  0.05069669540965693 0.04586845850410293
===========>   training    <===========
Epoch: [338][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0619 (0.0619)	
0.9999553 1.7221877e-06
===========>   testing    <===========
Epoch: [338][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0733 (0.0733)	
0.9999311 1.1837868e-07
Epoch: [338][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.2051 (0.0745)	
0.9998938 1.9098782e-07
Epoch: [338][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0967 (0.0665)	
0.9999291 9.960311e-08
loss:  0.051164416304153915 0.04586845850410293
===========>   training    <===========
Epoch: [339][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0697 (0.0697)	
0.99994326 1.4923467e-06
===========>   testing    <===========
Epoch: [339][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0480 (0.0480)	
0.99992776 1.3631362e-06
Epoch: [339][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.0241 (0.0702)	
0.9999031 1.0451889e-06
Epoch: [339][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00044012666865176535]	Loss 0.1134 (0.0629)	
0.99992263 1.561358e-06
loss:  0.0464304444513679 0.04586845850410293
===========>   training    <===========
Epoch: [340][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0597 (0.0597)	
0.9999361 1.2986374e-07
===========>   testing    <===========
Epoch: [340][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0494 (0.0494)	
0.999949 2.6083436e-07
Epoch: [340][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0360 (0.0700)	
0.9999094 3.0688955e-07
Epoch: [340][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1536 (0.0643)	
0.99993646 1.7344392e-07
loss:  0.04762857926103903 0.04586845850410293
===========>   training    <===========
Epoch: [341][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0639 (0.0639)	
0.99995947 5.252978e-07
===========>   testing    <===========
Epoch: [341][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0942 (0.0942)	
0.9999329 9.036675e-07
Epoch: [341][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0632 (0.0677)	
0.99987483 1.0013817e-06
Epoch: [341][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0789 (0.0612)	
0.9999274 1.0998225e-06
loss:  0.045667423926055384 0.04586845850410293
===========>   training    <===========
Epoch: [342][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0526 (0.0526)	
0.99993575 2.0346336e-07
===========>   testing    <===========
Epoch: [342][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0609 (0.0609)	
0.999933 1.7488392e-06
Epoch: [342][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0344 (0.0770)	
0.9998542 1.4588837e-06
Epoch: [342][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1020 (0.0690)	
0.9999249 2.4769251e-06
loss:  0.05214310932873867 0.045667423926055384
===========>   training    <===========
Epoch: [343][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0670 (0.0670)	
0.9999337 1.748094e-06
===========>   testing    <===========
Epoch: [343][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1057 (0.1057)	
0.99994385 2.6911647e-07
Epoch: [343][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1272 (0.0741)	
0.9998803 3.2941185e-07
Epoch: [343][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0889 (0.0672)	
0.99992704 5.9615894e-07
loss:  0.05101491224334975 0.045667423926055384
===========>   training    <===========
Epoch: [344][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0501 (0.0501)	
0.9999186 2.9723003e-08
===========>   testing    <===========
Epoch: [344][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0794 (0.0794)	
0.9999347 1.07225844e-07
Epoch: [344][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1164 (0.0695)	
0.999882 1.2336876e-07
Epoch: [344][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1185 (0.0632)	
0.999931 2.277239e-07
loss:  0.04899560803350245 0.045667423926055384
===========>   training    <===========
Epoch: [345][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0512 (0.0512)	
0.9999424 3.8682128e-07
===========>   testing    <===========
Epoch: [345][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0597 (0.0597)	
0.9999447 3.7955806e-07
Epoch: [345][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0387 (0.0712)	
0.9999156 5.326199e-07
Epoch: [345][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1484 (0.0645)	
0.99994266 6.348875e-07
loss:  0.04967795832766364 0.045667423926055384
===========>   training    <===========
Epoch: [346][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0709 (0.0709)	
0.99996316 5.270104e-07
===========>   testing    <===========
Epoch: [346][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0667 (0.0667)	
0.99992824 3.7034366e-07
Epoch: [346][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0611 (0.0690)	
0.9999149 5.024252e-07
Epoch: [346][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1399 (0.0644)	
0.99992085 1.1076581e-06
loss:  0.049916946552517216 0.045667423926055384
===========>   training    <===========
Epoch: [347][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0552 (0.0552)	
0.99994504 1.4675885e-06
===========>   testing    <===========
Epoch: [347][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0636 (0.0636)	
0.9999323 1.732753e-07
Epoch: [347][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0563 (0.0674)	
0.9999145 2.1617701e-07
Epoch: [347][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1786 (0.0619)	
0.9999188 2.7140365e-07
loss:  0.046391446636046774 0.045667423926055384
===========>   training    <===========
Epoch: [348][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0523 (0.0523)	
0.9999622 9.356969e-07
===========>   testing    <===========
Epoch: [348][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0538 (0.0538)	
0.9999516 7.474627e-07
Epoch: [348][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0493 (0.0641)	
0.999923 1.0431028e-06
Epoch: [348][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1435 (0.0630)	
0.9999324 1.4103166e-06
loss:  0.048739729099944396 0.045667423926055384
===========>   training    <===========
Epoch: [349][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0579 (0.0579)	
0.9999559 1.3298372e-06
===========>   testing    <===========
Epoch: [349][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0482 (0.0482)	
0.99992716 2.322665e-07
Epoch: [349][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0439 (0.0649)	
0.99987864 3.7914637e-07
Epoch: [349][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1947 (0.0626)	
0.9999201 2.8149233e-07
loss:  0.04683972140370796 0.045667423926055384
===========>   training    <===========
Epoch: [350][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0738 (0.0738)	
0.99987304 2.2328567e-07
===========>   testing    <===========
Epoch: [350][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0721 (0.0721)	
0.99994504 1.3070252e-07
Epoch: [350][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0398 (0.0664)	
0.9998764 3.0723717e-07
Epoch: [350][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1278 (0.0652)	
0.9999343 2.3670326e-07
loss:  0.04781435838574932 0.045667423926055384
===========>   training    <===========
Epoch: [351][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0774 (0.0774)	
0.999977 3.6808167e-08
===========>   testing    <===========
Epoch: [351][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0453 (0.0453)	
0.9999349 2.482693e-07
Epoch: [351][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1263 (0.0724)	
0.99991643 3.6593687e-07
Epoch: [351][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1928 (0.0667)	
0.9999161 3.0675787e-07
loss:  0.05033976551170871 0.045667423926055384
===========>   training    <===========
Epoch: [352][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0624 (0.0624)	
0.99994826 4.561512e-08
===========>   testing    <===========
Epoch: [352][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0960 (0.0960)	
0.99992096 6.3897915e-07
Epoch: [352][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1148 (0.0706)	
0.9998658 1.7604607e-06
Epoch: [352][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1338 (0.0642)	
0.9999193 2.3367295e-06
loss:  0.05098071995630715 0.045667423926055384
===========>   training    <===========
Epoch: [353][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0778 (0.0778)	
0.9999466 3.0049634e-07
===========>   testing    <===========
Epoch: [353][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0556 (0.0556)	
0.99994814 8.1694554e-07
Epoch: [353][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0301 (0.0695)	
0.99993825 1.1840843e-06
Epoch: [353][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1475 (0.0632)	
0.9999329 1.5738469e-06
loss:  0.048311277215367876 0.045667423926055384
===========>   training    <===========
Epoch: [354][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0688 (0.0688)	
0.99995553 3.7364541e-06
===========>   testing    <===========
Epoch: [354][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0434 (0.0434)	
0.99995494 1.0261292e-06
Epoch: [354][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0256 (0.0667)	
0.9999137 1.5736352e-06
Epoch: [354][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.2543 (0.0637)	
0.9999279 1.2807374e-06
loss:  0.048365460919418735 0.045667423926055384
===========>   training    <===========
Epoch: [355][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0616 (0.0616)	
0.99995923 9.848955e-06
===========>   testing    <===========
Epoch: [355][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0850 (0.0850)	
0.99995315 3.2086496e-06
Epoch: [355][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0323 (0.0665)	
0.99991786 2.861982e-06
Epoch: [355][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1230 (0.0633)	
0.99993 5.877683e-06
loss:  0.04936072540529002 0.045667423926055384
===========>   training    <===========
Epoch: [356][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0595 (0.0595)	
0.9999597 1.1697895e-06
===========>   testing    <===========
Epoch: [356][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0719 (0.0719)	
0.99993503 4.7864455e-07
Epoch: [356][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1891 (0.0705)	
0.99991536 1.013149e-06
Epoch: [356][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1268 (0.0659)	
0.99992716 1.2536525e-06
loss:  0.049920125308106855 0.045667423926055384
===========>   training    <===========
Epoch: [357][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0619 (0.0619)	
0.99994004 1.9951594e-06
===========>   testing    <===========
Epoch: [357][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0600 (0.0600)	
0.99993205 5.340231e-07
Epoch: [357][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0700 (0.0658)	
0.9998915 1.0076902e-06
Epoch: [357][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1177 (0.0625)	
0.99991775 1.720697e-06
loss:  0.04874084972208814 0.045667423926055384
===========>   training    <===========
Epoch: [358][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0630 (0.0630)	
0.9999528 2.955052e-07
===========>   testing    <===========
Epoch: [358][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0705 (0.0705)	
0.99995124 3.552503e-07
Epoch: [358][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0559 (0.0653)	
0.99992275 9.931209e-07
Epoch: [358][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1431 (0.0623)	
0.9999305 8.946092e-07
loss:  0.04831679217909679 0.045667423926055384
===========>   training    <===========
Epoch: [359][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0700 (0.0700)	
0.99993277 1.2430155e-06
===========>   testing    <===========
Epoch: [359][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.0706 (0.0706)	
0.9999306 1.8870168e-06
Epoch: [359][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1016 (0.0627)	
0.9998529 1.247589e-06
Epoch: [359][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0004181203352191771]	Loss 0.1176 (0.0608)	
0.9999193 4.0717246e-06
loss:  0.04721402801547181 0.045667423926055384
===========>   training    <===========
Epoch: [360][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0509 (0.0509)	
0.99996686 2.3598252e-06
===========>   testing    <===========
Epoch: [360][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0688 (0.0688)	
0.9999356 1.1135973e-07
Epoch: [360][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0318 (0.0682)	
0.99982244 1.7400856e-07
Epoch: [360][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1273 (0.0631)	
0.99994016 4.0095514e-07
loss:  0.04861664684900047 0.045667423926055384
===========>   training    <===========
Epoch: [361][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0613 (0.0613)	
0.99995184 1.8201829e-06
===========>   testing    <===========
Epoch: [361][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0720 (0.0720)	
0.9999455 3.5905896e-07
Epoch: [361][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0339 (0.0644)	
0.99989784 4.2082937e-07
Epoch: [361][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1827 (0.0622)	
0.9999348 1.266083e-06
loss:  0.04744025021566589 0.045667423926055384
===========>   training    <===========
Epoch: [362][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0603 (0.0603)	
0.9999585 5.351258e-07
===========>   testing    <===========
Epoch: [362][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0509 (0.0509)	
0.99993134 6.0157834e-07
Epoch: [362][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0317 (0.0630)	
0.999846 7.2991105e-07
Epoch: [362][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.2215 (0.0605)	
0.9999362 1.0482315e-06
loss:  0.04522301560520514 0.045667423926055384
===========>   training    <===========
Epoch: [363][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0563 (0.0563)	
0.99994755 9.1674195e-08
===========>   testing    <===========
Epoch: [363][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0783 (0.0783)	
0.9999447 3.77795e-07
Epoch: [363][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0422 (0.0679)	
0.9999093 6.44671e-07
Epoch: [363][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1540 (0.0650)	
0.9999547 1.8364472e-06
loss:  0.04909737608998699 0.04522301560520514
===========>   training    <===========
Epoch: [364][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0653 (0.0653)	
0.99995923 1.17033004e-07
===========>   testing    <===========
Epoch: [364][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0627 (0.0627)	
0.9999497 1.6197508e-07
Epoch: [364][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0495 (0.0659)	
0.9999081 4.6794926e-07
Epoch: [364][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.2428 (0.0633)	
0.99995315 6.471219e-07
loss:  0.047542313554730264 0.04522301560520514
===========>   training    <===========
Epoch: [365][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0604 (0.0604)	
0.9999447 2.9529306e-07
===========>   testing    <===========
Epoch: [365][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0528 (0.0528)	
0.99994254 4.3448864e-07
Epoch: [365][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0480 (0.0644)	
0.9999125 8.3982275e-07
Epoch: [365][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1557 (0.0619)	
0.99994695 9.774993e-07
loss:  0.046400313214556954 0.04522301560520514
===========>   training    <===========
Epoch: [366][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0585 (0.0585)	
0.9999553 1.2603188e-06
===========>   testing    <===========
Epoch: [366][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0570 (0.0570)	
0.99994624 1.2818087e-07
Epoch: [366][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0479 (0.0675)	
0.99986947 2.1882205e-07
Epoch: [366][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1061 (0.0625)	
0.99992573 1.8330948e-07
loss:  0.048729543789187924 0.04522301560520514
===========>   training    <===========
Epoch: [367][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0529 (0.0529)	
0.9999764 1.3522158e-07
===========>   testing    <===========
Epoch: [367][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0476 (0.0476)	
0.99995947 1.6269836e-06
Epoch: [367][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0262 (0.0709)	
0.99990296 1.7574245e-06
Epoch: [367][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1598 (0.0657)	
0.9999472 2.7750477e-06
loss:  0.049742400711142 0.04522301560520514
===========>   training    <===========
Epoch: [368][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0542 (0.0542)	
0.99995315 2.982875e-06
===========>   testing    <===========
Epoch: [368][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0408 (0.0408)	
0.9999503 3.8510308e-07
Epoch: [368][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0267 (0.0615)	
0.99990225 7.767165e-07
Epoch: [368][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1886 (0.0604)	
0.99993074 9.088116e-07
loss:  0.046665533031071904 0.04522301560520514
===========>   training    <===========
Epoch: [369][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0507 (0.0507)	
0.99993575 2.2289802e-07
===========>   testing    <===========
Epoch: [369][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0536 (0.0536)	
0.99994886 1.4849047e-07
Epoch: [369][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0666 (0.0673)	
0.9998845 2.4383934e-07
Epoch: [369][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1185 (0.0622)	
0.9999342 5.322172e-07
loss:  0.048201967183578054 0.04522301560520514
===========>   training    <===========
Epoch: [370][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0659 (0.0659)	
0.9999608 5.269802e-07
===========>   testing    <===========
Epoch: [370][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0449 (0.0449)	
0.9999436 1.2707739e-07
Epoch: [370][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0252 (0.0645)	
0.99986887 1.9901472e-07
Epoch: [370][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.2196 (0.0615)	
0.9999293 2.5484974e-07
loss:  0.04669232302313597 0.04522301560520514
===========>   training    <===========
Epoch: [371][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0554 (0.0554)	
0.99996877 4.418438e-07
===========>   testing    <===========
Epoch: [371][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0558 (0.0558)	
0.9999397 1.6852545e-07
Epoch: [371][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.2194 (0.0699)	
0.9998672 2.46616e-07
Epoch: [371][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1349 (0.0620)	
0.9999298 3.601282e-07
loss:  0.04773635749921845 0.04522301560520514
===========>   training    <===========
Epoch: [372][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0484 (0.0484)	
0.9999651 1.8741774e-06
===========>   testing    <===========
Epoch: [372][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0483 (0.0483)	
0.9999422 1.7758819e-07
Epoch: [372][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.2126 (0.0675)	
0.9998996 2.4787417e-07
Epoch: [372][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.2087 (0.0623)	
0.9999397 3.4169693e-07
loss:  0.046044827686227086 0.04522301560520514
===========>   training    <===========
Epoch: [373][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0482 (0.0482)	
0.999977 6.74349e-06
===========>   testing    <===========
Epoch: [373][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0495 (0.0495)	
0.9999399 2.1026538e-07
Epoch: [373][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0495 (0.0674)	
0.9998956 3.1049848e-07
Epoch: [373][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1589 (0.0615)	
0.99993277 4.1151554e-07
loss:  0.04583071577598041 0.04522301560520514
===========>   training    <===========
Epoch: [374][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0562 (0.0562)	
0.9999523 7.520819e-08
===========>   testing    <===========
Epoch: [374][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0456 (0.0456)	
0.99994636 1.5492796e-07
Epoch: [374][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0513 (0.0694)	
0.9998472 3.1603244e-07
Epoch: [374][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.2070 (0.0681)	
0.9999411 3.100635e-07
loss:  0.0524564401373212 0.04522301560520514
===========>   training    <===========
Epoch: [375][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0576 (0.0576)	
0.9999565 1.0986411e-06
===========>   testing    <===========
Epoch: [375][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0764 (0.0764)	
0.99994755 4.4599307e-07
Epoch: [375][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.2764 (0.0711)	
0.9998536 7.266356e-07
Epoch: [375][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0996 (0.0622)	
0.99993324 5.6568757e-07
loss:  0.047679925001501644 0.04522301560520514
===========>   training    <===========
Epoch: [376][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0604 (0.0604)	
0.99992895 3.4784507e-06
===========>   testing    <===========
Epoch: [376][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0589 (0.0589)	
0.99993384 3.4609386e-07
Epoch: [376][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1052 (0.0719)	
0.9998809 4.464752e-07
Epoch: [376][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1396 (0.0667)	
0.99993134 6.73498e-07
loss:  0.05134504412026697 0.04522301560520514
===========>   training    <===========
Epoch: [377][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0676 (0.0676)	
0.9999312 3.418785e-07
===========>   testing    <===========
Epoch: [377][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0491 (0.0491)	
0.9999405 1.5981955e-06
Epoch: [377][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0462 (0.0649)	
0.99989796 2.1926335e-06
Epoch: [377][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1746 (0.0614)	
0.9999238 7.319993e-06
loss:  0.04723854201670186 0.04522301560520514
===========>   training    <===========
Epoch: [378][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0530 (0.0530)	
0.999959 2.4666963e-07
===========>   testing    <===========
Epoch: [378][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0827 (0.0827)	
0.99993527 7.84986e-07
Epoch: [378][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0401 (0.0654)	
0.99989986 9.832559e-07
Epoch: [378][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.2148 (0.0610)	
0.99992406 1.4773254e-06
loss:  0.046757450240492826 0.04522301560520514
===========>   training    <===========
Epoch: [379][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0483 (0.0483)	
0.9999168 1.2095059e-06
===========>   testing    <===========
Epoch: [379][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0556 (0.0556)	
0.9999409 1.6582031e-06
Epoch: [379][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.0238 (0.0694)	
0.9999229 1.7580497e-06
Epoch: [379][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003972143184582182]	Loss 0.1831 (0.0628)	
0.9999355 4.441689e-06
loss:  0.04608304377189376 0.04522301560520514
===========>   training    <===========
Epoch: [380][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0563 (0.0563)	
0.9999689 8.232719e-06
===========>   testing    <===========
Epoch: [380][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0545 (0.0545)	
0.9999461 1.6654728e-06
Epoch: [380][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0694 (0.0641)	
0.99990475 1.5712465e-06
Epoch: [380][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.2682 (0.0619)	
0.9999404 3.3767556e-06
loss:  0.047253258769295425 0.04522301560520514
===========>   training    <===========
Epoch: [381][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0596 (0.0596)	
0.9999572 1.1581536e-05
===========>   testing    <===========
Epoch: [381][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0749 (0.0749)	
0.9999528 3.825481e-07
Epoch: [381][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.1386 (0.0665)	
0.9999088 5.0753727e-07
Epoch: [381][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.2078 (0.0622)	
0.99994767 6.153823e-07
loss:  0.04657992923931353 0.04522301560520514
===========>   training    <===========
Epoch: [382][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0609 (0.0609)	
0.99994063 1.1933144e-08
===========>   testing    <===========
Epoch: [382][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0607 (0.0607)	
0.99994636 3.8623332e-07
Epoch: [382][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0522 (0.0652)	
0.9998667 4.5291142e-07
Epoch: [382][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.1616 (0.0603)	
0.99994254 6.4064676e-07
loss:  0.04714214057529498 0.04522301560520514
===========>   training    <===========
Epoch: [383][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0761 (0.0761)	
0.99995136 5.5162826e-07
===========>   testing    <===========
Epoch: [383][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0998 (0.0998)	
0.99995875 9.5216296e-07
Epoch: [383][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.1075 (0.0705)	
0.99988556 1.6102476e-06
Epoch: [383][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0479 (0.0644)	
0.9999522 2.0436719e-06
loss:  0.04815962647466565 0.04522301560520514
===========>   training    <===========
Epoch: [384][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0608 (0.0608)	
0.99997187 1.2700049e-06
===========>   testing    <===========
Epoch: [384][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0598 (0.0598)	
0.9999422 6.3803043e-07
Epoch: [384][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0746 (0.0701)	
0.999897 9.851406e-07
Epoch: [384][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0813 (0.0636)	
0.9999424 5.130021e-07
loss:  0.04667351351398619 0.04522301560520514
===========>   training    <===========
Epoch: [385][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0593 (0.0593)	
0.9999771 1.7190273e-06
===========>   testing    <===========
Epoch: [385][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0484 (0.0484)	
0.9999442 5.37254e-07
Epoch: [385][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0527 (0.0673)	
0.99992836 6.484922e-07
Epoch: [385][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0882 (0.0611)	
0.9999337 8.6558464e-07
loss:  0.045761036606282834 0.04522301560520514
===========>   training    <===========
Epoch: [386][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0617 (0.0617)	
0.9999455 1.5103989e-06
===========>   testing    <===========
Epoch: [386][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0568 (0.0568)	
0.9999547 2.6141436e-07
Epoch: [386][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.1958 (0.0660)	
0.9999014 3.567142e-07
Epoch: [386][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0430 (0.0605)	
0.99994206 3.807806e-07
loss:  0.04734726327291838 0.04522301560520514
===========>   training    <===========
Epoch: [387][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0509 (0.0509)	
0.99995124 2.3238948e-07
===========>   testing    <===========
Epoch: [387][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0461 (0.0461)	
0.9999534 5.522694e-07
Epoch: [387][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.1657 (0.0643)	
0.9998807 8.3841593e-07
Epoch: [387][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0955 (0.0609)	
0.9999443 1.3999073e-06
loss:  0.04603374783676584 0.04522301560520514
===========>   training    <===========
Epoch: [388][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0516 (0.0516)	
0.9999652 7.0514426e-07
===========>   testing    <===========
Epoch: [388][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0401 (0.0401)	
0.9999422 3.0075665e-07
Epoch: [388][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0471 (0.0673)	
0.9998517 5.822973e-07
Epoch: [388][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.1039 (0.0623)	
0.999931 3.5415633e-07
loss:  0.046146149671818515 0.04522301560520514
===========>   training    <===========
Epoch: [389][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0597 (0.0597)	
0.99997115 5.039417e-07
===========>   testing    <===========
Epoch: [389][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0403 (0.0403)	
0.99995697 6.127517e-07
Epoch: [389][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0628 (0.0671)	
0.9999093 1.6660575e-06
Epoch: [389][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0866 (0.0615)	
0.9999547 1.0616513e-06
loss:  0.04604762099744253 0.04522301560520514
===========>   training    <===========
Epoch: [390][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0741 (0.0741)	
0.99994385 4.4948843e-07
===========>   testing    <===========
Epoch: [390][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0430 (0.0430)	
0.9999573 1.2185191e-06
Epoch: [390][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0947 (0.0647)	
0.9999316 1.4978133e-06
Epoch: [390][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0763 (0.0599)	
0.99993527 1.463749e-06
loss:  0.046989859805814826 0.04522301560520514
===========>   training    <===========
Epoch: [391][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0619 (0.0619)	
0.9999697 5.6795852e-06
===========>   testing    <===========
Epoch: [391][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0858 (0.0858)	
0.99994874 7.248015e-07
Epoch: [391][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0416 (0.0663)	
0.99989045 6.1144704e-07
Epoch: [391][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0652 (0.0591)	
0.99991965 1.796851e-06
loss:  0.045517148884852365 0.04522301560520514
===========>   training    <===========
Epoch: [392][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0484 (0.0484)	
0.99996674 1.3445392e-06
===========>   testing    <===========
Epoch: [392][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0765 (0.0765)	
0.9999502 9.715284e-08
Epoch: [392][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0813 (0.0699)	
0.99993193 1.4840468e-07
Epoch: [392][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0846 (0.0613)	
0.99993014 1.7695591e-07
loss:  0.04572713784279381 0.04522301560520514
===========>   training    <===========
Epoch: [393][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0544 (0.0544)	
0.9999509 5.7337406e-08
===========>   testing    <===========
Epoch: [393][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0505 (0.0505)	
0.9999498 1.2427026e-06
Epoch: [393][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0830 (0.0631)	
0.9999018 2.1945561e-06
Epoch: [393][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.1469 (0.0607)	
0.99991906 1.7603079e-06
loss:  0.045537741993669556 0.04522301560520514
===========>   training    <===========
Epoch: [394][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0564 (0.0564)	
0.9999645 2.752124e-06
===========>   testing    <===========
Epoch: [394][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0699 (0.0699)	
0.99995184 1.232792e-06
Epoch: [394][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0467 (0.0676)	
0.9999138 1.7817442e-06
Epoch: [394][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.1062 (0.0622)	
0.99992883 1.7207988e-06
loss:  0.04665147103738454 0.04522301560520514
===========>   training    <===========
Epoch: [395][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0500 (0.0500)	
0.9999492 1.0427149e-06
===========>   testing    <===========
Epoch: [395][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0370 (0.0370)	
0.9999584 1.0424305e-06
Epoch: [395][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0262 (0.0670)	
0.9999157 2.243282e-06
Epoch: [395][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0882 (0.0623)	
0.99993 1.5378771e-06
loss:  0.04691480255434988 0.04522301560520514
===========>   training    <===========
Epoch: [396][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0550 (0.0550)	
0.9999527 1.1959974e-06
===========>   testing    <===========
Epoch: [396][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0726 (0.0726)	
0.9999732 6.399214e-07
Epoch: [396][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0253 (0.0627)	
0.9998963 1.2656062e-06
Epoch: [396][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0509 (0.0591)	
0.99994814 1.4391918e-06
loss:  0.0466032360227272 0.04522301560520514
===========>   training    <===========
Epoch: [397][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0453 (0.0453)	
0.99997425 1.8231327e-06
===========>   testing    <===========
Epoch: [397][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0751 (0.0751)	
0.99996245 6.014573e-07
Epoch: [397][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0404 (0.0655)	
0.9999379 1.0173703e-06
Epoch: [397][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0469 (0.0603)	
0.9999404 8.115719e-07
loss:  0.04617685631063673 0.04522301560520514
===========>   training    <===========
Epoch: [398][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0567 (0.0567)	
0.99996805 5.510656e-07
===========>   testing    <===========
Epoch: [398][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0672 (0.0672)	
0.99995565 1.3246097e-06
Epoch: [398][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0216 (0.0669)	
0.9999441 1.0716467e-06
Epoch: [398][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0972 (0.0623)	
0.9999393 1.536023e-06
loss:  0.046123400091089506 0.04522301560520514
===========>   training    <===========
Epoch: [399][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0616 (0.0616)	
0.9999716 2.576078e-06
===========>   testing    <===========
Epoch: [399][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0440 (0.0440)	
0.999966 1.7787717e-07
Epoch: [399][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0605 (0.0674)	
0.99989605 3.8760268e-07
Epoch: [399][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00037735360253530727]	Loss 0.0447 (0.0629)	
0.99995077 5.5271516e-07
loss:  0.04977061702673646 0.04522301560520514
===========>   training    <===========
Epoch: [400][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0732 (0.0732)	
0.9999677 8.930561e-07
===========>   testing    <===========
Epoch: [400][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0619 (0.0619)	
0.99996257 1.6947652e-07
Epoch: [400][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0455 (0.0649)	
0.99986625 2.4253617e-07
Epoch: [400][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0752 (0.0612)	
0.9999596 3.540547e-07
loss:  0.04747568368294364 0.04522301560520514
===========>   training    <===========
Epoch: [401][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0496 (0.0496)	
0.99996173 3.9382857e-07
===========>   testing    <===========
Epoch: [401][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0804 (0.0804)	
0.99995494 3.5427658e-07
Epoch: [401][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1620 (0.0642)	
0.99992883 4.7115734e-07
Epoch: [401][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1052 (0.0607)	
0.9999442 5.172313e-07
loss:  0.04435434808956695 0.04522301560520514
===========>   training    <===========
Epoch: [402][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0621 (0.0621)	
0.9999745 2.2990997e-07
===========>   testing    <===========
Epoch: [402][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0557 (0.0557)	
0.9999634 5.30923e-07
Epoch: [402][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0335 (0.0655)	
0.9998933 4.8823114e-07
Epoch: [402][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1275 (0.0619)	
0.999961 5.3577537e-07
loss:  0.04586357102887695 0.04435434808956695
===========>   training    <===========
Epoch: [403][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0752 (0.0752)	
0.9999758 2.9106562e-07
===========>   testing    <===========
Epoch: [403][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0599 (0.0599)	
0.9999565 3.5461395e-07
Epoch: [403][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0433 (0.0632)	
0.99993324 8.13499e-07
Epoch: [403][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1227 (0.0586)	
0.99995923 7.328964e-07
loss:  0.04558373351745293 0.04435434808956695
===========>   training    <===========
Epoch: [404][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0572 (0.0572)	
0.9999747 8.9526463e-07
===========>   testing    <===========
Epoch: [404][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0405 (0.0405)	
0.99996114 1.1322948e-06
Epoch: [404][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0393 (0.0640)	
0.9998982 1.3512133e-06
Epoch: [404][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0787 (0.0584)	
0.9999354 2.1855938e-06
loss:  0.04356648355378068 0.04435434808956695
===========>   training    <===========
Epoch: [405][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0678 (0.0678)	
0.99997807 7.561538e-07
===========>   testing    <===========
Epoch: [405][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0697 (0.0697)	
0.9999573 1.6645139e-07
Epoch: [405][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0547 (0.0659)	
0.9998766 1.8246288e-07
Epoch: [405][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0601 (0.0600)	
0.9999244 3.867468e-07
loss:  0.045138499097508444 0.04356648355378068
===========>   training    <===========
Epoch: [406][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0600 (0.0600)	
0.9999739 1.3554608e-06
===========>   testing    <===========
Epoch: [406][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0445 (0.0445)	
0.9999589 8.0459785e-08
Epoch: [406][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0379 (0.0625)	
0.9998448 9.6161735e-08
Epoch: [406][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0453 (0.0587)	
0.99991953 1.3094507e-07
loss:  0.044386186120816795 0.04356648355378068
===========>   training    <===========
Epoch: [407][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0477 (0.0477)	
0.9999682 1.2883363e-06
===========>   testing    <===========
Epoch: [407][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0545 (0.0545)	
0.999954 1.01321e-06
Epoch: [407][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.2631 (0.0706)	
0.9999385 8.654228e-07
Epoch: [407][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0516 (0.0636)	
0.99993217 1.1767243e-06
loss:  0.048537451986625624 0.04356648355378068
===========>   training    <===========
Epoch: [408][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0601 (0.0601)	
0.99996185 1.3229836e-06
===========>   testing    <===========
Epoch: [408][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0632 (0.0632)	
0.9999578 3.9913754e-08
Epoch: [408][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0423 (0.0654)	
0.99975854 5.553581e-08
Epoch: [408][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1033 (0.0607)	
0.99995005 6.747484e-08
loss:  0.04559969663295804 0.04356648355378068
===========>   training    <===========
Epoch: [409][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0472 (0.0472)	
0.9999565 4.242477e-07
===========>   testing    <===========
Epoch: [409][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0573 (0.0573)	
0.9999428 3.5069697e-06
Epoch: [409][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0969 (0.0666)	
0.9999019 1.7691722e-06
Epoch: [409][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0560 (0.0627)	
0.9999285 8.08034e-06
loss:  0.0485730845670187 0.04356648355378068
===========>   training    <===========
Epoch: [410][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0703 (0.0703)	
0.9999496 2.2510212e-05
===========>   testing    <===========
Epoch: [410][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0855 (0.0855)	
0.9999496 3.0187965e-07
Epoch: [410][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1604 (0.0703)	
0.99991703 4.263373e-07
Epoch: [410][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0881 (0.0645)	
0.99993324 4.4312156e-07
loss:  0.04913748386703465 0.04356648355378068
===========>   training    <===========
Epoch: [411][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0520 (0.0520)	
0.99996257 1.1031514e-06
===========>   testing    <===========
Epoch: [411][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0562 (0.0562)	
0.9999423 9.738268e-07
Epoch: [411][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1571 (0.0690)	
0.99990046 1.1012321e-06
Epoch: [411][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0765 (0.0640)	
0.999933 4.00603e-06
loss:  0.04748661054859882 0.04356648355378068
===========>   training    <===========
Epoch: [412][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0550 (0.0550)	
0.9999536 1.3592329e-06
===========>   testing    <===========
Epoch: [412][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0569 (0.0569)	
0.999946 1.8973788e-07
Epoch: [412][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0228 (0.0666)	
0.9999057 1.5380179e-07
Epoch: [412][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1386 (0.0614)	
0.9999193 3.8729524e-07
loss:  0.04591509903242785 0.04356648355378068
===========>   training    <===========
Epoch: [413][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0607 (0.0607)	
0.999908 1.4254732e-07
===========>   testing    <===========
Epoch: [413][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0565 (0.0565)	
0.99995315 6.727527e-07
Epoch: [413][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1202 (0.0701)	
0.9998816 8.27514e-07
Epoch: [413][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0480 (0.0641)	
0.99990773 9.883844e-07
loss:  0.04877604046171047 0.04356648355378068
===========>   training    <===========
Epoch: [414][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0553 (0.0553)	
0.99996114 6.75069e-06
===========>   testing    <===========
Epoch: [414][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0430 (0.0430)	
0.99994504 2.1537818e-07
Epoch: [414][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0379 (0.0666)	
0.99986947 2.3144618e-07
Epoch: [414][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1385 (0.0636)	
0.9999217 4.4690717e-07
loss:  0.047040864871848664 0.04356648355378068
===========>   training    <===========
Epoch: [415][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0626 (0.0626)	
0.9999647 6.630064e-07
===========>   testing    <===========
Epoch: [415][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0691 (0.0691)	
0.999962 1.0189626e-06
Epoch: [415][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.3539 (0.0693)	
0.9999268 1.0026364e-06
Epoch: [415][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0810 (0.0629)	
0.99993455 2.5802137e-06
loss:  0.046331562132950865 0.04356648355378068
===========>   training    <===========
Epoch: [416][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0496 (0.0496)	
0.9999645 1.9551562e-06
===========>   testing    <===========
Epoch: [416][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0542 (0.0542)	
0.9999362 1.5991544e-07
Epoch: [416][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0686 (0.0660)	
0.99989617 2.487243e-07
Epoch: [416][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1972 (0.0636)	
0.9999504 2.1287687e-07
loss:  0.04733614925117691 0.04356648355378068
===========>   training    <===========
Epoch: [417][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0521 (0.0521)	
0.999946 1.4822405e-07
===========>   testing    <===========
Epoch: [417][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0671 (0.0671)	
0.9999511 1.2919843e-06
Epoch: [417][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.2213 (0.0680)	
0.99993193 1.7699484e-06
Epoch: [417][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0324 (0.0622)	
0.9999403 4.620122e-06
loss:  0.04790296182484921 0.04356648355378068
===========>   training    <===========
Epoch: [418][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0633 (0.0633)	
0.9999598 3.4064405e-07
===========>   testing    <===========
Epoch: [418][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0466 (0.0466)	
0.99994946 2.631543e-07
Epoch: [418][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.3373 (0.0683)	
0.9998896 1.6396412e-07
Epoch: [418][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0846 (0.0617)	
0.99994516 3.0668153e-07
loss:  0.04579524540098101 0.04356648355378068
===========>   training    <===========
Epoch: [419][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0499 (0.0499)	
0.99997663 5.2386348e-08
===========>   testing    <===========
Epoch: [419][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.0491 (0.0491)	
0.99995446 4.584574e-07
Epoch: [419][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1327 (0.0679)	
0.99992716 4.834302e-07
Epoch: [419][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003584859224085419]	Loss 0.1233 (0.0624)	
0.9999608 1.0280128e-06
loss:  0.04731488973733844 0.04356648355378068
===========>   training    <===========
Epoch: [420][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0599 (0.0599)	
0.9999294 6.180949e-08
===========>   testing    <===========
Epoch: [420][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0401 (0.0401)	
0.99996305 2.809881e-07
Epoch: [420][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0339 (0.0650)	
0.99993277 2.467562e-07
Epoch: [420][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.1299 (0.0610)	
0.9999559 7.413256e-07
loss:  0.04576826073324103 0.04356648355378068
===========>   training    <===========
Epoch: [421][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0634 (0.0634)	
0.99996364 5.470359e-07
===========>   testing    <===========
Epoch: [421][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0639 (0.0639)	
0.99995863 2.775175e-07
Epoch: [421][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.1278 (0.0665)	
0.99986374 2.2936335e-07
Epoch: [421][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0592 (0.0617)	
0.9999454 2.7505368e-07
loss:  0.04621853441984958 0.04356648355378068
===========>   training    <===========
Epoch: [422][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0447 (0.0447)	
0.9999733 6.12045e-07
===========>   testing    <===========
Epoch: [422][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0495 (0.0495)	
0.99994266 3.7217274e-07
Epoch: [422][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0391 (0.0617)	
0.99989104 2.9770442e-07
Epoch: [422][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0795 (0.0574)	
0.99994004 4.76884e-07
loss:  0.04312887322758707 0.04356648355378068
===========>   training    <===========
Epoch: [423][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0531 (0.0531)	
0.99997306 1.2223548e-07
===========>   testing    <===========
Epoch: [423][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0581 (0.0581)	
0.99995947 1.6136454e-07
Epoch: [423][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0801 (0.0659)	
0.9998833 1.2880128e-07
Epoch: [423][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0640 (0.0593)	
0.9999542 2.17294e-07
loss:  0.043534574952240446 0.04312887322758707
===========>   training    <===========
Epoch: [424][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0449 (0.0449)	
0.9999372 8.83329e-08
===========>   testing    <===========
Epoch: [424][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0675 (0.0675)	
0.99995613 2.3402592e-07
Epoch: [424][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.1008 (0.0681)	
0.99994814 7.2333634e-08
Epoch: [424][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.1169 (0.0634)	
0.9999498 3.394351e-07
loss:  0.04573064747014721 0.04312887322758707
===========>   training    <===========
Epoch: [425][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0582 (0.0582)	
0.99995387 3.662986e-07
===========>   testing    <===========
Epoch: [425][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0661 (0.0661)	
0.9999505 3.7723697e-07
Epoch: [425][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0767 (0.0698)	
0.99993706 4.6207956e-07
Epoch: [425][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0881 (0.0641)	
0.99994886 6.586969e-07
loss:  0.04680003279623979 0.04312887322758707
===========>   training    <===========
Epoch: [426][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0587 (0.0587)	
0.9999672 7.245479e-07
===========>   testing    <===========
Epoch: [426][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0555 (0.0555)	
0.9999646 5.050319e-07
Epoch: [426][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0519 (0.0668)	
0.99995077 3.9825628e-07
Epoch: [426][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.1199 (0.0632)	
0.9999516 6.726834e-07
loss:  0.047701733224470355 0.04312887322758707
===========>   training    <===========
Epoch: [427][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0464 (0.0464)	
0.999969 1.8292492e-06
===========>   testing    <===========
Epoch: [427][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0557 (0.0557)	
0.99995995 6.4014716e-07
Epoch: [427][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0324 (0.0681)	
0.99991465 6.5212896e-07
Epoch: [427][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.1268 (0.0640)	
0.9999436 1.4821885e-06
loss:  0.04725366123048769 0.04312887322758707
===========>   training    <===========
Epoch: [428][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0481 (0.0481)	
0.99996436 1.9857166e-07
===========>   testing    <===========
Epoch: [428][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0387 (0.0387)	
0.99995565 3.3442737e-07
Epoch: [428][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0685 (0.0632)	
0.9999039 4.0039765e-07
Epoch: [428][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.1205 (0.0598)	
0.9999409 1.4680674e-06
loss:  0.045436517089181616 0.04312887322758707
===========>   training    <===========
Epoch: [429][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0486 (0.0486)	
0.99997544 1.5012954e-07
===========>   testing    <===========
Epoch: [429][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0639 (0.0639)	
0.9999615 9.3470895e-08
Epoch: [429][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0826 (0.0659)	
0.99993694 5.846137e-08
Epoch: [429][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0976 (0.0617)	
0.9999418 4.3273903e-07
loss:  0.04611198404799699 0.04312887322758707
===========>   training    <===========
Epoch: [430][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0507 (0.0507)	
0.99996054 1.0825951e-07
===========>   testing    <===========
Epoch: [430][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0566 (0.0566)	
0.9999682 5.0565933e-07
Epoch: [430][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0446 (0.0628)	
0.9999337 7.033766e-07
Epoch: [430][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0964 (0.0598)	
0.9999634 1.6974955e-06
loss:  0.04396372234368784 0.04312887322758707
===========>   training    <===========
Epoch: [431][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0551 (0.0551)	
0.99996614 1.6232534e-07
===========>   testing    <===========
Epoch: [431][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0703 (0.0703)	
0.9999604 7.759511e-08
Epoch: [431][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0387 (0.0686)	
0.9999186 5.9372265e-08
Epoch: [431][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.1180 (0.0629)	
0.9999434 1.8197925e-07
loss:  0.046196632476098065 0.04312887322758707
===========>   training    <===========
Epoch: [432][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0488 (0.0488)	
0.9999541 8.5851934e-07
===========>   testing    <===========
Epoch: [432][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0476 (0.0476)	
0.99996245 7.147088e-08
Epoch: [432][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0401 (0.0678)	
0.99990034 1.18437626e-07
Epoch: [432][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0765 (0.0612)	
0.9999517 3.5356476e-07
loss:  0.04582418989529524 0.04312887322758707
===========>   training    <===========
Epoch: [433][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0531 (0.0531)	
0.9999721 7.528325e-07
===========>   testing    <===========
Epoch: [433][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0908 (0.0908)	
0.99996233 2.9952156e-07
Epoch: [433][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0944 (0.0760)	
0.9999386 1.0633724e-07
Epoch: [433][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.1094 (0.0656)	
0.99995494 1.0736721e-06
loss:  0.04803301207278132 0.04312887322758707
===========>   training    <===========
Epoch: [434][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0500 (0.0500)	
0.9999722 1.2805135e-07
===========>   testing    <===========
Epoch: [434][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0455 (0.0455)	
0.99996257 9.772356e-07
Epoch: [434][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0490 (0.0685)	
0.99994135 7.094498e-07
Epoch: [434][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0620 (0.0649)	
0.9999566 3.86843e-06
loss:  0.04773810257685174 0.04312887322758707
===========>   training    <===========
Epoch: [435][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0576 (0.0576)	
0.99996555 7.385813e-08
===========>   testing    <===========
Epoch: [435][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0446 (0.0446)	
0.9999596 7.5753024e-07
Epoch: [435][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0389 (0.0644)	
0.9999207 1.1860892e-06
Epoch: [435][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0586 (0.0595)	
0.9999479 1.2367451e-06
loss:  0.04327211111820417 0.04312887322758707
===========>   training    <===========
Epoch: [436][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0528 (0.0528)	
0.99996936 2.2192792e-06
===========>   testing    <===========
Epoch: [436][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0506 (0.0506)	
0.99994206 1.535645e-06
Epoch: [436][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0458 (0.0676)	
0.9999093 1.3888225e-06
Epoch: [436][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0618 (0.0610)	
0.9999417 4.621264e-06
loss:  0.045873738616953874 0.04312887322758707
===========>   training    <===========
Epoch: [437][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0567 (0.0567)	
0.9999347 1.6121025e-07
===========>   testing    <===========
Epoch: [437][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0537 (0.0537)	
0.999938 4.6274855e-07
Epoch: [437][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0429 (0.0645)	
0.9998946 6.3851496e-07
Epoch: [437][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0794 (0.0577)	
0.99994206 1.3477936e-06
loss:  0.04267602613727539 0.04312887322758707
===========>   training    <===========
Epoch: [438][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0595 (0.0595)	
0.99996746 3.4182372e-07
===========>   testing    <===========
Epoch: [438][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0459 (0.0459)	
0.9999491 8.6897325e-07
Epoch: [438][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0333 (0.0632)	
0.9998785 1.2079449e-06
Epoch: [438][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0671 (0.0569)	
0.9999567 1.7390915e-06
loss:  0.041548509921996546 0.04267602613727539
===========>   training    <===========
Epoch: [439][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0588 (0.0588)	
0.9999796 1.4298561e-06
===========>   testing    <===========
Epoch: [439][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0505 (0.0505)	
0.9999577 1.6189259e-06
Epoch: [439][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.1591 (0.0642)	
0.9999249 2.4706899e-06
Epoch: [439][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0003405616262881148]	Loss 0.0660 (0.0586)	
0.9999516 2.6650598e-06
loss:  0.04451911843741263 0.041548509921996546
===========>   training    <===========
Epoch: [440][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0521 (0.0521)	
0.99996626 6.7135676e-07
===========>   testing    <===========
Epoch: [440][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0442 (0.0442)	
0.99996436 8.7581043e-07
Epoch: [440][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0332 (0.0668)	
0.9999069 1.1096754e-06
Epoch: [440][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.1126 (0.0605)	
0.99995184 2.2200456e-06
loss:  0.045874315867004856 0.041548509921996546
===========>   training    <===========
Epoch: [441][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0554 (0.0554)	
0.9999708 1.0255119e-06
===========>   testing    <===========
Epoch: [441][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0762 (0.0762)	
0.9999529 1.4222806e-07
Epoch: [441][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.2789 (0.0703)	
0.9999193 2.5164707e-07
Epoch: [441][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0395 (0.0617)	
0.99994516 2.8103904e-07
loss:  0.046982442249216994 0.041548509921996546
===========>   training    <===========
Epoch: [442][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0484 (0.0484)	
0.99997175 3.518577e-07
===========>   testing    <===========
Epoch: [442][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0499 (0.0499)	
0.9999552 6.9579943e-07
Epoch: [442][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0344 (0.0678)	
0.9999267 8.903162e-07
Epoch: [442][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0630 (0.0622)	
0.99994576 5.248677e-07
loss:  0.046163589568763985 0.041548509921996546
===========>   training    <===========
Epoch: [443][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0540 (0.0540)	
0.9999809 1.4939643e-06
===========>   testing    <===========
Epoch: [443][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0430 (0.0430)	
0.9999528 3.138537e-07
Epoch: [443][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0365 (0.0643)	
0.99993515 4.6526512e-07
Epoch: [443][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.1163 (0.0577)	
0.9999428 3.8287294e-07
loss:  0.0427387420152745 0.041548509921996546
===========>   training    <===========
Epoch: [444][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0442 (0.0442)	
0.999964 4.5463509e-07
===========>   testing    <===========
Epoch: [444][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0522 (0.0522)	
0.9999577 8.3077975e-07
Epoch: [444][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0344 (0.0611)	
0.9999428 1.2097433e-06
Epoch: [444][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0948 (0.0562)	
0.9999509 1.0124265e-06
loss:  0.041398160100248216 0.041548509921996546
===========>   training    <===========
Epoch: [445][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0504 (0.0504)	
0.9999751 4.404025e-07
===========>   testing    <===========
Epoch: [445][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0857 (0.0857)	
0.99996877 2.1854801e-07
Epoch: [445][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0801 (0.0652)	
0.9999397 3.9784095e-07
Epoch: [445][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0648 (0.0588)	
0.9999651 1.0229352e-06
loss:  0.043816674671323 0.041398160100248216
===========>   training    <===========
Epoch: [446][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0587 (0.0587)	
0.9999821 7.059228e-07
===========>   testing    <===========
Epoch: [446][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0498 (0.0498)	
0.9999553 4.7022186e-07
Epoch: [446][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0515 (0.0667)	
0.99991703 5.8933824e-07
Epoch: [446][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.1042 (0.0602)	
0.9999517 9.630938e-07
loss:  0.04441289121128622 0.041398160100248216
===========>   training    <===========
Epoch: [447][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0489 (0.0489)	
0.9999838 3.2838304e-07
===========>   testing    <===========
Epoch: [447][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0490 (0.0490)	
0.9999596 1.7994046e-07
Epoch: [447][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0781 (0.0645)	
0.9999144 3.1073725e-07
Epoch: [447][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0837 (0.0591)	
0.9999522 1.8696184e-07
loss:  0.04344499437067906 0.041398160100248216
===========>   training    <===========
Epoch: [448][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0617 (0.0617)	
0.99996006 1.58849e-07
===========>   testing    <===========
Epoch: [448][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0594 (0.0594)	
0.99995077 8.836946e-08
Epoch: [448][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0812 (0.0645)	
0.9999045 1.5625675e-07
Epoch: [448][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0925 (0.0622)	
0.9999515 1.0242223e-07
loss:  0.047453645947424405 0.041398160100248216
===========>   training    <===========
Epoch: [449][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0576 (0.0576)	
0.99997926 4.2760732e-08
===========>   testing    <===========
Epoch: [449][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0562 (0.0562)	
0.99994695 5.648401e-07
Epoch: [449][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0566 (0.0678)	
0.999908 5.375302e-07
Epoch: [449][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.1035 (0.0633)	
0.99993455 7.945217e-07
loss:  0.04628205776082239 0.041398160100248216
===========>   training    <===========
Epoch: [450][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0566 (0.0566)	
0.9999684 1.6304772e-07
===========>   testing    <===========
Epoch: [450][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0571 (0.0571)	
0.99994886 3.3321984e-07
Epoch: [450][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0346 (0.0629)	
0.9998865 3.701544e-07
Epoch: [450][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0324 (0.0574)	
0.9999167 4.770946e-07
loss:  0.045035180586695756 0.041398160100248216
===========>   training    <===========
Epoch: [451][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0476 (0.0476)	
0.99998236 5.540841e-07
===========>   testing    <===========
Epoch: [451][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0469 (0.0469)	
0.9999714 5.2091127e-07
Epoch: [451][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0827 (0.0665)	
0.9999206 6.8724864e-07
Epoch: [451][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0540 (0.0601)	
0.99994767 1.4327458e-06
loss:  0.04414594416140538 0.041398160100248216
===========>   training    <===========
Epoch: [452][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0451 (0.0451)	
0.999962 1.6312158e-07
===========>   testing    <===========
Epoch: [452][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0558 (0.0558)	
0.9999572 9.752237e-07
Epoch: [452][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0720 (0.0676)	
0.9999175 8.3628134e-07
Epoch: [452][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0860 (0.0617)	
0.9999523 3.4283553e-06
loss:  0.045732592496488644 0.041398160100248216
===========>   training    <===========
Epoch: [453][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0431 (0.0431)	
0.9999627 3.9069636e-07
===========>   testing    <===========
Epoch: [453][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0355 (0.0355)	
0.9999552 1.7109494e-06
Epoch: [453][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0645 (0.0617)	
0.99994624 1.7514212e-06
Epoch: [453][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0711 (0.0575)	
0.99995434 1.6057471e-06
loss:  0.0433060356450059 0.041398160100248216
===========>   training    <===========
Epoch: [454][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0501 (0.0501)	
0.99996424 5.746435e-07
===========>   testing    <===========
Epoch: [454][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0391 (0.0391)	
0.9999647 9.3838764e-07
Epoch: [454][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0436 (0.0632)	
0.99993885 1.2904105e-06
Epoch: [454][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0615 (0.0580)	
0.9999368 7.5269173e-07
loss:  0.04371341704741594 0.041398160100248216
===========>   training    <===========
Epoch: [455][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0579 (0.0579)	
0.9999478 1.7597243e-07
===========>   testing    <===========
Epoch: [455][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0542 (0.0542)	
0.99996626 1.0568308e-06
Epoch: [455][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0403 (0.0706)	
0.9999007 1.4517306e-06
Epoch: [455][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0717 (0.0635)	
0.99994826 2.0235932e-06
loss:  0.0470438877440299 0.041398160100248216
===========>   training    <===========
Epoch: [456][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0498 (0.0498)	
0.99996185 1.0269085e-05
===========>   testing    <===========
Epoch: [456][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0621 (0.0621)	
0.99996996 5.969395e-07
Epoch: [456][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0571 (0.0664)	
0.9998542 7.562158e-07
Epoch: [456][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0356 (0.0605)	
0.9999496 9.5027434e-07
loss:  0.04459886885559583 0.041398160100248216
===========>   training    <===========
Epoch: [457][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0551 (0.0551)	
0.9999659 1.6844719e-07
===========>   testing    <===========
Epoch: [457][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0477 (0.0477)	
0.99996483 4.5884232e-07
Epoch: [457][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0358 (0.0684)	
0.9998486 5.93151e-07
Epoch: [457][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0693 (0.0616)	
0.9999602 6.5544907e-07
loss:  0.0451412408890014 0.041398160100248216
===========>   training    <===========
Epoch: [458][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0547 (0.0547)	
0.9999633 2.683988e-06
===========>   testing    <===========
Epoch: [458][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0399 (0.0399)	
0.99996686 9.508264e-07
Epoch: [458][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0311 (0.0654)	
0.999912 9.616465e-07
Epoch: [458][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0698 (0.0608)	
0.9999485 1.5736158e-06
loss:  0.04420590909865019 0.041398160100248216
===========>   training    <===========
Epoch: [459][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0540 (0.0540)	
0.99997926 2.2671245e-06
===========>   testing    <===========
Epoch: [459][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0364 (0.0364)	
0.99996555 2.4598697e-07
Epoch: [459][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0332 (0.0670)	
0.9999436 3.088317e-07
Epoch: [459][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000323533544973709]	Loss 0.0339 (0.0607)	
0.99996376 6.0180383e-07
loss:  0.043932799936535316 0.041398160100248216
===========>   training    <===========
Epoch: [460][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0577 (0.0577)	
0.9999728 3.6449634e-07
===========>   testing    <===========
Epoch: [460][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0612 (0.0612)	
0.999954 1.4004024e-07
Epoch: [460][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0432 (0.0707)	
0.99986804 1.344866e-07
Epoch: [460][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0352 (0.0615)	
0.9999354 1.6299516e-07
loss:  0.04668691779969014 0.041398160100248216
===========>   training    <===========
Epoch: [461][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0572 (0.0572)	
0.99996173 6.103023e-07
===========>   testing    <===========
Epoch: [461][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0431 (0.0431)	
0.9999672 5.885081e-07
Epoch: [461][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0548 (0.0644)	
0.99991786 5.5666726e-07
Epoch: [461][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0566 (0.0585)	
0.9999517 7.045743e-07
loss:  0.04328224345368603 0.041398160100248216
===========>   training    <===========
Epoch: [462][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0565 (0.0565)	
0.99995804 5.3586223e-08
===========>   testing    <===========
Epoch: [462][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0520 (0.0520)	
0.99996173 7.499232e-07
Epoch: [462][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0385 (0.0613)	
0.99993813 8.7904453e-07
Epoch: [462][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0269 (0.0565)	
0.9999528 7.3051825e-07
loss:  0.04266833505593293 0.041398160100248216
===========>   training    <===========
Epoch: [463][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0496 (0.0496)	
0.99996054 4.211192e-07
===========>   testing    <===========
Epoch: [463][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.1004 (0.1004)	
0.9999503 9.935121e-07
Epoch: [463][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0847 (0.0711)	
0.9998895 8.9041555e-07
Epoch: [463][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0421 (0.0637)	
0.99995244 1.357088e-06
loss:  0.048107422479698125 0.041398160100248216
===========>   training    <===========
Epoch: [464][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0652 (0.0652)	
0.99997735 2.2385707e-07
===========>   testing    <===========
Epoch: [464][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0340 (0.0340)	
0.9999664 6.516366e-07
Epoch: [464][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0650 (0.0657)	
0.9998996 8.7488957e-07
Epoch: [464][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0282 (0.0589)	
0.99994755 8.857802e-07
loss:  0.04368900517815577 0.041398160100248216
===========>   training    <===========
Epoch: [465][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0481 (0.0481)	
0.9999366 8.689379e-08
===========>   testing    <===========
Epoch: [465][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0459 (0.0459)	
0.9999651 1.4228045e-06
Epoch: [465][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.1092 (0.0638)	
0.9999157 1.1531591e-06
Epoch: [465][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0305 (0.0579)	
0.9999424 8.5345977e-07
loss:  0.045814672462250905 0.041398160100248216
===========>   training    <===========
Epoch: [466][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0453 (0.0453)	
0.9999527 3.8516626e-07
===========>   testing    <===========
Epoch: [466][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0627 (0.0627)	
0.99996674 9.603945e-07
Epoch: [466][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0923 (0.0738)	
0.99992967 6.520605e-07
Epoch: [466][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0476 (0.0646)	
0.9999639 1.0799157e-06
loss:  0.04692613252762168 0.041398160100248216
===========>   training    <===========
Epoch: [467][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0519 (0.0519)	
0.9999583 1.0961733e-06
===========>   testing    <===========
Epoch: [467][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0437 (0.0437)	
0.9999747 7.010675e-07
Epoch: [467][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0917 (0.0652)	
0.99992883 6.9350733e-07
Epoch: [467][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0804 (0.0599)	
0.999961 6.676268e-07
loss:  0.04515305784139123 0.041398160100248216
===========>   training    <===========
Epoch: [468][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0498 (0.0498)	
0.99997604 5.2964145e-07
===========>   testing    <===========
Epoch: [468][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0504 (0.0504)	
0.99996877 3.5345317e-07
Epoch: [468][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.1000 (0.0660)	
0.9999262 4.5051152e-07
Epoch: [468][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0508 (0.0581)	
0.99996185 3.8108504e-07
loss:  0.04450492679607865 0.041398160100248216
===========>   training    <===========
Epoch: [469][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0705 (0.0705)	
0.9999838 9.931607e-07
===========>   testing    <===========
Epoch: [469][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0479 (0.0479)	
0.9999746 1.2235132e-06
Epoch: [469][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0648 (0.0630)	
0.99992967 1.3884412e-06
Epoch: [469][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.1007 (0.0585)	
0.9999597 8.716666e-07
loss:  0.04371359481102177 0.041398160100248216
===========>   training    <===========
Epoch: [470][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0467 (0.0467)	
0.9999689 6.857671e-07
===========>   testing    <===========
Epoch: [470][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0745 (0.0745)	
0.99996185 3.9619167e-07
Epoch: [470][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.1886 (0.0658)	
0.9999243 8.1801824e-07
Epoch: [470][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0533 (0.0602)	
0.9999528 4.2974463e-07
loss:  0.046507641817384204 0.041398160100248216
===========>   training    <===========
Epoch: [471][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0559 (0.0559)	
0.99997556 2.519842e-07
===========>   testing    <===========
Epoch: [471][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0460 (0.0460)	
0.99997985 7.911918e-07
Epoch: [471][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0381 (0.0667)	
0.9999609 7.297461e-07
Epoch: [471][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0750 (0.0621)	
0.999954 8.8996984e-07
loss:  0.04570890928258253 0.041398160100248216
===========>   training    <===========
Epoch: [472][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0525 (0.0525)	
0.99994886 6.2424385e-07
===========>   testing    <===========
Epoch: [472][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0459 (0.0459)	
0.9999807 5.994948e-07
Epoch: [472][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0366 (0.0649)	
0.99993885 6.568e-07
Epoch: [472][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0682 (0.0600)	
0.9999633 9.21802e-07
loss:  0.04551450815595304 0.041398160100248216
===========>   training    <===========
Epoch: [473][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0430 (0.0430)	
0.99997807 1.18020665e-07
===========>   testing    <===========
Epoch: [473][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0837 (0.0837)	
0.9999765 2.1791086e-06
Epoch: [473][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0326 (0.0630)	
0.99989724 2.467106e-06
Epoch: [473][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0335 (0.0572)	
0.9999511 2.448703e-06
loss:  0.04263979191891332 0.041398160100248216
===========>   training    <===========
Epoch: [474][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0504 (0.0504)	
0.9999691 8.437194e-07
===========>   testing    <===========
Epoch: [474][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0586 (0.0586)	
0.9999745 7.600739e-07
Epoch: [474][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0261 (0.0651)	
0.99991727 4.71196e-07
Epoch: [474][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0683 (0.0600)	
0.999946 1.7363818e-06
loss:  0.04476369076436082 0.041398160100248216
===========>   training    <===========
Epoch: [475][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0602 (0.0602)	
0.9999739 1.0861672e-07
===========>   testing    <===========
Epoch: [475][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0861 (0.0861)	
0.9999733 1.3805149e-07
Epoch: [475][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0236 (0.0637)	
0.9999472 1.1779083e-07
Epoch: [475][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0606 (0.0619)	
0.9999486 6.370011e-07
loss:  0.04812885194032279 0.041398160100248216
===========>   training    <===========
Epoch: [476][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0562 (0.0562)	
0.9999739 3.1324785e-07
===========>   testing    <===========
Epoch: [476][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0739 (0.0739)	
0.999962 8.411084e-07
Epoch: [476][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0251 (0.0605)	
0.999938 7.87721e-07
Epoch: [476][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0683 (0.0598)	
0.99994504 1.4570247e-06
loss:  0.04561407674562634 0.041398160100248216
===========>   training    <===========
Epoch: [477][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0560 (0.0560)	
0.9999734 1.3428825e-06
===========>   testing    <===========
Epoch: [477][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0420 (0.0420)	
0.9999664 1.1973873e-06
Epoch: [477][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0216 (0.0616)	
0.99993324 1.2465342e-06
Epoch: [477][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0950 (0.0599)	
0.99994755 1.1385989e-06
loss:  0.044829506052873835 0.041398160100248216
===========>   training    <===========
Epoch: [478][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0510 (0.0510)	
0.9999771 1.1324134e-06
===========>   testing    <===========
Epoch: [478][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0752 (0.0752)	
0.99997354 3.9327537e-07
Epoch: [478][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0205 (0.0691)	
0.99995613 5.42842e-07
Epoch: [478][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0970 (0.0618)	
0.99995506 6.9937335e-07
loss:  0.04473738163779062 0.041398160100248216
===========>   training    <===========
Epoch: [479][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0516 (0.0516)	
0.999966 4.8978364e-07
===========>   testing    <===========
Epoch: [479][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0618 (0.0618)	
0.9999726 2.5945351e-07
Epoch: [479][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0246 (0.0651)	
0.9999291 4.0262273e-07
Epoch: [479][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00030735686772502356]	Loss 0.0876 (0.0594)	
0.99995637 6.200443e-07
loss:  0.043928819636402494 0.041398160100248216
===========>   training    <===========
Epoch: [480][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0586 (0.0586)	
0.9999683 1.9243853e-06
===========>   testing    <===========
Epoch: [480][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0542 (0.0542)	
0.9999759 8.308891e-07
Epoch: [480][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0412 (0.0633)	
0.999946 1.1188149e-06
Epoch: [480][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.1008 (0.0598)	
0.99995947 1.4386264e-06
loss:  0.04383791125303049 0.041398160100248216
===========>   training    <===========
Epoch: [481][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0608 (0.0608)	
0.99996316 4.5045354e-07
===========>   testing    <===========
Epoch: [481][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0453 (0.0453)	
0.99997616 6.6620464e-07
Epoch: [481][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0935 (0.0640)	
0.99993956 1.1053735e-06
Epoch: [481][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0775 (0.0590)	
0.9999548 8.954226e-07
loss:  0.04544259311823162 0.041398160100248216
===========>   training    <===========
Epoch: [482][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0613 (0.0613)	
0.9999672 1.897654e-07
===========>   testing    <===========
Epoch: [482][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0416 (0.0416)	
0.9999769 8.8910116e-07
Epoch: [482][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0509 (0.0608)	
0.9999354 1.1517764e-06
Epoch: [482][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0732 (0.0567)	
0.9999585 9.589813e-07
loss:  0.0423942142327457 0.041398160100248216
===========>   training    <===========
Epoch: [483][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0593 (0.0593)	
0.9999677 9.409317e-07
===========>   testing    <===========
Epoch: [483][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0464 (0.0464)	
0.99997616 1.6658875e-06
Epoch: [483][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0236 (0.0652)	
0.9999515 1.6019569e-06
Epoch: [483][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.1047 (0.0613)	
0.9999616 2.0282455e-06
loss:  0.04482086430234111 0.041398160100248216
===========>   training    <===========
Epoch: [484][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0506 (0.0506)	
0.9999715 3.8003833e-07
===========>   testing    <===========
Epoch: [484][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0848 (0.0848)	
0.99996996 1.7723018e-07
Epoch: [484][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0202 (0.0636)	
0.9999398 2.9434244e-07
Epoch: [484][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0771 (0.0591)	
0.99996674 1.5976316e-07
loss:  0.043251954605872944 0.041398160100248216
===========>   training    <===========
Epoch: [485][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0644 (0.0644)	
0.99997807 6.617468e-07
===========>   testing    <===========
Epoch: [485][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0563 (0.0563)	
0.99996483 7.9396125e-07
Epoch: [485][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0225 (0.0645)	
0.99994564 8.369923e-07
Epoch: [485][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0387 (0.0601)	
0.99994886 7.318362e-07
loss:  0.044278338432614084 0.041398160100248216
===========>   training    <===========
Epoch: [486][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0607 (0.0607)	
0.99998343 2.9787483e-07
===========>   testing    <===========
Epoch: [486][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0368 (0.0368)	
0.99996245 6.489766e-07
Epoch: [486][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0171 (0.0663)	
0.99991953 5.446466e-07
Epoch: [486][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0939 (0.0620)	
0.9999572 4.1046118e-07
loss:  0.04664440216214727 0.041398160100248216
===========>   training    <===========
Epoch: [487][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0507 (0.0507)	
0.99996805 1.6023373e-06
===========>   testing    <===========
Epoch: [487][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0399 (0.0399)	
0.9999789 1.0943568e-06
Epoch: [487][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0249 (0.0652)	
0.9999424 1.1408249e-06
Epoch: [487][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0507 (0.0595)	
0.9999541 1.2340247e-06
loss:  0.044756494017829995 0.041398160100248216
===========>   training    <===========
Epoch: [488][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0772 (0.0772)	
0.99997973 4.9277414e-06
===========>   testing    <===========
Epoch: [488][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.1035 (0.1035)	
0.99997234 5.388272e-07
Epoch: [488][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0592 (0.0668)	
0.99995136 6.9658824e-07
Epoch: [488][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0504 (0.0603)	
0.9999547 4.755143e-07
loss:  0.045664476995091574 0.041398160100248216
===========>   training    <===========
Epoch: [489][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0493 (0.0493)	
0.9999832 5.367869e-07
===========>   testing    <===========
Epoch: [489][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0824 (0.0824)	
0.99997544 1.846482e-06
Epoch: [489][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0488 (0.0672)	
0.99993706 2.2650413e-06
Epoch: [489][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0454 (0.0591)	
0.99996185 1.7546143e-06
loss:  0.04421967395359361 0.041398160100248216
===========>   training    <===========
Epoch: [490][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0462 (0.0462)	
0.9999789 4.3454088e-07
===========>   testing    <===========
Epoch: [490][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0386 (0.0386)	
0.99997556 6.9409623e-07
Epoch: [490][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0233 (0.0678)	
0.99995005 1.1720172e-06
Epoch: [490][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.1107 (0.0609)	
0.99996364 6.627314e-07
loss:  0.04466249737249384 0.041398160100248216
===========>   training    <===========
Epoch: [491][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0549 (0.0549)	
0.9999751 4.1556177e-08
===========>   testing    <===========
Epoch: [491][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0866 (0.0866)	
0.99998057 5.9221105e-07
Epoch: [491][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0345 (0.0642)	
0.99993885 1.0620028e-06
Epoch: [491][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0664 (0.0590)	
0.9999727 6.867927e-07
loss:  0.044526465724004316 0.041398160100248216
===========>   training    <===========
Epoch: [492][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0535 (0.0535)	
0.99997675 1.3435059e-07
===========>   testing    <===========
Epoch: [492][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0524 (0.0524)	
0.9999784 1.829661e-06
Epoch: [492][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0408 (0.0641)	
0.9999366 1.5520318e-06
Epoch: [492][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0539 (0.0596)	
0.99995613 1.8822736e-06
loss:  0.046299636668031496 0.041398160100248216
===========>   training    <===========
Epoch: [493][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0461 (0.0461)	
0.99998057 2.2227023e-06
===========>   testing    <===========
Epoch: [493][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0638 (0.0638)	
0.9999701 6.5740784e-07
Epoch: [493][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0551 (0.0659)	
0.99995613 1.2856667e-06
Epoch: [493][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0689 (0.0611)	
0.99996376 9.72138e-07
loss:  0.04587940590699402 0.041398160100248216
===========>   training    <===========
Epoch: [494][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0552 (0.0552)	
0.9999783 4.757166e-07
===========>   testing    <===========
Epoch: [494][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0752 (0.0752)	
0.99997044 7.409969e-07
Epoch: [494][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0278 (0.0672)	
0.99992085 1.0018871e-06
Epoch: [494][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0675 (0.0612)	
0.99995434 9.825472e-07
loss:  0.04493363441331677 0.041398160100248216
===========>   training    <===========
Epoch: [495][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0468 (0.0468)	
0.9999752 3.2726942e-07
===========>   testing    <===========
Epoch: [495][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0477 (0.0477)	
0.9999689 8.6428713e-07
Epoch: [495][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.1274 (0.0695)	
0.99995387 9.3362e-07
Epoch: [495][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0600 (0.0615)	
0.99996245 1.0633476e-06
loss:  0.04644294519471237 0.041398160100248216
===========>   training    <===========
Epoch: [496][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0477 (0.0477)	
0.9999808 2.0308198e-06
===========>   testing    <===========
Epoch: [496][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0429 (0.0429)	
0.9999738 7.7312933e-07
Epoch: [496][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0268 (0.0638)	
0.9999548 8.069813e-07
Epoch: [496][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0917 (0.0603)	
0.99996126 1.3509156e-06
loss:  0.045223114459582825 0.041398160100248216
===========>   training    <===========
Epoch: [497][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0658 (0.0658)	
0.999966 6.206795e-09
===========>   testing    <===========
Epoch: [497][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0659 (0.0659)	
0.9999789 3.0642425e-07
Epoch: [497][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0251 (0.0656)	
0.9999409 2.746728e-07
Epoch: [497][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0970 (0.0609)	
0.99996936 4.064219e-07
loss:  0.045090590722066226 0.041398160100248216
===========>   training    <===========
Epoch: [498][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0502 (0.0502)	
0.99998176 3.2048436e-07
===========>   testing    <===========
Epoch: [498][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0968 (0.0968)	
0.99997485 7.193078e-07
Epoch: [498][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0465 (0.0671)	
0.9999505 7.767846e-07
Epoch: [498][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0568 (0.0607)	
0.99996006 6.6773504e-07
loss:  0.04444594423829673 0.041398160100248216
===========>   training    <===========
Epoch: [499][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0440 (0.0440)	
0.9999815 1.3635389e-05
===========>   testing    <===========
Epoch: [499][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0575 (0.0575)	
0.99996185 6.5346495e-07
Epoch: [499][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0748 (0.0633)	
0.9999387 5.4884606e-07
Epoch: [499][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0002919890243387724]	Loss 0.0800 (0.0590)	
0.99996483 5.654152e-07
loss:  0.044212321985506065 0.041398160100248216
===========>   training    <===========
Epoch: [500][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0588 (0.0588)	
0.99997115 9.892067e-07
===========>   testing    <===========
Epoch: [500][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0599 (0.0599)	
0.99996686 1.7832299e-06
Epoch: [500][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0355 (0.0679)	
0.9999529 1.1821346e-06
Epoch: [500][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0787 (0.0627)	
0.9999684 1.8369569e-06
loss:  0.04511169325526743 0.041398160100248216
===========>   training    <===========
Epoch: [501][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0516 (0.0516)	
0.99997187 3.923957e-07
===========>   testing    <===========
Epoch: [501][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0724 (0.0724)	
0.9999765 1.2212518e-06
Epoch: [501][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0433 (0.0633)	
0.99993443 1.6423312e-06
Epoch: [501][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.1145 (0.0575)	
0.9999566 1.4659547e-06
loss:  0.04371956997011983 0.041398160100248216
===========>   training    <===========
Epoch: [502][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0505 (0.0505)	
0.99997926 1.4331175e-06
===========>   testing    <===========
Epoch: [502][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0877 (0.0877)	
0.9999771 1.5033602e-06
Epoch: [502][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0593 (0.0678)	
0.9999387 1.2217666e-06
Epoch: [502][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0563 (0.0606)	
0.9999547 2.068407e-06
loss:  0.045267982253272 0.041398160100248216
===========>   training    <===========
Epoch: [503][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0433 (0.0433)	
0.99997795 1.6370318e-06
===========>   testing    <===========
Epoch: [503][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0704 (0.0704)	
0.9999769 2.163215e-06
Epoch: [503][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0547 (0.0631)	
0.99993503 2.650253e-06
Epoch: [503][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.1048 (0.0580)	
0.99995935 1.9998172e-06
loss:  0.04383216469848428 0.041398160100248216
===========>   training    <===========
Epoch: [504][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0519 (0.0519)	
0.9999782 1.1633124e-06
===========>   testing    <===========
Epoch: [504][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0600 (0.0600)	
0.9999795 7.9477184e-07
Epoch: [504][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0349 (0.0633)	
0.9999461 6.1232527e-07
Epoch: [504][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0774 (0.0571)	
0.9999622 8.2112905e-07
loss:  0.0437032484662343 0.041398160100248216
===========>   training    <===========
Epoch: [505][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0522 (0.0522)	
0.9999726 2.217865e-07
===========>   testing    <===========
Epoch: [505][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0547 (0.0547)	
0.9999738 9.091514e-07
Epoch: [505][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0719 (0.0665)	
0.9999273 1.2723738e-06
Epoch: [505][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0538 (0.0604)	
0.9999629 1.2747786e-06
loss:  0.04336877460254929 0.041398160100248216
===========>   training    <===========
Epoch: [506][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0561 (0.0561)	
0.9999832 6.6288186e-07
===========>   testing    <===========
Epoch: [506][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0411 (0.0411)	
0.999977 2.5571575e-07
Epoch: [506][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0297 (0.0654)	
0.9999274 2.776348e-07
Epoch: [506][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0745 (0.0591)	
0.9999621 5.5924744e-07
loss:  0.04458844767747372 0.041398160100248216
===========>   training    <===========
Epoch: [507][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0480 (0.0480)	
0.99996483 2.6456723e-07
===========>   testing    <===========
Epoch: [507][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0569 (0.0569)	
0.99997175 4.9735667e-07
Epoch: [507][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0265 (0.0620)	
0.99994576 3.6929794e-07
Epoch: [507][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0639 (0.0572)	
0.9999614 6.573953e-07
loss:  0.043397782107363225 0.041398160100248216
===========>   training    <===========
Epoch: [508][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0624 (0.0624)	
0.99997926 6.231316e-08
===========>   testing    <===========
Epoch: [508][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0507 (0.0507)	
0.99996984 7.915721e-07
Epoch: [508][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0499 (0.0628)	
0.99992394 7.4716195e-07
Epoch: [508][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.1082 (0.0611)	
0.9999658 2.1326182e-06
loss:  0.04702808250347168 0.041398160100248216
===========>   training    <===========
Epoch: [509][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0390 (0.0390)	
0.99998665 5.0538166e-08
===========>   testing    <===========
Epoch: [509][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0457 (0.0457)	
0.9999726 7.201947e-07
Epoch: [509][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0268 (0.0598)	
0.9999087 8.158446e-07
Epoch: [509][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0655 (0.0596)	
0.9999596 8.9637354e-07
loss:  0.044186313832621615 0.041398160100248216
===========>   training    <===========
Epoch: [510][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0550 (0.0550)	
0.99996614 1.2188393e-07
===========>   testing    <===========
Epoch: [510][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0786 (0.0786)	
0.99996984 1.5972598e-06
Epoch: [510][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0798 (0.0680)	
0.9999366 1.0962402e-06
Epoch: [510][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0581 (0.0652)	
0.9999603 7.45549e-07
loss:  0.046883171469412566 0.041398160100248216
===========>   training    <===========
Epoch: [511][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0546 (0.0546)	
0.99997056 5.7601856e-06
===========>   testing    <===========
Epoch: [511][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0666 (0.0666)	
0.9999697 1.1288094e-07
Epoch: [511][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0746 (0.0643)	
0.99994254 1.6230892e-07
Epoch: [511][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0698 (0.0604)	
0.9999665 7.295896e-08
loss:  0.0453681680463377 0.041398160100248216
===========>   training    <===========
Epoch: [512][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0601 (0.0601)	
0.9999691 4.4188343e-07
===========>   testing    <===========
Epoch: [512][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0387 (0.0387)	
0.9999782 2.1394774e-06
Epoch: [512][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0268 (0.0626)	
0.9999536 1.6380094e-06
Epoch: [512][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0785 (0.0604)	
0.99997175 2.0007385e-06
loss:  0.044695168994971834 0.041398160100248216
===========>   training    <===========
Epoch: [513][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0509 (0.0509)	
0.9999753 4.1752287e-06
===========>   testing    <===========
Epoch: [513][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0860 (0.0860)	
0.99997723 7.736427e-07
Epoch: [513][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0326 (0.0618)	
0.9999268 8.909719e-07
Epoch: [513][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0758 (0.0585)	
0.99996436 9.737813e-07
loss:  0.044527353686413695 0.041398160100248216
===========>   training    <===========
Epoch: [514][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0531 (0.0531)	
0.99997556 1.9952574e-07
===========>   testing    <===========
Epoch: [514][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0419 (0.0419)	
0.99997616 9.0910464e-07
Epoch: [514][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0220 (0.0638)	
0.99993765 4.80446e-07
Epoch: [514][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0635 (0.0580)	
0.999961 8.419013e-07
loss:  0.04328001511620161 0.041398160100248216
===========>   training    <===========
Epoch: [515][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0419 (0.0419)	
0.99997544 2.2624267e-06
===========>   testing    <===========
Epoch: [515][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0514 (0.0514)	
0.9999788 6.7341256e-07
Epoch: [515][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0244 (0.0637)	
0.99995387 4.1105662e-07
Epoch: [515][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.1078 (0.0596)	
0.9999676 6.0449696e-07
loss:  0.04485621441284493 0.041398160100248216
===========>   training    <===========
Epoch: [516][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0472 (0.0472)	
0.9999747 1.2931504e-06
===========>   testing    <===========
Epoch: [516][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0612 (0.0612)	
0.9999689 2.0355799e-06
Epoch: [516][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0249 (0.0629)	
0.9999455 1.2377161e-06
Epoch: [516][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0397 (0.0579)	
0.9999652 2.5882307e-06
loss:  0.044743575192714324 0.041398160100248216
===========>   training    <===========
Epoch: [517][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0685 (0.0685)	
0.9999696 6.6986665e-08
===========>   testing    <===========
Epoch: [517][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0479 (0.0479)	
0.999972 2.2300732e-07
Epoch: [517][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0184 (0.0599)	
0.9999138 1.9908704e-07
Epoch: [517][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0729 (0.0587)	
0.99996066 2.7281976e-07
loss:  0.04422764295171244 0.041398160100248216
===========>   training    <===========
Epoch: [518][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0525 (0.0525)	
0.9999591 8.546052e-08
===========>   testing    <===========
Epoch: [518][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0792 (0.0792)	
0.99996686 5.452515e-07
Epoch: [518][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0242 (0.0605)	
0.9999192 4.907248e-07
Epoch: [518][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0673 (0.0578)	
0.9999646 9.283444e-07
loss:  0.04372526797702847 0.041398160100248216
===========>   training    <===========
Epoch: [519][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0568 (0.0568)	
0.9999739 4.5020786e-07
===========>   testing    <===========
Epoch: [519][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0501 (0.0501)	
0.999969 9.4104035e-07
Epoch: [519][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0246 (0.0658)	
0.9999366 5.3648495e-07
Epoch: [519][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00027738957312183375]	Loss 0.0579 (0.0619)	
0.99996066 1.4227693e-06
loss:  0.046765726182637746 0.041398160100248216
===========>   training    <===========
Epoch: [520][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0521 (0.0521)	
0.99996746 6.2618886e-07
===========>   testing    <===========
Epoch: [520][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0452 (0.0452)	
0.9999726 1.2506971e-06
Epoch: [520][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0391 (0.0593)	
0.9999441 1.348861e-06
Epoch: [520][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0752 (0.0555)	
0.999959 9.283736e-07
loss:  0.04277107421079451 0.041398160100248216
===========>   training    <===========
Epoch: [521][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0462 (0.0462)	
0.99997795 4.1398476e-07
===========>   testing    <===========
Epoch: [521][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0352 (0.0352)	
0.99997425 7.906299e-07
Epoch: [521][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0289 (0.0601)	
0.99992406 8.1978953e-07
Epoch: [521][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.1070 (0.0561)	
0.9999697 5.669378e-07
loss:  0.043803828418355506 0.041398160100248216
===========>   training    <===========
Epoch: [522][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0520 (0.0520)	
0.99998283 5.214605e-07
===========>   testing    <===========
Epoch: [522][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0377 (0.0377)	
0.9999765 7.9854476e-07
Epoch: [522][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0202 (0.0652)	
0.9999484 6.3554114e-07
Epoch: [522][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0843 (0.0590)	
0.99996996 8.251719e-07
loss:  0.0441480383454137 0.041398160100248216
===========>   training    <===========
Epoch: [523][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0581 (0.0581)	
0.99997425 8.456223e-08
===========>   testing    <===========
Epoch: [523][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0510 (0.0510)	
0.99996793 5.3354813e-07
Epoch: [523][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0191 (0.0645)	
0.9999435 5.5765395e-07
Epoch: [523][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0731 (0.0585)	
0.99996185 6.469775e-07
loss:  0.04402515696258025 0.041398160100248216
===========>   training    <===========
Epoch: [524][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0460 (0.0460)	
0.9999684 3.47645e-07
===========>   testing    <===========
Epoch: [524][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0535 (0.0535)	
0.99996865 3.2512418e-07
Epoch: [524][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0244 (0.0646)	
0.9999378 3.391924e-07
Epoch: [524][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0771 (0.0613)	
0.99995434 2.4009995e-07
loss:  0.047355048236869646 0.041398160100248216
===========>   training    <===========
Epoch: [525][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0638 (0.0638)	
0.9999784 3.0849378e-07
===========>   testing    <===========
Epoch: [525][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0562 (0.0562)	
0.9999347 1.6333999e-07
Epoch: [525][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0253 (0.0588)	
0.99987054 1.5331004e-07
Epoch: [525][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0625 (0.0574)	
0.99996984 1.0902186e-07
loss:  0.044063897037497135 0.041398160100248216
===========>   training    <===========
Epoch: [526][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0498 (0.0498)	
0.99997973 3.537351e-07
===========>   testing    <===========
Epoch: [526][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0376 (0.0376)	
0.9999696 1.6475725e-06
Epoch: [526][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.1215 (0.0704)	
0.99994874 1.4425749e-06
Epoch: [526][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0641 (0.0639)	
0.99995804 9.373903e-07
loss:  0.046359261159309106 0.041398160100248216
===========>   training    <===========
Epoch: [527][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0575 (0.0575)	
0.9999788 4.9355305e-07
===========>   testing    <===========
Epoch: [527][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0358 (0.0358)	
0.99997807 1.7223848e-06
Epoch: [527][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0308 (0.0683)	
0.999951 1.5760354e-06
Epoch: [527][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.1073 (0.0634)	
0.9999734 2.1229816e-06
loss:  0.04481011199371909 0.041398160100248216
===========>   training    <===========
Epoch: [528][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0431 (0.0431)	
0.99997234 1.0722304e-06
===========>   testing    <===========
Epoch: [528][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0589 (0.0589)	
0.9999713 5.737263e-07
Epoch: [528][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.1899 (0.0705)	
0.9999323 8.2490914e-07
Epoch: [528][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0387 (0.0632)	
0.99995995 7.511686e-07
loss:  0.047552536897331965 0.041398160100248216
===========>   training    <===========
Epoch: [529][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0450 (0.0450)	
0.9999746 9.0626355e-07
===========>   testing    <===========
Epoch: [529][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0495 (0.0495)	
0.9999751 3.3341723e-07
Epoch: [529][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0624 (0.0607)	
0.9999362 4.6626988e-07
Epoch: [529][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0956 (0.0578)	
0.99996793 2.951872e-07
loss:  0.04498788760733097 0.041398160100248216
===========>   training    <===========
Epoch: [530][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0519 (0.0519)	
0.99997604 1.8476427e-07
===========>   testing    <===========
Epoch: [530][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0579 (0.0579)	
0.99997604 1.0481966e-06
Epoch: [530][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0945 (0.0686)	
0.99994934 7.789626e-07
Epoch: [530][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0883 (0.0629)	
0.99996305 1.5034318e-06
loss:  0.04521102485846762 0.041398160100248216
===========>   training    <===========
Epoch: [531][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0484 (0.0484)	
0.99997616 4.947151e-07
===========>   testing    <===========
Epoch: [531][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0503 (0.0503)	
0.99995947 4.0788186e-07
Epoch: [531][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0454 (0.0628)	
0.99991286 3.5338473e-07
Epoch: [531][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0854 (0.0593)	
0.999962 4.2243053e-07
loss:  0.044268608847954916 0.041398160100248216
===========>   training    <===========
Epoch: [532][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0548 (0.0548)	
0.9999745 5.5847043e-08
===========>   testing    <===========
Epoch: [532][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0418 (0.0418)	
0.9999814 7.2863133e-07
Epoch: [532][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0292 (0.0619)	
0.99994564 6.938421e-07
Epoch: [532][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.1072 (0.0590)	
0.9999633 3.4825524e-07
loss:  0.04417030355255813 0.041398160100248216
===========>   training    <===========
Epoch: [533][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0493 (0.0493)	
0.9999827 7.7276674e-08
===========>   testing    <===========
Epoch: [533][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0461 (0.0461)	
0.9999734 8.313742e-07
Epoch: [533][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0290 (0.0609)	
0.9999467 1.0787793e-06
Epoch: [533][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0680 (0.0570)	
0.9999639 8.692708e-07
loss:  0.04314520144721079 0.041398160100248216
===========>   training    <===========
Epoch: [534][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0493 (0.0493)	
0.9999784 1.963702e-07
===========>   testing    <===========
Epoch: [534][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0474 (0.0474)	
0.9999784 1.0202292e-07
Epoch: [534][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0407 (0.0667)	
0.99992335 1.7618973e-07
Epoch: [534][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0524 (0.0606)	
0.9999646 2.4312436e-07
loss:  0.04539430478520734 0.041398160100248216
===========>   training    <===========
Epoch: [535][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0446 (0.0446)	
0.99998057 2.1677697e-07
===========>   testing    <===========
Epoch: [535][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0407 (0.0407)	
0.9999831 6.924579e-07
Epoch: [535][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0302 (0.0678)	
0.99994683 1.3868782e-06
Epoch: [535][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0814 (0.0608)	
0.99997056 8.6893925e-07
loss:  0.046268285290631206 0.041398160100248216
===========>   training    <===========
Epoch: [536][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0502 (0.0502)	
0.99996173 7.027846e-08
===========>   testing    <===========
Epoch: [536][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0451 (0.0451)	
0.99998426 1.3665309e-06
Epoch: [536][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0354 (0.0623)	
0.9999397 1.5452338e-06
Epoch: [536][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0741 (0.0589)	
0.9999727 2.5867573e-06
loss:  0.04590182356868544 0.041398160100248216
===========>   training    <===========
Epoch: [537][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0464 (0.0464)	
0.99998367 6.1615744e-08
===========>   testing    <===========
Epoch: [537][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0417 (0.0417)	
0.99997437 1.0402181e-06
Epoch: [537][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.1683 (0.0626)	
0.99993813 1.1343806e-06
Epoch: [537][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0955 (0.0588)	
0.99996483 9.754478e-07
loss:  0.044011186692938464 0.041398160100248216
===========>   training    <===========
Epoch: [538][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0623 (0.0623)	
0.9999807 7.235874e-07
===========>   testing    <===========
Epoch: [538][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0430 (0.0430)	
0.9999783 6.039029e-07
Epoch: [538][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0311 (0.0630)	
0.9998983 7.3431454e-07
Epoch: [538][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0641 (0.0577)	
0.9999653 1.0013856e-06
loss:  0.04326289275368955 0.041398160100248216
===========>   training    <===========
Epoch: [539][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0460 (0.0460)	
0.9999863 3.273212e-07
===========>   testing    <===========
Epoch: [539][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0581 (0.0581)	
0.99998045 7.5866967e-07
Epoch: [539][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0291 (0.0624)	
0.9998696 7.608419e-07
Epoch: [539][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00026352009446574203]	Loss 0.0846 (0.0586)	
0.99996686 1.1006189e-06
loss:  0.04439242913752495 0.041398160100248216
===========>   training    <===========
Epoch: [540][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0408 (0.0408)	
0.9999721 2.7791745e-07
===========>   testing    <===========
Epoch: [540][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0435 (0.0435)	
0.9999845 1.9874608e-06
Epoch: [540][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0272 (0.0658)	
0.9999511 1.6787064e-06
Epoch: [540][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0807 (0.0610)	
0.99997747 2.939611e-06
loss:  0.0451024534621679 0.041398160100248216
===========>   training    <===========
Epoch: [541][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0620 (0.0620)	
0.99996865 1.2039584e-07
===========>   testing    <===========
Epoch: [541][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0921 (0.0921)	
0.99998105 1.2071711e-06
Epoch: [541][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0524 (0.0631)	
0.9999517 1.3485111e-06
Epoch: [541][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0740 (0.0576)	
0.99996424 1.5627911e-06
loss:  0.04315950009242131 0.041398160100248216
===========>   training    <===========
Epoch: [542][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0591 (0.0591)	
0.99997866 4.5361688e-07
===========>   testing    <===========
Epoch: [542][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0412 (0.0412)	
0.99998486 1.5693401e-07
Epoch: [542][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0569 (0.0685)	
0.9999138 1.5645759e-07
Epoch: [542][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0997 (0.0631)	
0.9999728 2.684953e-07
loss:  0.045962836187359524 0.041398160100248216
===========>   training    <===========
Epoch: [543][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0494 (0.0494)	
0.99997556 7.40946e-07
===========>   testing    <===========
Epoch: [543][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0510 (0.0510)	
0.9999778 1.5045218e-06
Epoch: [543][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0348 (0.0646)	
0.9999553 1.5304577e-06
Epoch: [543][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0803 (0.0603)	
0.9999641 1.1946498e-06
loss:  0.045025460275890494 0.041398160100248216
===========>   training    <===========
Epoch: [544][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0467 (0.0467)	
0.9999832 2.2650318e-07
===========>   testing    <===========
Epoch: [544][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0857 (0.0857)	
0.99997926 8.46031e-07
Epoch: [544][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0324 (0.0655)	
0.9999435 1.0956716e-06
Epoch: [544][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0791 (0.0588)	
0.9999629 4.9212844e-07
loss:  0.04444087918751882 0.041398160100248216
===========>   training    <===========
Epoch: [545][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0416 (0.0416)	
0.9999862 1.8296802e-06
===========>   testing    <===========
Epoch: [545][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0524 (0.0524)	
0.9999815 6.3268743e-07
Epoch: [545][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0323 (0.0600)	
0.999923 8.39035e-07
Epoch: [545][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0816 (0.0585)	
0.999967 2.8330052e-07
loss:  0.043830109978965526 0.041398160100248216
===========>   training    <===========
Epoch: [546][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0529 (0.0529)	
0.9999733 2.4506488e-07
===========>   testing    <===========
Epoch: [546][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0666 (0.0666)	
0.999933 7.547418e-07
Epoch: [546][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0303 (0.0636)	
0.99993896 5.320452e-07
Epoch: [546][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.1059 (0.0616)	
0.9999677 6.208905e-07
loss:  0.044733575281300064 0.041398160100248216
===========>   training    <===========
Epoch: [547][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0503 (0.0503)	
0.99997807 5.122922e-07
===========>   testing    <===========
Epoch: [547][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0952 (0.0952)	
0.99997926 5.2591287e-07
Epoch: [547][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.1158 (0.0680)	
0.999949 3.947254e-07
Epoch: [547][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0724 (0.0637)	
0.99997115 3.8594504e-07
loss:  0.045571356316178924 0.041398160100248216
===========>   training    <===========
Epoch: [548][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0638 (0.0638)	
0.999979 6.752518e-07
===========>   testing    <===========
Epoch: [548][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0472 (0.0472)	
0.9999739 2.0534303e-06
Epoch: [548][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.1195 (0.0673)	
0.9999515 1.0668234e-06
Epoch: [548][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.1028 (0.0628)	
0.99997056 1.1043282e-06
loss:  0.045492295887741285 0.041398160100248216
===========>   training    <===========
Epoch: [549][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0477 (0.0477)	
0.99996376 2.7746194e-06
===========>   testing    <===========
Epoch: [549][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0538 (0.0538)	
0.9999709 2.2732964e-07
Epoch: [549][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.1135 (0.0640)	
0.9999639 1.681692e-07
Epoch: [549][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0969 (0.0611)	
0.999966 1.4632043e-07
loss:  0.044432514795149314 0.041398160100248216
===========>   training    <===========
Epoch: [550][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0545 (0.0545)	
0.9999614 3.759971e-06
===========>   testing    <===========
Epoch: [550][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0530 (0.0530)	
0.99997616 9.69406e-07
Epoch: [550][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0978 (0.0672)	
0.9999527 7.6176906e-07
Epoch: [550][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0642 (0.0614)	
0.99996364 1.0826474e-06
loss:  0.045820153227067006 0.041398160100248216
===========>   training    <===========
Epoch: [551][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0448 (0.0448)	
0.99998486 1.1309888e-06
===========>   testing    <===========
Epoch: [551][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0462 (0.0462)	
0.9999732 5.7338167e-07
Epoch: [551][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.1379 (0.0689)	
0.9999471 3.869224e-07
Epoch: [551][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0906 (0.0626)	
0.9999652 6.573032e-07
loss:  0.04536585523572123 0.041398160100248216
===========>   training    <===========
Epoch: [552][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0485 (0.0485)	
0.99997926 8.3054533e-07
===========>   testing    <===========
Epoch: [552][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0750 (0.0750)	
0.9999757 7.687774e-07
Epoch: [552][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.1327 (0.0690)	
0.9999471 5.71021e-07
Epoch: [552][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0826 (0.0634)	
0.9999714 7.1065654e-07
loss:  0.04504088626706293 0.041398160100248216
===========>   training    <===========
Epoch: [553][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0467 (0.0467)	
0.9999777 5.0641415e-07
===========>   testing    <===========
Epoch: [553][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0990 (0.0990)	
0.9999697 1.4158242e-06
Epoch: [553][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0512 (0.0677)	
0.99991953 1.1573502e-06
Epoch: [553][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0484 (0.0617)	
0.99996483 1.9867975e-06
loss:  0.045532375801782266 0.041398160100248216
===========>   training    <===========
Epoch: [554][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0533 (0.0533)	
0.99997795 2.7760169e-07
===========>   testing    <===========
Epoch: [554][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0901 (0.0901)	
0.9999472 1.3152867e-07
Epoch: [554][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0260 (0.0650)	
0.9999223 8.933835e-08
Epoch: [554][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0915 (0.0601)	
0.99995255 9.7754715e-08
loss:  0.04442672425539629 0.041398160100248216
===========>   training    <===========
Epoch: [555][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0522 (0.0522)	
0.99998164 7.0811416e-07
===========>   testing    <===========
Epoch: [555][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0608 (0.0608)	
0.9999789 1.516439e-06
Epoch: [555][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0585 (0.0615)	
0.99994314 1.154865e-06
Epoch: [555][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0560 (0.0589)	
0.9999676 6.1482035e-07
loss:  0.04324812793685928 0.041398160100248216
===========>   training    <===========
Epoch: [556][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0605 (0.0605)	
0.999984 8.1009034e-07
===========>   testing    <===========
Epoch: [556][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0405 (0.0405)	
0.99998045 3.8821418e-07
Epoch: [556][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0399 (0.0641)	
0.999933 2.6928768e-07
Epoch: [556][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0511 (0.0588)	
0.9999684 4.4916746e-07
loss:  0.0427447445391651 0.041398160100248216
===========>   training    <===========
Epoch: [557][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0405 (0.0405)	
0.99997556 1.5224555e-07
===========>   testing    <===========
Epoch: [557][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0523 (0.0523)	
0.99996865 1.7779917e-07
Epoch: [557][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.1116 (0.0680)	
0.9999454 2.0527516e-07
Epoch: [557][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0614 (0.0611)	
0.99996257 2.3418355e-07
loss:  0.04397761591688565 0.041398160100248216
===========>   training    <===========
Epoch: [558][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0427 (0.0427)	
0.99996555 5.616146e-07
===========>   testing    <===========
Epoch: [558][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0814 (0.0814)	
0.9999666 4.3639807e-07
Epoch: [558][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0699 (0.0620)	
0.9999105 3.6696434e-07
Epoch: [558][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0773 (0.0576)	
0.99995816 6.891704e-07
loss:  0.04217874930765453 0.041398160100248216
===========>   training    <===========
Epoch: [559][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0492 (0.0492)	
0.99994826 3.137483e-08
===========>   testing    <===========
Epoch: [559][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0752 (0.0752)	
0.9999765 5.751462e-07
Epoch: [559][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.1028 (0.0671)	
0.9999434 5.55871e-07
Epoch: [559][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00025034408974245495]	Loss 0.0604 (0.0616)	
0.9999633 1.0118551e-06
loss:  0.04478072023349933 0.041398160100248216
===========>   training    <===========
Epoch: [560][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0540 (0.0540)	
0.9999715 2.1156639e-07
===========>   testing    <===========
Epoch: [560][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0890 (0.0890)	
0.9999654 2.7170302e-07
Epoch: [560][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0913 (0.0660)	
0.9999403 2.800801e-07
Epoch: [560][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0528 (0.0609)	
0.9999746 3.554177e-07
loss:  0.04526731507693316 0.041398160100248216
===========>   training    <===========
Epoch: [561][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0496 (0.0496)	
0.9999777 1.19053574e-07
===========>   testing    <===========
Epoch: [561][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0883 (0.0883)	
0.99997604 1.9338071e-07
Epoch: [561][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0433 (0.0684)	
0.9999721 1.16479946e-07
Epoch: [561][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0546 (0.0637)	
0.99996483 3.443388e-07
loss:  0.046997937338531415 0.041398160100248216
===========>   training    <===========
Epoch: [562][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0514 (0.0514)	
0.99998784 9.8001145e-08
===========>   testing    <===========
Epoch: [562][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0501 (0.0501)	
0.9999672 3.6914122e-07
Epoch: [562][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0174 (0.0631)	
0.99995446 3.4929334e-07
Epoch: [562][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0935 (0.0606)	
0.9999659 7.5754537e-07
loss:  0.044819720325570245 0.041398160100248216
===========>   training    <===========
Epoch: [563][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0490 (0.0490)	
0.99998486 2.3022558e-06
===========>   testing    <===========
Epoch: [563][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0778 (0.0778)	
0.9999753 3.8853827e-07
Epoch: [563][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0450 (0.0617)	
0.9999429 4.808874e-07
Epoch: [563][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0323 (0.0573)	
0.99997187 7.187353e-07
loss:  0.043850572009747735 0.041398160100248216
===========>   training    <===========
Epoch: [564][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0411 (0.0411)	
0.99997854 1.839843e-07
===========>   testing    <===========
Epoch: [564][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0500 (0.0500)	
0.9999788 4.5534017e-07
Epoch: [564][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.1723 (0.0632)	
0.9999596 4.35275e-07
Epoch: [564][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0646 (0.0590)	
0.9999703 7.731456e-07
loss:  0.04361013306446382 0.041398160100248216
===========>   training    <===========
Epoch: [565][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0529 (0.0529)	
0.99998033 5.708806e-08
===========>   testing    <===========
Epoch: [565][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0647 (0.0647)	
0.9999815 1.0910647e-06
Epoch: [565][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0382 (0.0639)	
0.9999577 1.1654378e-06
Epoch: [565][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0423 (0.0591)	
0.9999709 9.617391e-07
loss:  0.04466211212265858 0.041398160100248216
===========>   training    <===========
Epoch: [566][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0414 (0.0414)	
0.99997437 3.528247e-07
===========>   testing    <===========
Epoch: [566][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0789 (0.0789)	
0.9999795 2.1388844e-07
Epoch: [566][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0289 (0.0623)	
0.9999335 2.5423924e-07
Epoch: [566][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0787 (0.0586)	
0.9999734 1.729616e-07
loss:  0.043074798422316984 0.041398160100248216
===========>   training    <===========
Epoch: [567][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0537 (0.0537)	
0.99997795 4.06425e-07
===========>   testing    <===========
Epoch: [567][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0480 (0.0480)	
0.999967 8.6293085e-08
Epoch: [567][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0738 (0.0629)	
0.999936 1.1753298e-07
Epoch: [567][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0700 (0.0569)	
0.9999671 7.3391064e-08
loss:  0.04176348340395697 0.041398160100248216
===========>   training    <===========
Epoch: [568][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0522 (0.0522)	
0.99996006 7.962393e-08
===========>   testing    <===========
Epoch: [568][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0389 (0.0389)	
0.99997413 3.7518473e-07
Epoch: [568][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.1849 (0.0653)	
0.99994814 4.515154e-07
Epoch: [568][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0730 (0.0600)	
0.9999702 8.0835315e-07
loss:  0.04476736024410599 0.041398160100248216
===========>   training    <===========
Epoch: [569][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0401 (0.0401)	
0.9999794 2.808546e-08
===========>   testing    <===========
Epoch: [569][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0508 (0.0508)	
0.99997866 4.148681e-07
Epoch: [569][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0445 (0.0613)	
0.999951 5.7658457e-07
Epoch: [569][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0727 (0.0584)	
0.99997365 3.19216e-07
loss:  0.04345369607207483 0.041398160100248216
===========>   training    <===========
Epoch: [570][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0508 (0.0508)	
0.999984 1.29235e-07
===========>   testing    <===========
Epoch: [570][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0984 (0.0984)	
0.99998295 5.6621377e-07
Epoch: [570][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0794 (0.0609)	
0.9999647 4.7229145e-07
Epoch: [570][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0761 (0.0579)	
0.99997556 7.6549475e-07
loss:  0.0440333570000625 0.041398160100248216
===========>   training    <===========
Epoch: [571][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0480 (0.0480)	
0.9999746 3.3666957e-08
===========>   testing    <===========
Epoch: [571][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0428 (0.0428)	
0.99997973 1.7495615e-06
Epoch: [571][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0390 (0.0604)	
0.99995935 1.48329e-06
Epoch: [571][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0748 (0.0574)	
0.9999727 1.8778575e-06
loss:  0.04363304957352521 0.041398160100248216
===========>   training    <===========
Epoch: [572][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0631 (0.0631)	
0.9999858 1.1885946e-07
===========>   testing    <===========
Epoch: [572][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0591 (0.0591)	
0.9999846 5.2708174e-07
Epoch: [572][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0506 (0.0626)	
0.9999478 3.145627e-07
Epoch: [572][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0636 (0.0578)	
0.99996674 5.301175e-07
loss:  0.04391307837391034 0.041398160100248216
===========>   training    <===========
Epoch: [573][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0410 (0.0410)	
0.9999821 4.9711954e-08
===========>   testing    <===========
Epoch: [573][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0508 (0.0508)	
0.99998057 3.329152e-07
Epoch: [573][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.1011 (0.0651)	
0.99995124 3.3300634e-07
Epoch: [573][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0802 (0.0591)	
0.99996626 1.539456e-07
loss:  0.04383684773443386 0.041398160100248216
===========>   training    <===========
Epoch: [574][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0462 (0.0462)	
0.99998045 4.882442e-07
===========>   testing    <===========
Epoch: [574][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0395 (0.0395)	
0.9999813 5.117102e-07
Epoch: [574][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0927 (0.0615)	
0.99992347 3.583105e-07
Epoch: [574][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0486 (0.0566)	
0.99996185 5.32757e-07
loss:  0.04295627801583901 0.041398160100248216
===========>   training    <===========
Epoch: [575][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0419 (0.0419)	
0.9999732 4.6724026e-07
===========>   testing    <===========
Epoch: [575][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0543 (0.0543)	
0.99998116 4.6990536e-07
Epoch: [575][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0531 (0.0628)	
0.99995506 5.3714535e-07
Epoch: [575][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0934 (0.0589)	
0.9999734 6.331045e-07
loss:  0.04471683833734741 0.041398160100248216
===========>   training    <===========
Epoch: [576][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0519 (0.0519)	
0.99997056 1.0175692e-06
===========>   testing    <===========
Epoch: [576][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0459 (0.0459)	
0.99998367 1.1790248e-06
Epoch: [576][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0605 (0.0622)	
0.9999566 1.0335876e-06
Epoch: [576][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.1399 (0.0602)	
0.9999728 9.2644814e-07
loss:  0.04497413028808417 0.041398160100248216
===========>   training    <===========
Epoch: [577][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0568 (0.0568)	
0.9999764 8.878034e-08
===========>   testing    <===========
Epoch: [577][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0960 (0.0960)	
0.9999826 1.0164587e-06
Epoch: [577][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.1672 (0.0681)	
0.9999459 8.4523026e-07
Epoch: [577][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0687 (0.0621)	
0.9999677 9.4905346e-07
loss:  0.04794903909762649 0.041398160100248216
===========>   training    <===========
Epoch: [578][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0536 (0.0536)	
0.9999752 3.370439e-07
===========>   testing    <===========
Epoch: [578][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0504 (0.0504)	
0.99998426 3.540537e-07
Epoch: [578][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0303 (0.0598)	
0.9999504 3.4981207e-07
Epoch: [578][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0791 (0.0562)	
0.9999739 4.1752062e-07
loss:  0.041341805590169534 0.041398160100248216
===========>   training    <===========
Epoch: [579][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0523 (0.0523)	
0.99998 4.253979e-07
===========>   testing    <===========
Epoch: [579][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0678 (0.0678)	
0.9999831 6.857265e-07
Epoch: [579][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0516 (0.0614)	
0.999954 5.094843e-07
Epoch: [579][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00023782688525533216]	Loss 0.0733 (0.0557)	
0.9999745 3.0466663e-07
loss:  0.042156707226605805 0.041341805590169534
===========>   training    <===========
Epoch: [580][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0436 (0.0436)	
0.99998474 1.3582148e-08
===========>   testing    <===========
Epoch: [580][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0600 (0.0600)	
0.99998343 4.511603e-07
Epoch: [580][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.3163 (0.0632)	
0.99995196 3.817682e-07
Epoch: [580][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0681 (0.0584)	
0.9999782 6.936409e-07
loss:  0.04435487618462475 0.041341805590169534
===========>   training    <===========
Epoch: [581][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0488 (0.0488)	
0.9999863 4.5594592e-07
===========>   testing    <===========
Epoch: [581][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0660 (0.0660)	
0.9999839 2.849333e-07
Epoch: [581][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0305 (0.0608)	
0.99994016 3.7760697e-07
Epoch: [581][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0723 (0.0584)	
0.99997747 2.0471916e-07
loss:  0.043411357853111676 0.041341805590169534
===========>   training    <===========
Epoch: [582][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0453 (0.0453)	
0.99998677 1.6582332e-07
===========>   testing    <===========
Epoch: [582][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0621 (0.0621)	
0.9999851 8.087364e-07
Epoch: [582][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0686 (0.0628)	
0.9999715 8.786766e-07
Epoch: [582][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0358 (0.0577)	
0.99998224 5.882994e-07
loss:  0.04273050188222005 0.041341805590169534
===========>   training    <===========
Epoch: [583][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0430 (0.0430)	
0.9999714 4.5424894e-08
===========>   testing    <===========
Epoch: [583][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0664 (0.0664)	
0.9999782 6.652796e-07
Epoch: [583][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.2622 (0.0623)	
0.999954 7.3242273e-07
Epoch: [583][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0847 (0.0592)	
0.9999703 1.8490442e-07
loss:  0.04578759928011167 0.041341805590169534
===========>   training    <===========
Epoch: [584][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0566 (0.0566)	
0.9999902 4.697016e-06
===========>   testing    <===========
Epoch: [584][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0442 (0.0442)	
0.99998546 4.652083e-07
Epoch: [584][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0368 (0.0638)	
0.99995685 4.6465362e-07
Epoch: [584][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0750 (0.0598)	
0.9999771 7.223229e-07
loss:  0.04280760520635696 0.041341805590169534
===========>   training    <===========
Epoch: [585][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0439 (0.0439)	
0.99997485 1.1504439e-08
===========>   testing    <===========
Epoch: [585][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0408 (0.0408)	
0.99998426 5.7218375e-07
Epoch: [585][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.1731 (0.0624)	
0.9999329 1.4345437e-06
Epoch: [585][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0670 (0.0595)	
0.99997544 5.494033e-07
loss:  0.044833998955398524 0.041341805590169534
===========>   training    <===========
Epoch: [586][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0531 (0.0531)	
0.99998 3.2195106e-07
===========>   testing    <===========
Epoch: [586][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0383 (0.0383)	
0.99998116 1.1218364e-06
Epoch: [586][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0292 (0.0602)	
0.9999548 1.0127761e-06
Epoch: [586][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.1007 (0.0587)	
0.99997246 1.4244827e-06
loss:  0.042477593659878354 0.041341805590169534
===========>   training    <===========
Epoch: [587][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0527 (0.0527)	
0.99997365 1.1515062e-06
===========>   testing    <===========
Epoch: [587][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0380 (0.0380)	
0.99998045 1.9427073e-07
Epoch: [587][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0326 (0.0600)	
0.9999455 1.0764264e-07
Epoch: [587][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.1189 (0.0570)	
0.99996436 3.5905347e-07
loss:  0.04209072066941566 0.041341805590169534
===========>   training    <===========
Epoch: [588][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0413 (0.0413)	
0.999987 1.0410978e-07
===========>   testing    <===========
Epoch: [588][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0453 (0.0453)	
0.99998033 2.336821e-06
Epoch: [588][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0722 (0.0634)	
0.9999573 1.2654855e-06
Epoch: [588][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0867 (0.0589)	
0.9999734 3.5365517e-06
loss:  0.04345018997486383 0.041341805590169534
===========>   training    <===========
Epoch: [589][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0460 (0.0460)	
0.9999763 1.0339278e-06
===========>   testing    <===========
Epoch: [589][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0519 (0.0519)	
0.9999831 1.6715719e-06
Epoch: [589][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0390 (0.0602)	
0.9999596 1.4680869e-06
Epoch: [589][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.1174 (0.0586)	
0.9999653 1.7848088e-06
loss:  0.04300996460431239 0.041341805590169534
===========>   training    <===========
Epoch: [590][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0461 (0.0461)	
0.99997723 8.742649e-07
===========>   testing    <===========
Epoch: [590][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0774 (0.0774)	
0.9999826 3.5500307e-07
Epoch: [590][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.2361 (0.0665)	
0.9999634 3.2263065e-07
Epoch: [590][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0669 (0.0617)	
0.9999713 5.624014e-07
loss:  0.04550536315376108 0.041341805590169534
===========>   training    <===========
Epoch: [591][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0582 (0.0582)	
0.99998295 5.087143e-07
===========>   testing    <===========
Epoch: [591][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0384 (0.0384)	
0.9999784 1.0247571e-06
Epoch: [591][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0711 (0.0562)	
0.99996436 9.871022e-07
Epoch: [591][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.1132 (0.0562)	
0.9999683 1.1659158e-06
loss:  0.04099785320565241 0.041341805590169534
===========>   training    <===========
Epoch: [592][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0467 (0.0467)	
0.99997294 3.5888914e-07
===========>   testing    <===========
Epoch: [592][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0652 (0.0652)	
0.9999807 2.4540122e-06
Epoch: [592][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0373 (0.0686)	
0.99995625 2.2315164e-06
Epoch: [592][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.1084 (0.0626)	
0.9999671 1.7508066e-06
loss:  0.04596728680385165 0.04099785320565241
===========>   training    <===========
Epoch: [593][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0512 (0.0512)	
0.99997747 4.806188e-07
===========>   testing    <===========
Epoch: [593][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0546 (0.0546)	
0.9999794 1.5746982e-06
Epoch: [593][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0473 (0.0643)	
0.99995446 1.1831543e-06
Epoch: [593][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.1168 (0.0603)	
0.9999732 1.3788244e-06
loss:  0.04553685957882825 0.04099785320565241
===========>   training    <===========
Epoch: [594][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0501 (0.0501)	
0.99998176 5.00424e-07
===========>   testing    <===========
Epoch: [594][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0437 (0.0437)	
0.9999814 7.7461425e-07
Epoch: [594][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0766 (0.0625)	
0.9999505 7.633122e-07
Epoch: [594][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0764 (0.0582)	
0.9999763 7.3126273e-07
loss:  0.04467362001232755 0.04099785320565241
===========>   training    <===========
Epoch: [595][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0431 (0.0431)	
0.99995947 1.2369097e-07
===========>   testing    <===========
Epoch: [595][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0552 (0.0552)	
0.99997807 2.045889e-06
Epoch: [595][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0609 (0.0639)	
0.9999567 1.8969025e-06
Epoch: [595][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0999 (0.0589)	
0.99997437 9.160522e-07
loss:  0.04249726860851444 0.04099785320565241
===========>   training    <===========
Epoch: [596][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0501 (0.0501)	
0.99998796 8.816985e-07
===========>   testing    <===========
Epoch: [596][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0422 (0.0422)	
0.99997485 6.9790616e-07
Epoch: [596][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0518 (0.0614)	
0.9999615 8.357608e-07
Epoch: [596][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.1259 (0.0590)	
0.99997437 8.274367e-07
loss:  0.04348407532095644 0.04099785320565241
===========>   training    <===========
Epoch: [597][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0477 (0.0477)	
0.9999819 4.277807e-07
===========>   testing    <===========
Epoch: [597][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0550 (0.0550)	
0.99997604 1.6783223e-06
Epoch: [597][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.1720 (0.0669)	
0.9999342 1.7306733e-06
Epoch: [597][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.1130 (0.0633)	
0.99997485 1.7128448e-06
loss:  0.04726892265558902 0.04099785320565241
===========>   training    <===========
Epoch: [598][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0463 (0.0463)	
0.99997425 1.3397843e-06
===========>   testing    <===========
Epoch: [598][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0777 (0.0777)	
0.999977 8.1546654e-07
Epoch: [598][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.1463 (0.0681)	
0.9999541 6.228868e-07
Epoch: [598][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0953 (0.0617)	
0.99997604 6.6106435e-07
loss:  0.04567384601817881 0.04099785320565241
===========>   training    <===========
Epoch: [599][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0446 (0.0446)	
0.999979 3.0762035e-07
===========>   testing    <===========
Epoch: [599][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.1294 (0.1294)	
0.999982 6.855794e-07
Epoch: [599][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.1637 (0.0637)	
0.99996066 5.008943e-07
Epoch: [599][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00022593554099256555]	Loss 0.0718 (0.0599)	
0.9999752 7.3231166e-07
loss:  0.04456781952889732 0.04099785320565241
===========>   training    <===========
Epoch: [600][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0432 (0.0432)	
0.99998176 1.3849473e-06
===========>   testing    <===========
Epoch: [600][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.1187 (0.1187)	
0.99998164 4.5179843e-07
Epoch: [600][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.3811 (0.0678)	
0.9999621 7.454673e-07
Epoch: [600][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0676 (0.0598)	
0.9999739 5.0249093e-07
loss:  0.044762775393749954 0.04099785320565241
===========>   training    <===========
Epoch: [601][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0459 (0.0459)	
0.9999752 7.8332526e-08
===========>   testing    <===========
Epoch: [601][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0686 (0.0686)	
0.99998224 4.817219e-07
Epoch: [601][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.1746 (0.0697)	
0.99996555 5.4619454e-07
Epoch: [601][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0632 (0.0596)	
0.9999776 4.3777533e-07
loss:  0.04409349878040414 0.04099785320565241
===========>   training    <===========
Epoch: [602][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0454 (0.0454)	
0.99998605 1.1906145e-06
===========>   testing    <===========
Epoch: [602][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.1124 (0.1124)	
0.999985 9.121738e-07
Epoch: [602][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0846 (0.0617)	
0.9999732 1.0316722e-06
Epoch: [602][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0810 (0.0559)	
0.9999753 9.0636036e-07
loss:  0.04246956447112571 0.04099785320565241
===========>   training    <===========
Epoch: [603][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0457 (0.0457)	
0.99998355 3.3585445e-07
===========>   testing    <===========
Epoch: [603][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0734 (0.0734)	
0.99998105 7.019533e-07
Epoch: [603][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0292 (0.0620)	
0.99995494 9.89317e-07
Epoch: [603][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0946 (0.0557)	
0.9999676 6.352049e-07
loss:  0.04202758830320208 0.04099785320565241
===========>   training    <===========
Epoch: [604][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0486 (0.0486)	
0.99998057 6.865465e-08
===========>   testing    <===========
Epoch: [604][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0666 (0.0666)	
0.99998415 4.6366162e-07
Epoch: [604][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0382 (0.0626)	
0.99996865 4.674533e-07
Epoch: [604][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0765 (0.0576)	
0.9999752 4.4283937e-07
loss:  0.04250837115103612 0.04099785320565241
===========>   training    <===========
Epoch: [605][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0408 (0.0408)	
0.9999789 2.5906337e-07
===========>   testing    <===========
Epoch: [605][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0885 (0.0885)	
0.99998355 7.62845e-07
Epoch: [605][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.1053 (0.0625)	
0.99997234 9.0734375e-07
Epoch: [605][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0745 (0.0585)	
0.9999764 1.1709479e-06
loss:  0.04293287397704959 0.04099785320565241
===========>   training    <===========
Epoch: [606][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0426 (0.0426)	
0.9999831 1.4245206e-06
===========>   testing    <===========
Epoch: [606][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0726 (0.0726)	
0.9999869 8.0424775e-07
Epoch: [606][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0254 (0.0637)	
0.9999666 1.1670938e-06
Epoch: [606][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.1245 (0.0596)	
0.9999722 7.0214276e-07
loss:  0.04293741613133739 0.04099785320565241
===========>   training    <===========
Epoch: [607][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0422 (0.0422)	
0.99998176 6.7681066e-07
===========>   testing    <===========
Epoch: [607][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.1319 (0.1319)	
0.9999809 2.7269283e-07
Epoch: [607][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0403 (0.0611)	
0.99996436 3.2396846e-07
Epoch: [607][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0954 (0.0580)	
0.9999701 1.3466318e-07
loss:  0.041369538815263174 0.04099785320565241
===========>   training    <===========
Epoch: [608][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0498 (0.0498)	
0.9999716 2.8409964e-08
===========>   testing    <===========
Epoch: [608][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0897 (0.0897)	
0.9999838 3.18054e-07
Epoch: [608][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.2613 (0.0634)	
0.9999672 3.1334108e-07
Epoch: [608][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.1104 (0.0583)	
0.999972 1.7498957e-07
loss:  0.04311901717179356 0.04099785320565241
===========>   training    <===========
Epoch: [609][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0397 (0.0397)	
0.999987 1.2925068e-06
===========>   testing    <===========
Epoch: [609][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0750 (0.0750)	
0.99997604 1.3055742e-06
Epoch: [609][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.2832 (0.0670)	
0.99996495 1.375251e-06
Epoch: [609][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.1011 (0.0617)	
0.9999664 1.0028458e-06
loss:  0.046433095410760905 0.04099785320565241
===========>   training    <===========
Epoch: [610][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0579 (0.0579)	
0.99998033 2.3278275e-07
===========>   testing    <===========
Epoch: [610][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0608 (0.0608)	
0.99998116 5.452598e-07
Epoch: [610][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.1887 (0.0650)	
0.9999734 7.57398e-07
Epoch: [610][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.1352 (0.0615)	
0.9999677 5.3183817e-07
loss:  0.04525495470974905 0.04099785320565241
===========>   training    <===========
Epoch: [611][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0460 (0.0460)	
0.99997807 9.2343674e-07
===========>   testing    <===========
Epoch: [611][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.1267 (0.1267)	
0.99997973 9.0737484e-07
Epoch: [611][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.1166 (0.0686)	
0.9999472 1.0196022e-06
Epoch: [611][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0960 (0.0618)	
0.99997103 8.551201e-07
loss:  0.04602537836303511 0.04099785320565241
===========>   training    <===========
Epoch: [612][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0381 (0.0381)	
0.9999776 3.63482e-07
===========>   testing    <===========
Epoch: [612][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.1007 (0.1007)	
0.99998415 6.044901e-07
Epoch: [612][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0756 (0.0627)	
0.99995494 6.689984e-07
Epoch: [612][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0858 (0.0586)	
0.99996185 3.7275314e-07
loss:  0.04285036768973227 0.04099785320565241
===========>   training    <===========
Epoch: [613][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0529 (0.0529)	
0.99997044 3.0073654e-08
===========>   testing    <===========
Epoch: [613][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.1338 (0.1338)	
0.9999864 7.0472413e-07
Epoch: [613][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0473 (0.0615)	
0.9999629 5.973712e-07
Epoch: [613][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0783 (0.0580)	
0.9999758 5.777355e-07
loss:  0.04344620390758813 0.04099785320565241
===========>   training    <===========
Epoch: [614][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0407 (0.0407)	
0.99998415 3.318745e-07
===========>   testing    <===========
Epoch: [614][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.1328 (0.1328)	
0.9999858 8.1323145e-07
Epoch: [614][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0388 (0.0651)	
0.9999672 5.204797e-07
Epoch: [614][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.1069 (0.0612)	
0.99997234 7.090156e-07
loss:  0.04528635223581323 0.04099785320565241
===========>   training    <===========
Epoch: [615][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0397 (0.0397)	
0.9999757 6.5097197e-07
===========>   testing    <===========
Epoch: [615][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.1139 (0.1139)	
0.9999852 4.0351943e-06
Epoch: [615][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0543 (0.0687)	
0.99996316 2.2574118e-06
Epoch: [615][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.1590 (0.0623)	
0.9999733 2.272948e-06
loss:  0.044967323571333595 0.04099785320565241
===========>   training    <===========
Epoch: [616][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0464 (0.0464)	
0.99997723 4.520458e-07
===========>   testing    <===========
Epoch: [616][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.1168 (0.1168)	
0.99998164 1.1637295e-06
Epoch: [616][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0418 (0.0658)	
0.99995697 1.0278285e-06
Epoch: [616][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0790 (0.0619)	
0.99996924 8.5264134e-07
loss:  0.04594421231424517 0.04099785320565241
===========>   training    <===========
Epoch: [617][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0509 (0.0509)	
0.9999808 1.78388e-07
===========>   testing    <===========
Epoch: [617][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.1221 (0.1221)	
0.9999689 3.730248e-07
Epoch: [617][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0977 (0.0667)	
0.99995863 3.505668e-07
Epoch: [617][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0898 (0.0619)	
0.99997103 2.3491812e-07
loss:  0.0456667398062337 0.04099785320565241
===========>   training    <===========
Epoch: [618][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0611 (0.0611)	
0.9999573 1.0909868e-06
===========>   testing    <===========
Epoch: [618][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.1020 (0.1020)	
0.9999739 7.1367884e-07
Epoch: [618][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.1363 (0.0701)	
0.9999522 8.749981e-07
Epoch: [618][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0713 (0.0637)	
0.9999627 7.9372273e-07
loss:  0.04706334439496673 0.04099785320565241
===========>   training    <===========
Epoch: [619][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0516 (0.0516)	
0.99996567 2.635222e-07
===========>   testing    <===========
Epoch: [619][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.1429 (0.1429)	
0.9999745 4.6437498e-07
Epoch: [619][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.3726 (0.0700)	
0.999949 6.2575543e-07
Epoch: [619][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00021463876394293727]	Loss 0.0539 (0.0612)	
0.9999641 4.994166e-07
loss:  0.04581913543553118 0.04099785320565241
===========>   training    <===========
Epoch: [620][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0472 (0.0472)	
0.9999802 3.5267266e-07
===========>   testing    <===========
Epoch: [620][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.1134 (0.1134)	
0.99997544 3.2830255e-07
Epoch: [620][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0324 (0.0632)	
0.99994206 4.4690162e-07
Epoch: [620][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0617 (0.0571)	
0.9999604 4.5270025e-07
loss:  0.04261122351578239 0.04099785320565241
===========>   training    <===========
Epoch: [621][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0483 (0.0483)	
0.99997723 2.1191775e-07
===========>   testing    <===========
Epoch: [621][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0961 (0.0961)	
0.9999765 1.3421283e-06
Epoch: [621][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0402 (0.0605)	
0.99993765 1.5877949e-06
Epoch: [621][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0830 (0.0567)	
0.99996233 1.3761917e-06
loss:  0.0444190650194245 0.04099785320565241
===========>   training    <===========
Epoch: [622][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0411 (0.0411)	
0.99996376 1.5915441e-07
===========>   testing    <===========
Epoch: [622][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.1113 (0.1113)	
0.9999722 5.1715926e-07
Epoch: [622][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0262 (0.0642)	
0.9999429 4.1745653e-07
Epoch: [622][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0687 (0.0581)	
0.9999671 6.3487965e-07
loss:  0.042633287891226335 0.04099785320565241
===========>   training    <===========
Epoch: [623][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0489 (0.0489)	
0.9999738 5.337792e-07
===========>   testing    <===========
Epoch: [623][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.1285 (0.1285)	
0.99997973 6.624502e-07
Epoch: [623][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.2089 (0.0658)	
0.99994934 6.661589e-07
Epoch: [623][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.1183 (0.0605)	
0.9999639 9.551507e-07
loss:  0.0452388740792985 0.04099785320565241
===========>   training    <===========
Epoch: [624][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0433 (0.0433)	
0.99998224 1.9421535e-07
===========>   testing    <===========
Epoch: [624][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.1166 (0.1166)	
0.9999801 1.1830775e-06
Epoch: [624][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0804 (0.0639)	
0.9999505 9.188775e-07
Epoch: [624][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.1273 (0.0596)	
0.9999654 1.2313784e-06
loss:  0.04253369760964887 0.04099785320565241
===========>   training    <===========
Epoch: [625][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0481 (0.0481)	
0.9999871 5.084888e-07
===========>   testing    <===========
Epoch: [625][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0842 (0.0842)	
0.99997187 1.2366967e-06
Epoch: [625][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0458 (0.0657)	
0.99993384 1.4298316e-06
Epoch: [625][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.1312 (0.0624)	
0.9999654 1.3665609e-06
loss:  0.04518523669579777 0.04099785320565241
===========>   training    <===========
Epoch: [626][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0439 (0.0439)	
0.9999714 7.757726e-07
===========>   testing    <===========
Epoch: [626][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0611 (0.0611)	
0.9999752 1.3435293e-06
Epoch: [626][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.3195 (0.0654)	
0.9999521 7.2173896e-07
Epoch: [626][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0929 (0.0619)	
0.99996364 1.1552064e-06
loss:  0.044515384622350496 0.04099785320565241
===========>   training    <===========
Epoch: [627][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0428 (0.0428)	
0.9999478 7.486369e-07
===========>   testing    <===========
Epoch: [627][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.1076 (0.1076)	
0.9999783 9.920512e-07
Epoch: [627][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.1684 (0.0619)	
0.99995875 1.1355246e-06
Epoch: [627][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0690 (0.0592)	
0.9999672 1.0741126e-06
loss:  0.042721772667585145 0.04099785320565241
===========>   training    <===========
Epoch: [628][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0622 (0.0622)	
0.999959 5.333259e-07
===========>   testing    <===========
Epoch: [628][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0878 (0.0878)	
0.9999831 4.3275102e-07
Epoch: [628][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.1381 (0.0628)	
0.99996495 2.5852137e-07
Epoch: [628][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0677 (0.0589)	
0.99996984 3.1601255e-07
loss:  0.04378572361657884 0.04099785320565241
===========>   training    <===========
Epoch: [629][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0439 (0.0439)	
0.9999713 6.475757e-07
===========>   testing    <===========
Epoch: [629][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0944 (0.0944)	
0.999982 8.6077716e-07
Epoch: [629][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0351 (0.0595)	
0.9999583 6.026377e-07
Epoch: [629][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0944 (0.0562)	
0.99996805 6.6006334e-07
loss:  0.0408500066591454 0.04099785320565241
===========>   training    <===========
Epoch: [630][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0509 (0.0509)	
0.9999653 8.493952e-08
===========>   testing    <===========
Epoch: [630][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.1081 (0.1081)	
0.999982 1.0672998e-06
Epoch: [630][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0345 (0.0613)	
0.9999647 6.6197407e-07
Epoch: [630][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.1102 (0.0567)	
0.9999684 7.130951e-07
loss:  0.04110598093572437 0.0408500066591454
===========>   training    <===========
Epoch: [631][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0386 (0.0386)	
0.9999815 1.9419238e-07
===========>   testing    <===========
Epoch: [631][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0909 (0.0909)	
0.999982 5.988885e-07
Epoch: [631][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0305 (0.0610)	
0.9999566 4.9901e-07
Epoch: [631][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0641 (0.0553)	
0.9999728 3.847118e-07
loss:  0.04096663340547524 0.0408500066591454
===========>   training    <===========
Epoch: [632][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0484 (0.0484)	
0.99997544 1.8147978e-07
===========>   testing    <===========
Epoch: [632][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.1191 (0.1191)	
0.9999858 1.2549468e-06
Epoch: [632][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0273 (0.0604)	
0.99995327 4.5271707e-07
Epoch: [632][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.1015 (0.0557)	
0.9999715 6.415388e-07
loss:  0.041418505394952176 0.0408500066591454
===========>   training    <===========
Epoch: [633][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0443 (0.0443)	
0.99998796 2.7674782e-08
===========>   testing    <===========
Epoch: [633][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.1057 (0.1057)	
0.99998534 9.176637e-07
Epoch: [633][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0576 (0.0608)	
0.99995995 6.7652417e-07
Epoch: [633][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.1051 (0.0574)	
0.9999726 6.8307463e-07
loss:  0.04268060790255246 0.0408500066591454
===========>   training    <===========
Epoch: [634][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0488 (0.0488)	
0.99997926 1.1868321e-07
===========>   testing    <===========
Epoch: [634][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0914 (0.0914)	
0.9999819 3.7732406e-07
Epoch: [634][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0306 (0.0600)	
0.999961 3.4526641e-07
Epoch: [634][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0990 (0.0566)	
0.99997294 1.5828073e-07
loss:  0.042189447742569164 0.0408500066591454
===========>   training    <===========
Epoch: [635][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0438 (0.0438)	
0.9999815 9.515475e-07
===========>   testing    <===========
Epoch: [635][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.1304 (0.1304)	
0.9999851 2.3680713e-07
Epoch: [635][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0402 (0.0637)	
0.9999633 2.7408012e-07
Epoch: [635][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0600 (0.0579)	
0.99997056 1.5362441e-07
loss:  0.04228084229432261 0.0408500066591454
===========>   training    <===========
Epoch: [636][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0456 (0.0456)	
0.99998415 2.3595765e-08
===========>   testing    <===========
Epoch: [636][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.1283 (0.1283)	
0.99997985 5.049042e-07
Epoch: [636][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0392 (0.0643)	
0.99993896 6.759167e-07
Epoch: [636][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0869 (0.0593)	
0.9999641 4.1521878e-07
loss:  0.04287816627055774 0.0408500066591454
===========>   training    <===========
Epoch: [637][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0528 (0.0528)	
0.9999738 2.9321757e-07
===========>   testing    <===========
Epoch: [637][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.1002 (0.1002)	
0.9999896 2.417192e-07
Epoch: [637][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.2480 (0.0651)	
0.99996114 3.1250846e-07
Epoch: [637][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0874 (0.0574)	
0.9999726 2.3140444e-07
loss:  0.04286784404497779 0.0408500066591454
===========>   training    <===========
Epoch: [638][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0489 (0.0489)	
0.999974 3.310501e-07
===========>   testing    <===========
Epoch: [638][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.1120 (0.1120)	
0.9999813 2.0531039e-07
Epoch: [638][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0472 (0.0616)	
0.99994886 2.1015914e-07
Epoch: [638][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0671 (0.0572)	
0.99996746 2.8374018e-07
loss:  0.042437139468570084 0.0408500066591454
===========>   training    <===========
Epoch: [639][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0411 (0.0411)	
0.99997616 3.862072e-07
===========>   testing    <===========
Epoch: [639][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.1179 (0.1179)	
0.9999629 2.3539266e-07
Epoch: [639][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.0467 (0.0602)	
0.9999378 2.3840305e-07
Epoch: [639][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00020390682574579038]	Loss 0.1069 (0.0553)	
0.9999635 2.0525343e-07
loss:  0.042455164391822175 0.0408500066591454
===========>   training    <===========
Epoch: [640][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0415 (0.0415)	
0.9999795 1.876426e-07
===========>   testing    <===========
Epoch: [640][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.1124 (0.1124)	
0.9999751 6.360147e-08
Epoch: [640][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0358 (0.0632)	
0.999933 9.6806566e-08
Epoch: [640][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0846 (0.0579)	
0.9999536 4.661756e-08
loss:  0.04311196089198621 0.0408500066591454
===========>   training    <===========
Epoch: [641][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0533 (0.0533)	
0.99995744 2.2410694e-08
===========>   testing    <===========
Epoch: [641][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0617 (0.0617)	
0.9999801 1.7357908e-06
Epoch: [641][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0236 (0.0621)	
0.9999461 1.8899885e-06
Epoch: [641][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.1119 (0.0581)	
0.99997187 2.6810717e-06
loss:  0.042423229895283354 0.0408500066591454
===========>   training    <===========
Epoch: [642][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0421 (0.0421)	
0.99998224 5.3282204e-08
===========>   testing    <===========
Epoch: [642][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0860 (0.0860)	
0.9999764 1.0621496e-06
Epoch: [642][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0588 (0.0611)	
0.9999448 1.0385537e-06
Epoch: [642][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0525 (0.0562)	
0.999966 1.4465039e-06
loss:  0.041711514747180156 0.0408500066591454
===========>   training    <===========
Epoch: [643][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0532 (0.0532)	
0.99998033 7.583435e-08
===========>   testing    <===========
Epoch: [643][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0554 (0.0554)	
0.9999815 4.410683e-07
Epoch: [643][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0276 (0.0638)	
0.9999542 3.8686042e-07
Epoch: [643][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0575 (0.0581)	
0.9999707 9.5124904e-07
loss:  0.043735691820657285 0.0408500066591454
===========>   training    <===========
Epoch: [644][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0448 (0.0448)	
0.9999882 1.4067164e-07
===========>   testing    <===========
Epoch: [644][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0625 (0.0625)	
0.999984 1.5022995e-06
Epoch: [644][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0286 (0.0631)	
0.9999536 1.5537289e-06
Epoch: [644][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0642 (0.0567)	
0.9999751 1.6313309e-06
loss:  0.042114800997299695 0.0408500066591454
===========>   training    <===========
Epoch: [645][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0523 (0.0523)	
0.9999858 1.4978804e-07
===========>   testing    <===========
Epoch: [645][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0750 (0.0750)	
0.999987 7.5370815e-07
Epoch: [645][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0411 (0.0600)	
0.9999541 6.9784096e-07
Epoch: [645][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0528 (0.0552)	
0.99997306 1.4321693e-06
loss:  0.04167413932342201 0.0408500066591454
===========>   training    <===========
Epoch: [646][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0529 (0.0529)	
0.99997914 8.158511e-08
===========>   testing    <===========
Epoch: [646][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0667 (0.0667)	
0.99998415 7.455135e-07
Epoch: [646][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.1732 (0.0598)	
0.99995947 6.282651e-07
Epoch: [646][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0593 (0.0546)	
0.9999702 8.891062e-07
loss:  0.04219590711045684 0.0408500066591454
===========>   training    <===========
Epoch: [647][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0557 (0.0557)	
0.99997365 1.4240875e-06
===========>   testing    <===========
Epoch: [647][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.1099 (0.1099)	
0.99998665 2.2026063e-07
Epoch: [647][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0892 (0.0615)	
0.99994445 2.117525e-07
Epoch: [647][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0884 (0.0560)	
0.9999652 1.261752e-07
loss:  0.04237293617952942 0.0408500066591454
===========>   training    <===========
Epoch: [648][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0505 (0.0505)	
0.9999517 2.5160674e-07
===========>   testing    <===========
Epoch: [648][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0865 (0.0865)	
0.99998343 4.3912462e-07
Epoch: [648][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0850 (0.0599)	
0.999951 5.895018e-07
Epoch: [648][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0805 (0.0547)	
0.9999702 5.2020135e-07
loss:  0.04165790812091341 0.0408500066591454
===========>   training    <===========
Epoch: [649][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0430 (0.0430)	
0.99997604 3.9456122e-08
===========>   testing    <===========
Epoch: [649][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0658 (0.0658)	
0.99998355 1.5650461e-06
Epoch: [649][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0717 (0.0612)	
0.9999504 1.3670041e-06
Epoch: [649][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0722 (0.0566)	
0.9999697 1.6137343e-06
loss:  0.043123784916061614 0.0408500066591454
===========>   training    <===========
Epoch: [650][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0466 (0.0466)	
0.99998593 7.4072844e-08
===========>   testing    <===========
Epoch: [650][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.1021 (0.1021)	
0.99998 7.527276e-07
Epoch: [650][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0780 (0.0623)	
0.999956 7.307984e-07
Epoch: [650][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0471 (0.0561)	
0.9999716 4.7448646e-07
loss:  0.042677023775932854 0.0408500066591454
===========>   training    <===========
Epoch: [651][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0395 (0.0395)	
0.9999845 1.1280772e-06
===========>   testing    <===========
Epoch: [651][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.1026 (0.1026)	
0.9999852 4.7255458e-07
Epoch: [651][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0404 (0.0617)	
0.999961 4.0438746e-07
Epoch: [651][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0547 (0.0565)	
0.9999759 5.642059e-07
loss:  0.04302206971938338 0.0408500066591454
===========>   training    <===========
Epoch: [652][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0509 (0.0509)	
0.9999757 4.4185978e-07
===========>   testing    <===========
Epoch: [652][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.1259 (0.1259)	
0.9999858 1.8391484e-07
Epoch: [652][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0496 (0.0652)	
0.9999653 1.9055808e-07
Epoch: [652][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0777 (0.0618)	
0.99997735 1.797463e-07
loss:  0.04448249719478292 0.0408500066591454
===========>   training    <===========
Epoch: [653][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0423 (0.0423)	
0.9999769 1.8999229e-07
===========>   testing    <===========
Epoch: [653][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.1118 (0.1118)	
0.9999856 4.5122314e-07
Epoch: [653][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0289 (0.0624)	
0.99996126 3.0115072e-07
Epoch: [653][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0748 (0.0587)	
0.999982 3.534845e-07
loss:  0.04312329935636461 0.0408500066591454
===========>   training    <===========
Epoch: [654][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0428 (0.0428)	
0.99998856 6.131498e-07
===========>   testing    <===========
Epoch: [654][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.1150 (0.1150)	
0.99998116 3.3106116e-07
Epoch: [654][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0320 (0.0619)	
0.9999292 2.6469291e-07
Epoch: [654][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0339 (0.0559)	
0.9999701 1.5093576e-07
loss:  0.0441887219032 0.0408500066591454
===========>   training    <===========
Epoch: [655][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0486 (0.0486)	
0.99997795 4.3637144e-07
===========>   testing    <===========
Epoch: [655][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.1511 (0.1511)	
0.9999887 5.222722e-07
Epoch: [655][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0491 (0.0619)	
0.9999548 3.9603378e-07
Epoch: [655][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0529 (0.0561)	
0.9999697 7.0588504e-07
loss:  0.042464012946617835 0.0408500066591454
===========>   training    <===========
Epoch: [656][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0426 (0.0426)	
0.99997497 1.2104935e-06
===========>   testing    <===========
Epoch: [656][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0974 (0.0974)	
0.9999869 4.3286988e-07
Epoch: [656][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0663 (0.0648)	
0.99995303 2.9535474e-07
Epoch: [656][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0382 (0.0572)	
0.9999739 3.3434415e-07
loss:  0.0445345750961037 0.0408500066591454
===========>   training    <===========
Epoch: [657][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0454 (0.0454)	
0.9999629 1.0709888e-08
===========>   testing    <===========
Epoch: [657][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.1247 (0.1247)	
0.9999871 5.805468e-07
Epoch: [657][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.1301 (0.0670)	
0.99996233 5.1317926e-07
Epoch: [657][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0542 (0.0603)	
0.9999707 6.8987595e-07
loss:  0.04495277188564328 0.0408500066591454
===========>   training    <===========
Epoch: [658][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0448 (0.0448)	
0.9999745 1.8868512e-06
===========>   testing    <===========
Epoch: [658][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.1257 (0.1257)	
0.9999802 1.7265573e-07
Epoch: [658][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.2467 (0.0627)	
0.9999504 2.3150864e-07
Epoch: [658][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0854 (0.0589)	
0.9999614 1.4662831e-07
loss:  0.042536883604516684 0.0408500066591454
===========>   training    <===========
Epoch: [659][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0428 (0.0428)	
0.9999809 5.8682854e-06
===========>   testing    <===========
Epoch: [659][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.1133 (0.1133)	
0.9999858 3.7350682e-07
Epoch: [659][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.2025 (0.0640)	
0.9999583 4.771401e-07
Epoch: [659][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00019371148445850088]	Loss 0.0743 (0.0604)	
0.9999739 6.034153e-07
loss:  0.043873140464281146 0.0408500066591454
===========>   training    <===========
Epoch: [660][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0491 (0.0491)	
0.99997365 1.1062998e-07
===========>   testing    <===========
Epoch: [660][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.1043 (0.1043)	
0.9999856 2.3797328e-07
Epoch: [660][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.2170 (0.0643)	
0.999949 4.2109434e-07
Epoch: [660][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0352 (0.0586)	
0.9999707 5.3532386e-07
loss:  0.04446344008165082 0.0408500066591454
===========>   training    <===========
Epoch: [661][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0435 (0.0435)	
0.99997663 1.274664e-07
===========>   testing    <===========
Epoch: [661][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0754 (0.0754)	
0.9999821 8.466243e-07
Epoch: [661][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.2280 (0.0630)	
0.9999466 7.264977e-07
Epoch: [661][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0853 (0.0579)	
0.99996483 9.24674e-07
loss:  0.04285342522553115 0.0408500066591454
===========>   training    <===========
Epoch: [662][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0546 (0.0546)	
0.9999703 7.105224e-08
===========>   testing    <===========
Epoch: [662][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0841 (0.0841)	
0.9999815 6.1091373e-07
Epoch: [662][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.2810 (0.0662)	
0.9999553 4.516881e-07
Epoch: [662][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.1614 (0.0603)	
0.9999716 2.99591e-07
loss:  0.04506754653622602 0.0408500066591454
===========>   training    <===========
Epoch: [663][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0429 (0.0429)	
0.9999844 1.1029957e-06
===========>   testing    <===========
Epoch: [663][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0942 (0.0942)	
0.9999838 6.443102e-07
Epoch: [663][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.2175 (0.0644)	
0.99995923 5.3270315e-07
Epoch: [663][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.1068 (0.0583)	
0.9999759 3.03414e-07
loss:  0.04339236789060619 0.0408500066591454
===========>   training    <===========
Epoch: [664][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0413 (0.0413)	
0.99998415 3.4323122e-08
===========>   testing    <===========
Epoch: [664][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0779 (0.0779)	
0.9999863 1.4197616e-06
Epoch: [664][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.1259 (0.0669)	
0.9999672 1.029186e-06
Epoch: [664][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0652 (0.0601)	
0.9999757 1.5963491e-06
loss:  0.044550223996558946 0.0408500066591454
===========>   training    <===========
Epoch: [665][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0742 (0.0742)	
0.99997485 8.8465555e-09
===========>   testing    <===========
Epoch: [665][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0620 (0.0620)	
0.9999844 3.6490846e-07
Epoch: [665][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0799 (0.0625)	
0.9999658 2.3697295e-07
Epoch: [665][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0711 (0.0587)	
0.9999758 3.010795e-07
loss:  0.04345560622005862 0.0408500066591454
===========>   training    <===========
Epoch: [666][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0471 (0.0471)	
0.99997723 1.0636995e-06
===========>   testing    <===========
Epoch: [666][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0536 (0.0536)	
0.99998724 5.6696433e-07
Epoch: [666][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0305 (0.0610)	
0.9999633 4.176142e-07
Epoch: [666][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0653 (0.0580)	
0.99997807 6.030598e-07
loss:  0.042772886134615384 0.0408500066591454
===========>   training    <===========
Epoch: [667][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0469 (0.0469)	
0.9999821 3.8267254e-07
===========>   testing    <===========
Epoch: [667][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0349 (0.0349)	
0.99998724 5.394364e-07
Epoch: [667][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0491 (0.0639)	
0.9999646 4.8669887e-07
Epoch: [667][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0639 (0.0612)	
0.999977 3.688766e-07
loss:  0.043254594351149867 0.0408500066591454
===========>   training    <===========
Epoch: [668][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0472 (0.0472)	
0.99998343 1.9284695e-08
===========>   testing    <===========
Epoch: [668][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.1031 (0.1031)	
0.99998796 2.2316198e-07
Epoch: [668][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0216 (0.0592)	
0.99995744 2.0206856e-07
Epoch: [668][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0498 (0.0570)	
0.9999764 2.5682823e-07
loss:  0.04113941488451034 0.0408500066591454
===========>   training    <===========
Epoch: [669][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0521 (0.0521)	
0.99998486 2.3173129e-07
===========>   testing    <===========
Epoch: [669][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0870 (0.0870)	
0.9999881 8.8051956e-07
Epoch: [669][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0216 (0.0625)	
0.9999746 5.797301e-07
Epoch: [669][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0412 (0.0577)	
0.9999826 4.390547e-07
loss:  0.04169344827629362 0.0408500066591454
===========>   training    <===========
Epoch: [670][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0394 (0.0394)	
0.9999857 2.517176e-07
===========>   testing    <===========
Epoch: [670][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0714 (0.0714)	
0.99998903 1.146293e-06
Epoch: [670][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0429 (0.0631)	
0.99996805 9.633472e-07
Epoch: [670][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0395 (0.0584)	
0.99998105 8.3016596e-07
loss:  0.045964672241074034 0.0408500066591454
===========>   training    <===========
Epoch: [671][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0414 (0.0414)	
0.99998903 1.2788333e-06
===========>   testing    <===========
Epoch: [671][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0767 (0.0767)	
0.9999881 5.230598e-07
Epoch: [671][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0397 (0.0594)	
0.9999689 3.865049e-07
Epoch: [671][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0585 (0.0560)	
0.99997675 7.477222e-07
loss:  0.04146952063192888 0.0408500066591454
===========>   training    <===========
Epoch: [672][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0397 (0.0397)	
0.9999908 5.734561e-07
===========>   testing    <===========
Epoch: [672][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0470 (0.0470)	
0.99999106 1.3491888e-07
Epoch: [672][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0319 (0.0616)	
0.9999778 1.1203038e-07
Epoch: [672][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0604 (0.0577)	
0.99998105 1.7697228e-07
loss:  0.04157867136550608 0.0408500066591454
===========>   training    <===========
Epoch: [673][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0513 (0.0513)	
0.9999924 4.6718412e-07
===========>   testing    <===========
Epoch: [673][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0583 (0.0583)	
0.99998903 4.212759e-07
Epoch: [673][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0230 (0.0631)	
0.99996936 6.260169e-07
Epoch: [673][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0837 (0.0586)	
0.99997234 2.2562422e-07
loss:  0.042335972898371654 0.0408500066591454
===========>   training    <===========
Epoch: [674][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0425 (0.0425)	
0.9999846 3.9951917e-08
===========>   testing    <===========
Epoch: [674][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0588 (0.0588)	
0.99998796 5.699894e-07
Epoch: [674][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0235 (0.0630)	
0.9999633 6.666451e-07
Epoch: [674][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0657 (0.0580)	
0.9999739 2.7745293e-07
loss:  0.04284643687455192 0.0408500066591454
===========>   training    <===========
Epoch: [675][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0405 (0.0405)	
0.9999888 9.7932e-08
===========>   testing    <===========
Epoch: [675][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0434 (0.0434)	
0.99998593 2.0246033e-07
Epoch: [675][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0445 (0.0640)	
0.999967 2.4693938e-07
Epoch: [675][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0506 (0.0586)	
0.99997616 1.2838763e-07
loss:  0.04231477137939499 0.0408500066591454
===========>   training    <===========
Epoch: [676][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0490 (0.0490)	
0.9999889 2.5763876e-07
===========>   testing    <===========
Epoch: [676][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0536 (0.0536)	
0.9999887 8.845587e-07
Epoch: [676][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0643 (0.0608)	
0.9999745 9.214838e-07
Epoch: [676][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0720 (0.0574)	
0.9999795 9.403738e-07
loss:  0.04108705009209612 0.0408500066591454
===========>   training    <===========
Epoch: [677][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0501 (0.0501)	
0.9999802 1.9360215e-07
===========>   testing    <===========
Epoch: [677][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0883 (0.0883)	
0.99997866 3.3975056e-07
Epoch: [677][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0634 (0.0668)	
0.9999697 2.8593828e-07
Epoch: [677][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0495 (0.0614)	
0.99997807 1.9579126e-07
loss:  0.044020901821590463 0.0408500066591454
===========>   training    <===========
Epoch: [678][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0449 (0.0449)	
0.9999933 1.8183076e-07
===========>   testing    <===========
Epoch: [678][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0497 (0.0497)	
0.99998975 8.3766787e-07
Epoch: [678][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0574 (0.0622)	
0.9999689 9.953073e-07
Epoch: [678][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0547 (0.0572)	
0.9999832 6.2259465e-07
loss:  0.04211116171367846 0.0408500066591454
===========>   training    <===========
Epoch: [679][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0401 (0.0401)	
0.9999858 1.2362993e-06
===========>   testing    <===========
Epoch: [679][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0467 (0.0467)	
0.99998534 8.544354e-07
Epoch: [679][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.1742 (0.0609)	
0.9999609 9.4750067e-07
Epoch: [679][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00018402591023557584]	Loss 0.0662 (0.0563)	
0.9999802 6.131375e-07
loss:  0.04272196251135785 0.0408500066591454
===========>   training    <===========
Epoch: [680][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0389 (0.0389)	
0.9999852 3.8006587e-07
===========>   testing    <===========
Epoch: [680][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0653 (0.0653)	
0.9999857 7.205698e-07
Epoch: [680][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0733 (0.0593)	
0.99996614 7.566436e-07
Epoch: [680][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0745 (0.0555)	
0.999979 5.273829e-07
loss:  0.04274229695160758 0.0408500066591454
===========>   training    <===========
Epoch: [681][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0458 (0.0458)	
0.99998367 1.0496075e-07
===========>   testing    <===========
Epoch: [681][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0554 (0.0554)	
0.9999851 2.4726552e-07
Epoch: [681][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0476 (0.0608)	
0.9999542 3.3691245e-07
Epoch: [681][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0800 (0.0555)	
0.99997604 2.4189077e-07
loss:  0.04147367694148041 0.0408500066591454
===========>   training    <===========
Epoch: [682][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0400 (0.0400)	
0.9999901 3.5095687e-07
===========>   testing    <===========
Epoch: [682][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.1363 (0.1363)	
0.999987 9.264032e-07
Epoch: [682][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.1039 (0.0661)	
0.9999728 8.5816816e-07
Epoch: [682][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0487 (0.0592)	
0.99997616 1.5616855e-06
loss:  0.046276913634659245 0.0408500066591454
===========>   training    <===========
Epoch: [683][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0538 (0.0538)	
0.99997854 5.135616e-07
===========>   testing    <===========
Epoch: [683][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0629 (0.0629)	
0.9999857 7.754938e-07
Epoch: [683][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0998 (0.0610)	
0.99997234 8.4477574e-07
Epoch: [683][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0755 (0.0570)	
0.999974 1.1367447e-06
loss:  0.04331713794186953 0.0408500066591454
===========>   training    <===========
Epoch: [684][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0427 (0.0427)	
0.99998045 6.4156815e-08
===========>   testing    <===========
Epoch: [684][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0646 (0.0646)	
0.9999876 1.5392769e-07
Epoch: [684][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.1243 (0.0611)	
0.99996984 1.7926011e-07
Epoch: [684][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0593 (0.0562)	
0.9999702 1.18787504e-07
loss:  0.042384122606512586 0.0408500066591454
===========>   training    <===========
Epoch: [685][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0495 (0.0495)	
0.9999871 3.7594468e-08
===========>   testing    <===========
Epoch: [685][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0631 (0.0631)	
0.99998367 5.5002084e-07
Epoch: [685][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0548 (0.0635)	
0.9999633 4.5539622e-07
Epoch: [685][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0673 (0.0576)	
0.99997485 7.311358e-07
loss:  0.0430843131086579 0.0408500066591454
===========>   training    <===========
Epoch: [686][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0535 (0.0535)	
0.9999832 3.7087914e-06
===========>   testing    <===========
Epoch: [686][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0721 (0.0721)	
0.99997187 8.220074e-07
Epoch: [686][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0831 (0.0607)	
0.9999696 6.828219e-07
Epoch: [686][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0858 (0.0572)	
0.99997914 9.500478e-07
loss:  0.0428233132759257 0.0408500066591454
===========>   training    <===========
Epoch: [687][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0566 (0.0566)	
0.9999813 8.540525e-07
===========>   testing    <===========
Epoch: [687][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0628 (0.0628)	
0.99998784 5.7730426e-07
Epoch: [687][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0623 (0.0596)	
0.99996173 7.519126e-07
Epoch: [687][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0893 (0.0552)	
0.9999747 9.333548e-07
loss:  0.04150681119700317 0.0408500066591454
===========>   training    <===========
Epoch: [688][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0439 (0.0439)	
0.9999713 9.657923e-07
===========>   testing    <===========
Epoch: [688][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0462 (0.0462)	
0.99998736 7.1346517e-07
Epoch: [688][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0643 (0.0597)	
0.99996006 7.7213315e-07
Epoch: [688][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0753 (0.0544)	
0.9999739 1.3820683e-06
loss:  0.04110931005604723 0.0408500066591454
===========>   training    <===========
Epoch: [689][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0363 (0.0363)	
0.999977 6.5209036e-07
===========>   testing    <===========
Epoch: [689][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0405 (0.0405)	
0.99998915 1.5794975e-06
Epoch: [689][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0276 (0.0586)	
0.9999659 1.3861337e-06
Epoch: [689][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0909 (0.0551)	
0.9999757 1.8759066e-06
loss:  0.04082051878233972 0.0408500066591454
===========>   training    <===========
Epoch: [690][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0480 (0.0480)	
0.9999677 3.979988e-08
===========>   testing    <===========
Epoch: [690][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0420 (0.0420)	
0.9999877 3.8094151e-07
Epoch: [690][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0293 (0.0625)	
0.99996173 4.6455304e-07
Epoch: [690][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0703 (0.0565)	
0.9999745 5.647313e-07
loss:  0.04135138172415209 0.04082051878233972
===========>   training    <===========
Epoch: [691][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0431 (0.0431)	
0.9999733 4.9479206e-07
===========>   testing    <===========
Epoch: [691][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0627 (0.0627)	
0.9999882 1.057099e-06
Epoch: [691][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0303 (0.0619)	
0.99995995 9.216367e-07
Epoch: [691][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.1107 (0.0561)	
0.9999753 1.0782568e-06
loss:  0.04129987383002354 0.04082051878233972
===========>   training    <===========
Epoch: [692][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0442 (0.0442)	
0.9999708 6.398292e-08
===========>   testing    <===========
Epoch: [692][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0635 (0.0635)	
0.9999871 4.0268262e-07
Epoch: [692][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0505 (0.0634)	
0.9999647 4.272429e-07
Epoch: [692][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0887 (0.0572)	
0.99997187 7.169704e-07
loss:  0.0421279899301269 0.04082051878233972
===========>   training    <===========
Epoch: [693][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0425 (0.0425)	
0.9999862 2.5635302e-07
===========>   testing    <===========
Epoch: [693][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0475 (0.0475)	
0.99998915 8.1756747e-07
Epoch: [693][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.1952 (0.0648)	
0.9999633 6.483326e-07
Epoch: [693][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.1076 (0.0583)	
0.99997044 8.547875e-07
loss:  0.043442474937153364 0.04082051878233972
===========>   training    <===========
Epoch: [694][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0426 (0.0426)	
0.99998546 5.869628e-07
===========>   testing    <===========
Epoch: [694][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0433 (0.0433)	
0.999984 2.0269003e-07
Epoch: [694][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0975 (0.0669)	
0.9999565 1.5522286e-07
Epoch: [694][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.1963 (0.0621)	
0.99996436 1.1183951e-07
loss:  0.046387117585476645 0.04082051878233972
===========>   training    <===========
Epoch: [695][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0537 (0.0537)	
0.99998856 2.9765324e-08
===========>   testing    <===========
Epoch: [695][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0712 (0.0712)	
0.9999875 1.0347318e-06
Epoch: [695][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0691 (0.0618)	
0.9999521 5.165747e-07
Epoch: [695][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0720 (0.0566)	
0.999969 1.0056366e-06
loss:  0.04271262569356249 0.04082051878233972
===========>   training    <===========
Epoch: [696][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0501 (0.0501)	
0.9999727 6.0199096e-07
===========>   testing    <===========
Epoch: [696][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0538 (0.0538)	
0.99997485 7.124534e-07
Epoch: [696][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0730 (0.0615)	
0.9999517 5.960589e-07
Epoch: [696][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0754 (0.0570)	
0.9999677 4.5365843e-07
loss:  0.04223434163454165 0.04082051878233972
===========>   training    <===========
Epoch: [697][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0429 (0.0429)	
0.9999851 3.6596685e-08
===========>   testing    <===========
Epoch: [697][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0506 (0.0506)	
0.99997306 3.640058e-07
Epoch: [697][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.1463 (0.0607)	
0.99995804 3.3554966e-07
Epoch: [697][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0892 (0.0576)	
0.9999666 3.300823e-07
loss:  0.04269650315431217 0.04082051878233972
===========>   training    <===========
Epoch: [698][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0386 (0.0386)	
0.9999862 5.078709e-07
===========>   testing    <===========
Epoch: [698][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0460 (0.0460)	
0.9999795 3.560195e-07
Epoch: [698][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0296 (0.0612)	
0.99996257 3.437351e-07
Epoch: [698][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0924 (0.0562)	
0.99997044 2.924613e-07
loss:  0.041575849905986284 0.04082051878233972
===========>   training    <===========
Epoch: [699][0/23]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0434 (0.0434)	
0.99996305 4.8832587e-09
===========>   testing    <===========
Epoch: [699][0/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0318 (0.0318)	
0.999984 5.396757e-07
Epoch: [699][100/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0696 (0.0607)	
0.999951 4.95403e-07
Epoch: [699][200/289]	Lr-deconv: [0.0]	Lr-other: [0.000174824614723797]	Loss 0.0887 (0.0555)	
0.9999695 3.8748738e-07
loss:  0.04101938752191825 0.04082051878233972
===========>   training    <===========
Epoch: [700][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0446 (0.0446)	
0.9999784 2.0393614e-08
===========>   testing    <===========
Epoch: [700][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0458 (0.0458)	
0.99998546 5.788639e-07
Epoch: [700][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0746 (0.0630)	
0.9999751 6.616976e-07
Epoch: [700][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0691 (0.0566)	
0.99998283 5.0781375e-07
loss:  0.04188426136093082 0.04082051878233972
===========>   training    <===========
Epoch: [701][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0440 (0.0440)	
0.99997556 1.288003e-07
===========>   testing    <===========
Epoch: [701][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0357 (0.0357)	
0.9999893 3.132873e-07
Epoch: [701][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.1170 (0.0628)	
0.9999753 2.5027876e-07
Epoch: [701][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0568 (0.0573)	
0.99997723 2.1211369e-07
loss:  0.041775477572748354 0.04082051878233972
===========>   training    <===========
Epoch: [702][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0441 (0.0441)	
0.9999714 2.9120322e-08
===========>   testing    <===========
Epoch: [702][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0481 (0.0481)	
0.99998546 8.2422656e-07
Epoch: [702][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0693 (0.0618)	
0.9999722 6.271433e-07
Epoch: [702][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0787 (0.0561)	
0.9999739 6.613771e-07
loss:  0.04156989310969661 0.04082051878233972
===========>   training    <===========
Epoch: [703][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0331 (0.0331)	
0.99996257 4.7970013e-07
===========>   testing    <===========
Epoch: [703][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0445 (0.0445)	
0.99998534 1.5359629e-07
Epoch: [703][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.1644 (0.0623)	
0.9999708 1.3050337e-07
Epoch: [703][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0675 (0.0561)	
0.9999738 1.0871952e-07
loss:  0.042291996480834815 0.04082051878233972
===========>   training    <===========
Epoch: [704][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0520 (0.0520)	
0.9999739 7.5042685e-08
===========>   testing    <===========
Epoch: [704][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0351 (0.0351)	
0.99998903 7.148668e-07
Epoch: [704][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0728 (0.0634)	
0.9999701 6.3934306e-07
Epoch: [704][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0738 (0.0572)	
0.99997795 4.9522635e-07
loss:  0.041295844256060366 0.04082051878233972
===========>   training    <===========
Epoch: [705][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0431 (0.0431)	
0.99996734 4.430041e-07
===========>   testing    <===========
Epoch: [705][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0724 (0.0724)	
0.99998915 8.073893e-07
Epoch: [705][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.1080 (0.0595)	
0.99997175 1.134861e-06
Epoch: [705][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0642 (0.0557)	
0.99997866 7.753651e-07
loss:  0.04318839544728159 0.04082051878233972
===========>   training    <===========
Epoch: [706][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0427 (0.0427)	
0.9999889 8.6730336e-07
===========>   testing    <===========
Epoch: [706][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0353 (0.0353)	
0.99998856 7.163191e-07
Epoch: [706][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0968 (0.0579)	
0.9999722 4.923918e-07
Epoch: [706][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0586 (0.0549)	
0.99997604 6.5697105e-07
loss:  0.040933448069197964 0.04082051878233972
===========>   training    <===========
Epoch: [707][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0445 (0.0445)	
0.99997795 1.1771953e-07
===========>   testing    <===========
Epoch: [707][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0534 (0.0534)	
0.99998224 5.8963167e-07
Epoch: [707][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.1213 (0.0624)	
0.9999659 4.392725e-07
Epoch: [707][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0615 (0.0581)	
0.9999783 6.1614924e-07
loss:  0.04252243316444271 0.04082051878233972
===========>   training    <===========
Epoch: [708][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0502 (0.0502)	
0.9999882 3.5458183e-07
===========>   testing    <===========
Epoch: [708][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0769 (0.0769)	
0.9999869 7.585314e-07
Epoch: [708][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0344 (0.0593)	
0.9999759 5.519914e-07
Epoch: [708][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0477 (0.0558)	
0.9999782 8.2408116e-07
loss:  0.04168712307029643 0.04082051878233972
===========>   training    <===========
Epoch: [709][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0375 (0.0375)	
0.9999678 1.424274e-08
===========>   testing    <===========
Epoch: [709][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0428 (0.0428)	
0.9999784 5.2748806e-07
Epoch: [709][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0368 (0.0619)	
0.99996483 3.717761e-07
Epoch: [709][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0496 (0.0575)	
0.9999759 5.3186454e-07
loss:  0.04204696379114836 0.04082051878233972
===========>   training    <===========
Epoch: [710][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0513 (0.0513)	
0.9999789 7.5825227e-07
===========>   testing    <===========
Epoch: [710][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0447 (0.0447)	
0.99997866 4.0595856e-07
Epoch: [710][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0937 (0.0627)	
0.9999651 4.2548476e-07
Epoch: [710][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0513 (0.0568)	
0.99997425 2.5678955e-07
loss:  0.04270900616124118 0.04082051878233972
===========>   training    <===========
Epoch: [711][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0442 (0.0442)	
0.99998844 2.4196066e-07
===========>   testing    <===========
Epoch: [711][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0587 (0.0587)	
0.9999845 4.8935084e-07
Epoch: [711][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0565 (0.0594)	
0.9999795 3.3537307e-07
Epoch: [711][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0601 (0.0557)	
0.9999783 6.2700093e-07
loss:  0.04241864466183387 0.04082051878233972
===========>   training    <===========
Epoch: [712][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0357 (0.0357)	
0.99998856 4.2858676e-07
===========>   testing    <===========
Epoch: [712][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0385 (0.0385)	
0.9999777 3.4409982e-07
Epoch: [712][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0482 (0.0609)	
0.99998116 2.8653503e-07
Epoch: [712][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0797 (0.0587)	
0.9999726 2.2159496e-07
loss:  0.04246170766330859 0.04082051878233972
===========>   training    <===========
Epoch: [713][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0577 (0.0577)	
0.9999809 1.1912132e-08
===========>   testing    <===========
Epoch: [713][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0424 (0.0424)	
0.9999871 7.887983e-07
Epoch: [713][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0419 (0.0653)	
0.999984 7.722259e-07
Epoch: [713][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0972 (0.0631)	
0.999982 7.9530105e-07
loss:  0.04628045580736373 0.04082051878233972
===========>   training    <===========
Epoch: [714][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0505 (0.0505)	
0.9999709 4.789934e-08
===========>   testing    <===========
Epoch: [714][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0480 (0.0480)	
0.999961 8.7501e-08
Epoch: [714][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0990 (0.0652)	
0.9999558 8.034921e-08
Epoch: [714][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0943 (0.0615)	
0.9999765 3.4738775e-08
loss:  0.04443736746890892 0.04082051878233972
===========>   training    <===========
Epoch: [715][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0466 (0.0466)	
0.99999213 1.0476874e-07
===========>   testing    <===========
Epoch: [715][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0581 (0.0581)	
0.9999858 8.6914315e-07
Epoch: [715][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.3400 (0.0711)	
0.99997616 7.8884415e-07
Epoch: [715][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.1062 (0.0632)	
0.99997866 8.91249e-07
loss:  0.04348922695826385 0.04082051878233972
===========>   training    <===========
Epoch: [716][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0389 (0.0389)	
0.99998426 6.032933e-07
===========>   testing    <===========
Epoch: [716][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0372 (0.0372)	
0.9999819 6.274621e-07
Epoch: [716][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0336 (0.0633)	
0.99996364 5.139977e-07
Epoch: [716][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.1610 (0.0575)	
0.9999734 4.4022784e-07
loss:  0.04329616646840684 0.04082051878233972
===========>   training    <===========
Epoch: [717][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0416 (0.0416)	
0.99997497 5.4553965e-07
===========>   testing    <===========
Epoch: [717][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0380 (0.0380)	
0.99997556 5.1908927e-07
Epoch: [717][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.1882 (0.0648)	
0.99996436 4.6385182e-07
Epoch: [717][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0971 (0.0578)	
0.99997306 3.8190072e-07
loss:  0.04302438618201998 0.04082051878233972
===========>   training    <===========
Epoch: [718][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0532 (0.0532)	
0.9999913 1.6327016e-08
===========>   testing    <===========
Epoch: [718][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0326 (0.0326)	
0.99998045 3.66539e-07
Epoch: [718][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0783 (0.0636)	
0.999964 4.0672433e-07
Epoch: [718][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.1210 (0.0577)	
0.9999757 1.7526081e-07
loss:  0.04285231592769134 0.04082051878233972
===========>   training    <===========
Epoch: [719][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0581 (0.0581)	
0.9999728 1.833922e-07
===========>   testing    <===========
Epoch: [719][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0547 (0.0547)	
0.9999875 1.0277197e-06
Epoch: [719][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.0556 (0.0618)	
0.99996495 5.607813e-07
Epoch: [719][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00016608338398760718]	Loss 0.1977 (0.0577)	
0.9999788 5.4004335e-07
loss:  0.0425589667883115 0.04082051878233972
===========>   training    <===========
Epoch: [720][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0352 (0.0352)	
0.9999808 3.7322405e-08
===========>   testing    <===========
Epoch: [720][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0746 (0.0746)	
0.99998605 4.060647e-07
Epoch: [720][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.1194 (0.0633)	
0.9999676 3.6152323e-07
Epoch: [720][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.1032 (0.0566)	
0.9999733 2.897274e-07
loss:  0.04108395420754607 0.04082051878233972
===========>   training    <===========
Epoch: [721][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0398 (0.0398)	
0.9999832 3.9229354e-07
===========>   testing    <===========
Epoch: [721][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0532 (0.0532)	
0.99999166 5.693766e-07
Epoch: [721][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0672 (0.0603)	
0.9999714 5.422501e-07
Epoch: [721][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.1238 (0.0554)	
0.9999815 4.131167e-07
loss:  0.041452453418800994 0.04082051878233972
===========>   training    <===========
Epoch: [722][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0430 (0.0430)	
0.99997485 1.0973807e-07
===========>   testing    <===========
Epoch: [722][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0502 (0.0502)	
0.9999851 3.5719825e-07
Epoch: [722][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0615 (0.0629)	
0.9999728 3.5382922e-07
Epoch: [722][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0819 (0.0557)	
0.9999776 2.9401028e-07
loss:  0.04281757971123934 0.04082051878233972
===========>   training    <===========
Epoch: [723][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0435 (0.0435)	
0.9999875 8.838091e-07
===========>   testing    <===========
Epoch: [723][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0550 (0.0550)	
0.99999034 9.388988e-07
Epoch: [723][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0952 (0.0648)	
0.9999801 1.2685063e-06
Epoch: [723][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0923 (0.0574)	
0.9999826 7.97049e-07
loss:  0.04244803235167105 0.04082051878233972
===========>   training    <===========
Epoch: [724][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0472 (0.0472)	
0.9999882 4.880198e-07
===========>   testing    <===========
Epoch: [724][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0572 (0.0572)	
0.99998975 5.830458e-07
Epoch: [724][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0486 (0.0606)	
0.9999751 7.5197e-07
Epoch: [724][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0962 (0.0555)	
0.9999802 6.1638553e-07
loss:  0.04073634235372914 0.04082051878233972
===========>   training    <===========
Epoch: [725][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0390 (0.0390)	
0.99997926 3.690828e-08
===========>   testing    <===========
Epoch: [725][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0649 (0.0649)	
0.99998736 4.353057e-07
Epoch: [725][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.1476 (0.0616)	
0.9999666 5.6844453e-07
Epoch: [725][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0633 (0.0562)	
0.9999765 4.2585984e-07
loss:  0.043875340301132604 0.04073634235372914
===========>   training    <===========
Epoch: [726][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0340 (0.0340)	
0.9999832 1.0252587e-06
===========>   testing    <===========
Epoch: [726][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0740 (0.0740)	
0.9999881 2.627122e-07
Epoch: [726][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0991 (0.0604)	
0.9999751 4.46276e-07
Epoch: [726][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0398 (0.0555)	
0.99997914 3.245204e-07
loss:  0.042522092407846324 0.04073634235372914
===========>   training    <===========
Epoch: [727][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0399 (0.0399)	
0.99997973 6.493722e-07
===========>   testing    <===========
Epoch: [727][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0702 (0.0702)	
0.99998176 2.1140463e-07
Epoch: [727][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0875 (0.0613)	
0.9999696 1.931297e-07
Epoch: [727][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0543 (0.0564)	
0.9999764 2.8893385e-07
loss:  0.0420799396965853 0.04073634235372914
===========>   training    <===========
Epoch: [728][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0413 (0.0413)	
0.9999871 9.713746e-08
===========>   testing    <===========
Epoch: [728][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0662 (0.0662)	
0.9999893 4.354365e-07
Epoch: [728][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0419 (0.0611)	
0.99996996 4.0223128e-07
Epoch: [728][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.1192 (0.0584)	
0.9999764 5.255268e-07
loss:  0.04367839489443326 0.04073634235372914
===========>   training    <===========
Epoch: [729][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0417 (0.0417)	
0.9999858 2.1079337e-08
===========>   testing    <===========
Epoch: [729][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0762 (0.0762)	
0.9999881 1.6737177e-07
Epoch: [729][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.1197 (0.0610)	
0.99996924 1.6062342e-07
Epoch: [729][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0685 (0.0560)	
0.9999763 1.0411653e-07
loss:  0.041349220327807745 0.04073634235372914
===========>   training    <===========
Epoch: [730][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0366 (0.0366)	
0.99998903 5.9862526e-07
===========>   testing    <===========
Epoch: [730][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0775 (0.0775)	
0.99998534 7.9632184e-07
Epoch: [730][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0386 (0.0601)	
0.9999566 6.530108e-07
Epoch: [730][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.1244 (0.0567)	
0.99997556 1.0445343e-06
loss:  0.04233057446853816 0.04073634235372914
===========>   training    <===========
Epoch: [731][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0374 (0.0374)	
0.9999832 8.5739674e-07
===========>   testing    <===========
Epoch: [731][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.1012 (0.1012)	
0.999985 5.331138e-07
Epoch: [731][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0438 (0.0578)	
0.99996006 5.213337e-07
Epoch: [731][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0791 (0.0526)	
0.9999757 4.7511722e-07
loss:  0.03954592776721555 0.04073634235372914
===========>   training    <===========
Epoch: [732][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0399 (0.0399)	
0.9999876 9.790567e-08
===========>   testing    <===========
Epoch: [732][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0836 (0.0836)	
0.99997544 1.1762919e-07
Epoch: [732][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0375 (0.0596)	
0.9999405 1.08206876e-07
Epoch: [732][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0740 (0.0562)	
0.9999752 7.237254e-08
loss:  0.041814170294053876 0.03954592776721555
===========>   training    <===========
Epoch: [733][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0419 (0.0419)	
0.9999838 4.358615e-08
===========>   testing    <===========
Epoch: [733][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0533 (0.0533)	
0.99998415 5.7574334e-07
Epoch: [733][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0466 (0.0616)	
0.9999703 9.557957e-07
Epoch: [733][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0798 (0.0568)	
0.9999821 1.315272e-06
loss:  0.04121806432697184 0.03954592776721555
===========>   training    <===========
Epoch: [734][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0467 (0.0467)	
0.99998057 1.1464512e-07
===========>   testing    <===========
Epoch: [734][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0575 (0.0575)	
0.99997723 5.2210186e-07
Epoch: [734][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0880 (0.0590)	
0.99996924 5.3569977e-07
Epoch: [734][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0730 (0.0542)	
0.9999739 5.3082226e-07
loss:  0.040579584385902145 0.03954592776721555
===========>   training    <===========
Epoch: [735][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0439 (0.0439)	
0.99998724 3.6279076e-07
===========>   testing    <===========
Epoch: [735][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0776 (0.0776)	
0.99998105 7.3283917e-07
Epoch: [735][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0385 (0.0598)	
0.999969 6.4607485e-07
Epoch: [735][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0645 (0.0544)	
0.99997723 5.5405724e-07
loss:  0.03966762552813363 0.03954592776721555
===========>   training    <===========
Epoch: [736][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0442 (0.0442)	
0.99998474 1.0461757e-07
===========>   testing    <===========
Epoch: [736][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0742 (0.0742)	
0.9999747 3.7964566e-07
Epoch: [736][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0347 (0.0593)	
0.9999696 3.0180252e-07
Epoch: [736][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0796 (0.0550)	
0.9999776 3.4040372e-07
loss:  0.040581876422998375 0.03954592776721555
===========>   training    <===========
Epoch: [737][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0506 (0.0506)	
0.9999888 3.8539113e-07
===========>   testing    <===========
Epoch: [737][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0666 (0.0666)	
0.99998355 8.767555e-07
Epoch: [737][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.1382 (0.0631)	
0.99997795 6.4930407e-07
Epoch: [737][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0675 (0.0578)	
0.99998164 9.066907e-07
loss:  0.042749713776693454 0.03954592776721555
===========>   training    <===========
Epoch: [738][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0413 (0.0413)	
0.9999906 1.4303292e-07
===========>   testing    <===========
Epoch: [738][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0830 (0.0830)	
0.9999807 5.920456e-07
Epoch: [738][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0571 (0.0611)	
0.99997246 2.4149062e-07
Epoch: [738][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0801 (0.0559)	
0.99998164 5.847386e-07
loss:  0.04146063014595447 0.03954592776721555
===========>   training    <===========
Epoch: [739][0/23]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0406 (0.0406)	
0.99998844 2.557723e-07
===========>   testing    <===========
Epoch: [739][0/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0763 (0.0763)	
0.9999815 3.1543865e-07
Epoch: [739][100/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.0902 (0.0651)	
0.9999713 2.1345524e-07
Epoch: [739][200/289]	Lr-deconv: [0.0]	Lr-other: [0.0001577792147882268]	Loss 0.1121 (0.0589)	
0.9999814 3.0192055e-07
loss:  0.04474846684369915 0.03954592776721555
===========>   training    <===========
Epoch: [740][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0503 (0.0503)	
0.9999902 4.2662688e-07
===========>   testing    <===========
Epoch: [740][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0523 (0.0523)	
0.99998593 6.0994154e-07
Epoch: [740][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.1230 (0.0618)	
0.99996376 3.7070623e-07
Epoch: [740][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0672 (0.0559)	
0.99998295 7.5370673e-07
loss:  0.04199380158151311 0.03954592776721555
===========>   training    <===========
Epoch: [741][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0439 (0.0439)	
0.99999094 6.941611e-07
===========>   testing    <===========
Epoch: [741][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0739 (0.0739)	
0.9999808 3.8407467e-07
Epoch: [741][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0453 (0.0608)	
0.99995816 2.2754284e-07
Epoch: [741][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.1080 (0.0564)	
0.99998355 2.9481356e-07
loss:  0.042510644694774946 0.03954592776721555
===========>   training    <===========
Epoch: [742][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0485 (0.0485)	
0.9999522 1.7024462e-08
===========>   testing    <===========
Epoch: [742][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0397 (0.0397)	
0.9999826 5.760009e-07
Epoch: [742][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0915 (0.0602)	
0.9999747 3.273668e-07
Epoch: [742][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.1013 (0.0559)	
0.99998343 4.0229804e-07
loss:  0.041636438083937244 0.03954592776721555
===========>   training    <===========
Epoch: [743][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0488 (0.0488)	
0.99998677 9.4391055e-08
===========>   testing    <===========
Epoch: [743][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0793 (0.0793)	
0.9999814 4.9462545e-07
Epoch: [743][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0422 (0.0619)	
0.99995303 5.11259e-07
Epoch: [743][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.1238 (0.0561)	
0.99998033 2.9053092e-07
loss:  0.04131288988643267 0.03954592776721555
===========>   training    <===========
Epoch: [744][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0495 (0.0495)	
0.9999863 9.087443e-08
===========>   testing    <===========
Epoch: [744][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0866 (0.0866)	
0.9999862 5.8715597e-07
Epoch: [744][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.1437 (0.0649)	
0.9999716 5.5407463e-07
Epoch: [744][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0940 (0.0592)	
0.99998283 5.3562314e-07
loss:  0.04321970194241487 0.03954592776721555
===========>   training    <===========
Epoch: [745][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0539 (0.0539)	
0.99995065 1.9633498e-07
===========>   testing    <===========
Epoch: [745][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0798 (0.0798)	
0.9999863 2.1494274e-07
Epoch: [745][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.3921 (0.0674)	
0.99995816 2.8419944e-07
Epoch: [745][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0971 (0.0604)	
0.99998736 1.7412641e-07
loss:  0.04357589974445075 0.03954592776721555
===========>   training    <===========
Epoch: [746][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0394 (0.0394)	
0.99998856 1.5595788e-08
===========>   testing    <===========
Epoch: [746][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0761 (0.0761)	
0.99999046 6.439699e-07
Epoch: [746][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0891 (0.0638)	
0.9999622 4.78098e-07
Epoch: [746][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.1041 (0.0583)	
0.99998534 5.2862924e-07
loss:  0.0425915041257966 0.03954592776721555
===========>   training    <===========
Epoch: [747][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0539 (0.0539)	
0.99998796 3.474614e-07
===========>   testing    <===========
Epoch: [747][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0751 (0.0751)	
0.99998784 5.9270036e-07
Epoch: [747][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0354 (0.0623)	
0.99996424 6.545602e-07
Epoch: [747][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0885 (0.0580)	
0.9999825 5.0315793e-07
loss:  0.04207241023893393 0.03954592776721555
===========>   training    <===========
Epoch: [748][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0398 (0.0398)	
0.9999912 3.579157e-07
===========>   testing    <===========
Epoch: [748][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.1189 (0.1189)	
0.99998426 3.0990563e-07
Epoch: [748][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0777 (0.0621)	
0.99995077 2.9073047e-07
Epoch: [748][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0764 (0.0574)	
0.99998367 1.1222243e-07
loss:  0.0420250432052397 0.03954592776721555
===========>   training    <===========
Epoch: [749][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0397 (0.0397)	
0.99998474 9.894284e-07
===========>   testing    <===========
Epoch: [749][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0988 (0.0988)	
0.9999907 8.0538064e-07
Epoch: [749][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0454 (0.0613)	
0.9999733 5.492152e-07
Epoch: [749][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0905 (0.0564)	
0.99998283 7.663903e-07
loss:  0.04162273833238639 0.03954592776721555
===========>   training    <===========
Epoch: [750][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0400 (0.0400)	
0.9999907 3.5223437e-07
===========>   testing    <===========
Epoch: [750][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0803 (0.0803)	
0.9999858 1.2343224e-06
Epoch: [750][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0468 (0.0607)	
0.99995255 1.0024328e-06
Epoch: [750][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.1116 (0.0570)	
0.9999764 7.724616e-07
loss:  0.04291271426800425 0.03954592776721555
===========>   training    <===========
Epoch: [751][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0411 (0.0411)	
0.9999863 4.3714866e-07
===========>   testing    <===========
Epoch: [751][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0928 (0.0928)	
0.9999858 1.4042477e-06
Epoch: [751][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0760 (0.0629)	
0.99997723 1.2654156e-06
Epoch: [751][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0979 (0.0589)	
0.999984 1.1292019e-06
loss:  0.04200436255218143 0.03954592776721555
===========>   training    <===========
Epoch: [752][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0591 (0.0591)	
0.9999602 5.5408105e-08
===========>   testing    <===========
Epoch: [752][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.1340 (0.1340)	
0.9999856 3.1623625e-07
Epoch: [752][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0380 (0.0618)	
0.9999696 2.5645915e-07
Epoch: [752][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0533 (0.0564)	
0.99998283 1.7775865e-07
loss:  0.04063227151668025 0.03954592776721555
===========>   training    <===========
Epoch: [753][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0412 (0.0412)	
0.9999701 3.2104506e-07
===========>   testing    <===========
Epoch: [753][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.1138 (0.1138)	
0.9999918 1.127003e-06
Epoch: [753][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0292 (0.0613)	
0.99997234 1.0716262e-06
Epoch: [753][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0515 (0.0565)	
0.99998176 9.1912113e-07
loss:  0.042503678851209314 0.03954592776721555
===========>   training    <===========
Epoch: [754][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0475 (0.0475)	
0.9999734 3.6951425e-07
===========>   testing    <===========
Epoch: [754][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.1274 (0.1274)	
0.99998736 3.8902655e-07
Epoch: [754][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0736 (0.0615)	
0.99997187 3.5768093e-07
Epoch: [754][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0612 (0.0559)	
0.99997914 5.322547e-07
loss:  0.04166914193857574 0.03954592776721555
===========>   training    <===========
Epoch: [755][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0435 (0.0435)	
0.9999852 2.34517e-07
===========>   testing    <===========
Epoch: [755][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.1173 (0.1173)	
0.99997723 2.2019405e-07
Epoch: [755][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.1264 (0.0586)	
0.99996126 2.4113416e-07
Epoch: [755][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0994 (0.0553)	
0.999977 1.0429899e-07
loss:  0.042220934345684524 0.03954592776721555
===========>   training    <===========
Epoch: [756][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0411 (0.0411)	
0.9999827 4.8972055e-07
===========>   testing    <===========
Epoch: [756][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0910 (0.0910)	
0.99998426 3.7006225e-07
Epoch: [756][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0426 (0.0593)	
0.99997354 4.9537374e-07
Epoch: [756][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0991 (0.0564)	
0.99998164 7.135495e-07
loss:  0.0413412985649082 0.03954592776721555
===========>   training    <===========
Epoch: [757][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0576 (0.0576)	
0.9999771 1.6319923e-07
===========>   testing    <===========
Epoch: [757][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0586 (0.0586)	
0.9999875 3.201712e-07
Epoch: [757][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0933 (0.0627)	
0.9999726 3.887436e-07
Epoch: [757][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.1196 (0.0579)	
0.9999807 5.199459e-07
loss:  0.04312163015556947 0.03954592776721555
===========>   training    <===========
Epoch: [758][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0409 (0.0409)	
0.99997675 6.8736284e-08
===========>   testing    <===========
Epoch: [758][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0583 (0.0583)	
0.99998534 2.4613576e-07
Epoch: [758][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0906 (0.0601)	
0.9999715 3.9808842e-07
Epoch: [758][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.1451 (0.0566)	
0.9999788 3.061923e-07
loss:  0.041744839006343515 0.03954592776721555
===========>   training    <===========
Epoch: [759][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0457 (0.0457)	
0.9999788 8.636027e-08
===========>   testing    <===========
Epoch: [759][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.1005 (0.1005)	
0.9999844 3.62038e-07
Epoch: [759][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.2511 (0.0627)	
0.9999752 4.3522226e-07
Epoch: [759][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014989025404881545]	Loss 0.0824 (0.0570)	
0.9999789 6.8770765e-07
loss:  0.043157242596360335 0.03954592776721555
===========>   training    <===========
Epoch: [760][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0414 (0.0414)	
0.9999896 2.2528386e-07
===========>   testing    <===========
Epoch: [760][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0968 (0.0968)	
0.99998355 1.2497607e-07
Epoch: [760][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0435 (0.0596)	
0.99996674 1.9269551e-07
Epoch: [760][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0828 (0.0552)	
0.9999809 1.7334834e-07
loss:  0.04204421678638659 0.03954592776721555
===========>   training    <===========
Epoch: [761][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0408 (0.0408)	
0.9999721 1.7129317e-07
===========>   testing    <===========
Epoch: [761][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.1079 (0.1079)	
0.9999871 1.8816782e-07
Epoch: [761][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0412 (0.0602)	
0.9999682 1.9511016e-07
Epoch: [761][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0968 (0.0562)	
0.99997973 3.2476098e-07
loss:  0.04217009914061598 0.03954592776721555
===========>   training    <===========
Epoch: [762][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0534 (0.0534)	
0.99997306 6.201603e-08
===========>   testing    <===========
Epoch: [762][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.1053 (0.1053)	
0.99998283 2.2745996e-07
Epoch: [762][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0827 (0.0593)	
0.99995995 1.958159e-07
Epoch: [762][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0887 (0.0546)	
0.99998164 1.5158e-07
loss:  0.04143885292151117 0.03954592776721555
===========>   training    <===========
Epoch: [763][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0409 (0.0409)	
0.9999888 1.8266171e-07
===========>   testing    <===========
Epoch: [763][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0649 (0.0649)	
0.9999894 3.620518e-07
Epoch: [763][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0405 (0.0624)	
0.99996877 3.4545513e-07
Epoch: [763][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0860 (0.0572)	
0.9999844 2.7431915e-07
loss:  0.04178158825663636 0.03954592776721555
===========>   training    <===========
Epoch: [764][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0387 (0.0387)	
0.9999871 1.0206082e-06
===========>   testing    <===========
Epoch: [764][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.1257 (0.1257)	
0.99998736 6.077896e-07
Epoch: [764][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.1275 (0.0633)	
0.9999697 4.3593096e-07
Epoch: [764][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0802 (0.0565)	
0.9999831 7.810604e-07
loss:  0.042226655000635716 0.03954592776721555
===========>   training    <===========
Epoch: [765][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0440 (0.0440)	
0.9999906 9.598688e-09
===========>   testing    <===========
Epoch: [765][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.1255 (0.1255)	
0.9999813 4.2295457e-07
Epoch: [765][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0584 (0.0654)	
0.9999174 4.5259796e-07
Epoch: [765][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0829 (0.0578)	
0.99998343 2.6537282e-07
loss:  0.04269808580976886 0.03954592776721555
===========>   training    <===========
Epoch: [766][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0501 (0.0501)	
0.99996185 1.0007519e-07
===========>   testing    <===========
Epoch: [766][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0859 (0.0859)	
0.99999106 7.6196375e-07
Epoch: [766][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0602 (0.0613)	
0.99997604 6.234895e-07
Epoch: [766][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.1082 (0.0554)	
0.9999875 8.492816e-07
loss:  0.03991648101607237 0.03954592776721555
===========>   training    <===========
Epoch: [767][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0342 (0.0342)	
0.99998856 3.718747e-07
===========>   testing    <===========
Epoch: [767][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.1205 (0.1205)	
0.9999869 2.5515956e-07
Epoch: [767][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.1180 (0.0586)	
0.9999676 1.8044378e-07
Epoch: [767][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0742 (0.0550)	
0.9999844 3.9830527e-07
loss:  0.04007313041949234 0.03954592776721555
===========>   training    <===========
Epoch: [768][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0474 (0.0474)	
0.9999633 4.885106e-07
===========>   testing    <===========
Epoch: [768][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.1005 (0.1005)	
0.99998105 4.0363307e-07
Epoch: [768][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0314 (0.0599)	
0.9999665 3.355772e-07
Epoch: [768][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.1049 (0.0568)	
0.9999846 2.0607425e-07
loss:  0.04118324402302942 0.03954592776721555
===========>   training    <===========
Epoch: [769][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0367 (0.0367)	
0.99998665 3.8360207e-07
===========>   testing    <===========
Epoch: [769][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0931 (0.0931)	
0.9999881 1.2605673e-07
Epoch: [769][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0652 (0.0586)	
0.9999578 8.692097e-08
Epoch: [769][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0937 (0.0549)	
0.9999845 7.217556e-08
loss:  0.039739726268688935 0.03954592776721555
===========>   training    <===========
Epoch: [770][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0431 (0.0431)	
0.9999894 1.0153488e-07
===========>   testing    <===========
Epoch: [770][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0682 (0.0682)	
0.9999912 8.4759216e-07
Epoch: [770][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0637 (0.0601)	
0.999974 5.451829e-07
Epoch: [770][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.1310 (0.0566)	
0.9999863 7.2947125e-07
loss:  0.04026219355254179 0.03954592776721555
===========>   training    <===========
Epoch: [771][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0436 (0.0436)	
0.9999862 3.5663046e-08
===========>   testing    <===========
Epoch: [771][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0891 (0.0891)	
0.9999925 6.4794756e-07
Epoch: [771][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0526 (0.0606)	
0.9999769 4.2761957e-07
Epoch: [771][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.1134 (0.0566)	
0.99998856 3.3182326e-07
loss:  0.04133746643541636 0.03954592776721555
===========>   training    <===========
Epoch: [772][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0435 (0.0435)	
0.9999715 9.815454e-08
===========>   testing    <===========
Epoch: [772][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0913 (0.0913)	
0.99999046 4.5112506e-07
Epoch: [772][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0439 (0.0606)	
0.9999807 2.506191e-07
Epoch: [772][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0956 (0.0561)	
0.9999845 3.1876576e-07
loss:  0.03981844090702702 0.03954592776721555
===========>   training    <===========
Epoch: [773][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0374 (0.0374)	
0.99998796 2.6816625e-07
===========>   testing    <===========
Epoch: [773][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0557 (0.0557)	
0.9999907 2.944264e-07
Epoch: [773][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0771 (0.0613)	
0.9999826 2.3897644e-07
Epoch: [773][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0768 (0.0560)	
0.9999857 1.421211e-07
loss:  0.04007427722250989 0.03954592776721555
===========>   training    <===========
Epoch: [774][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0455 (0.0455)	
0.99999225 2.8767596e-07
===========>   testing    <===========
Epoch: [774][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0776 (0.0776)	
0.9999864 2.1509922e-07
Epoch: [774][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0233 (0.0594)	
0.99997723 2.550309e-07
Epoch: [774][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0798 (0.0542)	
0.99998665 1.5103714e-07
loss:  0.03905957591933473 0.03954592776721555
===========>   training    <===========
Epoch: [775][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0572 (0.0572)	
0.9999882 1.3913078e-07
===========>   testing    <===========
Epoch: [775][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0307 (0.0307)	
0.9999925 5.1078916e-07
Epoch: [775][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0379 (0.0647)	
0.99998176 3.7938545e-07
Epoch: [775][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.1196 (0.0592)	
0.9999865 8.4342815e-07
loss:  0.04199483444455643 0.03905957591933473
===========>   training    <===========
Epoch: [776][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0503 (0.0503)	
0.9999844 4.0437815e-08
===========>   testing    <===========
Epoch: [776][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0500 (0.0500)	
0.99998367 1.8143218e-07
Epoch: [776][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0234 (0.0602)	
0.9999678 2.1135726e-07
Epoch: [776][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0937 (0.0560)	
0.9999825 1.0761595e-07
loss:  0.03995308109432172 0.03905957591933473
===========>   training    <===========
Epoch: [777][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0492 (0.0492)	
0.9999893 4.6933927e-08
===========>   testing    <===========
Epoch: [777][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0424 (0.0424)	
0.9999913 4.1558644e-07
Epoch: [777][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0235 (0.0592)	
0.9999672 3.1655338e-07
Epoch: [777][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0768 (0.0559)	
0.99998593 5.035448e-07
loss:  0.04042056828977458 0.03905957591933473
===========>   training    <===========
Epoch: [778][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0384 (0.0384)	
0.9999856 3.158456e-08
===========>   testing    <===========
Epoch: [778][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0669 (0.0669)	
0.9999883 4.8105346e-07
Epoch: [778][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0232 (0.0583)	
0.9999695 4.145106e-07
Epoch: [778][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0696 (0.0556)	
0.9999832 5.0479497e-07
loss:  0.03995901719590533 0.03905957591933473
===========>   training    <===========
Epoch: [779][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0517 (0.0517)	
0.9999825 6.018153e-08
===========>   testing    <===========
Epoch: [779][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0897 (0.0897)	
0.9999819 9.910848e-07
Epoch: [779][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0300 (0.0603)	
0.99994326 8.47441e-07
Epoch: [779][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00014239574134637466]	Loss 0.0857 (0.0572)	
0.9999764 7.687965e-07
loss:  0.04176108933767653 0.03905957591933473
===========>   training    <===========
Epoch: [780][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0382 (0.0382)	
0.99998665 4.723856e-07
===========>   testing    <===========
Epoch: [780][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0649 (0.0649)	
0.9999888 1.6270425e-06
Epoch: [780][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0345 (0.0600)	
0.9999597 1.2377444e-06
Epoch: [780][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0954 (0.0584)	
0.99998283 5.791726e-07
loss:  0.04200471446637577 0.03905957591933473
===========>   training    <===========
Epoch: [781][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0397 (0.0397)	
0.9999856 9.8099136e-08
===========>   testing    <===========
Epoch: [781][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0562 (0.0562)	
0.9999827 4.926952e-07
Epoch: [781][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0229 (0.0621)	
0.9999566 4.980905e-07
Epoch: [781][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.1135 (0.0582)	
0.99997926 1.597234e-07
loss:  0.04109306755823294 0.03905957591933473
===========>   training    <===========
Epoch: [782][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0411 (0.0411)	
0.99997437 8.518695e-08
===========>   testing    <===========
Epoch: [782][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0526 (0.0526)	
0.9999819 4.6908687e-07
Epoch: [782][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0278 (0.0655)	
0.9999633 4.160885e-07
Epoch: [782][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.1078 (0.0616)	
0.99997854 1.6488458e-07
loss:  0.04413182340891242 0.03905957591933473
===========>   training    <===========
Epoch: [783][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0467 (0.0467)	
0.999985 1.059882e-06
===========>   testing    <===========
Epoch: [783][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0574 (0.0574)	
0.99998283 7.293015e-07
Epoch: [783][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0319 (0.0601)	
0.999964 8.297916e-07
Epoch: [783][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0864 (0.0574)	
0.99997973 6.672035e-07
loss:  0.04311703990548432 0.03905957591933473
===========>   training    <===========
Epoch: [784][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0478 (0.0478)	
0.9999826 1.4555068e-06
===========>   testing    <===========
Epoch: [784][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0761 (0.0761)	
0.999984 7.801968e-07
Epoch: [784][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0775 (0.0610)	
0.9999685 7.5972457e-07
Epoch: [784][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0848 (0.0570)	
0.9999783 5.969008e-07
loss:  0.042431217336911464 0.03905957591933473
===========>   training    <===========
Epoch: [785][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0455 (0.0455)	
0.9999832 3.5857917e-07
===========>   testing    <===========
Epoch: [785][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0848 (0.0848)	
0.9999876 9.0280105e-07
Epoch: [785][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0701 (0.0603)	
0.999972 8.616297e-07
Epoch: [785][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0716 (0.0561)	
0.99998045 8.416019e-07
loss:  0.04254672713081409 0.03905957591933473
===========>   training    <===========
Epoch: [786][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0357 (0.0357)	
0.99998 8.0642053e-07
===========>   testing    <===========
Epoch: [786][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0423 (0.0423)	
0.99998236 6.5484863e-07
Epoch: [786][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0608 (0.0635)	
0.9999585 4.467299e-07
Epoch: [786][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0820 (0.0576)	
0.9999783 2.7780348e-07
loss:  0.04155633101068201 0.03905957591933473
===========>   training    <===========
Epoch: [787][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0420 (0.0420)	
0.9999932 7.342061e-08
===========>   testing    <===========
Epoch: [787][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0506 (0.0506)	
0.9999864 6.3516427e-07
Epoch: [787][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0299 (0.0616)	
0.99997413 4.912647e-07
Epoch: [787][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.1194 (0.0567)	
0.9999833 4.0467762e-07
loss:  0.04053144249484697 0.03905957591933473
===========>   training    <===========
Epoch: [788][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0395 (0.0395)	
0.99998665 1.307994e-07
===========>   testing    <===========
Epoch: [788][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0543 (0.0543)	
0.9999862 4.811645e-07
Epoch: [788][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0217 (0.0608)	
0.99996865 4.280545e-07
Epoch: [788][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.1134 (0.0564)	
0.99998796 4.1969233e-07
loss:  0.04183581070353726 0.03905957591933473
===========>   training    <===========
Epoch: [789][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0450 (0.0450)	
0.999987 3.5139482e-08
===========>   testing    <===========
Epoch: [789][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0739 (0.0739)	
0.99998736 1.020036e-06
Epoch: [789][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0248 (0.0595)	
0.9999726 8.6395164e-07
Epoch: [789][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0927 (0.0562)	
0.999984 4.8563714e-07
loss:  0.04126287562794961 0.03905957591933473
===========>   training    <===========
Epoch: [790][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0501 (0.0501)	
0.99998534 5.362403e-09
===========>   testing    <===========
Epoch: [790][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0389 (0.0389)	
0.9999883 8.5614664e-07
Epoch: [790][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0313 (0.0608)	
0.999974 7.685356e-07
Epoch: [790][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.1164 (0.0576)	
0.9999831 3.2914366e-07
loss:  0.04128909188737084 0.03905957591933473
===========>   training    <===========
Epoch: [791][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0373 (0.0373)	
0.99999166 5.177593e-07
===========>   testing    <===========
Epoch: [791][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0383 (0.0383)	
0.99999154 5.3473605e-07
Epoch: [791][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0372 (0.0609)	
0.99997663 5.026055e-07
Epoch: [791][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.1207 (0.0574)	
0.9999852 4.061301e-07
loss:  0.04160187046966435 0.03905957591933473
===========>   training    <===========
Epoch: [792][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0476 (0.0476)	
0.99998474 7.8194137e-07
===========>   testing    <===========
Epoch: [792][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0676 (0.0676)	
0.9999908 5.95368e-07
Epoch: [792][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0192 (0.0624)	
0.9999716 5.329857e-07
Epoch: [792][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.1418 (0.0582)	
0.99998784 3.278223e-07
loss:  0.041793490490892427 0.03905957591933473
===========>   training    <===========
Epoch: [793][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0468 (0.0468)	
0.99998593 2.2331058e-07
===========>   testing    <===========
Epoch: [793][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0392 (0.0392)	
0.9999932 5.9995523e-07
Epoch: [793][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0379 (0.0599)	
0.9999807 5.417683e-07
Epoch: [793][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.1249 (0.0559)	
0.9999896 2.5317658e-07
loss:  0.04003151935362592 0.03905957591933473
===========>   training    <===========
Epoch: [794][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0407 (0.0407)	
0.9999895 2.247281e-07
===========>   testing    <===========
Epoch: [794][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0355 (0.0355)	
0.9999918 1.2522975e-06
Epoch: [794][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0256 (0.0589)	
0.99997854 1.0454611e-06
Epoch: [794][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.1319 (0.0578)	
0.9999871 8.6297507e-07
loss:  0.04134847334184577 0.03905957591933473
===========>   training    <===========
Epoch: [795][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0454 (0.0454)	
0.99998844 9.1444446e-07
===========>   testing    <===========
Epoch: [795][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0721 (0.0721)	
0.999987 2.586432e-07
Epoch: [795][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0245 (0.0576)	
0.99995506 4.2392458e-07
Epoch: [795][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.1003 (0.0559)	
0.99997306 1.6443985e-07
loss:  0.040968957734754397 0.03905957591933473
===========>   training    <===========
Epoch: [796][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0332 (0.0332)	
0.99999094 1.1588483e-07
===========>   testing    <===========
Epoch: [796][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0885 (0.0885)	
0.99999034 4.887445e-07
Epoch: [796][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0277 (0.0607)	
0.9999758 4.6488015e-07
Epoch: [796][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.1064 (0.0570)	
0.99998224 4.4399593e-07
loss:  0.04142999855260554 0.03905957591933473
===========>   training    <===========
Epoch: [797][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0545 (0.0545)	
0.99998915 1.8921869e-08
===========>   testing    <===========
Epoch: [797][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0389 (0.0389)	
0.99999046 3.7491648e-07
Epoch: [797][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0244 (0.0611)	
0.99996316 3.548697e-07
Epoch: [797][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.1002 (0.0571)	
0.99997556 1.9973231e-07
loss:  0.04115904829493178 0.03905957591933473
===========>   training    <===========
Epoch: [798][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0347 (0.0347)	
0.9999857 2.866695e-07
===========>   testing    <===========
Epoch: [798][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0379 (0.0379)	
0.9999875 3.840197e-07
Epoch: [798][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0268 (0.0591)	
0.999967 3.4655793e-07
Epoch: [798][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0782 (0.0550)	
0.99998105 2.944699e-07
loss:  0.04036523496916622 0.03905957591933473
===========>   training    <===========
Epoch: [799][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0410 (0.0410)	
0.9999913 1.5093772e-08
===========>   testing    <===========
Epoch: [799][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0404 (0.0404)	
0.99999213 5.908183e-07
Epoch: [799][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0462 (0.0634)	
0.9999763 5.1398393e-07
Epoch: [799][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00013527595427905592]	Loss 0.0940 (0.0592)	
0.99998355 3.0431642e-07
loss:  0.0425656596900289 0.03905957591933473
===========>   training    <===========
Epoch: [800][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0442 (0.0442)	
0.99998236 1.1001828e-07
===========>   testing    <===========
Epoch: [800][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0452 (0.0452)	
0.9999919 8.9677883e-07
Epoch: [800][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0434 (0.0615)	
0.9999758 8.2693657e-07
Epoch: [800][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0735 (0.0563)	
0.9999887 8.288678e-07
loss:  0.041810265054703866 0.03905957591933473
===========>   training    <===========
Epoch: [801][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0418 (0.0418)	
0.9999906 6.7231404e-08
===========>   testing    <===========
Epoch: [801][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0342 (0.0342)	
0.99999166 9.369551e-07
Epoch: [801][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0208 (0.0600)	
0.9999815 9.037969e-07
Epoch: [801][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0929 (0.0556)	
0.9999871 9.020385e-07
loss:  0.04121546716588953 0.03905957591933473
===========>   training    <===========
Epoch: [802][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0484 (0.0484)	
0.99997854 3.709346e-08
===========>   testing    <===========
Epoch: [802][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0359 (0.0359)	
0.99999094 7.7844277e-07
Epoch: [802][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0202 (0.0619)	
0.9999813 6.949261e-07
Epoch: [802][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.1385 (0.0578)	
0.99998724 9.699062e-07
loss:  0.04112034874248871 0.03905957591933473
===========>   training    <===========
Epoch: [803][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0426 (0.0426)	
0.999974 1.5468437e-07
===========>   testing    <===========
Epoch: [803][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0506 (0.0506)	
0.9999912 6.2824654e-07
Epoch: [803][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0315 (0.0600)	
0.9999759 5.6645627e-07
Epoch: [803][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.1222 (0.0572)	
0.9999845 4.7682852e-07
loss:  0.04148618063207232 0.03905957591933473
===========>   training    <===========
Epoch: [804][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0458 (0.0458)	
0.9999856 3.302926e-08
===========>   testing    <===========
Epoch: [804][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0655 (0.0655)	
0.99998677 3.4921473e-07
Epoch: [804][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0287 (0.0597)	
0.99998033 2.2182458e-07
Epoch: [804][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0799 (0.0556)	
0.9999795 4.069971e-07
loss:  0.04084086752881266 0.03905957591933473
===========>   training    <===========
Epoch: [805][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0439 (0.0439)	
0.9999912 5.597533e-07
===========>   testing    <===========
Epoch: [805][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0441 (0.0441)	
0.9999889 3.933958e-07
Epoch: [805][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0399 (0.0627)	
0.99998057 4.0427682e-07
Epoch: [805][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0770 (0.0572)	
0.99998343 3.414565e-07
loss:  0.041480812621403906 0.03905957591933473
===========>   training    <===========
Epoch: [806][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0403 (0.0403)	
0.9999918 3.7707153e-07
===========>   testing    <===========
Epoch: [806][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0440 (0.0440)	
0.9999912 4.8936016e-07
Epoch: [806][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0298 (0.0593)	
0.9999858 5.504942e-07
Epoch: [806][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0973 (0.0552)	
0.9999876 4.827732e-07
loss:  0.03989880838592719 0.03905957591933473
===========>   training    <===========
Epoch: [807][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0471 (0.0471)	
0.99998724 8.3949146e-08
===========>   testing    <===========
Epoch: [807][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0512 (0.0512)	
0.99999094 5.2038894e-07
Epoch: [807][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0219 (0.0592)	
0.9999751 4.6477464e-07
Epoch: [807][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0819 (0.0548)	
0.9999862 6.018107e-07
loss:  0.04049057063240036 0.03905957591933473
===========>   training    <===========
Epoch: [808][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0423 (0.0423)	
0.99998856 2.6113746e-08
===========>   testing    <===========
Epoch: [808][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0462 (0.0462)	
0.9999919 8.747553e-07
Epoch: [808][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0201 (0.0635)	
0.99998045 6.773686e-07
Epoch: [808][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0802 (0.0575)	
0.9999869 8.5855373e-07
loss:  0.04099571638254851 0.03905957591933473
===========>   training    <===========
Epoch: [809][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0433 (0.0433)	
0.9999896 4.410271e-08
===========>   testing    <===========
Epoch: [809][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0407 (0.0407)	
0.99998903 4.6069968e-07
Epoch: [809][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0194 (0.0622)	
0.99995685 4.1074156e-07
Epoch: [809][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.1016 (0.0569)	
0.9999825 5.479632e-07
loss:  0.0418352267537031 0.03905957591933473
===========>   training    <===========
Epoch: [810][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0347 (0.0347)	
0.99999166 4.3320437e-08
===========>   testing    <===========
Epoch: [810][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0516 (0.0516)	
0.99999094 5.06347e-07
Epoch: [810][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0246 (0.0585)	
0.9999685 5.256877e-07
Epoch: [810][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0988 (0.0561)	
0.9999888 7.5693157e-07
loss:  0.04163191066829275 0.03905957591933473
===========>   training    <===========
Epoch: [811][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0432 (0.0432)	
0.99998796 3.949724e-07
===========>   testing    <===========
Epoch: [811][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0425 (0.0425)	
0.99999046 3.5180938e-07
Epoch: [811][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0206 (0.0642)	
0.9999727 3.066675e-07
Epoch: [811][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0842 (0.0589)	
0.9999876 5.052525e-07
loss:  0.04241831712500199 0.03905957591933473
===========>   training    <===========
Epoch: [812][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0545 (0.0545)	
0.9999831 4.1002526e-08
===========>   testing    <===========
Epoch: [812][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0531 (0.0531)	
0.9999914 5.418541e-07
Epoch: [812][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0192 (0.0610)	
0.99997437 5.246895e-07
Epoch: [812][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0827 (0.0567)	
0.9999869 6.552647e-07
loss:  0.042143593251129596 0.03905957591933473
===========>   training    <===========
Epoch: [813][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0348 (0.0348)	
0.9999913 2.7019363e-08
===========>   testing    <===========
Epoch: [813][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0461 (0.0461)	
0.99999 8.520439e-07
Epoch: [813][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0221 (0.0589)	
0.9999703 7.300997e-07
Epoch: [813][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0953 (0.0555)	
0.9999838 7.985219e-07
loss:  0.041557187098020365 0.03905957591933473
===========>   training    <===========
Epoch: [814][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0342 (0.0342)	
0.99998 4.424898e-08
===========>   testing    <===========
Epoch: [814][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0906 (0.0906)	
0.9999896 2.9215076e-07
Epoch: [814][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0258 (0.0591)	
0.9999728 3.5830163e-07
Epoch: [814][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0761 (0.0547)	
0.99998367 2.7112424e-07
loss:  0.04060136728558328 0.03905957591933473
===========>   training    <===========
Epoch: [815][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0432 (0.0432)	
0.9999864 2.125225e-07
===========>   testing    <===========
Epoch: [815][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0936 (0.0936)	
0.9999913 6.5305e-07
Epoch: [815][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0309 (0.0612)	
0.99997616 5.7368305e-07
Epoch: [815][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0817 (0.0559)	
0.99998903 7.748152e-07
loss:  0.040370656788315085 0.03905957591933473
===========>   training    <===========
Epoch: [816][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0461 (0.0461)	
0.99998736 3.7731468e-07
===========>   testing    <===========
Epoch: [816][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0521 (0.0521)	
0.9999914 3.4134712e-07
Epoch: [816][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0239 (0.0614)	
0.9999757 2.7723868e-07
Epoch: [816][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0990 (0.0567)	
0.9999863 3.2500884e-07
loss:  0.04024378239051862 0.03905957591933473
===========>   training    <===========
Epoch: [817][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0403 (0.0403)	
0.9999765 3.3283737e-08
===========>   testing    <===========
Epoch: [817][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0536 (0.0536)	
0.99998987 4.5561774e-07
Epoch: [817][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0219 (0.0605)	
0.999977 4.380852e-07
Epoch: [817][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0754 (0.0549)	
0.99998295 4.6223383e-07
loss:  0.039981231416599816 0.03905957591933473
===========>   training    <===========
Epoch: [818][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0365 (0.0365)	
0.99999166 4.0993308e-07
===========>   testing    <===========
Epoch: [818][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0881 (0.0881)	
0.99999094 4.6961236e-07
Epoch: [818][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0198 (0.0612)	
0.9999782 5.08627e-07
Epoch: [818][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0868 (0.0573)	
0.9999844 4.8410374e-07
loss:  0.04172813450666868 0.03905957591933473
===========>   training    <===========
Epoch: [819][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0394 (0.0394)	
0.9999895 1.519424e-07
===========>   testing    <===========
Epoch: [819][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0587 (0.0587)	
0.9999889 2.7613362e-07
Epoch: [819][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0525 (0.0648)	
0.99997807 3.923972e-07
Epoch: [819][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012851215656510312]	Loss 0.0856 (0.0599)	
0.9999851 2.965633e-07
loss:  0.04178341267574903 0.03905957591933473
===========>   training    <===========
Epoch: [820][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0463 (0.0463)	
0.9999902 1.2783977e-07
===========>   testing    <===========
Epoch: [820][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0699 (0.0699)	
0.99999 4.910881e-07
Epoch: [820][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0214 (0.0635)	
0.99997973 3.2339366e-07
Epoch: [820][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.1091 (0.0596)	
0.9999863 5.6646655e-07
loss:  0.042388245691466375 0.03905957591933473
===========>   training    <===========
Epoch: [821][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0371 (0.0371)	
0.9999726 1.2465914e-08
===========>   testing    <===========
Epoch: [821][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0643 (0.0643)	
0.99998665 3.2991392e-07
Epoch: [821][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0192 (0.0617)	
0.9999771 4.6389604e-07
Epoch: [821][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0911 (0.0588)	
0.9999845 3.103114e-07
loss:  0.042849126316405806 0.03905957591933473
===========>   training    <===========
Epoch: [822][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0404 (0.0404)	
0.9999938 2.2110585e-07
===========>   testing    <===========
Epoch: [822][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0652 (0.0652)	
0.99998903 1.6751835e-07
Epoch: [822][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0218 (0.0627)	
0.9999733 1.5888052e-07
Epoch: [822][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0967 (0.0596)	
0.99998605 2.7854017e-07
loss:  0.043348628552233204 0.03905957591933473
===========>   training    <===========
Epoch: [823][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0443 (0.0443)	
0.9999902 3.767142e-08
===========>   testing    <===========
Epoch: [823][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0367 (0.0367)	
0.99999034 7.9307284e-07
Epoch: [823][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0180 (0.0621)	
0.99997556 6.326953e-07
Epoch: [823][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0861 (0.0575)	
0.99999094 7.577795e-07
loss:  0.04213546875090135 0.03905957591933473
===========>   training    <===========
Epoch: [824][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0345 (0.0345)	
0.9999944 2.7323065e-07
===========>   testing    <===========
Epoch: [824][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0720 (0.0720)	
0.9999882 4.9318794e-07
Epoch: [824][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0233 (0.0648)	
0.9999665 3.8263423e-07
Epoch: [824][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0560 (0.0586)	
0.9999852 4.5169844e-07
loss:  0.04169147221240799 0.03905957591933473
===========>   training    <===========
Epoch: [825][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0369 (0.0369)	
0.99998736 5.00101e-07
===========>   testing    <===========
Epoch: [825][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0586 (0.0586)	
0.99998856 5.4429194e-07
Epoch: [825][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0235 (0.0594)	
0.99997175 5.804671e-07
Epoch: [825][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0652 (0.0555)	
0.99998534 6.1951596e-07
loss:  0.041305543316242255 0.03905957591933473
===========>   training    <===========
Epoch: [826][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0415 (0.0415)	
0.99998736 6.662059e-07
===========>   testing    <===========
Epoch: [826][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0520 (0.0520)	
0.99999106 1.7717863e-07
Epoch: [826][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0507 (0.0614)	
0.9999782 1.9806669e-07
Epoch: [826][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0723 (0.0573)	
0.99998426 1.2454012e-07
loss:  0.04120217130008852 0.03905957591933473
===========>   training    <===========
Epoch: [827][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0417 (0.0417)	
0.9999752 9.392949e-08
===========>   testing    <===========
Epoch: [827][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0460 (0.0460)	
0.99999034 3.985245e-07
Epoch: [827][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0277 (0.0623)	
0.9999682 3.9710898e-07
Epoch: [827][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0751 (0.0571)	
0.9999857 3.7833007e-07
loss:  0.04092023434397929 0.03905957591933473
===========>   training    <===========
Epoch: [828][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0487 (0.0487)	
0.9999893 2.0222414e-07
===========>   testing    <===========
Epoch: [828][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0651 (0.0651)	
0.9999865 1.8838293e-07
Epoch: [828][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0243 (0.0621)	
0.99996793 1.9440807e-07
Epoch: [828][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.1087 (0.0584)	
0.9999862 1.1210712e-07
loss:  0.042517985161719896 0.03905957591933473
===========>   training    <===========
Epoch: [829][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0409 (0.0409)	
0.9999889 5.763251e-07
===========>   testing    <===========
Epoch: [829][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0766 (0.0766)	
0.99998426 2.0070247e-07
Epoch: [829][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0444 (0.0613)	
0.99997556 2.549076e-07
Epoch: [829][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0740 (0.0577)	
0.99998474 2.3893634e-07
loss:  0.04183204739533697 0.03905957591933473
===========>   training    <===========
Epoch: [830][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0428 (0.0428)	
0.9999838 5.301458e-07
===========>   testing    <===========
Epoch: [830][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0683 (0.0683)	
0.9999889 1.0843678e-06
Epoch: [830][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.1045 (0.0619)	
0.99997556 8.4278736e-07
Epoch: [830][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0729 (0.0577)	
0.9999851 7.97652e-07
loss:  0.041588013127924706 0.03905957591933473
===========>   training    <===========
Epoch: [831][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0468 (0.0468)	
0.9999883 6.03839e-07
===========>   testing    <===========
Epoch: [831][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0620 (0.0620)	
0.9999919 8.68709e-07
Epoch: [831][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0291 (0.0632)	
0.9999795 6.479939e-07
Epoch: [831][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0847 (0.0584)	
0.99998736 1.0576324e-06
loss:  0.0419380439458763 0.03905957591933473
===========>   training    <===========
Epoch: [832][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0414 (0.0414)	
0.99998593 2.527095e-08
===========>   testing    <===========
Epoch: [832][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0759 (0.0759)	
0.99999154 6.9869867e-07
Epoch: [832][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0317 (0.0623)	
0.9999757 5.1274725e-07
Epoch: [832][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0715 (0.0572)	
0.99998474 1.1935464e-06
loss:  0.04200334354176638 0.03905957591933473
===========>   training    <===========
Epoch: [833][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0481 (0.0481)	
0.9999753 2.6243276e-07
===========>   testing    <===========
Epoch: [833][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.1038 (0.1038)	
0.9999838 2.4388422e-07
Epoch: [833][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0550 (0.0624)	
0.9999496 1.6320266e-07
Epoch: [833][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0680 (0.0568)	
0.9999846 1.2572788e-07
loss:  0.041188531522961536 0.03905957591933473
===========>   training    <===========
Epoch: [834][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0392 (0.0392)	
0.9999813 1.0120214e-07
===========>   testing    <===========
Epoch: [834][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0414 (0.0414)	
0.9999901 4.069292e-07
Epoch: [834][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0310 (0.0622)	
0.9999676 2.8269864e-07
Epoch: [834][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.1034 (0.0577)	
0.999985 2.1381217e-07
loss:  0.040407304338518024 0.03905957591933473
===========>   training    <===========
Epoch: [835][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0364 (0.0364)	
0.99999046 9.576836e-07
===========>   testing    <===========
Epoch: [835][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0877 (0.0877)	
0.99998605 8.079254e-07
Epoch: [835][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0242 (0.0626)	
0.9999672 5.2600114e-07
Epoch: [835][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0776 (0.0568)	
0.9999831 9.36671e-07
loss:  0.04090710584966195 0.03905957591933473
===========>   training    <===========
Epoch: [836][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0472 (0.0472)	
0.9999893 4.641545e-08
===========>   testing    <===========
Epoch: [836][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0520 (0.0520)	
0.999992 5.8778176e-07
Epoch: [836][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0287 (0.0616)	
0.9999758 9.654912e-07
Epoch: [836][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0891 (0.0569)	
0.9999871 4.2786064e-07
loss:  0.04099659997990912 0.03905957591933473
===========>   training    <===========
Epoch: [837][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0352 (0.0352)	
0.9999877 7.350292e-07
===========>   testing    <===========
Epoch: [837][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0695 (0.0695)	
0.99998283 2.8225014e-07
Epoch: [837][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0278 (0.0621)	
0.99997485 2.9953583e-07
Epoch: [837][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0591 (0.0568)	
0.99998236 2.0838094e-07
loss:  0.04172024238920813 0.03905957591933473
===========>   training    <===========
Epoch: [838][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0520 (0.0520)	
0.99998057 7.7794574e-08
===========>   testing    <===========
Epoch: [838][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0800 (0.0800)	
0.9999901 2.621816e-07
Epoch: [838][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0212 (0.0603)	
0.99997103 3.173989e-07
Epoch: [838][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0628 (0.0557)	
0.9999815 2.1499605e-07
loss:  0.04088215170506404 0.03905957591933473
===========>   training    <===========
Epoch: [839][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0381 (0.0381)	
0.99998724 5.5530727e-08
===========>   testing    <===========
Epoch: [839][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0783 (0.0783)	
0.9999893 3.1736832e-07
Epoch: [839][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0241 (0.0625)	
0.99996626 3.452559e-07
Epoch: [839][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00012208654873684796]	Loss 0.0662 (0.0571)	
0.9999808 5.647076e-07
loss:  0.04074714426101256 0.03905957591933473
===========>   training    <===========
Epoch: [840][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0470 (0.0470)	
0.99999547 8.153235e-07
===========>   testing    <===========
Epoch: [840][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0565 (0.0565)	
0.99998903 2.4648244e-07
Epoch: [840][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0168 (0.0655)	
0.99996364 3.2229636e-07
Epoch: [840][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.1428 (0.0604)	
0.9999865 2.5038284e-07
loss:  0.0417293446479311 0.03905957591933473
===========>   training    <===========
Epoch: [841][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0416 (0.0416)	
0.9999887 5.2531936e-07
===========>   testing    <===========
Epoch: [841][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0778 (0.0778)	
0.9999881 2.439596e-07
Epoch: [841][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0547 (0.0613)	
0.9999646 2.65738e-07
Epoch: [841][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.1088 (0.0577)	
0.999984 2.023756e-07
loss:  0.04000566481215173 0.03905957591933473
===========>   training    <===========
Epoch: [842][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0453 (0.0453)	
0.9999721 7.306062e-08
===========>   testing    <===========
Epoch: [842][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0651 (0.0651)	
0.9999912 6.03046e-07
Epoch: [842][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0332 (0.0612)	
0.99997497 5.5371544e-07
Epoch: [842][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0929 (0.0574)	
0.99998605 6.923007e-07
loss:  0.04068526367352776 0.03905957591933473
===========>   training    <===========
Epoch: [843][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0532 (0.0532)	
0.99998057 2.681186e-08
===========>   testing    <===========
Epoch: [843][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.1089 (0.1089)	
0.9999943 7.6593e-07
Epoch: [843][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0182 (0.0641)	
0.9999827 5.985083e-07
Epoch: [843][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.1491 (0.0611)	
0.9999887 1.24565e-06
loss:  0.04164693371332706 0.03905957591933473
===========>   training    <===========
Epoch: [844][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0415 (0.0415)	
0.9999814 1.4599259e-07
===========>   testing    <===========
Epoch: [844][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0946 (0.0946)	
0.9999913 6.6232514e-07
Epoch: [844][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0352 (0.0628)	
0.9999815 4.1872366e-07
Epoch: [844][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0977 (0.0583)	
0.99998665 6.638466e-07
loss:  0.04055783257596235 0.03905957591933473
===========>   training    <===========
Epoch: [845][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0358 (0.0358)	
0.99998915 2.2307239e-07
===========>   testing    <===========
Epoch: [845][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0631 (0.0631)	
0.9999924 6.7347105e-07
Epoch: [845][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0653 (0.0598)	
0.9999862 6.3099844e-07
Epoch: [845][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.1245 (0.0583)	
0.9999869 5.652938e-07
loss:  0.040439638282862456 0.03905957591933473
===========>   training    <===========
Epoch: [846][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0418 (0.0418)	
0.99998903 6.944352e-07
===========>   testing    <===========
Epoch: [846][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0500 (0.0500)	
0.9999914 5.2777085e-07
Epoch: [846][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0550 (0.0616)	
0.9999807 4.898224e-07
Epoch: [846][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0957 (0.0574)	
0.9999871 4.782804e-07
loss:  0.04029006159221438 0.03905957591933473
===========>   training    <===========
Epoch: [847][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0403 (0.0403)	
0.99998987 5.0152715e-07
===========>   testing    <===========
Epoch: [847][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0915 (0.0915)	
0.99999166 6.9066e-07
Epoch: [847][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0395 (0.0621)	
0.9999778 5.471622e-07
Epoch: [847][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0829 (0.0579)	
0.9999863 6.177484e-07
loss:  0.040031441975888815 0.03905957591933473
===========>   training    <===========
Epoch: [848][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0423 (0.0423)	
0.99998784 2.3258414e-07
===========>   testing    <===========
Epoch: [848][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0375 (0.0375)	
0.9999908 4.7176522e-07
Epoch: [848][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.1774 (0.0620)	
0.99997926 3.3101412e-07
Epoch: [848][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0706 (0.0574)	
0.99998593 4.18157e-07
loss:  0.04113432283626106 0.03905957591933473
===========>   training    <===========
Epoch: [849][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0348 (0.0348)	
0.9999938 3.1730627e-07
===========>   testing    <===========
Epoch: [849][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0902 (0.0902)	
0.99998915 5.384845e-07
Epoch: [849][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.1047 (0.0605)	
0.99997914 6.961247e-07
Epoch: [849][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0786 (0.0578)	
0.9999882 4.7170315e-07
loss:  0.04091243870015904 0.03905957591933473
===========>   training    <===========
Epoch: [850][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0492 (0.0492)	
0.99999154 7.021937e-08
===========>   testing    <===========
Epoch: [850][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0557 (0.0557)	
0.99998987 6.480155e-07
Epoch: [850][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0717 (0.0613)	
0.99997425 5.609953e-07
Epoch: [850][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0711 (0.0576)	
0.99999034 5.596236e-07
loss:  0.04265386095720625 0.03905957591933473
===========>   training    <===========
Epoch: [851][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0430 (0.0430)	
0.9999838 7.7426563e-07
===========>   testing    <===========
Epoch: [851][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0871 (0.0871)	
0.99998724 4.0829127e-07
Epoch: [851][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0718 (0.0610)	
0.99997604 5.3095033e-07
Epoch: [851][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0883 (0.0566)	
0.9999881 6.025665e-07
loss:  0.04022923179015492 0.03905957591933473
===========>   training    <===========
Epoch: [852][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0397 (0.0397)	
0.99999094 8.74985e-08
===========>   testing    <===========
Epoch: [852][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0513 (0.0513)	
0.9999887 6.463633e-07
Epoch: [852][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.2093 (0.0617)	
0.9999751 4.154232e-07
Epoch: [852][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0882 (0.0575)	
0.999984 7.868523e-07
loss:  0.04054751590268035 0.03905957591933473
===========>   training    <===========
Epoch: [853][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0437 (0.0437)	
0.9999894 9.453733e-07
===========>   testing    <===========
Epoch: [853][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.1051 (0.1051)	
0.99998975 7.384854e-07
Epoch: [853][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0931 (0.0633)	
0.9999807 5.1027405e-07
Epoch: [853][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0799 (0.0594)	
0.99998295 7.9428384e-07
loss:  0.04180989152856274 0.03905957591933473
===========>   training    <===========
Epoch: [854][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0344 (0.0344)	
0.9999881 1.3642015e-06
===========>   testing    <===========
Epoch: [854][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0972 (0.0972)	
0.99997985 1.10428026e-07
Epoch: [854][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0534 (0.0608)	
0.99997103 1.0868697e-07
Epoch: [854][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.1145 (0.0579)	
0.9999759 7.298039e-08
loss:  0.03918197184140937 0.03905957591933473
===========>   training    <===========
Epoch: [855][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0400 (0.0400)	
0.9999659 1.1486023e-08
===========>   testing    <===========
Epoch: [855][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.1042 (0.1042)	
0.99999225 9.838543e-07
Epoch: [855][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0619 (0.0641)	
0.9999807 4.3239004e-07
Epoch: [855][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0825 (0.0595)	
0.99998605 1.1668012e-06
loss:  0.03972109449940131 0.03905957591933473
===========>   training    <===========
Epoch: [856][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0401 (0.0401)	
0.99997747 3.039956e-07
===========>   testing    <===========
Epoch: [856][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0804 (0.0804)	
0.9999906 4.121801e-07
Epoch: [856][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0628 (0.0629)	
0.999977 3.2256574e-07
Epoch: [856][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0699 (0.0574)	
0.9999857 7.474598e-07
loss:  0.03923088757729776 0.03905957591933473
===========>   training    <===========
Epoch: [857][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0438 (0.0438)	
0.9999783 1.214962e-07
===========>   testing    <===========
Epoch: [857][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.1064 (0.1064)	
0.9999906 5.986173e-07
Epoch: [857][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0708 (0.0613)	
0.9999807 3.7350503e-07
Epoch: [857][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0966 (0.0570)	
0.9999844 7.338056e-07
loss:  0.0398448880826473 0.03905957591933473
===========>   training    <===========
Epoch: [858][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0414 (0.0414)	
0.99999213 3.6031437e-08
===========>   testing    <===========
Epoch: [858][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0859 (0.0859)	
0.99999094 6.5683696e-07
Epoch: [858][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0188 (0.0602)	
0.9999765 5.4349624e-07
Epoch: [858][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.1471 (0.0583)	
0.9999858 6.0003646e-07
loss:  0.03911315072299548 0.03905957591933473
===========>   training    <===========
Epoch: [859][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0353 (0.0353)	
0.9999809 3.1708662e-08
===========>   testing    <===========
Epoch: [859][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0692 (0.0692)	
0.9999913 4.60857e-07
Epoch: [859][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.0617 (0.0632)	
0.9999789 4.6129495e-07
Epoch: [859][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011598222130000556]	Loss 0.1117 (0.0600)	
0.9999881 6.5373797e-07
loss:  0.04211445745015441 0.03905957591933473
===========>   training    <===========
Epoch: [860][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0427 (0.0427)	
0.9999691 2.0860105e-07
===========>   testing    <===========
Epoch: [860][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0774 (0.0774)	
0.99999225 3.491548e-07
Epoch: [860][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0450 (0.0609)	
0.9999795 3.488632e-07
Epoch: [860][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0722 (0.0569)	
0.99998724 3.8606578e-07
loss:  0.03941985084802002 0.03905957591933473
===========>   training    <===========
Epoch: [861][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0312 (0.0312)	
0.99998367 2.745167e-07
===========>   testing    <===========
Epoch: [861][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.1056 (0.1056)	
0.99998736 1.2837538e-07
Epoch: [861][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0788 (0.0625)	
0.99996877 1.5145919e-07
Epoch: [861][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0900 (0.0589)	
0.9999833 1.17402124e-07
loss:  0.041610034848240995 0.03905957591933473
===========>   training    <===========
Epoch: [862][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0435 (0.0435)	
0.99999285 1.3938067e-08
===========>   testing    <===========
Epoch: [862][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.1004 (0.1004)	
0.9999919 8.5414047e-07
Epoch: [862][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0724 (0.0660)	
0.99996567 8.6636095e-07
Epoch: [862][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0874 (0.0597)	
0.99998987 1.2454088e-06
loss:  0.041709614039561416 0.03905957591933473
===========>   training    <===========
Epoch: [863][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0412 (0.0412)	
0.99999475 1.15272876e-07
===========>   testing    <===========
Epoch: [863][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.1078 (0.1078)	
0.99999046 4.2239992e-07
Epoch: [863][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0872 (0.0624)	
0.99997187 5.141222e-07
Epoch: [863][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0983 (0.0578)	
0.99998486 7.959855e-07
loss:  0.04081965992935843 0.03905957591933473
===========>   training    <===========
Epoch: [864][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0454 (0.0454)	
0.9999858 3.7936047e-07
===========>   testing    <===========
Epoch: [864][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0942 (0.0942)	
0.99999 4.182838e-07
Epoch: [864][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.1382 (0.0611)	
0.99997616 4.4739286e-07
Epoch: [864][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.1068 (0.0567)	
0.9999863 1.0466392e-06
loss:  0.04067871936173728 0.03905957591933473
===========>   training    <===========
Epoch: [865][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0370 (0.0370)	
0.9999745 8.366589e-08
===========>   testing    <===========
Epoch: [865][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.1041 (0.1041)	
0.9999888 4.490107e-07
Epoch: [865][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0387 (0.0619)	
0.9999654 6.6452185e-07
Epoch: [865][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.1680 (0.0585)	
0.9999813 6.239641e-07
loss:  0.041101641302728975 0.03905957591933473
===========>   training    <===========
Epoch: [866][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0413 (0.0413)	
0.9999801 2.1360995e-08
===========>   testing    <===========
Epoch: [866][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0788 (0.0788)	
0.9999907 4.1109502e-07
Epoch: [866][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.1192 (0.0641)	
0.99997294 5.5603533e-07
Epoch: [866][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0941 (0.0592)	
0.9999865 1.0898367e-06
loss:  0.040929388368085906 0.03905957591933473
===========>   training    <===========
Epoch: [867][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0400 (0.0400)	
0.9999894 4.5172777e-07
===========>   testing    <===========
Epoch: [867][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0900 (0.0900)	
0.99999106 5.0964957e-07
Epoch: [867][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.2851 (0.0626)	
0.9999728 5.799359e-07
Epoch: [867][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0955 (0.0580)	
0.99998856 1.0886494e-06
loss:  0.04097934272587067 0.03905957591933473
===========>   training    <===========
Epoch: [868][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0536 (0.0536)	
0.9999819 1.8924973e-06
===========>   testing    <===========
Epoch: [868][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0833 (0.0833)	
0.9999913 3.3396236e-07
Epoch: [868][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.2528 (0.0637)	
0.9999776 4.8137747e-07
Epoch: [868][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.1242 (0.0596)	
0.9999844 3.7448515e-07
loss:  0.04196839905904659 0.03905957591933473
===========>   training    <===========
Epoch: [869][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0385 (0.0385)	
0.99999356 9.75712e-07
===========>   testing    <===========
Epoch: [869][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.1238 (0.1238)	
0.9999906 2.6363205e-07
Epoch: [869][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.3590 (0.0662)	
0.9999708 3.8586188e-07
Epoch: [869][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0686 (0.0602)	
0.9999864 3.8949617e-07
loss:  0.042029475114088055 0.03905957591933473
===========>   training    <===========
Epoch: [870][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0526 (0.0526)	
0.9999851 1.930442e-08
===========>   testing    <===========
Epoch: [870][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0979 (0.0979)	
0.9999887 7.4122164e-07
Epoch: [870][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0622 (0.0612)	
0.9999682 9.919112e-07
Epoch: [870][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.1032 (0.0590)	
0.9999833 1.391726e-06
loss:  0.041023928235523366 0.03905957591933473
===========>   training    <===========
Epoch: [871][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0346 (0.0346)	
0.99999106 2.540526e-07
===========>   testing    <===========
Epoch: [871][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0838 (0.0838)	
0.9999907 6.997296e-07
Epoch: [871][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0644 (0.0607)	
0.9999757 8.9949407e-07
Epoch: [871][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0714 (0.0579)	
0.9999865 9.372938e-07
loss:  0.04120375925459996 0.03905957591933473
===========>   training    <===========
Epoch: [872][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0343 (0.0343)	
0.9999889 2.5967282e-07
===========>   testing    <===========
Epoch: [872][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0620 (0.0620)	
0.99998426 2.93941e-07
Epoch: [872][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0494 (0.0602)	
0.9999751 3.458995e-07
Epoch: [872][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0885 (0.0570)	
0.9999808 2.5926897e-07
loss:  0.04095381331378933 0.03905957591933473
===========>   training    <===========
Epoch: [873][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0369 (0.0369)	
0.9999881 9.701032e-07
===========>   testing    <===========
Epoch: [873][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0847 (0.0847)	
0.9999913 5.37743e-07
Epoch: [873][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.2198 (0.0665)	
0.9999838 6.514949e-07
Epoch: [873][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.1047 (0.0624)	
0.99999 7.7714253e-07
loss:  0.04433424823963017 0.03905957591933473
===========>   training    <===========
Epoch: [874][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0438 (0.0438)	
0.99999106 6.764081e-08
===========>   testing    <===========
Epoch: [874][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.1121 (0.1121)	
0.99998784 2.8692085e-07
Epoch: [874][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0294 (0.0640)	
0.9999752 4.6442196e-07
Epoch: [874][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.1040 (0.0604)	
0.9999852 5.560237e-07
loss:  0.042909844927434104 0.03905957591933473
===========>   training    <===========
Epoch: [875][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0350 (0.0350)	
0.99999 2.3632607e-08
===========>   testing    <===========
Epoch: [875][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.1103 (0.1103)	
0.99999106 2.9520916e-07
Epoch: [875][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0340 (0.0623)	
0.9999802 4.6150703e-07
Epoch: [875][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.1374 (0.0601)	
0.9999845 3.7726937e-07
loss:  0.04061210033758356 0.03905957591933473
===========>   training    <===========
Epoch: [876][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0381 (0.0381)	
0.9999877 1.2157019e-06
===========>   testing    <===========
Epoch: [876][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0977 (0.0977)	
0.9999926 2.220231e-07
Epoch: [876][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0975 (0.0642)	
0.9999819 4.1152535e-07
Epoch: [876][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0963 (0.0589)	
0.9999858 3.2887132e-07
loss:  0.04168108372345969 0.03905957591933473
===========>   training    <===========
Epoch: [877][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0388 (0.0388)	
0.9999882 2.6677577e-07
===========>   testing    <===========
Epoch: [877][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.1080 (0.1080)	
0.99999356 1.8270754e-07
Epoch: [877][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0854 (0.0625)	
0.99998164 3.7659424e-07
Epoch: [877][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.1094 (0.0591)	
0.9999852 3.2809066e-07
loss:  0.04148132800725035 0.03905957591933473
===========>   training    <===========
Epoch: [878][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0428 (0.0428)	
0.9999789 1.3185977e-06
===========>   testing    <===========
Epoch: [878][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.1206 (0.1206)	
0.99999356 3.0992544e-07
Epoch: [878][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.1403 (0.0638)	
0.9999782 5.7799895e-07
Epoch: [878][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.1434 (0.0594)	
0.9999845 4.6370056e-07
loss:  0.04251239397180018 0.03905957591933473
===========>   training    <===========
Epoch: [879][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0390 (0.0390)	
0.99998105 7.445899e-08
===========>   testing    <===========
Epoch: [879][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.0577 (0.0577)	
0.99999297 6.915181e-07
Epoch: [879][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.1388 (0.0618)	
0.99998224 7.5889903e-07
Epoch: [879][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00011018311023500529]	Loss 0.1815 (0.0600)	
0.99998903 9.314305e-07
loss:  0.04149689265861456 0.03905957591933473
===========>   training    <===========
Epoch: [880][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0419 (0.0419)	
0.99996614 4.525237e-08
===========>   testing    <===========
Epoch: [880][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0778 (0.0778)	
0.99999046 3.1222308e-07
Epoch: [880][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.1402 (0.0585)	
0.9999827 5.936105e-07
Epoch: [880][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.1451 (0.0567)	
0.99998796 6.352412e-07
loss:  0.04090306425900714 0.03905957591933473
===========>   training    <===========
Epoch: [881][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0474 (0.0474)	
0.99999094 3.3738813e-06
===========>   testing    <===========
Epoch: [881][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0337 (0.0337)	
0.9999907 1.5855993e-07
Epoch: [881][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0376 (0.0600)	
0.9999784 3.3617235e-07
Epoch: [881][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.1370 (0.0566)	
0.9999858 2.1717467e-07
loss:  0.04023082116339105 0.03905957591933473
===========>   training    <===========
Epoch: [882][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0411 (0.0411)	
0.99998915 2.8351565e-07
===========>   testing    <===========
Epoch: [882][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0339 (0.0339)	
0.99999213 5.3042345e-07
Epoch: [882][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.2137 (0.0661)	
0.99998367 5.0144683e-07
Epoch: [882][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.1089 (0.0602)	
0.99999034 9.753827e-07
loss:  0.04189799185637266 0.03905957591933473
===========>   training    <===========
Epoch: [883][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0396 (0.0396)	
0.9999931 2.7020187e-08
===========>   testing    <===========
Epoch: [883][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0495 (0.0495)	
0.99998856 5.283858e-07
Epoch: [883][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.1614 (0.0625)	
0.99997556 4.9549703e-07
Epoch: [883][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0964 (0.0576)	
0.99998784 5.885935e-07
loss:  0.04155666174568007 0.03905957591933473
===========>   training    <===========
Epoch: [884][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0443 (0.0443)	
0.99996793 7.7820675e-07
===========>   testing    <===========
Epoch: [884][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0451 (0.0451)	
0.9999919 5.084223e-07
Epoch: [884][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0989 (0.0625)	
0.9999738 4.0806472e-07
Epoch: [884][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.1568 (0.0589)	
0.9999876 4.4927717e-07
loss:  0.04110403582289501 0.03905957591933473
===========>   training    <===========
Epoch: [885][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0350 (0.0350)	
0.999987 2.7607885e-07
===========>   testing    <===========
Epoch: [885][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0436 (0.0436)	
0.9999918 7.3685334e-07
Epoch: [885][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0437 (0.0628)	
0.9999666 4.90678e-07
Epoch: [885][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.1323 (0.0594)	
0.9999895 7.991855e-07
loss:  0.04126372242462528 0.03905957591933473
===========>   training    <===========
Epoch: [886][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0497 (0.0497)	
0.999992 7.530163e-08
===========>   testing    <===========
Epoch: [886][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0551 (0.0551)	
0.9999881 3.1627636e-07
Epoch: [886][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0252 (0.0640)	
0.9999733 3.3828724e-07
Epoch: [886][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.1058 (0.0593)	
0.9999875 4.0521633e-07
loss:  0.041824791375085324 0.03905957591933473
===========>   training    <===========
Epoch: [887][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0365 (0.0365)	
0.99998796 4.515572e-08
===========>   testing    <===========
Epoch: [887][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0398 (0.0398)	
0.99999 4.5316892e-07
Epoch: [887][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0252 (0.0629)	
0.99997544 2.9058356e-07
Epoch: [887][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.1081 (0.0590)	
0.99998844 6.332186e-07
loss:  0.04072379214718258 0.03905957591933473
===========>   training    <===========
Epoch: [888][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0394 (0.0394)	
0.9999895 7.6908776e-08
===========>   testing    <===========
Epoch: [888][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0794 (0.0794)	
0.9999906 2.322787e-07
Epoch: [888][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.1369 (0.0610)	
0.9999614 3.2249991e-07
Epoch: [888][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0811 (0.0567)	
0.99998415 3.169482e-07
loss:  0.04108108193326365 0.03905957591933473
===========>   training    <===========
Epoch: [889][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0348 (0.0348)	
0.9999864 2.3655545e-07
===========>   testing    <===========
Epoch: [889][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0614 (0.0614)	
0.99998987 3.6558214e-07
Epoch: [889][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.1344 (0.0619)	
0.99997354 3.8414572e-07
Epoch: [889][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0789 (0.0582)	
0.99998605 6.054882e-07
loss:  0.041799085885608545 0.03905957591933473
===========>   training    <===========
Epoch: [890][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0354 (0.0354)	
0.99996257 6.437304e-08
===========>   testing    <===========
Epoch: [890][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0623 (0.0623)	
0.9999907 2.6401977e-07
Epoch: [890][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.1235 (0.0619)	
0.9999802 4.3553035e-07
Epoch: [890][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0788 (0.0579)	
0.9999895 4.318679e-07
loss:  0.041379463222281365 0.03905957591933473
===========>   training    <===========
Epoch: [891][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0452 (0.0452)	
0.9999893 2.8408664e-08
===========>   testing    <===========
Epoch: [891][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0507 (0.0507)	
0.99999213 1.5367218e-07
Epoch: [891][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.1175 (0.0606)	
0.999979 2.8060919e-07
Epoch: [891][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0729 (0.0572)	
0.9999908 1.9424702e-07
loss:  0.04192666306376658 0.03905957591933473
===========>   training    <===========
Epoch: [892][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0443 (0.0443)	
0.99999356 1.4447046e-07
===========>   testing    <===========
Epoch: [892][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0649 (0.0649)	
0.9999919 1.3546476e-07
Epoch: [892][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0325 (0.0638)	
0.99997926 2.0240783e-07
Epoch: [892][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0998 (0.0599)	
0.9999896 1.1198616e-07
loss:  0.042838742266802954 0.03905957591933473
===========>   training    <===========
Epoch: [893][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0387 (0.0387)	
0.9999931 1.1863247e-08
===========>   testing    <===========
Epoch: [893][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0812 (0.0812)	
0.9999914 4.069835e-07
Epoch: [893][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0509 (0.0626)	
0.99998057 4.477668e-07
Epoch: [893][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0754 (0.0575)	
0.9999906 3.5887888e-07
loss:  0.04170427984398617 0.03905957591933473
===========>   training    <===========
Epoch: [894][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0371 (0.0371)	
0.99999404 2.1340394e-07
===========>   testing    <===========
Epoch: [894][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0787 (0.0787)	
0.99998856 1.3504464e-07
Epoch: [894][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0197 (0.0602)	
0.9999745 1.8308864e-07
Epoch: [894][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0817 (0.0577)	
0.99998724 2.2168331e-07
loss:  0.0406024027001749 0.03905957591933473
===========>   training    <===========
Epoch: [895][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0382 (0.0382)	
0.9999926 1.6923279e-07
===========>   testing    <===========
Epoch: [895][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0934 (0.0934)	
0.9999927 4.1786996e-07
Epoch: [895][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0318 (0.0591)	
0.99997747 7.349374e-07
Epoch: [895][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0710 (0.0580)	
0.99998987 8.1851925e-07
loss:  0.040890322698393544 0.03905957591933473
===========>   training    <===========
Epoch: [896][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0338 (0.0338)	
0.9999863 8.805497e-09
===========>   testing    <===========
Epoch: [896][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.1205 (0.1205)	
0.9999896 1.16377905e-07
Epoch: [896][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0268 (0.0599)	
0.9999701 1.8045205e-07
Epoch: [896][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0860 (0.0568)	
0.99998844 7.332908e-08
loss:  0.03967991789346903 0.03905957591933473
===========>   training    <===========
Epoch: [897][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0394 (0.0394)	
0.99999297 6.842182e-07
===========>   testing    <===========
Epoch: [897][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.1104 (0.1104)	
0.9999913 3.4298392e-07
Epoch: [897][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0416 (0.0621)	
0.99998295 2.6810793e-07
Epoch: [897][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.1041 (0.0573)	
0.9999869 4.4226033e-07
loss:  0.0417078734496934 0.03905957591933473
===========>   training    <===========
Epoch: [898][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0448 (0.0448)	
0.99999034 4.9561326e-08
===========>   testing    <===========
Epoch: [898][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0850 (0.0850)	
0.99999166 4.0318216e-07
Epoch: [898][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0356 (0.0644)	
0.9999857 5.2060335e-07
Epoch: [898][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0972 (0.0583)	
0.99998665 7.0813843e-07
loss:  0.04197147482447139 0.03905957591933473
===========>   training    <===========
Epoch: [899][0/23]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0295 (0.0295)	
0.99998343 3.4294925e-07
===========>   testing    <===========
Epoch: [899][0/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0906 (0.0906)	
0.9999913 1.365879e-07
Epoch: [899][100/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0310 (0.0633)	
0.99997795 2.3548111e-07
Epoch: [899][200/289]	Lr-deconv: [0.0]	Lr-other: [0.00010467395472325501]	Loss 0.0958 (0.0590)	
0.99998796 1.3320924e-07
loss:  0.042567617417908155 0.03905957591933473
===========>   training    <===========
Epoch: [900][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0405 (0.0405)	
0.99998677 6.884056e-09
===========>   testing    <===========
Epoch: [900][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0687 (0.0687)	
0.99999356 6.707501e-07
Epoch: [900][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0354 (0.0625)	
0.999984 9.040391e-07
Epoch: [900][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.1169 (0.0591)	
0.9999889 1.009486e-06
loss:  0.04184468181562273 0.03905957591933473
===========>   training    <===========
Epoch: [901][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0306 (0.0306)	
0.99999774 1.8034916e-07
===========>   testing    <===========
Epoch: [901][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0750 (0.0750)	
0.9999939 4.7489524e-07
Epoch: [901][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0662 (0.0605)	
0.99997723 7.519872e-07
Epoch: [901][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.1259 (0.0584)	
0.9999893 8.14422e-07
loss:  0.041954466785828926 0.03905957591933473
===========>   training    <===========
Epoch: [902][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0326 (0.0326)	
0.99998415 6.577616e-08
===========>   testing    <===========
Epoch: [902][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0731 (0.0731)	
0.9999925 4.9555945e-07
Epoch: [902][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.1598 (0.0652)	
0.99998 6.600048e-07
Epoch: [902][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.1192 (0.0612)	
0.9999889 6.4067916e-07
loss:  0.04251004763407973 0.03905957591933473
===========>   training    <===========
Epoch: [903][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0365 (0.0365)	
0.9999938 6.852271e-07
===========>   testing    <===========
Epoch: [903][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0885 (0.0885)	
0.9999926 3.7314933e-07
Epoch: [903][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0762 (0.0644)	
0.99997556 3.6796942e-07
Epoch: [903][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0801 (0.0578)	
0.99998724 3.2221155e-07
loss:  0.0413361107735537 0.03905957591933473
===========>   training    <===========
Epoch: [904][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0333 (0.0333)	
0.99997556 3.1259222e-07
===========>   testing    <===========
Epoch: [904][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0666 (0.0666)	
0.9999913 5.828234e-07
Epoch: [904][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0744 (0.0639)	
0.999977 5.5724144e-07
Epoch: [904][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0801 (0.0587)	
0.99998796 5.112317e-07
loss:  0.04241497065022726 0.03905957591933473
===========>   training    <===========
Epoch: [905][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0426 (0.0426)	
0.9999914 1.7850579e-07
===========>   testing    <===========
Epoch: [905][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0885 (0.0885)	
0.9999925 2.5034203e-07
Epoch: [905][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0932 (0.0649)	
0.9999809 4.932857e-07
Epoch: [905][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.1279 (0.0593)	
0.9999894 1.7496572e-07
loss:  0.042462271015616726 0.03905957591933473
===========>   training    <===========
Epoch: [906][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0367 (0.0367)	
0.9999933 1.8808954e-08
===========>   testing    <===========
Epoch: [906][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0592 (0.0592)	
0.9999907 3.9246268e-07
Epoch: [906][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.1820 (0.0657)	
0.99997675 5.6432754e-07
Epoch: [906][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.1001 (0.0591)	
0.9999882 5.290443e-07
loss:  0.04251545623544861 0.03905957591933473
===========>   training    <===========
Epoch: [907][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0381 (0.0381)	
0.9999876 1.8305828e-07
===========>   testing    <===========
Epoch: [907][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0446 (0.0446)	
0.999992 4.387667e-07
Epoch: [907][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.1181 (0.0648)	
0.99997854 7.2996113e-07
Epoch: [907][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.1360 (0.0608)	
0.9999877 5.892753e-07
loss:  0.0440989356541055 0.03905957591933473
===========>   training    <===========
Epoch: [908][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0345 (0.0345)	
0.99999297 4.1928384e-08
===========>   testing    <===========
Epoch: [908][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0751 (0.0751)	
0.9999926 7.275273e-07
Epoch: [908][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0713 (0.0643)	
0.999984 1.1123221e-06
Epoch: [908][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.1865 (0.0607)	
0.9999883 3.9333088e-07
loss:  0.042611720721709156 0.03905957591933473
===========>   training    <===========
Epoch: [909][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0427 (0.0427)	
0.99996686 3.6058935e-08
===========>   testing    <===========
Epoch: [909][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0896 (0.0896)	
0.99998975 3.0462186e-07
Epoch: [909][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.4084 (0.0663)	
0.9999844 4.787139e-07
Epoch: [909][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.1732 (0.0609)	
0.99999 2.496954e-07
loss:  0.04286644386982075 0.03905957591933473
===========>   training    <===========
Epoch: [910][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0327 (0.0327)	
0.9999907 3.1485659e-09
===========>   testing    <===========
Epoch: [910][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0776 (0.0776)	
0.99998987 3.1006056e-07
Epoch: [910][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.2821 (0.0623)	
0.9999827 3.2708283e-07
Epoch: [910][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.1074 (0.0574)	
0.99998975 1.4129901e-07
loss:  0.042033708815176984 0.03905957591933473
===========>   training    <===========
Epoch: [911][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0436 (0.0436)	
0.99999046 8.5868336e-08
===========>   testing    <===========
Epoch: [911][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0648 (0.0648)	
0.9999901 5.7214606e-07
Epoch: [911][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.2653 (0.0645)	
0.9999815 3.976096e-07
Epoch: [911][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.1722 (0.0597)	
0.9999876 2.942563e-07
loss:  0.04386806131557708 0.03905957591933473
===========>   training    <===========
Epoch: [912][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0404 (0.0404)	
0.99998677 2.4841896e-07
===========>   testing    <===========
Epoch: [912][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0630 (0.0630)	
0.99999416 5.6168693e-07
Epoch: [912][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.2654 (0.0635)	
0.999985 7.8312496e-07
Epoch: [912][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0957 (0.0581)	
0.9999889 5.527294e-07
loss:  0.0427151913240974 0.03905957591933473
===========>   training    <===========
Epoch: [913][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0331 (0.0331)	
0.9999893 9.782016e-07
===========>   testing    <===========
Epoch: [913][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0494 (0.0494)	
0.99999475 2.6670685e-07
Epoch: [913][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.1593 (0.0611)	
0.9999877 2.795453e-07
Epoch: [913][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.1045 (0.0583)	
0.99998987 3.6510238e-07
loss:  0.04265590904708183 0.03905957591933473
===========>   training    <===========
Epoch: [914][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0358 (0.0358)	
0.99999106 6.7352566e-08
===========>   testing    <===========
Epoch: [914][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0524 (0.0524)	
0.9999932 5.555154e-07
Epoch: [914][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.2145 (0.0633)	
0.99998486 6.130106e-07
Epoch: [914][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.1296 (0.0579)	
0.9999893 4.4579573e-07
loss:  0.04235691349241444 0.03905957591933473
===========>   training    <===========
Epoch: [915][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0405 (0.0405)	
0.9999782 1.6198939e-08
===========>   testing    <===========
Epoch: [915][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0597 (0.0597)	
0.9999932 4.0669252e-07
Epoch: [915][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.1644 (0.0615)	
0.99998164 4.1855915e-07
Epoch: [915][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0930 (0.0575)	
0.99998796 6.774183e-07
loss:  0.04106152838743371 0.03905957591933473
===========>   training    <===========
Epoch: [916][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0369 (0.0369)	
0.9999907 4.1408697e-08
===========>   testing    <===========
Epoch: [916][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0905 (0.0905)	
0.9999924 2.3348866e-07
Epoch: [916][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0500 (0.0583)	
0.99998057 2.531703e-07
Epoch: [916][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.1033 (0.0562)	
0.99998534 2.8759723e-07
loss:  0.03949574276395362 0.03905957591933473
===========>   training    <===========
Epoch: [917][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0442 (0.0442)	
0.9999877 3.7150713e-07
===========>   testing    <===========
Epoch: [917][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.1004 (0.1004)	
0.9999924 3.0266085e-07
Epoch: [917][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.1200 (0.0612)	
0.99998474 3.256244e-07
Epoch: [917][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.1427 (0.0594)	
0.9999894 5.1320615e-07
loss:  0.042129890721616214 0.03905957591933473
===========>   training    <===========
Epoch: [918][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0331 (0.0331)	
0.99999523 3.1310744e-08
===========>   testing    <===========
Epoch: [918][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0802 (0.0802)	
0.99999154 2.4351561e-07
Epoch: [918][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.1091 (0.0647)	
0.9999838 3.7060863e-07
Epoch: [918][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0683 (0.0599)	
0.9999877 4.697566e-07
loss:  0.04331811664622032 0.03905957591933473
===========>   training    <===========
Epoch: [919][0/23]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0465 (0.0465)	
0.99999106 3.0026544e-07
===========>   testing    <===========
Epoch: [919][0/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.1208 (0.1208)	
0.999992 2.0406227e-07
Epoch: [919][100/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.1276 (0.0628)	
0.99998224 3.4823663e-07
Epoch: [919][200/289]	Lr-deconv: [0.0]	Lr-other: [9.944025698709225e-05]	Loss 0.0598 (0.0587)	
0.9999875 2.2911587e-07
loss:  0.04152055260994514 0.03905957591933473
===========>   training    <===========
Epoch: [920][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0412 (0.0412)	
0.99999475 7.188622e-08
===========>   testing    <===========
Epoch: [920][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0645 (0.0645)	
0.9999931 5.0683735e-07
Epoch: [920][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.1703 (0.0618)	
0.9999784 5.7743586e-07
Epoch: [920][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.1019 (0.0590)	
0.9999876 7.0987215e-07
loss:  0.04114807190558323 0.03905957591933473
===========>   training    <===========
Epoch: [921][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0428 (0.0428)	
0.99998987 2.7235954e-08
===========>   testing    <===========
Epoch: [921][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0535 (0.0535)	
0.9999938 4.0995656e-07
Epoch: [921][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.1508 (0.0628)	
0.9999845 5.3197664e-07
Epoch: [921][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.1123 (0.0595)	
0.99998975 7.280846e-07
loss:  0.042759254747975484 0.03905957591933473
===========>   training    <===========
Epoch: [922][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0369 (0.0369)	
0.99999464 1.9072208e-07
===========>   testing    <===========
Epoch: [922][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0708 (0.0708)	
0.9999939 2.6614074e-07
Epoch: [922][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.2607 (0.0641)	
0.99998426 3.162124e-07
Epoch: [922][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0953 (0.0583)	
0.9999896 4.1351166e-07
loss:  0.04146335741802809 0.03905957591933473
===========>   training    <===========
Epoch: [923][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0373 (0.0373)	
0.99999034 2.0833914e-08
===========>   testing    <===========
Epoch: [923][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0872 (0.0872)	
0.9999937 1.8817428e-07
Epoch: [923][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.3642 (0.0627)	
0.9999814 2.884614e-07
Epoch: [923][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0690 (0.0578)	
0.9999889 1.2689732e-07
loss:  0.041167180619785304 0.03905957591933473
===========>   training    <===========
Epoch: [924][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0385 (0.0385)	
0.99999344 4.0916328e-07
===========>   testing    <===========
Epoch: [924][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0716 (0.0716)	
0.99999547 8.81416e-07
Epoch: [924][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.5937 (0.0680)	
0.99998784 9.1254964e-07
Epoch: [924][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0595 (0.0605)	
0.99999106 9.2645087e-07
loss:  0.0437500430879838 0.03905957591933473
===========>   training    <===========
Epoch: [925][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0356 (0.0356)	
0.99999154 1.00718026e-07
===========>   testing    <===========
Epoch: [925][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.1069 (0.1069)	
0.9999927 3.2391037e-07
Epoch: [925][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.2569 (0.0641)	
0.99998426 3.7648724e-07
Epoch: [925][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0895 (0.0582)	
0.9999889 3.7066096e-07
loss:  0.040918801181946796 0.03905957591933473
===========>   training    <===========
Epoch: [926][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0409 (0.0409)	
0.99998546 6.6442304e-08
===========>   testing    <===========
Epoch: [926][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.1020 (0.1020)	
0.99999464 4.1072312e-07
Epoch: [926][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.2310 (0.0641)	
0.9999851 3.6998253e-07
Epoch: [926][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0674 (0.0582)	
0.99999 5.7134133e-07
loss:  0.041582801441395256 0.03905957591933473
===========>   training    <===========
Epoch: [927][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0444 (0.0444)	
0.9999857 4.1602073e-09
===========>   testing    <===========
Epoch: [927][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.1007 (0.1007)	
0.9999927 1.9215543e-07
Epoch: [927][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.1760 (0.0645)	
0.9999801 1.9910148e-07
Epoch: [927][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0830 (0.0588)	
0.99998844 1.1457145e-07
loss:  0.04202794474884397 0.03905957591933473
===========>   training    <===========
Epoch: [928][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0411 (0.0411)	
0.99999285 2.215108e-08
===========>   testing    <===========
Epoch: [928][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0809 (0.0809)	
0.9999939 6.036392e-07
Epoch: [928][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.2453 (0.0660)	
0.99998474 6.131159e-07
Epoch: [928][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0710 (0.0591)	
0.9999912 6.698341e-07
loss:  0.04219392779447673 0.03905957591933473
===========>   training    <===========
Epoch: [929][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0465 (0.0465)	
0.9999919 5.0745064e-07
===========>   testing    <===========
Epoch: [929][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.1188 (0.1188)	
0.9999927 4.99691e-07
Epoch: [929][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.2456 (0.0648)	
0.99998355 5.729166e-07
Epoch: [929][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0680 (0.0590)	
0.99999034 4.748943e-07
loss:  0.04155500667844514 0.03905957591933473
===========>   training    <===========
Epoch: [930][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0364 (0.0364)	
0.999987 1.284785e-07
===========>   testing    <===========
Epoch: [930][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0971 (0.0971)	
0.9999938 4.1075253e-07
Epoch: [930][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.2137 (0.0636)	
0.99998546 3.7220502e-07
Epoch: [930][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0700 (0.0589)	
0.99999046 4.0076438e-07
loss:  0.042141321670378096 0.03905957591933473
===========>   training    <===========
Epoch: [931][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0422 (0.0422)	
0.9999888 7.95456e-08
===========>   testing    <===========
Epoch: [931][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.1018 (0.1018)	
0.9999943 4.8463454e-07
Epoch: [931][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.1018 (0.0645)	
0.99998415 4.5348537e-07
Epoch: [931][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0665 (0.0594)	
0.99999154 4.165709e-07
loss:  0.04320458698111429 0.03905957591933473
===========>   training    <===========
Epoch: [932][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0389 (0.0389)	
0.9999876 3.3384065e-08
===========>   testing    <===========
Epoch: [932][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.1135 (0.1135)	
0.99999213 4.7327663e-07
Epoch: [932][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.1484 (0.0643)	
0.99998736 7.1185985e-07
Epoch: [932][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0533 (0.0590)	
0.9999914 6.1504613e-07
loss:  0.04168745380786143 0.03905957591933473
===========>   training    <===========
Epoch: [933][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0431 (0.0431)	
0.99998844 7.3798975e-07
===========>   testing    <===========
Epoch: [933][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.1138 (0.1138)	
0.9999926 4.9401456e-07
Epoch: [933][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0274 (0.0635)	
0.9999862 5.262053e-07
Epoch: [933][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0708 (0.0592)	
0.9999908 4.9609184e-07
loss:  0.04156700711352479 0.03905957591933473
===========>   training    <===========
Epoch: [934][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0516 (0.0516)	
0.99998987 1.8295912e-06
===========>   testing    <===========
Epoch: [934][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0944 (0.0944)	
0.9999902 3.2108701e-07
Epoch: [934][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0362 (0.0611)	
0.9999821 4.4607856e-07
Epoch: [934][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0719 (0.0577)	
0.9999895 3.450087e-07
loss:  0.04125762708979075 0.03905957591933473
===========>   training    <===========
Epoch: [935][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0405 (0.0405)	
0.99999297 8.270014e-08
===========>   testing    <===========
Epoch: [935][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.1032 (0.1032)	
0.9999914 1.2500574e-07
Epoch: [935][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0222 (0.0628)	
0.99998176 1.8484042e-07
Epoch: [935][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0683 (0.0591)	
0.9999889 1.1434953e-07
loss:  0.04186783926085358 0.03905957591933473
===========>   training    <===========
Epoch: [936][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0435 (0.0435)	
0.9999933 3.655072e-07
===========>   testing    <===========
Epoch: [936][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.1117 (0.1117)	
0.99999297 2.3271903e-07
Epoch: [936][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0214 (0.0623)	
0.99998236 3.3947265e-07
Epoch: [936][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0631 (0.0582)	
0.9999889 4.0638935e-07
loss:  0.04170186205019166 0.03905957591933473
===========>   training    <===========
Epoch: [937][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0462 (0.0462)	
0.9999875 7.6212814e-08
===========>   testing    <===========
Epoch: [937][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0836 (0.0836)	
0.99999154 3.1158535e-07
Epoch: [937][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0370 (0.0623)	
0.9999831 5.6822284e-07
Epoch: [937][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0521 (0.0583)	
0.9999864 5.1286855e-07
loss:  0.04150536253494885 0.03905957591933473
===========>   training    <===========
Epoch: [938][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0462 (0.0462)	
0.9999845 7.0851954e-08
===========>   testing    <===========
Epoch: [938][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0627 (0.0627)	
0.99999213 4.1040875e-07
Epoch: [938][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0314 (0.0594)	
0.9999825 6.195834e-07
Epoch: [938][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0864 (0.0572)	
0.9999895 5.478697e-07
loss:  0.04005094626049688 0.03905957591933473
===========>   training    <===========
Epoch: [939][0/23]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0391 (0.0391)	
0.9999943 6.2314825e-07
===========>   testing    <===========
Epoch: [939][0/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0530 (0.0530)	
0.9999914 5.156631e-07
Epoch: [939][100/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.0266 (0.0621)	
0.9999858 8.049199e-07
Epoch: [939][200/289]	Lr-deconv: [0.0]	Lr-other: [9.446824413773763e-05]	Loss 0.1218 (0.0597)	
0.999992 6.032645e-07
loss:  0.041243836968206216 0.03905957591933473
===========>   training    <===========
Epoch: [940][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0440 (0.0440)	
0.99999607 1.5660673e-06
===========>   testing    <===========
Epoch: [940][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0665 (0.0665)	
0.99999344 2.7246952e-07
Epoch: [940][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0401 (0.0619)	
0.99998474 4.3389818e-07
Epoch: [940][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0825 (0.0580)	
0.9999914 3.7416316e-07
loss:  0.0417889297609626 0.03905957591933473
===========>   training    <===========
Epoch: [941][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0326 (0.0326)	
0.99999166 4.535161e-07
===========>   testing    <===========
Epoch: [941][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0819 (0.0819)	
0.9999931 3.0467416e-07
Epoch: [941][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1192 (0.0612)	
0.9999858 4.8280225e-07
Epoch: [941][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1053 (0.0580)	
0.99999213 3.9488464e-07
loss:  0.04056384998855389 0.03905957591933473
===========>   training    <===========
Epoch: [942][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0408 (0.0408)	
0.9999919 5.7992708e-08
===========>   testing    <===========
Epoch: [942][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1096 (0.1096)	
0.9999945 3.023317e-07
Epoch: [942][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0893 (0.0607)	
0.9999869 4.6301471e-07
Epoch: [942][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0609 (0.0566)	
0.9999914 3.9227038e-07
loss:  0.04042344548774934 0.03905957591933473
===========>   training    <===========
Epoch: [943][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0324 (0.0324)	
0.99999166 4.0934555e-07
===========>   testing    <===========
Epoch: [943][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0967 (0.0967)	
0.99999225 1.828658e-07
Epoch: [943][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0290 (0.0615)	
0.99997985 2.8938663e-07
Epoch: [943][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0848 (0.0569)	
0.99999046 1.6586017e-07
loss:  0.04012905536742861 0.03905957591933473
===========>   training    <===========
Epoch: [944][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0383 (0.0383)	
0.9999931 2.9428293e-07
===========>   testing    <===========
Epoch: [944][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1063 (0.1063)	
0.9999943 2.624638e-07
Epoch: [944][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0430 (0.0637)	
0.9999865 3.5540685e-07
Epoch: [944][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0389 (0.0577)	
0.9999908 3.0771747e-07
loss:  0.04118557177811211 0.03905957591933473
===========>   training    <===========
Epoch: [945][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0408 (0.0408)	
0.99998486 7.9837136e-08
===========>   testing    <===========
Epoch: [945][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1084 (0.1084)	
0.9999945 4.79263e-07
Epoch: [945][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0251 (0.0615)	
0.99998736 5.9010534e-07
Epoch: [945][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0655 (0.0574)	
0.9999933 5.5685894e-07
loss:  0.04002788304474958 0.03905957591933473
===========>   training    <===========
Epoch: [946][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0320 (0.0320)	
0.9999949 1.6204383e-07
===========>   testing    <===========
Epoch: [946][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1122 (0.1122)	
0.99999356 2.8760053e-07
Epoch: [946][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0380 (0.0595)	
0.9999832 4.6630632e-07
Epoch: [946][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0498 (0.0547)	
0.99998987 4.786884e-07
loss:  0.03969825645312142 0.03905957591933473
===========>   training    <===========
Epoch: [947][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0372 (0.0372)	
0.9999919 1.8283251e-07
===========>   testing    <===========
Epoch: [947][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0771 (0.0771)	
0.99999344 5.6105733e-07
Epoch: [947][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0643 (0.0620)	
0.9999871 6.840903e-07
Epoch: [947][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0740 (0.0571)	
0.99999 6.521227e-07
loss:  0.04064472235246419 0.03905957591933473
===========>   training    <===========
Epoch: [948][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0469 (0.0469)	
0.9999763 6.605288e-08
===========>   testing    <===========
Epoch: [948][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1258 (0.1258)	
0.999995 5.2864834e-07
Epoch: [948][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1058 (0.0617)	
0.9999895 6.05621e-07
Epoch: [948][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0604 (0.0556)	
0.99999297 6.801689e-07
loss:  0.04051836572500789 0.03905957591933473
===========>   training    <===========
Epoch: [949][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0313 (0.0313)	
0.9999912 7.4543685e-08
===========>   testing    <===========
Epoch: [949][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0963 (0.0963)	
0.99999297 3.5356913e-07
Epoch: [949][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0331 (0.0609)	
0.99998844 5.5236e-07
Epoch: [949][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0977 (0.0564)	
0.9999914 4.3658125e-07
loss:  0.04111943753401148 0.03905957591933473
===========>   training    <===========
Epoch: [950][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0355 (0.0355)	
0.99999213 6.2514562e-09
===========>   testing    <===========
Epoch: [950][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0994 (0.0994)	
0.99999213 3.4562024e-07
Epoch: [950][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1818 (0.0606)	
0.9999852 3.2512884e-07
Epoch: [950][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1008 (0.0556)	
0.9999888 4.0374783e-07
loss:  0.04001630871627815 0.03905957591933473
===========>   training    <===========
Epoch: [951][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0349 (0.0349)	
0.99998593 1.1194046e-07
===========>   testing    <===========
Epoch: [951][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1092 (0.1092)	
0.9999931 6.709049e-07
Epoch: [951][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0922 (0.0630)	
0.99998415 4.385458e-07
Epoch: [951][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0924 (0.0585)	
0.9999882 4.9598117e-07
loss:  0.04184815754493121 0.03905957591933473
===========>   training    <===========
Epoch: [952][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0405 (0.0405)	
0.9999912 9.577058e-08
===========>   testing    <===========
Epoch: [952][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1446 (0.1446)	
0.9999933 2.771327e-07
Epoch: [952][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0344 (0.0624)	
0.99997926 3.89634e-07
Epoch: [952][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0945 (0.0582)	
0.99998987 3.414728e-07
loss:  0.04056527908835228 0.03905957591933473
===========>   training    <===========
Epoch: [953][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0354 (0.0354)	
0.99998355 3.398027e-07
===========>   testing    <===========
Epoch: [953][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1253 (0.1253)	
0.9999924 2.9857586e-07
Epoch: [953][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1790 (0.0636)	
0.99998605 4.1865096e-07
Epoch: [953][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0875 (0.0584)	
0.9999901 4.674426e-07
loss:  0.04259784861905902 0.03905957591933473
===========>   training    <===========
Epoch: [954][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0308 (0.0308)	
0.99998593 7.7022537e-07
===========>   testing    <===========
Epoch: [954][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1054 (0.1054)	
0.99999344 4.1321994e-07
Epoch: [954][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0378 (0.0608)	
0.999985 5.47158e-07
Epoch: [954][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0776 (0.0560)	
0.9999893 6.078696e-07
loss:  0.03999014742740992 0.03905957591933473
===========>   training    <===========
Epoch: [955][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0437 (0.0437)	
0.99998474 5.805335e-07
===========>   testing    <===========
Epoch: [955][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1033 (0.1033)	
0.9999949 5.7050556e-07
Epoch: [955][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.2483 (0.0646)	
0.9999869 5.7555445e-07
Epoch: [955][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0708 (0.0576)	
0.9999912 9.508763e-07
loss:  0.04079753154925836 0.03905957591933473
===========>   training    <===========
Epoch: [956][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0365 (0.0365)	
0.9999883 4.1367485e-08
===========>   testing    <===========
Epoch: [956][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0951 (0.0951)	
0.99999154 3.2538037e-07
Epoch: [956][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0288 (0.0656)	
0.99998367 2.6737305e-07
Epoch: [956][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0740 (0.0591)	
0.99998736 3.3563097e-07
loss:  0.04164982386495997 0.03905957591933473
===========>   training    <===========
Epoch: [957][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0344 (0.0344)	
0.9999924 5.5686428e-08
===========>   testing    <===========
Epoch: [957][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0599 (0.0599)	
0.99998915 2.1947328e-07
Epoch: [957][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0385 (0.0644)	
0.9999862 3.2026438e-07
Epoch: [957][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0632 (0.0579)	
0.99998784 4.003648e-07
loss:  0.04171530077491803 0.03905957591933473
===========>   training    <===========
Epoch: [958][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0593 (0.0593)	
0.99998605 1.6797582e-08
===========>   testing    <===========
Epoch: [958][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1014 (0.1014)	
0.9999931 3.9682695e-07
Epoch: [958][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1284 (0.0645)	
0.9999858 4.719317e-07
Epoch: [958][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0976 (0.0591)	
0.999992 6.292617e-07
loss:  0.04156165031331449 0.03905957591933473
===========>   training    <===========
Epoch: [959][0/23]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0435 (0.0435)	
0.9999907 1.13684614e-07
===========>   testing    <===========
Epoch: [959][0/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1073 (0.1073)	
0.9999919 2.720507e-07
Epoch: [959][100/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.1252 (0.0647)	
0.9999857 2.812047e-07
Epoch: [959][200/289]	Lr-deconv: [0.0]	Lr-other: [8.974483193085076e-05]	Loss 0.0469 (0.0585)	
0.9999913 3.8283497e-07
loss:  0.04102939311744991 0.03905957591933473
===========>   training    <===========
Epoch: [960][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0371 (0.0371)	
0.9999887 1.07968965e-07
===========>   testing    <===========
Epoch: [960][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.1030 (0.1030)	
0.99998987 2.711695e-07
Epoch: [960][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.1278 (0.0638)	
0.9999839 4.9973676e-07
Epoch: [960][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0702 (0.0573)	
0.9999889 6.162104e-07
loss:  0.040379372678695624 0.03905957591933473
===========>   training    <===========
Epoch: [961][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0375 (0.0375)	
0.99998 2.5670752e-07
===========>   testing    <===========
Epoch: [961][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0653 (0.0653)	
0.9999894 2.626972e-07
Epoch: [961][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0432 (0.0615)	
0.9999802 4.4261728e-07
Epoch: [961][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0675 (0.0565)	
0.99998856 3.2732746e-07
loss:  0.04000059738176198 0.03905957591933473
===========>   training    <===========
Epoch: [962][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0338 (0.0338)	
0.99998844 1.1806164e-07
===========>   testing    <===========
Epoch: [962][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0840 (0.0840)	
0.9999914 3.106371e-07
Epoch: [962][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0236 (0.0611)	
0.99998736 4.294226e-07
Epoch: [962][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.1021 (0.0574)	
0.99999046 2.814129e-07
loss:  0.040323977704773806 0.03905957591933473
===========>   training    <===========
Epoch: [963][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0326 (0.0326)	
0.9999914 5.409918e-07
===========>   testing    <===========
Epoch: [963][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.1006 (0.1006)	
0.9999919 2.3960447e-07
Epoch: [963][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0464 (0.0625)	
0.9999881 3.0572605e-07
Epoch: [963][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0856 (0.0578)	
0.99999034 3.5827017e-07
loss:  0.03985525549911684 0.03905957591933473
===========>   training    <===========
Epoch: [964][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0389 (0.0389)	
0.9999933 2.1310254e-07
===========>   testing    <===========
Epoch: [964][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.1137 (0.1137)	
0.99999285 6.298327e-07
Epoch: [964][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0206 (0.0618)	
0.9999887 6.3055023e-07
Epoch: [964][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0576 (0.0574)	
0.99999166 7.9243773e-07
loss:  0.03968056382581531 0.03905957591933473
===========>   training    <===========
Epoch: [965][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0438 (0.0438)	
0.99998856 5.1714743e-08
===========>   testing    <===========
Epoch: [965][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.1097 (0.1097)	
0.99999225 4.617642e-07
Epoch: [965][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0193 (0.0631)	
0.9999858 4.5591986e-07
Epoch: [965][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0463 (0.0569)	
0.99998987 8.417905e-07
loss:  0.0397171574430113 0.03905957591933473
===========>   training    <===========
Epoch: [966][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0390 (0.0390)	
0.9999839 2.8843857e-07
===========>   testing    <===========
Epoch: [966][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.1184 (0.1184)	
0.99999046 4.0268108e-07
Epoch: [966][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0310 (0.0638)	
0.9999838 3.5312772e-07
Epoch: [966][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0797 (0.0584)	
0.9999887 5.124921e-07
loss:  0.040389568926197494 0.03905957591933473
===========>   training    <===========
Epoch: [967][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0381 (0.0381)	
0.9999901 4.156978e-07
===========>   testing    <===========
Epoch: [967][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0945 (0.0945)	
0.9999925 2.1670151e-07
Epoch: [967][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0231 (0.0634)	
0.9999865 2.2177699e-07
Epoch: [967][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0832 (0.0582)	
0.9999895 3.1740313e-07
loss:  0.03968554006685221 0.03905957591933473
===========>   training    <===========
Epoch: [968][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0497 (0.0497)	
0.9999759 8.839219e-09
===========>   testing    <===========
Epoch: [968][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.1238 (0.1238)	
0.9999938 2.6897408e-07
Epoch: [968][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0278 (0.0644)	
0.99998355 3.8395453e-07
Epoch: [968][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0615 (0.0573)	
0.9999924 4.5116462e-07
loss:  0.04100035348689968 0.03905957591933473
===========>   training    <===========
Epoch: [969][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0366 (0.0366)	
0.9999912 1.6406283e-07
===========>   testing    <===========
Epoch: [969][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.1074 (0.1074)	
0.99999285 3.398847e-07
Epoch: [969][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0222 (0.0625)	
0.999984 3.7880156e-07
Epoch: [969][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0831 (0.0568)	
0.9999918 2.959206e-07
loss:  0.0398705943855544 0.03905957591933473
===========>   training    <===========
Epoch: [970][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0416 (0.0416)	
0.9999931 6.427734e-08
===========>   testing    <===========
Epoch: [970][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0760 (0.0760)	
0.9999937 4.8715395e-07
Epoch: [970][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0392 (0.0605)	
0.99998534 6.638542e-07
Epoch: [970][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0868 (0.0552)	
0.9999925 4.9489444e-07
loss:  0.03946149980536717 0.03905957591933473
===========>   training    <===========
Epoch: [971][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0352 (0.0352)	
0.9999918 1.3841871e-08
===========>   testing    <===========
Epoch: [971][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0741 (0.0741)	
0.9999931 5.0371676e-07
Epoch: [971][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0288 (0.0592)	
0.9999839 6.9442723e-07
Epoch: [971][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0927 (0.0546)	
0.9999913 3.6325295e-07
loss:  0.039377826010985606 0.03905957591933473
===========>   training    <===========
Epoch: [972][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0433 (0.0433)	
0.99999475 4.94072e-07
===========>   testing    <===========
Epoch: [972][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0953 (0.0953)	
0.99999225 2.7660937e-07
Epoch: [972][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0264 (0.0595)	
0.9999815 4.3673282e-07
Epoch: [972][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0756 (0.0545)	
0.9999912 2.2200743e-07
loss:  0.03897757529122903 0.03905957591933473
===========>   training    <===========
Epoch: [973][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0398 (0.0398)	
0.99998546 6.3088685e-09
===========>   testing    <===========
Epoch: [973][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0985 (0.0985)	
0.9999924 4.6608582e-07
Epoch: [973][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0245 (0.0616)	
0.99998105 5.3334264e-07
Epoch: [973][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0874 (0.0554)	
0.99999154 6.848044e-07
loss:  0.03953063413300062 0.03897757529122903
===========>   training    <===========
Epoch: [974][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0322 (0.0322)	
0.99998975 2.4117618e-08
===========>   testing    <===========
Epoch: [974][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0906 (0.0906)	
0.99999213 6.671444e-07
Epoch: [974][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0261 (0.0622)	
0.99998367 7.114499e-07
Epoch: [974][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0935 (0.0571)	
0.99998975 6.75849e-07
loss:  0.03999360446666145 0.03897757529122903
===========>   training    <===========
Epoch: [975][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0420 (0.0420)	
0.99998915 3.3578016e-07
===========>   testing    <===========
Epoch: [975][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0946 (0.0946)	
0.9999912 5.6160764e-07
Epoch: [975][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0386 (0.0612)	
0.9999789 5.749894e-07
Epoch: [975][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0721 (0.0560)	
0.9999894 7.211273e-07
loss:  0.03980189657641908 0.03897757529122903
===========>   training    <===========
Epoch: [976][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0361 (0.0361)	
0.9999945 3.8328213e-07
===========>   testing    <===========
Epoch: [976][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0927 (0.0927)	
0.99999154 9.736169e-07
Epoch: [976][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0525 (0.0618)	
0.9999715 1.0359136e-06
Epoch: [976][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0670 (0.0566)	
0.9999882 1.0232962e-06
loss:  0.0402547768375523 0.03897757529122903
===========>   training    <===========
Epoch: [977][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0407 (0.0407)	
0.99999356 1.1770487e-06
===========>   testing    <===========
Epoch: [977][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.1298 (0.1298)	
0.99999154 2.884801e-07
Epoch: [977][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.1211 (0.0631)	
0.99997807 2.8357894e-07
Epoch: [977][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0737 (0.0574)	
0.99999046 3.5951328e-07
loss:  0.04007874395202504 0.03897757529122903
===========>   training    <===========
Epoch: [978][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0338 (0.0338)	
0.999984 3.5174403e-09
===========>   testing    <===========
Epoch: [978][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.1316 (0.1316)	
0.9999896 2.8499633e-07
Epoch: [978][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.2510 (0.0646)	
0.9999771 2.8444293e-07
Epoch: [978][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0681 (0.0589)	
0.9999918 4.179919e-07
loss:  0.040255484855256984 0.03897757529122903
===========>   training    <===========
Epoch: [979][0/23]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0472 (0.0472)	
0.99998343 3.6379756e-08
===========>   testing    <===========
Epoch: [979][0/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.1135 (0.1135)	
0.9999893 1.3666349e-07
Epoch: [979][100/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.1501 (0.0640)	
0.99997234 2.7583437e-07
Epoch: [979][200/289]	Lr-deconv: [0.0]	Lr-other: [8.52575903343082e-05]	Loss 0.0844 (0.0581)	
0.99999046 1.214969e-07
loss:  0.04149480121747651 0.03897757529122903
===========>   training    <===========
Epoch: [980][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0410 (0.0410)	
0.99998987 4.5685475e-08
===========>   testing    <===========
Epoch: [980][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1239 (0.1239)	
0.99999166 4.288292e-07
Epoch: [980][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1625 (0.0654)	
0.99997425 4.0548036e-07
Epoch: [980][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0746 (0.0586)	
0.9999894 3.2954318e-07
loss:  0.041928137054285775 0.03897757529122903
===========>   training    <===========
Epoch: [981][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0358 (0.0358)	
0.9999832 1.0567265e-07
===========>   testing    <===========
Epoch: [981][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1296 (0.1296)	
0.9999912 2.9990716e-07
Epoch: [981][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1207 (0.0631)	
0.99997747 2.8599612e-07
Epoch: [981][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0888 (0.0576)	
0.9999889 3.8266853e-07
loss:  0.041579702172027666 0.03897757529122903
===========>   training    <===========
Epoch: [982][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0438 (0.0438)	
0.99997926 1.210226e-08
===========>   testing    <===========
Epoch: [982][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1384 (0.1384)	
0.99999034 3.8762337e-07
Epoch: [982][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0451 (0.0616)	
0.9999794 3.470342e-07
Epoch: [982][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0750 (0.0559)	
0.99999 5.0584936e-07
loss:  0.040090396772039294 0.03897757529122903
===========>   training    <===========
Epoch: [983][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0399 (0.0399)	
0.9999893 6.230912e-08
===========>   testing    <===========
Epoch: [983][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1501 (0.1501)	
0.9999883 3.139938e-07
Epoch: [983][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0504 (0.0625)	
0.9999777 3.0296724e-07
Epoch: [983][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0979 (0.0586)	
0.99998796 3.232654e-07
loss:  0.042460176829090535 0.03897757529122903
===========>   training    <===========
Epoch: [984][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0359 (0.0359)	
0.9999808 2.2239946e-07
===========>   testing    <===========
Epoch: [984][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1550 (0.1550)	
0.9999931 4.0091498e-07
Epoch: [984][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0536 (0.0640)	
0.9999832 3.9959542e-07
Epoch: [984][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0725 (0.0576)	
0.99999046 6.124765e-07
loss:  0.041976984149460606 0.03897757529122903
===========>   training    <===========
Epoch: [985][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0455 (0.0455)	
0.99999344 1.4509428e-07
===========>   testing    <===========
Epoch: [985][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1190 (0.1190)	
0.9999938 4.1358265e-07
Epoch: [985][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0435 (0.0627)	
0.99998593 4.2109994e-07
Epoch: [985][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0988 (0.0579)	
0.99999 6.298958e-07
loss:  0.04137683444171625 0.03897757529122903
===========>   training    <===========
Epoch: [986][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0330 (0.0330)	
0.999995 3.1009367e-07
===========>   testing    <===========
Epoch: [986][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1090 (0.1090)	
0.9999913 3.165229e-07
Epoch: [986][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0471 (0.0639)	
0.9999877 3.1196177e-07
Epoch: [986][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1177 (0.0587)	
0.99999106 4.9345607e-07
loss:  0.04261192597955443 0.03897757529122903
===========>   training    <===========
Epoch: [987][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0390 (0.0390)	
0.99999297 7.0927676e-08
===========>   testing    <===========
Epoch: [987][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0984 (0.0984)	
0.99999154 2.5871375e-07
Epoch: [987][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0799 (0.0614)	
0.9999864 3.385861e-07
Epoch: [987][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1030 (0.0567)	
0.9999908 1.661678e-07
loss:  0.04111204111713318 0.03897757529122903
===========>   training    <===========
Epoch: [988][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0460 (0.0460)	
0.99999404 2.427486e-07
===========>   testing    <===========
Epoch: [988][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0948 (0.0948)	
0.9999926 2.1554051e-07
Epoch: [988][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0425 (0.0608)	
0.9999783 2.8909042e-07
Epoch: [988][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0952 (0.0561)	
0.9999914 1.4191035e-07
loss:  0.04104313833869733 0.03897757529122903
===========>   training    <===========
Epoch: [989][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0315 (0.0315)	
0.99998903 2.2607199e-07
===========>   testing    <===========
Epoch: [989][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0974 (0.0974)	
0.9999933 2.9502536e-07
Epoch: [989][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0616 (0.0614)	
0.9999839 3.9745643e-07
Epoch: [989][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1106 (0.0572)	
0.9999914 3.9440138e-07
loss:  0.0407406487441937 0.03897757529122903
===========>   training    <===========
Epoch: [990][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0340 (0.0340)	
0.99998677 5.8619925e-08
===========>   testing    <===========
Epoch: [990][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0725 (0.0725)	
0.9999927 3.24405e-07
Epoch: [990][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0871 (0.0626)	
0.9999858 3.6216716e-07
Epoch: [990][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1223 (0.0588)	
0.99999034 5.984991e-07
loss:  0.04152696273270762 0.03897757529122903
===========>   training    <===========
Epoch: [991][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0394 (0.0394)	
0.9999906 4.7826217e-07
===========>   testing    <===========
Epoch: [991][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0920 (0.0920)	
0.9999907 2.2303242e-07
Epoch: [991][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1095 (0.0643)	
0.9999788 2.2701094e-07
Epoch: [991][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1085 (0.0612)	
0.9999912 2.2924702e-07
loss:  0.04367260439332643 0.03897757529122903
===========>   training    <===========
Epoch: [992][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0395 (0.0395)	
0.9999865 2.3413435e-08
===========>   testing    <===========
Epoch: [992][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0872 (0.0872)	
0.9999931 3.5271373e-07
Epoch: [992][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1225 (0.0635)	
0.9999857 3.6315356e-07
Epoch: [992][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1302 (0.0586)	
0.9999927 6.442715e-07
loss:  0.04190465123817233 0.03897757529122903
===========>   training    <===========
Epoch: [993][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0391 (0.0391)	
0.999992 8.373195e-09
===========>   testing    <===========
Epoch: [993][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0804 (0.0804)	
0.99998784 2.8570824e-07
Epoch: [993][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0817 (0.0642)	
0.99997914 3.4993417e-07
Epoch: [993][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1295 (0.0581)	
0.99999166 2.553553e-07
loss:  0.04134536364407959 0.03897757529122903
===========>   training    <===========
Epoch: [994][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0435 (0.0435)	
0.99998546 5.3332126e-08
===========>   testing    <===========
Epoch: [994][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1140 (0.1140)	
0.9999927 3.351429e-07
Epoch: [994][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.2245 (0.0664)	
0.99998665 3.3644625e-07
Epoch: [994][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0774 (0.0583)	
0.99999213 5.2097835e-07
loss:  0.041753287904196856 0.03897757529122903
===========>   training    <===========
Epoch: [995][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0366 (0.0366)	
0.9999802 5.370122e-07
===========>   testing    <===========
Epoch: [995][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1022 (0.1022)	
0.9999918 2.953477e-07
Epoch: [995][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1349 (0.0631)	
0.9999844 3.2246484e-07
Epoch: [995][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0878 (0.0571)	
0.9999888 5.528596e-07
loss:  0.04137673537843489 0.03897757529122903
===========>   training    <===========
Epoch: [996][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0363 (0.0363)	
0.9999895 3.9751063e-07
===========>   testing    <===========
Epoch: [996][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1205 (0.1205)	
0.99999154 1.0646367e-07
Epoch: [996][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0884 (0.0641)	
0.99998355 1.3708903e-07
Epoch: [996][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0878 (0.0579)	
0.9999893 1.2536235e-07
loss:  0.04111023279940673 0.03897757529122903
===========>   training    <===========
Epoch: [997][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0358 (0.0358)	
0.99999166 3.6105874e-08
===========>   testing    <===========
Epoch: [997][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0966 (0.0966)	
0.99999106 3.1185766e-07
Epoch: [997][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1948 (0.0648)	
0.99998593 2.9009263e-07
Epoch: [997][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1116 (0.0590)	
0.999992 4.435638e-07
loss:  0.0422250928059098 0.03897757529122903
===========>   training    <===========
Epoch: [998][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0405 (0.0405)	
0.9999839 3.5479722e-08
===========>   testing    <===========
Epoch: [998][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1250 (0.1250)	
0.9999912 4.3120696e-07
Epoch: [998][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.3725 (0.0670)	
0.9999871 2.8881456e-07
Epoch: [998][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0794 (0.0595)	
0.99998987 7.048458e-07
loss:  0.04204190102939187 0.03897757529122903
===========>   training    <===========
Epoch: [999][0/23]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0449 (0.0449)	
0.9999877 3.3777717e-08
===========>   testing    <===========
Epoch: [999][0/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.0937 (0.0937)	
0.9999939 2.792586e-07
Epoch: [999][100/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.2285 (0.0649)	
0.9999888 2.9180407e-07
Epoch: [999][200/289]	Lr-deconv: [0.0]	Lr-other: [8.099471081759279e-05]	Loss 0.1074 (0.0592)	
0.99999154 4.856923e-07
loss:  0.041840253238635605 0.03897757529122903
===========>   training    <===========
Epoch: [1000][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0388 (0.0388)	
0.9999831 2.7555515e-07
===========>   testing    <===========
Epoch: [1000][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0920 (0.0920)	
0.9999914 2.5341959e-07
Epoch: [1000][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1315 (0.0633)	
0.9999856 2.589942e-07
Epoch: [1000][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1006 (0.0585)	
0.99999106 4.1609007e-07
loss:  0.04127900574520538 0.03897757529122903
===========>   training    <===========
Epoch: [1001][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0358 (0.0358)	
0.9999882 2.9127543e-08
===========>   testing    <===========
Epoch: [1001][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1019 (0.1019)	
0.99999285 2.7430474e-07
Epoch: [1001][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.2110 (0.0631)	
0.99998736 3.2388814e-07
Epoch: [1001][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0869 (0.0575)	
0.9999914 4.3870477e-07
loss:  0.03985100204201619 0.03897757529122903
===========>   training    <===========
Epoch: [1002][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0373 (0.0373)	
0.9999856 2.7064425e-07
===========>   testing    <===========
Epoch: [1002][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1098 (0.1098)	
0.99999285 3.8780752e-07
Epoch: [1002][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1488 (0.0636)	
0.99998724 5.382017e-07
Epoch: [1002][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1065 (0.0579)	
0.9999913 6.669319e-07
loss:  0.04109481851974395 0.03897757529122903
===========>   training    <===========
Epoch: [1003][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0381 (0.0381)	
0.9999932 5.874528e-07
===========>   testing    <===========
Epoch: [1003][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1107 (0.1107)	
0.99999356 4.052739e-07
Epoch: [1003][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.3050 (0.0666)	
0.99998605 4.3873786e-07
Epoch: [1003][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1020 (0.0598)	
0.9999925 6.2047087e-07
loss:  0.041920595978979236 0.03897757529122903
===========>   training    <===========
Epoch: [1004][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0410 (0.0410)	
0.9999944 3.435732e-07
===========>   testing    <===========
Epoch: [1004][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1277 (0.1277)	
0.99999464 3.074183e-07
Epoch: [1004][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1365 (0.0657)	
0.99998176 3.3604283e-07
Epoch: [1004][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0890 (0.0588)	
0.99999285 4.456117e-07
loss:  0.042182773357939185 0.03897757529122903
===========>   training    <===========
Epoch: [1005][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0396 (0.0396)	
0.99999034 1.1696316e-07
===========>   testing    <===========
Epoch: [1005][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1051 (0.1051)	
0.99999285 4.55292e-07
Epoch: [1005][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1285 (0.0627)	
0.9999864 3.8205445e-07
Epoch: [1005][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0749 (0.0572)	
0.99999 4.5845218e-07
loss:  0.0406742686860363 0.03897757529122903
===========>   training    <===========
Epoch: [1006][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0414 (0.0414)	
0.99998534 3.3179444e-07
===========>   testing    <===========
Epoch: [1006][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1272 (0.1272)	
0.99999356 2.8188077e-07
Epoch: [1006][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0724 (0.0632)	
0.9999857 1.9986359e-07
Epoch: [1006][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0697 (0.0577)	
0.9999908 4.1573588e-07
loss:  0.040578333184122184 0.03897757529122903
===========>   training    <===========
Epoch: [1007][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0327 (0.0327)	
0.99998915 2.732155e-07
===========>   testing    <===========
Epoch: [1007][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1279 (0.1279)	
0.9999912 3.6076173e-07
Epoch: [1007][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0589 (0.0629)	
0.99998283 2.6784164e-07
Epoch: [1007][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0660 (0.0576)	
0.9999901 3.2238583e-07
loss:  0.04090219719171573 0.03897757529122903
===========>   training    <===========
Epoch: [1008][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0414 (0.0414)	
0.9999889 4.4951372e-07
===========>   testing    <===========
Epoch: [1008][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1057 (0.1057)	
0.99999416 5.7843897e-07
Epoch: [1008][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1191 (0.0624)	
0.99998784 4.0832126e-07
Epoch: [1008][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0868 (0.0576)	
0.9999919 4.513243e-07
loss:  0.04031926699649624 0.03897757529122903
===========>   training    <===========
Epoch: [1009][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0466 (0.0466)	
0.9999846 1.4867426e-07
===========>   testing    <===========
Epoch: [1009][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1135 (0.1135)	
0.9999925 3.2286795e-07
Epoch: [1009][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1007 (0.0619)	
0.9999846 2.771446e-07
Epoch: [1009][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0931 (0.0568)	
0.9999906 2.4565338e-07
loss:  0.040152094236777236 0.03897757529122903
===========>   training    <===========
Epoch: [1010][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0422 (0.0422)	
0.9999894 2.2124695e-07
===========>   testing    <===========
Epoch: [1010][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1007 (0.1007)	
0.99999225 4.968911e-07
Epoch: [1010][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0532 (0.0614)	
0.99998546 4.7521328e-07
Epoch: [1010][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0958 (0.0562)	
0.99999154 6.614944e-07
loss:  0.04120905590972379 0.03897757529122903
===========>   training    <===========
Epoch: [1011][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0319 (0.0319)	
0.9999895 1.9771208e-07
===========>   testing    <===========
Epoch: [1011][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0942 (0.0942)	
0.9999918 3.6398083e-07
Epoch: [1011][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0310 (0.0608)	
0.9999846 4.2511076e-07
Epoch: [1011][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0894 (0.0557)	
0.9999907 3.9207512e-07
loss:  0.039725796165329896 0.03897757529122903
===========>   training    <===========
Epoch: [1012][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0480 (0.0480)	
0.999995 2.572219e-07
===========>   testing    <===========
Epoch: [1012][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0872 (0.0872)	
0.99999464 3.8095712e-07
Epoch: [1012][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1585 (0.0611)	
0.9999902 4.109022e-07
Epoch: [1012][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0907 (0.0567)	
0.99999297 5.9309787e-07
loss:  0.039820645914865116 0.03897757529122903
===========>   training    <===========
Epoch: [1013][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0294 (0.0294)	
0.9999927 6.128166e-07
===========>   testing    <===========
Epoch: [1013][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.1091 (0.1091)	
0.99999106 3.8901877e-07
Epoch: [1013][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0437 (0.0618)	
0.9999887 3.4786453e-07
Epoch: [1013][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0840 (0.0560)	
0.99999094 3.889368e-07
loss:  0.04015581532746637 0.03897757529122903
===========>   training    <===========
Epoch: [1014][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0362 (0.0362)	
0.9999938 1.9004538e-07
===========>   testing    <===========
Epoch: [1014][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0766 (0.0766)	
0.99999225 3.7646714e-07
Epoch: [1014][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0295 (0.0619)	
0.99998593 2.9613966e-07
Epoch: [1014][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0835 (0.0568)	
0.9999908 6.1849295e-07
loss:  0.04052674952488389 0.03897757529122903
===========>   training    <===========
Epoch: [1015][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0344 (0.0344)	
0.99999416 3.924455e-07
===========>   testing    <===========
Epoch: [1015][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0742 (0.0742)	
0.9999945 2.2630994e-07
Epoch: [1015][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0423 (0.0624)	
0.99998987 2.6335263e-07
Epoch: [1015][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0864 (0.0572)	
0.99999213 4.1136096e-07
loss:  0.0410214505569223 0.03897757529122903
===========>   training    <===========
Epoch: [1016][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0391 (0.0391)	
0.99999416 4.172106e-07
===========>   testing    <===========
Epoch: [1016][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0863 (0.0863)	
0.9999956 3.5346326e-07
Epoch: [1016][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0838 (0.0607)	
0.9999906 3.9114147e-07
Epoch: [1016][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0944 (0.0561)	
0.999992 7.2505316e-07
loss:  0.040710233915356 0.03897757529122903
===========>   training    <===========
Epoch: [1017][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0423 (0.0423)	
0.99999225 9.8461115e-08
===========>   testing    <===========
Epoch: [1017][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0731 (0.0731)	
0.9999944 2.4112794e-07
Epoch: [1017][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0483 (0.0622)	
0.9999893 2.6877944e-07
Epoch: [1017][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0909 (0.0569)	
0.9999913 3.9743787e-07
loss:  0.04089736807810107 0.03897757529122903
===========>   training    <===========
Epoch: [1018][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0415 (0.0415)	
0.99999285 2.634403e-07
===========>   testing    <===========
Epoch: [1018][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0984 (0.0984)	
0.9999943 2.5099226e-07
Epoch: [1018][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0238 (0.0611)	
0.9999889 2.6540877e-07
Epoch: [1018][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0977 (0.0572)	
0.9999913 2.7928388e-07
loss:  0.04034453744922406 0.03897757529122903
===========>   training    <===========
Epoch: [1019][0/23]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0398 (0.0398)	
0.99998903 2.3887574e-07
===========>   testing    <===========
Epoch: [1019][0/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0798 (0.0798)	
0.99999404 2.2991611e-07
Epoch: [1019][100/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0250 (0.0610)	
0.9999877 2.2924658e-07
Epoch: [1019][200/289]	Lr-deconv: [0.0]	Lr-other: [7.694497527671315e-05]	Loss 0.0921 (0.0574)	
0.9999907 3.6140224e-07
loss:  0.04081331641921859 0.03897757529122903
===========>   training    <===========
Epoch: [1020][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0366 (0.0366)	
0.9999938 1.850175e-07
===========>   testing    <===========
Epoch: [1020][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0734 (0.0734)	
0.999995 2.960513e-07
Epoch: [1020][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0442 (0.0620)	
0.9999882 3.063366e-07
Epoch: [1020][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0856 (0.0575)	
0.9999914 4.554735e-07
loss:  0.04040194357580895 0.03897757529122903
===========>   training    <===========
Epoch: [1021][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0324 (0.0324)	
0.9999938 1.0903704e-07
===========>   testing    <===========
Epoch: [1021][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0921 (0.0921)	
0.9999932 2.296479e-07
Epoch: [1021][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0556 (0.0642)	
0.9999858 2.400569e-07
Epoch: [1021][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0833 (0.0590)	
0.9999895 3.5205974e-07
loss:  0.042037300784459 0.03897757529122903
===========>   training    <===========
Epoch: [1022][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0324 (0.0324)	
0.9999844 2.5908116e-07
===========>   testing    <===========
Epoch: [1022][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0933 (0.0933)	
0.99999416 3.44503e-07
Epoch: [1022][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0297 (0.0634)	
0.9999887 3.5521035e-07
Epoch: [1022][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0849 (0.0581)	
0.9999912 5.320624e-07
loss:  0.04070595729111415 0.03897757529122903
===========>   training    <===========
Epoch: [1023][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0388 (0.0388)	
0.9999927 2.4439387e-07
===========>   testing    <===========
Epoch: [1023][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0918 (0.0918)	
0.9999931 2.9996377e-07
Epoch: [1023][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0235 (0.0624)	
0.9999869 2.9495135e-07
Epoch: [1023][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0765 (0.0577)	
0.99998987 4.80803e-07
loss:  0.0414508624883303 0.03897757529122903
===========>   training    <===========
Epoch: [1024][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0394 (0.0394)	
0.99999034 5.947018e-07
===========>   testing    <===========
Epoch: [1024][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.1002 (0.1002)	
0.9999931 4.0188195e-07
Epoch: [1024][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0648 (0.0643)	
0.9999881 3.8721845e-07
Epoch: [1024][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0793 (0.0575)	
0.9999887 5.8004207e-07
loss:  0.041040984390684154 0.03897757529122903
===========>   training    <===========
Epoch: [1025][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0337 (0.0337)	
0.9999881 8.014485e-07
===========>   testing    <===========
Epoch: [1025][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0935 (0.0935)	
0.99999344 2.533389e-07
Epoch: [1025][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0638 (0.0646)	
0.99998736 2.7430264e-07
Epoch: [1025][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0577 (0.0576)	
0.9999902 3.4889382e-07
loss:  0.040772551892875986 0.03897757529122903
===========>   training    <===========
Epoch: [1026][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0349 (0.0349)	
0.99998987 5.5564414e-07
===========>   testing    <===========
Epoch: [1026][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0691 (0.0691)	
0.9999939 2.9769478e-07
Epoch: [1026][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0261 (0.0638)	
0.99998534 3.4739247e-07
Epoch: [1026][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0913 (0.0584)	
0.9999902 4.905704e-07
loss:  0.040855213388143574 0.03897757529122903
===========>   training    <===========
Epoch: [1027][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0422 (0.0422)	
0.9999914 9.374156e-08
===========>   testing    <===========
Epoch: [1027][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.1255 (0.1255)	
0.9999939 3.5908943e-07
Epoch: [1027][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0227 (0.0633)	
0.9999852 3.9106163e-07
Epoch: [1027][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0893 (0.0579)	
0.99999225 4.968726e-07
loss:  0.04080241189263645 0.03897757529122903
===========>   training    <===========
Epoch: [1028][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0387 (0.0387)	
0.9999932 2.8909315e-07
===========>   testing    <===========
Epoch: [1028][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.1064 (0.1064)	
0.9999924 4.1349588e-07
Epoch: [1028][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0260 (0.0615)	
0.99998236 4.7077106e-07
Epoch: [1028][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0840 (0.0564)	
0.99999106 5.2476105e-07
loss:  0.03943901986293086 0.03897757529122903
===========>   training    <===========
Epoch: [1029][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0377 (0.0377)	
0.99998724 3.3293395e-07
===========>   testing    <===========
Epoch: [1029][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0969 (0.0969)	
0.9999924 2.3087587e-07
Epoch: [1029][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0246 (0.0619)	
0.99998236 2.5366793e-07
Epoch: [1029][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0819 (0.0568)	
0.99998975 3.2874715e-07
loss:  0.03974934758319315 0.03897757529122903
===========>   training    <===========
Epoch: [1030][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0437 (0.0437)	
0.99999416 1.2850938e-07
===========>   testing    <===========
Epoch: [1030][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0889 (0.0889)	
0.9999937 3.0855205e-07
Epoch: [1030][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0371 (0.0630)	
0.9999869 3.1660076e-07
Epoch: [1030][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0754 (0.0578)	
0.99999106 3.9022862e-07
loss:  0.040633777681881256 0.03897757529122903
===========>   training    <===========
Epoch: [1031][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0344 (0.0344)	
0.99998593 2.5618903e-07
===========>   testing    <===========
Epoch: [1031][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0860 (0.0860)	
0.99999464 3.8567939e-07
Epoch: [1031][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0251 (0.0621)	
0.9999864 3.6595432e-07
Epoch: [1031][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.1091 (0.0571)	
0.99999154 4.650402e-07
loss:  0.04041065006877853 0.03897757529122903
===========>   training    <===========
Epoch: [1032][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0359 (0.0359)	
0.9999919 6.1500214e-07
===========>   testing    <===========
Epoch: [1032][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.1218 (0.1218)	
0.9999957 2.9794245e-07
Epoch: [1032][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0784 (0.0627)	
0.99998724 2.9093627e-07
Epoch: [1032][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0975 (0.0576)	
0.9999932 3.6007256e-07
loss:  0.04099206237906117 0.03897757529122903
===========>   training    <===========
Epoch: [1033][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0409 (0.0409)	
0.99999046 9.6942195e-08
===========>   testing    <===========
Epoch: [1033][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0790 (0.0790)	
0.9999951 3.40394e-07
Epoch: [1033][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0256 (0.0626)	
0.9999844 3.1022086e-07
Epoch: [1033][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.1012 (0.0582)	
0.99999285 3.983136e-07
loss:  0.04014869453746672 0.03897757529122903
===========>   training    <===========
Epoch: [1034][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0340 (0.0340)	
0.99999106 1.4495997e-07
===========>   testing    <===========
Epoch: [1034][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0895 (0.0895)	
0.9999944 2.659104e-07
Epoch: [1034][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0573 (0.0630)	
0.9999826 2.5941392e-07
Epoch: [1034][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0993 (0.0573)	
0.9999924 3.5500918e-07
loss:  0.04162115431446223 0.03897757529122903
===========>   training    <===========
Epoch: [1035][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0621 (0.0621)	
0.9999933 3.0213312e-07
===========>   testing    <===========
Epoch: [1035][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0686 (0.0686)	
0.9999951 1.4384959e-07
Epoch: [1035][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.1243 (0.0632)	
0.9999846 1.8874366e-07
Epoch: [1035][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.1054 (0.0576)	
0.9999912 2.042558e-07
loss:  0.04115300843862579 0.03897757529122903
===========>   training    <===========
Epoch: [1036][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0463 (0.0463)	
0.9999871 4.544786e-07
===========>   testing    <===========
Epoch: [1036][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0828 (0.0828)	
0.999995 3.6838864e-07
Epoch: [1036][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0503 (0.0609)	
0.99998295 2.4432606e-07
Epoch: [1036][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0993 (0.0558)	
0.9999919 3.6711344e-07
loss:  0.039668149101773964 0.03897757529122903
===========>   training    <===========
Epoch: [1037][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0363 (0.0363)	
0.9999881 7.818998e-08
===========>   testing    <===========
Epoch: [1037][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0872 (0.0872)	
0.9999945 3.8759828e-07
Epoch: [1037][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0643 (0.0621)	
0.9999819 3.3797767e-07
Epoch: [1037][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0988 (0.0572)	
0.99998796 5.2784986e-07
loss:  0.040500607762861796 0.03897757529122903
===========>   training    <===========
Epoch: [1038][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0381 (0.0381)	
0.99998057 2.961679e-07
===========>   testing    <===========
Epoch: [1038][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0941 (0.0941)	
0.999995 3.112456e-07
Epoch: [1038][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0922 (0.0612)	
0.9999863 3.3440983e-07
Epoch: [1038][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0936 (0.0572)	
0.99999034 3.895519e-07
loss:  0.04071830217660899 0.03897757529122903
===========>   training    <===========
Epoch: [1039][0/23]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0427 (0.0427)	
0.9999895 1.242691e-08
===========>   testing    <===========
Epoch: [1039][0/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0639 (0.0639)	
0.9999949 3.176193e-07
Epoch: [1039][100/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0274 (0.0628)	
0.99998295 2.4151873e-07
Epoch: [1039][200/289]	Lr-deconv: [0.0]	Lr-other: [7.30977265128775e-05]	Loss 0.0866 (0.0575)	
0.99998844 4.0334524e-07
loss:  0.04006636174179801 0.03897757529122903
===========>   training    <===========
Epoch: [1040][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0420 (0.0420)	
0.9999907 1.15404426e-07
===========>   testing    <===========
Epoch: [1040][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.1082 (0.1082)	
0.99999475 3.449248e-07
Epoch: [1040][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.1705 (0.0633)	
0.99998593 2.3482673e-07
Epoch: [1040][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0664 (0.0573)	
0.99998796 4.3308458e-07
loss:  0.041693432189164104 0.03897757529122903
===========>   training    <===========
Epoch: [1041][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0311 (0.0311)	
0.9999814 1.3997456e-07
===========>   testing    <===========
Epoch: [1041][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0849 (0.0849)	
0.9999958 1.9315401e-07
Epoch: [1041][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.1182 (0.0647)	
0.9999856 2.0031659e-07
Epoch: [1041][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0864 (0.0586)	
0.9999918 2.3745889e-07
loss:  0.04137445589951294 0.03897757529122903
===========>   training    <===========
Epoch: [1042][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0369 (0.0369)	
0.99999297 6.8116606e-08
===========>   testing    <===========
Epoch: [1042][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0687 (0.0687)	
0.9999958 2.0584503e-07
Epoch: [1042][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0472 (0.0645)	
0.99998224 2.1603893e-07
Epoch: [1042][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0750 (0.0578)	
0.99999166 2.7516307e-07
loss:  0.04162124089447106 0.03897757529122903
===========>   training    <===========
Epoch: [1043][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0404 (0.0404)	
0.99999285 3.394726e-08
===========>   testing    <===========
Epoch: [1043][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0511 (0.0511)	
0.99999523 2.3258991e-07
Epoch: [1043][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0368 (0.0622)	
0.99998176 2.4064278e-07
Epoch: [1043][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0865 (0.0566)	
0.99999285 3.0157406e-07
loss:  0.04081588737841246 0.03897757529122903
===========>   training    <===========
Epoch: [1044][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0338 (0.0338)	
0.99999225 3.6025358e-07
===========>   testing    <===========
Epoch: [1044][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0644 (0.0644)	
0.9999944 2.698687e-07
Epoch: [1044][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0246 (0.0628)	
0.99997926 2.6285082e-07
Epoch: [1044][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.1008 (0.0583)	
0.999992 3.4717522e-07
loss:  0.040700870612551676 0.03897757529122903
===========>   training    <===========
Epoch: [1045][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0308 (0.0308)	
0.99999547 7.8565805e-08
===========>   testing    <===========
Epoch: [1045][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0579 (0.0579)	
0.99999535 4.365604e-07
Epoch: [1045][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0309 (0.0646)	
0.999984 4.3648797e-07
Epoch: [1045][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0816 (0.0582)	
0.9999925 5.0779437e-07
loss:  0.04193638413750145 0.03897757529122903
===========>   training    <===========
Epoch: [1046][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0515 (0.0515)	
0.99998975 5.6806414e-08
===========>   testing    <===========
Epoch: [1046][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.1125 (0.1125)	
0.999995 4.3001273e-07
Epoch: [1046][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.1049 (0.0661)	
0.9999826 3.271861e-07
Epoch: [1046][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0583 (0.0581)	
0.99999154 5.37645e-07
loss:  0.04152843950977114 0.03897757529122903
===========>   training    <===========
Epoch: [1047][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0367 (0.0367)	
0.99998736 3.3170107e-08
===========>   testing    <===========
Epoch: [1047][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0756 (0.0756)	
0.9999958 1.6268024e-07
Epoch: [1047][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.1077 (0.0624)	
0.99998534 1.4809068e-07
Epoch: [1047][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0689 (0.0574)	
0.9999938 1.9061335e-07
loss:  0.040691449911719024 0.03897757529122903
===========>   training    <===========
Epoch: [1048][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0358 (0.0358)	
0.9999933 6.6851385e-06
===========>   testing    <===========
Epoch: [1048][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0865 (0.0865)	
0.9999951 2.6804707e-07
Epoch: [1048][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0462 (0.0629)	
0.9999826 2.3282206e-07
Epoch: [1048][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0757 (0.0575)	
0.9999918 2.858576e-07
loss:  0.039690563399374934 0.03897757529122903
===========>   training    <===========
Epoch: [1049][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0431 (0.0431)	
0.99998593 7.580239e-08
===========>   testing    <===========
Epoch: [1049][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.1091 (0.1091)	
0.99999475 3.524387e-07
Epoch: [1049][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0808 (0.0619)	
0.99998546 3.0962173e-07
Epoch: [1049][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0696 (0.0576)	
0.99999285 4.0109208e-07
loss:  0.04056077667883762 0.03897757529122903
===========>   training    <===========
Epoch: [1050][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0376 (0.0376)	
0.9999912 3.276632e-07
===========>   testing    <===========
Epoch: [1050][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.1146 (0.1146)	
0.9999944 2.0635272e-07
Epoch: [1050][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.1136 (0.0610)	
0.999985 4.026926e-07
Epoch: [1050][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0933 (0.0569)	
0.9999918 3.6153875e-07
loss:  0.039650256314844756 0.03897757529122903
===========>   training    <===========
Epoch: [1051][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0389 (0.0389)	
0.9999932 3.6582173e-07
===========>   testing    <===========
Epoch: [1051][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.1355 (0.1355)	
0.9999945 2.3633221e-07
Epoch: [1051][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.1789 (0.0627)	
0.9999845 1.4664984e-07
Epoch: [1051][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0647 (0.0574)	
0.99999225 2.770011e-07
loss:  0.04075674612986302 0.03897757529122903
===========>   training    <===========
Epoch: [1052][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0415 (0.0415)	
0.9999912 3.5472897e-07
===========>   testing    <===========
Epoch: [1052][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.1063 (0.1063)	
0.9999951 4.79264e-07
Epoch: [1052][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.1149 (0.0612)	
0.99998665 4.9243033e-07
Epoch: [1052][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0843 (0.0565)	
0.99999213 5.8722765e-07
loss:  0.039906984412483415 0.03897757529122903
===========>   training    <===========
Epoch: [1053][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0387 (0.0387)	
0.99999094 3.872166e-07
===========>   testing    <===========
Epoch: [1053][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0910 (0.0910)	
0.99999285 2.3320871e-07
Epoch: [1053][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.1722 (0.0617)	
0.99998224 1.4430658e-07
Epoch: [1053][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0714 (0.0560)	
0.9999889 1.9382382e-07
loss:  0.04072134104310143 0.03897757529122903
===========>   training    <===========
Epoch: [1054][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0349 (0.0349)	
0.9999939 3.399087e-07
===========>   testing    <===========
Epoch: [1054][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.1119 (0.1119)	
0.99999475 3.7071752e-07
Epoch: [1054][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.2601 (0.0616)	
0.99998677 1.897359e-07
Epoch: [1054][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0702 (0.0551)	
0.99999106 4.7197315e-07
loss:  0.04017512164291004 0.03897757529122903
===========>   training    <===========
Epoch: [1055][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0360 (0.0360)	
0.99998796 8.779964e-07
===========>   testing    <===========
Epoch: [1055][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0581 (0.0581)	
0.9999945 7.568738e-07
Epoch: [1055][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.2574 (0.0622)	
0.9999889 3.7198785e-07
Epoch: [1055][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0722 (0.0554)	
0.99999166 8.459004e-07
loss:  0.040753447884798844 0.03897757529122903
===========>   training    <===========
Epoch: [1056][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0363 (0.0363)	
0.9999951 4.5033755e-08
===========>   testing    <===========
Epoch: [1056][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0682 (0.0682)	
0.9999933 2.384374e-07
Epoch: [1056][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.1476 (0.0636)	
0.9999852 1.9089495e-07
Epoch: [1056][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0815 (0.0563)	
0.99999106 3.3552857e-07
loss:  0.04121429013630573 0.03897757529122903
===========>   training    <===========
Epoch: [1057][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0376 (0.0376)	
0.9999875 6.174386e-08
===========>   testing    <===========
Epoch: [1057][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0818 (0.0818)	
0.9999949 2.6370876e-07
Epoch: [1057][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0558 (0.0608)	
0.9999864 1.8685454e-07
Epoch: [1057][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0799 (0.0556)	
0.99999094 3.9466138e-07
loss:  0.04013628074060516 0.03897757529122903
===========>   training    <===========
Epoch: [1058][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0329 (0.0329)	
0.99999404 1.6879132e-07
===========>   testing    <===========
Epoch: [1058][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0949 (0.0949)	
0.99999535 4.663259e-07
Epoch: [1058][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.1356 (0.0625)	
0.9999852 2.2167738e-07
Epoch: [1058][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0873 (0.0567)	
0.99999154 5.156749e-07
loss:  0.04052286182841458 0.03897757529122903
===========>   training    <===========
Epoch: [1059][0/23]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0377 (0.0377)	
0.9999957 2.1731638e-07
===========>   testing    <===========
Epoch: [1059][0/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.1049 (0.1049)	
0.9999958 4.4029417e-07
Epoch: [1059][100/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.1104 (0.0615)	
0.9999863 3.1141363e-07
Epoch: [1059][200/289]	Lr-deconv: [0.0]	Lr-other: [6.94428401872336e-05]	Loss 0.0776 (0.0559)	
0.9999919 6.170595e-07
loss:  0.03980130814676075 0.03897757529122903
===========>   training    <===========
Epoch: [1060][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0436 (0.0436)	
0.9999943 9.4112735e-09
===========>   testing    <===========
Epoch: [1060][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0933 (0.0933)	
0.9999957 2.5139087e-07
Epoch: [1060][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0890 (0.0610)	
0.9999875 1.8562193e-07
Epoch: [1060][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0729 (0.0559)	
0.99999213 3.4001243e-07
loss:  0.04014253011940894 0.03897757529122903
===========>   training    <===========
Epoch: [1061][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0369 (0.0369)	
0.9999908 2.9123885e-07
===========>   testing    <===========
Epoch: [1061][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.1212 (0.1212)	
0.9999957 3.1104443e-07
Epoch: [1061][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.1406 (0.0628)	
0.9999896 1.8632691e-07
Epoch: [1061][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0745 (0.0568)	
0.9999932 5.1223503e-07
loss:  0.040834490269092805 0.03897757529122903
===========>   training    <===========
Epoch: [1062][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0365 (0.0365)	
0.9999919 5.3355683e-07
===========>   testing    <===========
Epoch: [1062][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.1214 (0.1214)	
0.9999951 2.664003e-07
Epoch: [1062][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0954 (0.0615)	
0.9999887 2.7037828e-07
Epoch: [1062][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0619 (0.0564)	
0.9999914 5.3420496e-07
loss:  0.03990434231760798 0.03897757529122903
===========>   training    <===========
Epoch: [1063][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0327 (0.0327)	
0.99998343 6.423102e-08
===========>   testing    <===========
Epoch: [1063][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.1156 (0.1156)	
0.999995 2.4251256e-07
Epoch: [1063][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0503 (0.0618)	
0.9999882 3.3053053e-07
Epoch: [1063][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0852 (0.0573)	
0.9999906 4.140444e-07
loss:  0.040107442289118 0.03897757529122903
===========>   training    <===========
Epoch: [1064][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0390 (0.0390)	
0.9999931 4.513187e-08
===========>   testing    <===========
Epoch: [1064][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0976 (0.0976)	
0.9999949 2.5817496e-07
Epoch: [1064][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0998 (0.0622)	
0.9999902 4.35714e-07
Epoch: [1064][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0776 (0.0572)	
0.99999166 4.6707277e-07
loss:  0.039894952275909 0.03897757529122903
===========>   training    <===========
Epoch: [1065][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0337 (0.0337)	
0.99999154 5.126201e-08
===========>   testing    <===========
Epoch: [1065][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0931 (0.0931)	
0.99999535 2.310091e-07
Epoch: [1065][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0517 (0.0638)	
0.99999106 2.3450066e-07
Epoch: [1065][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0869 (0.0573)	
0.9999926 2.8064585e-07
loss:  0.0407485857444283 0.03897757529122903
===========>   training    <===========
Epoch: [1066][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0417 (0.0417)	
0.9999956 1.05598104e-07
===========>   testing    <===========
Epoch: [1066][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0958 (0.0958)	
0.9999949 4.1388645e-07
Epoch: [1066][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0292 (0.0611)	
0.9999877 3.4973e-07
Epoch: [1066][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0779 (0.0553)	
0.99999154 4.9793096e-07
loss:  0.03992760916363569 0.03897757529122903
===========>   training    <===========
Epoch: [1067][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0399 (0.0399)	
0.9999956 1.2235817e-07
===========>   testing    <===========
Epoch: [1067][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0631 (0.0631)	
0.99999297 3.4833792e-07
Epoch: [1067][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0187 (0.0620)	
0.99998486 3.9429233e-07
Epoch: [1067][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0690 (0.0567)	
0.9999914 6.037008e-07
loss:  0.041331607721805885 0.03897757529122903
===========>   training    <===========
Epoch: [1068][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0401 (0.0401)	
0.99998975 1.400341e-07
===========>   testing    <===========
Epoch: [1068][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0919 (0.0919)	
0.9999931 3.5671215e-07
Epoch: [1068][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0212 (0.0601)	
0.9999839 4.1411863e-07
Epoch: [1068][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0581 (0.0552)	
0.9999912 6.990712e-07
loss:  0.040057450758269275 0.03897757529122903
===========>   training    <===========
Epoch: [1069][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0544 (0.0544)	
0.9999968 3.4436436e-08
===========>   testing    <===========
Epoch: [1069][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.1116 (0.1116)	
0.99999285 1.2930491e-07
Epoch: [1069][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0319 (0.0626)	
0.9999821 1.0238082e-07
Epoch: [1069][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0557 (0.0572)	
0.9999906 1.0144468e-07
loss:  0.04088014756415348 0.03897757529122903
===========>   training    <===========
Epoch: [1070][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0381 (0.0381)	
0.9999945 7.6652755e-09
===========>   testing    <===========
Epoch: [1070][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.1132 (0.1132)	
0.99999464 3.970541e-07
Epoch: [1070][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0714 (0.0634)	
0.99998844 5.980609e-07
Epoch: [1070][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0583 (0.0576)	
0.9999914 5.8613773e-07
loss:  0.04070444660660899 0.03897757529122903
===========>   training    <===========
Epoch: [1071][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0388 (0.0388)	
0.9999877 4.5336432e-07
===========>   testing    <===========
Epoch: [1071][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0961 (0.0961)	
0.9999949 3.6407042e-07
Epoch: [1071][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0330 (0.0631)	
0.99998844 3.849114e-07
Epoch: [1071][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0811 (0.0570)	
0.999992 4.4048485e-07
loss:  0.04017328308616441 0.03897757529122903
===========>   training    <===========
Epoch: [1072][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0369 (0.0369)	
0.99998915 3.688027e-08
===========>   testing    <===========
Epoch: [1072][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0703 (0.0703)	
0.99999475 3.9315722e-07
Epoch: [1072][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0271 (0.0638)	
0.99998724 3.163358e-07
Epoch: [1072][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0732 (0.0576)	
0.99999213 5.730351e-07
loss:  0.0409095333769095 0.03897757529122903
===========>   training    <===========
Epoch: [1073][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0320 (0.0320)	
0.99999416 2.1884773e-07
===========>   testing    <===========
Epoch: [1073][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.1425 (0.1425)	
0.9999896 1.8877066e-07
Epoch: [1073][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0774 (0.0631)	
0.99997985 2.2231889e-07
Epoch: [1073][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0791 (0.0563)	
0.9999876 2.3059287e-07
loss:  0.040245830570393326 0.03897757529122903
===========>   training    <===========
Epoch: [1074][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0336 (0.0336)	
0.9999646 1.0336305e-07
===========>   testing    <===========
Epoch: [1074][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.1279 (0.1279)	
0.9999937 3.3347828e-07
Epoch: [1074][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0298 (0.0625)	
0.9999887 3.8272984e-07
Epoch: [1074][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0645 (0.0561)	
0.99999 5.0157263e-07
loss:  0.04044856334848179 0.03897757529122903
===========>   training    <===========
Epoch: [1075][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0430 (0.0430)	
0.99998856 1.944815e-07
===========>   testing    <===========
Epoch: [1075][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0846 (0.0846)	
0.9999939 2.5502163e-07
Epoch: [1075][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0294 (0.0617)	
0.99998295 2.7459737e-07
Epoch: [1075][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0758 (0.0556)	
0.9999914 3.2512014e-07
loss:  0.039774972315537394 0.03897757529122903
===========>   training    <===========
Epoch: [1076][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0367 (0.0367)	
0.99999285 8.985032e-08
===========>   testing    <===========
Epoch: [1076][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.1412 (0.1412)	
0.9999949 4.1381463e-07
Epoch: [1076][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0316 (0.0625)	
0.9999876 4.3168424e-07
Epoch: [1076][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.1052 (0.0569)	
0.99999166 5.3921684e-07
loss:  0.04076212077814467 0.03897757529122903
===========>   training    <===========
Epoch: [1077][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0307 (0.0307)	
0.9999925 7.1916254e-08
===========>   testing    <===========
Epoch: [1077][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.1430 (0.1430)	
0.9999951 2.9926318e-07
Epoch: [1077][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0696 (0.0627)	
0.99998987 3.5410568e-07
Epoch: [1077][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0755 (0.0570)	
0.9999914 3.8790702e-07
loss:  0.041359054421229446 0.03897757529122903
===========>   training    <===========
Epoch: [1078][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0331 (0.0331)	
0.99999046 1.6540587e-06
===========>   testing    <===========
Epoch: [1078][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.1514 (0.1514)	
0.9999944 4.0135993e-07
Epoch: [1078][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0410 (0.0617)	
0.9999894 4.703295e-07
Epoch: [1078][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0693 (0.0558)	
0.99999046 4.834865e-07
loss:  0.040470778962232834 0.03897757529122903
===========>   training    <===========
Epoch: [1079][0/23]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0389 (0.0389)	
0.9999933 1.799432e-07
===========>   testing    <===========
Epoch: [1079][0/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.1226 (0.1226)	
0.9999938 3.1605052e-07
Epoch: [1079][100/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0353 (0.0596)	
0.99998677 3.5135034e-07
Epoch: [1079][200/289]	Lr-deconv: [0.0]	Lr-other: [6.597069817787194e-05]	Loss 0.0783 (0.0557)	
0.9999907 3.835988e-07
loss:  0.04047187354200055 0.03897757529122903
===========>   training    <===========
Epoch: [1080][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0339 (0.0339)	
0.99998915 1.1333447e-06
===========>   testing    <===========
Epoch: [1080][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.1265 (0.1265)	
0.99999464 3.0146768e-07
Epoch: [1080][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0279 (0.0613)	
0.99998677 3.3284252e-07
Epoch: [1080][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0816 (0.0568)	
0.9999926 3.7115794e-07
loss:  0.04120415079836315 0.03897757529122903
===========>   training    <===========
Epoch: [1081][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0404 (0.0404)	
0.9999893 5.1780427e-07
===========>   testing    <===========
Epoch: [1081][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.1252 (0.1252)	
0.9999951 2.4035975e-07
Epoch: [1081][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0768 (0.0617)	
0.9999877 2.6643534e-07
Epoch: [1081][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0531 (0.0562)	
0.99999213 2.9183775e-07
loss:  0.04043539838739996 0.03897757529122903
===========>   training    <===========
Epoch: [1082][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0347 (0.0347)	
0.99999666 5.4890474e-08
===========>   testing    <===========
Epoch: [1082][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.1300 (0.1300)	
0.9999932 5.3627434e-07
Epoch: [1082][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0705 (0.0616)	
0.9999846 4.263243e-07
Epoch: [1082][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0547 (0.0563)	
0.9999901 6.822823e-07
loss:  0.04129109141142395 0.03897757529122903
===========>   training    <===========
Epoch: [1083][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0322 (0.0322)	
0.9999919 3.8723505e-07
===========>   testing    <===========
Epoch: [1083][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.1137 (0.1137)	
0.9999937 3.6105635e-07
Epoch: [1083][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0432 (0.0622)	
0.99998367 3.02863e-07
Epoch: [1083][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0625 (0.0568)	
0.9999908 4.3031056e-07
loss:  0.04151768275102263 0.03897757529122903
===========>   training    <===========
Epoch: [1084][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0370 (0.0370)	
0.99998367 2.417146e-07
===========>   testing    <===========
Epoch: [1084][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.1086 (0.1086)	
0.9999944 4.261434e-07
Epoch: [1084][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0831 (0.0618)	
0.9999869 4.997663e-07
Epoch: [1084][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0693 (0.0564)	
0.9999919 5.302955e-07
loss:  0.040858961861174325 0.03897757529122903
===========>   training    <===========
Epoch: [1085][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0376 (0.0376)	
0.9999956 2.0434426e-07
===========>   testing    <===========
Epoch: [1085][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.1271 (0.1271)	
0.9999933 4.6437233e-07
Epoch: [1085][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0724 (0.0609)	
0.99998295 3.0191825e-07
Epoch: [1085][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0801 (0.0552)	
0.9999901 6.042526e-07
loss:  0.040070970205409284 0.03897757529122903
===========>   training    <===========
Epoch: [1086][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0415 (0.0415)	
0.9999938 1.243251e-07
===========>   testing    <===========
Epoch: [1086][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.1201 (0.1201)	
0.99999416 4.39311e-07
Epoch: [1086][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0400 (0.0605)	
0.9999844 3.0764352e-07
Epoch: [1086][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0767 (0.0550)	
0.9999918 5.547165e-07
loss:  0.03956119716215034 0.03897757529122903
===========>   training    <===========
Epoch: [1087][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0376 (0.0376)	
0.99999547 6.4879407e-07
===========>   testing    <===========
Epoch: [1087][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.1002 (0.1002)	
0.99999416 4.3541863e-07
Epoch: [1087][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0343 (0.0609)	
0.99998546 5.0250964e-07
Epoch: [1087][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.1041 (0.0562)	
0.9999919 5.719459e-07
loss:  0.040052460754710806 0.03897757529122903
===========>   training    <===========
Epoch: [1088][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0398 (0.0398)	
0.99999106 2.4388422e-07
===========>   testing    <===========
Epoch: [1088][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.1322 (0.1322)	
0.9999945 3.3068534e-07
Epoch: [1088][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0319 (0.0618)	
0.9999869 3.0085994e-07
Epoch: [1088][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0697 (0.0564)	
0.99999225 4.5247796e-07
loss:  0.04004051140524656 0.03897757529122903
===========>   training    <===========
Epoch: [1089][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0392 (0.0392)	
0.99998796 9.2601745e-08
===========>   testing    <===========
Epoch: [1089][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.1190 (0.1190)	
0.99999404 4.99189e-07
Epoch: [1089][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0233 (0.0624)	
0.99998486 5.6940377e-07
Epoch: [1089][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0872 (0.0578)	
0.99999213 6.7528725e-07
loss:  0.040938691834190855 0.03897757529122903
===========>   training    <===========
Epoch: [1090][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0336 (0.0336)	
0.9999958 1.04025226e-07
===========>   testing    <===========
Epoch: [1090][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.1438 (0.1438)	
0.9999937 3.1797666e-07
Epoch: [1090][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0195 (0.0611)	
0.9999869 3.4291784e-07
Epoch: [1090][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0689 (0.0561)	
0.9999912 4.3077165e-07
loss:  0.03975743043455837 0.03897757529122903
===========>   training    <===========
Epoch: [1091][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0355 (0.0355)	
0.9999908 6.5633415e-08
===========>   testing    <===========
Epoch: [1091][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.1168 (0.1168)	
0.99999464 3.006385e-07
Epoch: [1091][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0200 (0.0614)	
0.9999888 3.2127784e-07
Epoch: [1091][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0927 (0.0570)	
0.9999926 3.7747952e-07
loss:  0.040807177656830174 0.03897757529122903
===========>   training    <===========
Epoch: [1092][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0283 (0.0283)	
0.9999969 1.5214728e-07
===========>   testing    <===========
Epoch: [1092][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.1106 (0.1106)	
0.999995 4.3917782e-07
Epoch: [1092][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0189 (0.0609)	
0.9999901 4.8105943e-07
Epoch: [1092][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0829 (0.0564)	
0.9999927 5.616976e-07
loss:  0.04053537949209207 0.03897757529122903
===========>   training    <===========
Epoch: [1093][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0350 (0.0350)	
0.99999356 1.0595338e-07
===========>   testing    <===========
Epoch: [1093][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.1185 (0.1185)	
0.9999957 4.6175052e-07
Epoch: [1093][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0202 (0.0596)	
0.9999908 4.840442e-07
Epoch: [1093][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0581 (0.0552)	
0.999992 5.6895647e-07
loss:  0.039511257265018584 0.03897757529122903
===========>   training    <===========
Epoch: [1094][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0311 (0.0311)	
0.99995804 1.3547962e-07
===========>   testing    <===========
Epoch: [1094][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0979 (0.0979)	
0.99999523 1.5533556e-07
Epoch: [1094][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0202 (0.0619)	
0.9999919 2.0123875e-07
Epoch: [1094][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0788 (0.0577)	
0.99999154 2.1151111e-07
loss:  0.041271090032734326 0.03897757529122903
===========>   training    <===========
Epoch: [1095][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0329 (0.0329)	
0.9999895 3.818854e-08
===========>   testing    <===========
Epoch: [1095][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.1100 (0.1100)	
0.99999416 3.995276e-07
Epoch: [1095][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0251 (0.0610)	
0.9999901 4.2895394e-07
Epoch: [1095][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0903 (0.0569)	
0.99998987 5.6921425e-07
loss:  0.04097586639292483 0.03897757529122903
===========>   training    <===========
Epoch: [1096][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0369 (0.0369)	
0.9999926 3.9879404e-07
===========>   testing    <===========
Epoch: [1096][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.1087 (0.1087)	
0.9999937 4.2783165e-07
Epoch: [1096][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0644 (0.0603)	
0.99998915 4.122076e-07
Epoch: [1096][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0783 (0.0562)	
0.99999034 5.6550516e-07
loss:  0.04041835628419532 0.03897757529122903
===========>   training    <===========
Epoch: [1097][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0351 (0.0351)	
0.99999285 4.0759994e-07
===========>   testing    <===========
Epoch: [1097][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.1033 (0.1033)	
0.9999931 2.6510418e-07
Epoch: [1097][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0407 (0.0604)	
0.9999875 2.4540446e-07
Epoch: [1097][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0918 (0.0558)	
0.9999893 3.032248e-07
loss:  0.04001161406840936 0.03897757529122903
===========>   training    <===========
Epoch: [1098][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0339 (0.0339)	
0.999992 6.773403e-08
===========>   testing    <===========
Epoch: [1098][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.1116 (0.1116)	
0.99999595 5.5907145e-07
Epoch: [1098][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0362 (0.0601)	
0.99999213 5.3771635e-07
Epoch: [1098][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0939 (0.0562)	
0.9999926 8.639995e-07
loss:  0.04041888156914675 0.03897757529122903
===========>   training    <===========
Epoch: [1099][0/23]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0489 (0.0489)	
0.9999962 2.4040054e-07
===========>   testing    <===========
Epoch: [1099][0/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.1032 (0.1032)	
0.99999535 3.542786e-07
Epoch: [1099][100/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0326 (0.0610)	
0.99999046 3.4027715e-07
Epoch: [1099][200/289]	Lr-deconv: [0.0]	Lr-other: [6.267216326897833e-05]	Loss 0.0762 (0.0560)	
0.99999166 4.7617684e-07
loss:  0.04034714769833303 0.03897757529122903
===========>   training    <===========
Epoch: [1100][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0328 (0.0328)	
0.99998796 3.191563e-08
===========>   testing    <===========
Epoch: [1100][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.1417 (0.1417)	
0.99999535 3.2132414e-07
Epoch: [1100][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0428 (0.0622)	
0.9999883 3.2954696e-07
Epoch: [1100][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0734 (0.0562)	
0.9999912 4.70992e-07
loss:  0.04038847228561515 0.03897757529122903
===========>   training    <===========
Epoch: [1101][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0323 (0.0323)	
0.9999943 8.480888e-08
===========>   testing    <===========
Epoch: [1101][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.1151 (0.1151)	
0.99999535 4.5671533e-07
Epoch: [1101][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0516 (0.0611)	
0.99998677 4.1891616e-07
Epoch: [1101][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0676 (0.0554)	
0.99999106 6.262175e-07
loss:  0.03950031936314635 0.03897757529122903
===========>   training    <===========
Epoch: [1102][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0446 (0.0446)	
0.9999963 1.2126294e-07
===========>   testing    <===========
Epoch: [1102][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.1074 (0.1074)	
0.9999949 3.506785e-07
Epoch: [1102][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0401 (0.0620)	
0.99998593 1.941598e-07
Epoch: [1102][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0949 (0.0567)	
0.9999907 4.979623e-07
loss:  0.040358259137401764 0.03897757529122903
===========>   training    <===========
Epoch: [1103][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0370 (0.0370)	
0.99998903 3.4120514e-08
===========>   testing    <===========
Epoch: [1103][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.1195 (0.1195)	
0.99999535 2.0480155e-07
Epoch: [1103][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0580 (0.0624)	
0.9999883 2.6199714e-07
Epoch: [1103][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.1165 (0.0574)	
0.9999914 2.8049868e-07
loss:  0.04057731362575412 0.03897757529122903
===========>   training    <===========
Epoch: [1104][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0333 (0.0333)	
0.999995 8.950478e-09
===========>   testing    <===========
Epoch: [1104][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.1277 (0.1277)	
0.9999957 3.5040705e-07
Epoch: [1104][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0464 (0.0625)	
0.9999902 3.9978485e-07
Epoch: [1104][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0988 (0.0571)	
0.999992 3.6293613e-07
loss:  0.04075335798704183 0.03897757529122903
===========>   training    <===========
Epoch: [1105][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0339 (0.0339)	
0.9999856 1.0447973e-06
===========>   testing    <===========
Epoch: [1105][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.1511 (0.1511)	
0.99999523 3.011312e-07
Epoch: [1105][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0300 (0.0612)	
0.99999046 1.9942986e-07
Epoch: [1105][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0760 (0.0563)	
0.9999913 3.5017453e-07
loss:  0.040593396791120395 0.03897757529122903
===========>   training    <===========
Epoch: [1106][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0370 (0.0370)	
0.9999883 5.6402996e-07
===========>   testing    <===========
Epoch: [1106][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.1129 (0.1129)	
0.9999949 2.3598291e-07
Epoch: [1106][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0443 (0.0617)	
0.9999889 1.9991049e-07
Epoch: [1106][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0825 (0.0569)	
0.99999166 3.430039e-07
loss:  0.04072611753764355 0.03897757529122903
===========>   training    <===========
Epoch: [1107][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0410 (0.0410)	
0.99999285 1.2975165e-08
===========>   testing    <===========
Epoch: [1107][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.1367 (0.1367)	
0.9999957 2.5170417e-07
Epoch: [1107][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0258 (0.0609)	
0.9999906 2.925511e-07
Epoch: [1107][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0718 (0.0563)	
0.99999356 3.9824943e-07
loss:  0.03993192078301777 0.03897757529122903
===========>   training    <===========
Epoch: [1108][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0389 (0.0389)	
0.9999956 1.3941603e-08
===========>   testing    <===========
Epoch: [1108][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.1072 (0.1072)	
0.9999939 2.6339256e-07
Epoch: [1108][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0437 (0.0607)	
0.99998856 2.6082344e-07
Epoch: [1108][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0755 (0.0566)	
0.9999918 4.089998e-07
loss:  0.039469707428687495 0.03897757529122903
===========>   training    <===========
Epoch: [1109][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0398 (0.0398)	
0.99998474 2.4564649e-08
===========>   testing    <===========
Epoch: [1109][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0986 (0.0986)	
0.9999949 3.5754795e-07
Epoch: [1109][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0294 (0.0618)	
0.9999895 2.4506627e-07
Epoch: [1109][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0994 (0.0575)	
0.999992 5.043772e-07
loss:  0.040711259681207035 0.03897757529122903
===========>   training    <===========
Epoch: [1110][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0369 (0.0369)	
0.99998975 1.9931235e-07
===========>   testing    <===========
Epoch: [1110][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.1022 (0.1022)	
0.99999475 3.1117972e-07
Epoch: [1110][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0417 (0.0605)	
0.9999893 3.641541e-07
Epoch: [1110][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0659 (0.0570)	
0.9999894 5.347662e-07
loss:  0.04071888515244593 0.03897757529122903
===========>   training    <===========
Epoch: [1111][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0376 (0.0376)	
0.9999913 3.0063276e-08
===========>   testing    <===========
Epoch: [1111][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.1268 (0.1268)	
0.99999547 2.276681e-07
Epoch: [1111][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.1013 (0.0598)	
0.9999896 2.7379173e-07
Epoch: [1111][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0618 (0.0562)	
0.9999913 3.343776e-07
loss:  0.04094115969585943 0.03897757529122903
===========>   training    <===========
Epoch: [1112][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0312 (0.0312)	
0.9999927 1.4555704e-07
===========>   testing    <===========
Epoch: [1112][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.1037 (0.1037)	
0.99999547 4.19812e-07
Epoch: [1112][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0781 (0.0597)	
0.99999154 4.319997e-07
Epoch: [1112][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0903 (0.0568)	
0.9999918 6.1961407e-07
loss:  0.04120252897272092 0.03897757529122903
===========>   training    <===========
Epoch: [1113][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0358 (0.0358)	
0.9999933 1.6916631e-07
===========>   testing    <===========
Epoch: [1113][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.1172 (0.1172)	
0.9999944 3.364546e-07
Epoch: [1113][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0273 (0.0584)	
0.99998915 2.5742705e-07
Epoch: [1113][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0833 (0.0567)	
0.99999106 4.726429e-07
loss:  0.04000436113890893 0.03897757529122903
===========>   training    <===========
Epoch: [1114][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0426 (0.0426)	
0.99998975 7.79889e-08
===========>   testing    <===========
Epoch: [1114][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.1146 (0.1146)	
0.999995 3.3914455e-07
Epoch: [1114][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0184 (0.0606)	
0.99998796 4.6663376e-07
Epoch: [1114][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0642 (0.0565)	
0.9999908 4.953251e-07
loss:  0.04101183860124724 0.03897757529122903
===========>   training    <===========
Epoch: [1115][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0338 (0.0338)	
0.999992 2.5406706e-08
===========>   testing    <===========
Epoch: [1115][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.1310 (0.1310)	
0.9999937 1.7644614e-07
Epoch: [1115][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0206 (0.0595)	
0.9999863 2.5005997e-07
Epoch: [1115][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0566 (0.0566)	
0.99999 2.7004432e-07
loss:  0.04215375789041953 0.03897757529122903
===========>   training    <===========
Epoch: [1116][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0372 (0.0372)	
0.99998415 9.273162e-09
===========>   testing    <===========
Epoch: [1116][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.1247 (0.1247)	
0.99999475 2.7892378e-07
Epoch: [1116][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0325 (0.0590)	
0.99998856 1.6714318e-07
Epoch: [1116][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0703 (0.0566)	
0.999992 3.7678177e-07
loss:  0.040941233685600764 0.03897757529122903
===========>   training    <===========
Epoch: [1117][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0336 (0.0336)	
0.99999404 8.390046e-07
===========>   testing    <===========
Epoch: [1117][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.1277 (0.1277)	
0.9999951 4.6269693e-07
Epoch: [1117][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0246 (0.0598)	
0.99998736 2.2150621e-07
Epoch: [1117][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0767 (0.0568)	
0.99999106 5.968234e-07
loss:  0.041769422148572044 0.03897757529122903
===========>   training    <===========
Epoch: [1118][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0329 (0.0329)	
0.999995 1.9616729e-07
===========>   testing    <===========
Epoch: [1118][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.1119 (0.1119)	
0.99999535 4.466515e-07
Epoch: [1118][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0221 (0.0621)	
0.9999887 3.6016118e-07
Epoch: [1118][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0780 (0.0598)	
0.9999907 6.681924e-07
loss:  0.041835013859948256 0.03897757529122903
===========>   training    <===========
Epoch: [1119][0/23]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0388 (0.0388)	
0.9999938 9.646521e-08
===========>   testing    <===========
Epoch: [1119][0/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.1104 (0.1104)	
0.9999957 3.6488794e-07
Epoch: [1119][100/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0188 (0.0606)	
0.99998593 2.1968144e-07
Epoch: [1119][200/289]	Lr-deconv: [0.0]	Lr-other: [5.953855510552941e-05]	Loss 0.0690 (0.0579)	
0.9999901 6.044808e-07
loss:  0.04135633339175637 0.03897757529122903
===========>   training    <===========
Epoch: [1120][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0328 (0.0328)	
0.99999404 7.0181466e-07
===========>   testing    <===========
Epoch: [1120][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0711 (0.0711)	
0.99999416 2.7774362e-07
Epoch: [1120][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0272 (0.0623)	
0.9999857 2.6707642e-07
Epoch: [1120][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0853 (0.0592)	
0.9999918 4.6285138e-07
loss:  0.04203689717415737 0.03897757529122903
===========>   training    <===========
Epoch: [1121][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0401 (0.0401)	
0.99998355 6.3374665e-07
===========>   testing    <===========
Epoch: [1121][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0930 (0.0930)	
0.99999547 3.3086957e-07
Epoch: [1121][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.1063 (0.0612)	
0.9999869 1.3845072e-07
Epoch: [1121][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0769 (0.0573)	
0.9999914 4.3719785e-07
loss:  0.041306765947237034 0.03897757529122903
===========>   training    <===========
Epoch: [1122][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0502 (0.0502)	
0.9999869 9.53295e-09
===========>   testing    <===========
Epoch: [1122][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0759 (0.0759)	
0.9999951 6.384297e-07
Epoch: [1122][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0228 (0.0588)	
0.9999857 7.0599816e-07
Epoch: [1122][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0745 (0.0561)	
0.99999225 9.903913e-07
loss:  0.040200630326587605 0.03897757529122903
===========>   training    <===========
Epoch: [1123][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0384 (0.0384)	
0.9999943 3.094511e-07
===========>   testing    <===========
Epoch: [1123][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0755 (0.0755)	
0.9999945 5.994382e-07
Epoch: [1123][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0216 (0.0595)	
0.9999819 2.9978074e-07
Epoch: [1123][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0722 (0.0566)	
0.99999166 7.308549e-07
loss:  0.04001566517850752 0.03897757529122903
===========>   training    <===========
Epoch: [1124][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0378 (0.0378)	
0.9999924 3.6466392e-07
===========>   testing    <===========
Epoch: [1124][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0715 (0.0715)	
0.9999949 2.901549e-07
Epoch: [1124][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0384 (0.0590)	
0.9999815 3.5646357e-07
Epoch: [1124][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0938 (0.0566)	
0.99999046 4.5778762e-07
loss:  0.04040919937475107 0.03897757529122903
===========>   training    <===========
Epoch: [1125][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0360 (0.0360)	
0.999985 2.8598464e-07
===========>   testing    <===========
Epoch: [1125][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0730 (0.0730)	
0.99999535 3.937099e-07
Epoch: [1125][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0703 (0.0608)	
0.99998665 5.109212e-07
Epoch: [1125][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.1011 (0.0576)	
0.9999914 5.7474324e-07
loss:  0.0408369721871894 0.03897757529122903
===========>   training    <===========
Epoch: [1126][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0382 (0.0382)	
0.9999913 4.430679e-07
===========>   testing    <===========
Epoch: [1126][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.1121 (0.1121)	
0.99999547 2.8289068e-07
Epoch: [1126][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0260 (0.0599)	
0.99998736 3.4828847e-07
Epoch: [1126][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0820 (0.0565)	
0.99999046 4.448313e-07
loss:  0.03982515465690073 0.03897757529122903
===========>   training    <===========
Epoch: [1127][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0346 (0.0346)	
0.9999852 2.216617e-08
===========>   testing    <===========
Epoch: [1127][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0925 (0.0925)	
0.9999951 5.436699e-07
Epoch: [1127][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0284 (0.0610)	
0.99998903 6.837863e-07
Epoch: [1127][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0866 (0.0575)	
0.9999907 7.4146203e-07
loss:  0.040196129349150955 0.03897757529122903
===========>   training    <===========
Epoch: [1128][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0367 (0.0367)	
0.9999901 9.724479e-08
===========>   testing    <===========
Epoch: [1128][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.1028 (0.1028)	
0.9999943 3.5061495e-07
Epoch: [1128][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0282 (0.0603)	
0.99998796 4.3899985e-07
Epoch: [1128][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0846 (0.0569)	
0.9999896 5.895991e-07
loss:  0.039976181039537706 0.03897757529122903
===========>   training    <===========
Epoch: [1129][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0417 (0.0417)	
0.99999404 5.6185307e-08
===========>   testing    <===========
Epoch: [1129][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0800 (0.0800)	
0.9999956 7.08287e-07
Epoch: [1129][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0334 (0.0609)	
0.99999 6.9348744e-07
Epoch: [1129][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0913 (0.0574)	
0.9999927 9.2587675e-07
loss:  0.04167394380170364 0.03897757529122903
===========>   training    <===========
Epoch: [1130][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0334 (0.0334)	
0.9999956 5.1521283e-07
===========>   testing    <===========
Epoch: [1130][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0917 (0.0917)	
0.9999938 3.8208944e-07
Epoch: [1130][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0468 (0.0604)	
0.99998987 3.6035667e-07
Epoch: [1130][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0973 (0.0568)	
0.99999154 4.3096645e-07
loss:  0.04008158204766388 0.03897757529122903
===========>   training    <===========
Epoch: [1131][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0346 (0.0346)	
0.99999166 7.7873904e-07
===========>   testing    <===========
Epoch: [1131][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0990 (0.0990)	
0.99999523 5.88562e-07
Epoch: [1131][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0350 (0.0586)	
0.99999106 6.7410394e-07
Epoch: [1131][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0786 (0.0558)	
0.9999926 8.9803353e-07
loss:  0.04099037285420337 0.03897757529122903
===========>   training    <===========
Epoch: [1132][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0314 (0.0314)	
0.99999404 2.0471172e-07
===========>   testing    <===========
Epoch: [1132][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0762 (0.0762)	
0.99999607 4.0430263e-07
Epoch: [1132][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0526 (0.0608)	
0.9999912 4.1491163e-07
Epoch: [1132][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0910 (0.0582)	
0.99999213 5.405431e-07
loss:  0.040973256326713 0.03897757529122903
===========>   training    <===========
Epoch: [1133][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0343 (0.0343)	
0.9999968 3.9272024e-08
===========>   testing    <===========
Epoch: [1133][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0888 (0.0888)	
0.99999607 4.801867e-07
Epoch: [1133][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0182 (0.0587)	
0.99998915 5.988645e-07
Epoch: [1133][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0794 (0.0562)	
0.9999908 8.020158e-07
loss:  0.04007382614072441 0.03897757529122903
===========>   training    <===========
Epoch: [1134][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0343 (0.0343)	
0.999995 1.1085092e-07
===========>   testing    <===========
Epoch: [1134][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0810 (0.0810)	
0.9999963 6.1699774e-07
Epoch: [1134][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0245 (0.0594)	
0.9999889 7.3378465e-07
Epoch: [1134][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0803 (0.0564)	
0.99999297 7.954429e-07
loss:  0.04064161323106852 0.03897757529122903
===========>   training    <===========
Epoch: [1135][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0388 (0.0388)	
0.9999888 3.8388768e-09
===========>   testing    <===========
Epoch: [1135][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0759 (0.0759)	
0.99999595 3.7777735e-07
Epoch: [1135][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0440 (0.0593)	
0.9999896 4.5636443e-07
Epoch: [1135][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0734 (0.0557)	
0.9999927 7.7625145e-07
loss:  0.04059588173237527 0.03897757529122903
===========>   training    <===========
Epoch: [1136][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0260 (0.0260)	
0.9999939 2.785447e-07
===========>   testing    <===========
Epoch: [1136][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0933 (0.0933)	
0.99999595 2.2825552e-07
Epoch: [1136][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0259 (0.0593)	
0.9999852 2.5822126e-07
Epoch: [1136][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0812 (0.0562)	
0.9999908 3.6354857e-07
loss:  0.04148606759139517 0.03897757529122903
===========>   training    <===========
Epoch: [1137][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0336 (0.0336)	
0.9999926 2.03721e-07
===========>   testing    <===========
Epoch: [1137][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0759 (0.0759)	
0.9999963 2.883863e-07
Epoch: [1137][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0369 (0.0603)	
0.9999871 3.4984842e-07
Epoch: [1137][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0842 (0.0583)	
0.999992 4.851335e-07
loss:  0.041722695545344024 0.03897757529122903
===========>   training    <===========
Epoch: [1138][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0427 (0.0427)	
0.99998283 2.8113705e-08
===========>   testing    <===========
Epoch: [1138][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.1037 (0.1037)	
0.9999956 3.0675875e-07
Epoch: [1138][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0329 (0.0598)	
0.9999863 3.133118e-07
Epoch: [1138][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0861 (0.0577)	
0.9999906 3.4400597e-07
loss:  0.04044751840075689 0.03897757529122903
===========>   training    <===========
Epoch: [1139][0/23]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0351 (0.0351)	
0.99999106 4.5590636e-07
===========>   testing    <===========
Epoch: [1139][0/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.1067 (0.1067)	
0.9999958 3.528059e-07
Epoch: [1139][100/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0340 (0.0606)	
0.9999857 4.009001e-07
Epoch: [1139][200/289]	Lr-deconv: [0.0]	Lr-other: [5.656162735025293e-05]	Loss 0.0927 (0.0571)	
0.9999918 3.7988323e-07
loss:  0.040783216644130316 0.03897757529122903
===========>   training    <===========
Epoch: [1140][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0422 (0.0422)	
0.9999881 5.524148e-07
===========>   testing    <===========
Epoch: [1140][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.1216 (0.1216)	
0.9999958 3.5999085e-07
Epoch: [1140][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0292 (0.0616)	
0.9999871 4.0053055e-07
Epoch: [1140][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.1050 (0.0577)	
0.999992 4.0380942e-07
loss:  0.03999053826312171 0.03897757529122903
===========>   training    <===========
Epoch: [1141][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0426 (0.0426)	
0.9999919 6.501009e-08
===========>   testing    <===========
Epoch: [1141][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.1151 (0.1151)	
0.99999547 2.5623936e-07
Epoch: [1141][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0785 (0.0617)	
0.999985 2.8315574e-07
Epoch: [1141][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0990 (0.0574)	
0.9999931 4.0922532e-07
loss:  0.041431325448944456 0.03897757529122903
===========>   training    <===========
Epoch: [1142][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0364 (0.0364)	
0.99999535 1.1700221e-07
===========>   testing    <===========
Epoch: [1142][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.1349 (0.1349)	
0.99999595 4.4580383e-07
Epoch: [1142][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.1320 (0.0618)	
0.999987 4.4184128e-07
Epoch: [1142][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0790 (0.0570)	
0.9999924 5.149141e-07
loss:  0.04187322696410889 0.03897757529122903
===========>   training    <===========
Epoch: [1143][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0360 (0.0360)	
0.9999987 4.794175e-08
===========>   testing    <===========
Epoch: [1143][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.1564 (0.1564)	
0.9999958 3.6230085e-07
Epoch: [1143][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0459 (0.0616)	
0.99998474 3.3062668e-07
Epoch: [1143][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0855 (0.0571)	
0.9999907 4.993166e-07
loss:  0.04143582922886602 0.03897757529122903
===========>   training    <===========
Epoch: [1144][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0359 (0.0359)	
0.99998915 1.00939e-07
===========>   testing    <===========
Epoch: [1144][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.1421 (0.1421)	
0.99999523 3.041107e-07
Epoch: [1144][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0573 (0.0609)	
0.9999845 3.7569174e-07
Epoch: [1144][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0866 (0.0572)	
0.9999895 3.090727e-07
loss:  0.04098414756423929 0.03897757529122903
===========>   training    <===========
Epoch: [1145][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0327 (0.0327)	
0.9999851 2.4319533e-07
===========>   testing    <===========
Epoch: [1145][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.1187 (0.1187)	
0.9999957 2.470329e-07
Epoch: [1145][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0517 (0.0616)	
0.9999845 2.74639e-07
Epoch: [1145][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0746 (0.0578)	
0.99998915 2.866944e-07
loss:  0.04054054934785778 0.03897757529122903
===========>   training    <===========
Epoch: [1146][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0364 (0.0364)	
0.99998367 6.5394e-08
===========>   testing    <===========
Epoch: [1146][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.1479 (0.1479)	
0.99999547 1.840745e-07
Epoch: [1146][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0607 (0.0609)	
0.9999865 2.5165235e-07
Epoch: [1146][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0611 (0.0563)	
0.99998975 2.2775257e-07
loss:  0.04004097335204648 0.03897757529122903
===========>   training    <===========
Epoch: [1147][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0339 (0.0339)	
0.99999404 3.0669906e-08
===========>   testing    <===========
Epoch: [1147][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.1206 (0.1206)	
0.9999951 2.1643467e-07
Epoch: [1147][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0424 (0.0602)	
0.99998736 2.7027204e-07
Epoch: [1147][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0782 (0.0563)	
0.9999887 2.5590407e-07
loss:  0.03970668375205988 0.03897757529122903
===========>   training    <===========
Epoch: [1148][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0359 (0.0359)	
0.9999925 6.45075e-08
===========>   testing    <===========
Epoch: [1148][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.1211 (0.1211)	
0.99999416 2.772001e-07
Epoch: [1148][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0399 (0.0593)	
0.99998355 4.3453716e-07
Epoch: [1148][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0697 (0.0555)	
0.9999901 3.7366001e-07
loss:  0.04033251739296895 0.03897757529122903
===========>   training    <===========
Epoch: [1149][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0308 (0.0308)	
0.99998987 2.1352156e-08
===========>   testing    <===========
Epoch: [1149][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.1150 (0.1150)	
0.99999475 2.3599662e-07
Epoch: [1149][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0844 (0.0606)	
0.9999844 3.7130204e-07
Epoch: [1149][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0638 (0.0559)	
0.99998856 2.9323405e-07
loss:  0.04040640242439186 0.03897757529122903
===========>   training    <===========
Epoch: [1150][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0370 (0.0370)	
0.9999808 1.2726271e-07
===========>   testing    <===========
Epoch: [1150][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0687 (0.0687)	
0.9999963 3.4496395e-07
Epoch: [1150][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0921 (0.0621)	
0.99998665 3.5384912e-07
Epoch: [1150][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0621 (0.0577)	
0.9999908 4.4374153e-07
loss:  0.04034241810835626 0.03897757529122903
===========>   training    <===========
Epoch: [1151][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0477 (0.0477)	
0.99999297 4.0244805e-07
===========>   testing    <===========
Epoch: [1151][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0820 (0.0820)	
0.9999962 4.1902723e-07
Epoch: [1151][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0434 (0.0607)	
0.999987 4.2594837e-07
Epoch: [1151][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0505 (0.0563)	
0.99999094 6.104641e-07
loss:  0.03960154185670284 0.03897757529122903
===========>   training    <===========
Epoch: [1152][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0397 (0.0397)	
0.9999912 3.7008238e-07
===========>   testing    <===========
Epoch: [1152][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0770 (0.0770)	
0.9999964 3.2574428e-07
Epoch: [1152][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0341 (0.0589)	
0.99998677 3.3293142e-07
Epoch: [1152][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0708 (0.0556)	
0.9999902 4.2866975e-07
loss:  0.04045219118802501 0.03897757529122903
===========>   training    <===========
Epoch: [1153][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0411 (0.0411)	
0.9999924 3.952629e-07
===========>   testing    <===========
Epoch: [1153][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0637 (0.0637)	
0.9999962 2.1251317e-07
Epoch: [1153][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0267 (0.0589)	
0.99998856 2.18859e-07
Epoch: [1153][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0860 (0.0554)	
0.9999907 2.6639773e-07
loss:  0.038747089495286824 0.03897757529122903
===========>   training    <===========
Epoch: [1154][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0353 (0.0353)	
0.9999865 8.409642e-08
===========>   testing    <===========
Epoch: [1154][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0678 (0.0678)	
0.9999962 3.2405495e-07
Epoch: [1154][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0857 (0.0605)	
0.9999871 3.078384e-07
Epoch: [1154][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0639 (0.0559)	
0.9999893 3.7845888e-07
loss:  0.039951957826675266 0.038747089495286824
===========>   training    <===========
Epoch: [1155][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0384 (0.0384)	
0.99998975 2.4157768e-07
===========>   testing    <===========
Epoch: [1155][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0797 (0.0797)	
0.99999607 2.3728232e-07
Epoch: [1155][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0784 (0.0591)	
0.9999887 2.6578033e-07
Epoch: [1155][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0747 (0.0552)	
0.9999908 3.4011848e-07
loss:  0.03958041538907142 0.038747089495286824
===========>   training    <===========
Epoch: [1156][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0448 (0.0448)	
0.9999933 8.7501505e-08
===========>   testing    <===========
Epoch: [1156][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0828 (0.0828)	
0.99999595 2.443587e-07
Epoch: [1156][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.2850 (0.0609)	
0.9999881 2.5832495e-07
Epoch: [1156][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0543 (0.0556)	
0.9999901 3.211501e-07
loss:  0.04060193778118537 0.038747089495286824
===========>   training    <===========
Epoch: [1157][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0376 (0.0376)	
0.9999864 1.6334373e-07
===========>   testing    <===========
Epoch: [1157][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0995 (0.0995)	
0.9999962 2.9876014e-07
Epoch: [1157][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0524 (0.0584)	
0.9999894 3.1132694e-07
Epoch: [1157][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0518 (0.0539)	
0.9999913 4.156534e-07
loss:  0.0390952372817015 0.038747089495286824
===========>   training    <===========
Epoch: [1158][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0346 (0.0346)	
0.999995 5.7665556e-08
===========>   testing    <===========
Epoch: [1158][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0859 (0.0859)	
0.99999547 4.2977496e-07
Epoch: [1158][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0194 (0.0598)	
0.9999888 5.150811e-07
Epoch: [1158][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0747 (0.0560)	
0.99999166 5.936875e-07
loss:  0.03957810915048743 0.038747089495286824
===========>   training    <===========
Epoch: [1159][0/23]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0341 (0.0341)	
0.99997854 2.6933849e-08
===========>   testing    <===========
Epoch: [1159][0/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0730 (0.0730)	
0.9999962 3.6917572e-07
Epoch: [1159][100/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0249 (0.0581)	
0.9999912 3.9573703e-07
Epoch: [1159][200/289]	Lr-deconv: [0.0]	Lr-other: [5.373354598274029e-05]	Loss 0.0851 (0.0556)	
0.9999919 5.099666e-07
loss:  0.04014355735117059 0.038747089495286824
===========>   training    <===========
Epoch: [1160][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0383 (0.0383)	
0.9999938 6.638581e-08
===========>   testing    <===========
Epoch: [1160][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0751 (0.0751)	
0.9999958 3.0146137e-07
Epoch: [1160][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0280 (0.0584)	
0.99998736 3.4396365e-07
Epoch: [1160][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0824 (0.0559)	
0.9999907 3.7426415e-07
loss:  0.03954958587590074 0.038747089495286824
===========>   training    <===========
Epoch: [1161][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0381 (0.0381)	
0.9999919 7.709544e-07
===========>   testing    <===========
Epoch: [1161][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0777 (0.0777)	
0.9999951 2.3870086e-07
Epoch: [1161][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0244 (0.0573)	
0.9999875 2.9483775e-07
Epoch: [1161][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0899 (0.0554)	
0.99999225 3.105204e-07
loss:  0.03973107547633403 0.038747089495286824
===========>   training    <===========
Epoch: [1162][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0382 (0.0382)	
0.9999846 5.1474622e-08
===========>   testing    <===========
Epoch: [1162][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0938 (0.0938)	
0.9999951 3.1663097e-07
Epoch: [1162][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0330 (0.0582)	
0.9999881 3.0888472e-07
Epoch: [1162][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0805 (0.0557)	
0.9999919 3.7581356e-07
loss:  0.03947081205397618 0.038747089495286824
===========>   training    <===========
Epoch: [1163][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0429 (0.0429)	
0.99998176 2.5766719e-08
===========>   testing    <===========
Epoch: [1163][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.1010 (0.1010)	
0.9999956 3.2533165e-07
Epoch: [1163][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0375 (0.0605)	
0.9999889 4.916392e-07
Epoch: [1163][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0783 (0.0566)	
0.9999926 3.6578686e-07
loss:  0.04042279111536706 0.038747089495286824
===========>   training    <===========
Epoch: [1164][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0400 (0.0400)	
0.9999937 1.9638287e-08
===========>   testing    <===========
Epoch: [1164][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.1145 (0.1145)	
0.9999968 4.429669e-07
Epoch: [1164][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0342 (0.0579)	
0.9999896 5.45095e-07
Epoch: [1164][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0842 (0.0550)	
0.99999297 6.013403e-07
loss:  0.0393045434188789 0.038747089495286824
===========>   training    <===========
Epoch: [1165][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0371 (0.0371)	
0.9999896 6.209971e-08
===========>   testing    <===========
Epoch: [1165][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0844 (0.0844)	
0.9999962 5.335003e-07
Epoch: [1165][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0224 (0.0587)	
0.9999877 5.925929e-07
Epoch: [1165][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0729 (0.0559)	
0.99999166 7.749245e-07
loss:  0.03942120360380108 0.038747089495286824
===========>   training    <===========
Epoch: [1166][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0364 (0.0364)	
0.9999937 4.7531272e-09
===========>   testing    <===========
Epoch: [1166][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0871 (0.0871)	
0.9999958 4.3747355e-07
Epoch: [1166][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0232 (0.0594)	
0.99998987 5.448533e-07
Epoch: [1166][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0607 (0.0561)	
0.99999154 6.583835e-07
loss:  0.04000958578971914 0.038747089495286824
===========>   training    <===========
Epoch: [1167][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0360 (0.0360)	
0.99999464 8.190442e-08
===========>   testing    <===========
Epoch: [1167][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.1001 (0.1001)	
0.99999666 3.5844104e-07
Epoch: [1167][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0338 (0.0583)	
0.99999094 3.9908815e-07
Epoch: [1167][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0757 (0.0557)	
0.9999927 5.082808e-07
loss:  0.03980291373198519 0.038747089495286824
===========>   training    <===========
Epoch: [1168][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0304 (0.0304)	
0.9999924 3.276135e-08
===========>   testing    <===========
Epoch: [1168][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0959 (0.0959)	
0.99999666 2.6383907e-07
Epoch: [1168][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0435 (0.0591)	
0.9999894 2.8167227e-07
Epoch: [1168][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0842 (0.0560)	
0.9999924 3.0455826e-07
loss:  0.04012452503128805 0.038747089495286824
===========>   training    <===========
Epoch: [1169][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0380 (0.0380)	
0.9999938 8.625488e-07
===========>   testing    <===========
Epoch: [1169][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0815 (0.0815)	
0.99999523 3.1847924e-07
Epoch: [1169][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.1590 (0.0603)	
0.9999881 3.857883e-07
Epoch: [1169][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0881 (0.0567)	
0.9999908 3.4513573e-07
loss:  0.040378678801365586 0.038747089495286824
===========>   training    <===========
Epoch: [1170][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0430 (0.0430)	
0.9999862 2.4765011e-08
===========>   testing    <===========
Epoch: [1170][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0830 (0.0830)	
0.99999595 3.01004e-07
Epoch: [1170][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0788 (0.0588)	
0.99998736 4.6449014e-07
Epoch: [1170][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0941 (0.0557)	
0.9999907 3.6023468e-07
loss:  0.04030035212448613 0.038747089495286824
===========>   training    <===========
Epoch: [1171][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0344 (0.0344)	
0.9999801 1.526142e-07
===========>   testing    <===========
Epoch: [1171][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.1191 (0.1191)	
0.9999962 4.000225e-07
Epoch: [1171][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.1290 (0.0599)	
0.9999862 4.2813943e-07
Epoch: [1171][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0821 (0.0552)	
0.9999919 5.070361e-07
loss:  0.04058558975261828 0.038747089495286824
===========>   training    <===========
Epoch: [1172][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0298 (0.0298)	
0.999992 6.742104e-09
===========>   testing    <===========
Epoch: [1172][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0820 (0.0820)	
0.99999654 4.6361214e-07
Epoch: [1172][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.1072 (0.0597)	
0.9999857 5.247976e-07
Epoch: [1172][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0875 (0.0558)	
0.9999919 5.703538e-07
loss:  0.04043692087672768 0.038747089495286824
===========>   training    <===========
Epoch: [1173][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0365 (0.0365)	
0.9999914 6.324679e-08
===========>   testing    <===========
Epoch: [1173][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0733 (0.0733)	
0.9999964 6.3781755e-07
Epoch: [1173][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.1213 (0.0601)	
0.9999833 4.897617e-07
Epoch: [1173][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0898 (0.0560)	
0.99999166 8.4907265e-07
loss:  0.04052639943069769 0.038747089495286824
===========>   training    <===========
Epoch: [1174][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0351 (0.0351)	
0.9999858 5.960032e-07
===========>   testing    <===========
Epoch: [1174][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.1126 (0.1126)	
0.9999958 4.5467365e-07
Epoch: [1174][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0413 (0.0597)	
0.9999851 4.8060775e-07
Epoch: [1174][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0700 (0.0554)	
0.9999919 5.848145e-07
loss:  0.039980394263842145 0.038747089495286824
===========>   training    <===========
Epoch: [1175][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0366 (0.0366)	
0.9999902 7.569475e-08
===========>   testing    <===========
Epoch: [1175][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0939 (0.0939)	
0.9999964 3.9838577e-07
Epoch: [1175][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0359 (0.0598)	
0.99998677 4.6710394e-07
Epoch: [1175][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0723 (0.0558)	
0.99999225 4.5274646e-07
loss:  0.04076224138068141 0.038747089495286824
===========>   training    <===========
Epoch: [1176][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0323 (0.0323)	
0.9999877 2.349454e-08
===========>   testing    <===========
Epoch: [1176][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.1047 (0.1047)	
0.99999654 5.4737825e-07
Epoch: [1176][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0348 (0.0598)	
0.99998534 5.2665365e-07
Epoch: [1176][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0806 (0.0569)	
0.9999927 5.708555e-07
loss:  0.04239576939022316 0.038747089495286824
===========>   training    <===========
Epoch: [1177][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0375 (0.0375)	
0.9999895 6.218718e-08
===========>   testing    <===========
Epoch: [1177][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.1080 (0.1080)	
0.99999666 3.2886945e-07
Epoch: [1177][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0380 (0.0597)	
0.99998736 3.7962175e-07
Epoch: [1177][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.1032 (0.0566)	
0.99999285 3.6357943e-07
loss:  0.04015652680670123 0.038747089495286824
===========>   training    <===========
Epoch: [1178][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0362 (0.0362)	
0.99999213 2.6081048e-07
===========>   testing    <===========
Epoch: [1178][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0908 (0.0908)	
0.999997 2.8291552e-07
Epoch: [1178][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.1457 (0.0606)	
0.9999887 2.2045313e-07
Epoch: [1178][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.1034 (0.0574)	
0.99999356 3.456687e-07
loss:  0.04258418397505814 0.038747089495286824
===========>   training    <===========
Epoch: [1179][0/23]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0358 (0.0358)	
0.99999297 3.9799573e-08
===========>   testing    <===========
Epoch: [1179][0/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.1075 (0.1075)	
0.999997 2.9623342e-07
Epoch: [1179][100/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.0991 (0.0603)	
0.99998987 2.9389338e-07
Epoch: [1179][200/289]	Lr-deconv: [0.0]	Lr-other: [5.1046868683603266e-05]	Loss 0.1002 (0.0567)	
0.9999937 3.9295895e-07
loss:  0.04138942013308333 0.038747089495286824
===========>   training    <===========
Epoch: [1180][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0292 (0.0292)	
0.9999912 3.09563e-07
===========>   testing    <===========
Epoch: [1180][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.1063 (0.1063)	
0.9999964 2.7538832e-07
Epoch: [1180][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.1059 (0.0596)	
0.9999895 3.896329e-07
Epoch: [1180][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.1092 (0.0561)	
0.99999225 3.772866e-07
loss:  0.04119677833796487 0.038747089495286824
===========>   training    <===========
Epoch: [1181][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0400 (0.0400)	
0.9999887 6.304589e-08
===========>   testing    <===========
Epoch: [1181][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.1195 (0.1195)	
0.9999963 2.7576624e-07
Epoch: [1181][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.1947 (0.0598)	
0.99998677 3.2165892e-07
Epoch: [1181][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.1024 (0.0556)	
0.9999919 3.2936785e-07
loss:  0.040563088242357104 0.038747089495286824
===========>   training    <===========
Epoch: [1182][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0343 (0.0343)	
0.9999925 6.37184e-07
===========>   testing    <===========
Epoch: [1182][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.1066 (0.1066)	
0.9999963 4.852723e-07
Epoch: [1182][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.1922 (0.0623)	
0.9999906 5.8527417e-07
Epoch: [1182][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0800 (0.0569)	
0.9999908 5.0752374e-07
loss:  0.041251256695909344 0.038747089495286824
===========>   training    <===========
Epoch: [1183][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0329 (0.0329)	
0.99999 4.3336058e-07
===========>   testing    <===========
Epoch: [1183][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.1158 (0.1158)	
0.99999523 2.7209273e-07
Epoch: [1183][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.1609 (0.0612)	
0.9999857 3.5071596e-07
Epoch: [1183][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0893 (0.0568)	
0.9999883 3.1714532e-07
loss:  0.041185590329432475 0.038747089495286824
===========>   training    <===========
Epoch: [1184][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0337 (0.0337)	
0.99998844 3.6825588e-07
===========>   testing    <===========
Epoch: [1184][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.1156 (0.1156)	
0.99999607 2.8306692e-07
Epoch: [1184][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.1734 (0.0616)	
0.9999882 4.1294496e-07
Epoch: [1184][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0908 (0.0568)	
0.9999924 3.2188845e-07
loss:  0.04108706285043562 0.038747089495286824
===========>   training    <===========
Epoch: [1185][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0320 (0.0320)	
0.99998724 3.7291848e-06
===========>   testing    <===========
Epoch: [1185][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.1242 (0.1242)	
0.9999956 1.599522e-07
Epoch: [1185][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.1240 (0.0624)	
0.9999865 2.502341e-07
Epoch: [1185][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0915 (0.0580)	
0.9999926 1.905997e-07
loss:  0.041149954347395434 0.038747089495286824
===========>   training    <===========
Epoch: [1186][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0357 (0.0357)	
0.9999895 1.6836576e-07
===========>   testing    <===========
Epoch: [1186][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0991 (0.0991)	
0.9999951 3.0405153e-07
Epoch: [1186][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0560 (0.0618)	
0.99998724 4.6544443e-07
Epoch: [1186][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0939 (0.0582)	
0.9999919 3.3547286e-07
loss:  0.04148061775695966 0.038747089495286824
===========>   training    <===========
Epoch: [1187][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0301 (0.0301)	
0.99999225 4.21165e-08
===========>   testing    <===========
Epoch: [1187][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.1071 (0.1071)	
0.9999956 2.7525653e-07
Epoch: [1187][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0903 (0.0595)	
0.9999875 3.9595864e-07
Epoch: [1187][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.1227 (0.0574)	
0.9999919 3.381711e-07
loss:  0.041521643945714226 0.038747089495286824
===========>   training    <===========
Epoch: [1188][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0288 (0.0288)	
0.9999826 3.2935247e-07
===========>   testing    <===========
Epoch: [1188][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.1020 (0.1020)	
0.99999535 3.8087393e-07
Epoch: [1188][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.2052 (0.0635)	
0.99998856 6.3278276e-07
Epoch: [1188][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0852 (0.0586)	
0.9999908 4.7236398e-07
loss:  0.04258891182281699 0.038747089495286824
===========>   training    <===========
Epoch: [1189][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0455 (0.0455)	
0.99998975 2.9094684e-07
===========>   testing    <===========
Epoch: [1189][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0908 (0.0908)	
0.9999957 4.5474047e-07
Epoch: [1189][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.1643 (0.0618)	
0.9999895 7.31458e-07
Epoch: [1189][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0806 (0.0567)	
0.99999154 5.5494934e-07
loss:  0.04178296930073799 0.038747089495286824
===========>   training    <===========
Epoch: [1190][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0403 (0.0403)	
0.9999957 9.772709e-07
===========>   testing    <===========
Epoch: [1190][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0954 (0.0954)	
0.9999964 3.721628e-07
Epoch: [1190][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0723 (0.0598)	
0.99998736 3.937223e-07
Epoch: [1190][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0977 (0.0559)	
0.9999912 4.758237e-07
loss:  0.040580166631059456 0.038747089495286824
===========>   training    <===========
Epoch: [1191][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0378 (0.0378)	
0.99998105 2.3973286e-08
===========>   testing    <===========
Epoch: [1191][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0901 (0.0901)	
0.9999969 2.7209066e-07
Epoch: [1191][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0997 (0.0605)	
0.9999908 2.82005e-07
Epoch: [1191][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0997 (0.0566)	
0.9999926 3.195986e-07
loss:  0.041128637392672585 0.038747089495286824
===========>   training    <===========
Epoch: [1192][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0372 (0.0372)	
0.99999094 1.20519745e-08
===========>   testing    <===========
Epoch: [1192][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0827 (0.0827)	
0.99999666 3.5521438e-07
Epoch: [1192][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.1156 (0.0608)	
0.9999887 3.695837e-07
Epoch: [1192][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.1017 (0.0571)	
0.9999919 4.117228e-07
loss:  0.04123317497186585 0.038747089495286824
===========>   training    <===========
Epoch: [1193][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0389 (0.0389)	
0.9999968 7.538499e-08
===========>   testing    <===========
Epoch: [1193][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0769 (0.0769)	
0.99999547 2.7244846e-07
Epoch: [1193][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.1543 (0.0629)	
0.9999852 2.8159545e-07
Epoch: [1193][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0806 (0.0580)	
0.9999895 3.0588703e-07
loss:  0.041693307861513706 0.038747089495286824
===========>   training    <===========
Epoch: [1194][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0323 (0.0323)	
0.9999852 5.362764e-07
===========>   testing    <===========
Epoch: [1194][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.1186 (0.1186)	
0.99999535 2.884394e-07
Epoch: [1194][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.1765 (0.0617)	
0.9999831 3.9734425e-07
Epoch: [1194][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0796 (0.0566)	
0.9999895 3.668751e-07
loss:  0.04118954067822633 0.038747089495286824
===========>   training    <===========
Epoch: [1195][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0369 (0.0369)	
0.99998796 2.0926994e-07
===========>   testing    <===========
Epoch: [1195][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0992 (0.0992)	
0.99999607 1.893303e-07
Epoch: [1195][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.1472 (0.0619)	
0.99998534 2.0824149e-07
Epoch: [1195][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0796 (0.0572)	
0.9999913 2.2012729e-07
loss:  0.04161526164118168 0.038747089495286824
===========>   training    <===========
Epoch: [1196][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0351 (0.0351)	
0.99999404 2.5903444e-07
===========>   testing    <===========
Epoch: [1196][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.1013 (0.1013)	
0.999995 1.9342166e-07
Epoch: [1196][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.2377 (0.0625)	
0.99998415 2.0212465e-07
Epoch: [1196][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0811 (0.0572)	
0.99999046 2.1296316e-07
loss:  0.04168990168356135 0.038747089495286824
===========>   training    <===========
Epoch: [1197][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0351 (0.0351)	
0.99998724 5.472507e-09
===========>   testing    <===========
Epoch: [1197][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0894 (0.0894)	
0.9999958 1.9653301e-07
Epoch: [1197][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.2778 (0.0628)	
0.9999844 2.0200055e-07
Epoch: [1197][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0729 (0.0575)	
0.9999908 2.2020224e-07
loss:  0.04209767248763674 0.038747089495286824
===========>   training    <===========
Epoch: [1198][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0340 (0.0340)	
0.9999881 5.4613942e-08
===========>   testing    <===========
Epoch: [1198][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0767 (0.0767)	
0.99999547 3.4440973e-07
Epoch: [1198][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0922 (0.0603)	
0.99998534 3.3802985e-07
Epoch: [1198][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.1017 (0.0567)	
0.99999106 3.9047657e-07
loss:  0.04190799774834342 0.038747089495286824
===========>   training    <===========
Epoch: [1199][0/23]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0438 (0.0438)	
0.9999864 1.510141e-07
===========>   testing    <===========
Epoch: [1199][0/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.0771 (0.0771)	
0.9999964 4.1313444e-07
Epoch: [1199][100/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.1051 (0.0608)	
0.9999887 4.1951427e-07
Epoch: [1199][200/289]	Lr-deconv: [0.0]	Lr-other: [4.8494525249423105e-05]	Loss 0.1077 (0.0573)	
0.99999225 4.65777e-07
loss:  0.041876628950842654 0.038747089495286824
===========>   training    <===========
Epoch: [1200][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0366 (0.0366)	
0.99998426 3.4661016e-07
===========>   testing    <===========
Epoch: [1200][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.1106 (0.1106)	
0.9999962 3.2780292e-07
Epoch: [1200][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.1044 (0.0597)	
0.9999877 3.3255313e-07
Epoch: [1200][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0923 (0.0565)	
0.99999213 3.9006122e-07
loss:  0.04153333045144669 0.038747089495286824
===========>   training    <===========
Epoch: [1201][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0352 (0.0352)	
0.99999094 7.650202e-09
===========>   testing    <===========
Epoch: [1201][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.1157 (0.1157)	
0.9999956 3.4255112e-07
Epoch: [1201][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.2889 (0.0621)	
0.99998736 3.7691908e-07
Epoch: [1201][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0894 (0.0570)	
0.9999913 3.9549593e-07
loss:  0.04113565544269704 0.038747089495286824
===========>   training    <===========
Epoch: [1202][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0316 (0.0316)	
0.9999864 1.80392e-07
===========>   testing    <===========
Epoch: [1202][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.1049 (0.1049)	
0.999995 2.1799971e-07
Epoch: [1202][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.2394 (0.0623)	
0.9999827 2.2466317e-07
Epoch: [1202][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0879 (0.0574)	
0.99998987 2.4865813e-07
loss:  0.04176797206093985 0.038747089495286824
===========>   training    <===========
Epoch: [1203][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0437 (0.0437)	
0.9999821 6.60239e-08
===========>   testing    <===========
Epoch: [1203][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0890 (0.0890)	
0.99999535 2.3833236e-07
Epoch: [1203][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0491 (0.0612)	
0.9999852 3.2061672e-07
Epoch: [1203][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0922 (0.0562)	
0.9999896 3.1400518e-07
loss:  0.0410780780217086 0.038747089495286824
===========>   training    <===========
Epoch: [1204][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0286 (0.0286)	
0.9999918 1.4207745e-07
===========>   testing    <===========
Epoch: [1204][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0798 (0.0798)	
0.9999957 2.5039168e-07
Epoch: [1204][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.2424 (0.0608)	
0.9999846 2.644e-07
Epoch: [1204][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.1062 (0.0557)	
0.99999106 3.2331474e-07
loss:  0.040710004917878906 0.038747089495286824
===========>   training    <===========
Epoch: [1205][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0360 (0.0360)	
0.9999988 4.8049042e-08
===========>   testing    <===========
Epoch: [1205][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0875 (0.0875)	
0.99999607 2.9045e-07
Epoch: [1205][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.3112 (0.0622)	
0.9999833 3.9218546e-07
Epoch: [1205][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0998 (0.0561)	
0.9999914 3.8892307e-07
loss:  0.040905895370651146 0.038747089495286824
===========>   training    <===========
Epoch: [1206][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0387 (0.0387)	
0.99998987 2.4055603e-07
===========>   testing    <===========
Epoch: [1206][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0715 (0.0715)	
0.9999963 4.2760286e-07
Epoch: [1206][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.2767 (0.0629)	
0.9999887 4.1771457e-07
Epoch: [1206][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.1080 (0.0574)	
0.99999285 6.0909167e-07
loss:  0.04198654545771019 0.038747089495286824
===========>   training    <===========
Epoch: [1207][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0349 (0.0349)	
0.9999877 5.840537e-07
===========>   testing    <===========
Epoch: [1207][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0644 (0.0644)	
0.9999964 3.292931e-07
Epoch: [1207][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0973 (0.0606)	
0.99998295 3.5697963e-07
Epoch: [1207][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.1100 (0.0558)	
0.9999919 4.0542776e-07
loss:  0.040204475501831594 0.038747089495286824
===========>   training    <===========
Epoch: [1208][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0293 (0.0293)	
0.9999851 9.161057e-08
===========>   testing    <===========
Epoch: [1208][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0804 (0.0804)	
0.9999964 4.315529e-07
Epoch: [1208][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.1051 (0.0616)	
0.99998355 4.7510363e-07
Epoch: [1208][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0810 (0.0566)	
0.99999225 5.6087384e-07
loss:  0.04076750723535416 0.038747089495286824
===========>   training    <===========
Epoch: [1209][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0402 (0.0402)	
0.99999106 9.4303215e-07
===========>   testing    <===========
Epoch: [1209][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0596 (0.0596)	
0.99999654 5.513837e-07
Epoch: [1209][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0390 (0.0610)	
0.9999857 5.02202e-07
Epoch: [1209][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0944 (0.0566)	
0.9999924 7.08946e-07
loss:  0.041498958217329074 0.038747089495286824
===========>   training    <===========
Epoch: [1210][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0366 (0.0366)	
0.9999926 6.296213e-07
===========>   testing    <===========
Epoch: [1210][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0546 (0.0546)	
0.9999962 3.9320372e-07
Epoch: [1210][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0287 (0.0621)	
0.9999825 5.264518e-07
Epoch: [1210][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.1124 (0.0578)	
0.99999106 5.142977e-07
loss:  0.04136629102741929 0.038747089495286824
===========>   training    <===========
Epoch: [1211][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0338 (0.0338)	
0.9999902 5.3270213e-07
===========>   testing    <===========
Epoch: [1211][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0697 (0.0697)	
0.9999962 5.445759e-07
Epoch: [1211][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0224 (0.0625)	
0.999984 5.48234e-07
Epoch: [1211][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0962 (0.0583)	
0.9999918 5.85483e-07
loss:  0.04114964251844344 0.038747089495286824
===========>   training    <===========
Epoch: [1212][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0341 (0.0341)	
0.99998426 2.5821635e-07
===========>   testing    <===========
Epoch: [1212][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0959 (0.0959)	
0.9999958 4.114508e-07
Epoch: [1212][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0351 (0.0612)	
0.9999827 3.694279e-07
Epoch: [1212][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0996 (0.0576)	
0.9999919 4.9960147e-07
loss:  0.04036049700240829 0.038747089495286824
===========>   training    <===========
Epoch: [1213][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0366 (0.0366)	
0.9999937 2.075151e-07
===========>   testing    <===========
Epoch: [1213][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0893 (0.0893)	
0.9999963 3.8068512e-07
Epoch: [1213][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0581 (0.0627)	
0.99998236 4.773954e-07
Epoch: [1213][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0941 (0.0579)	
0.99999213 4.743593e-07
loss:  0.040808254717235815 0.038747089495286824
===========>   training    <===========
Epoch: [1214][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0338 (0.0338)	
0.9999914 5.93555e-07
===========>   testing    <===========
Epoch: [1214][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0752 (0.0752)	
0.9999964 3.639541e-07
Epoch: [1214][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0618 (0.0632)	
0.99998677 5.071265e-07
Epoch: [1214][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0929 (0.0584)	
0.99999356 5.020134e-07
loss:  0.04173541048027707 0.038747089495286824
===========>   training    <===========
Epoch: [1215][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0422 (0.0422)	
0.99998105 2.509687e-08
===========>   testing    <===========
Epoch: [1215][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0801 (0.0801)	
0.9999958 3.2454548e-07
Epoch: [1215][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0410 (0.0614)	
0.9999802 3.9071423e-07
Epoch: [1215][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0918 (0.0570)	
0.9999912 4.7265598e-07
loss:  0.04214913200721282 0.038747089495286824
===========>   training    <===========
Epoch: [1216][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0376 (0.0376)	
0.99999654 4.2658783e-07
===========>   testing    <===========
Epoch: [1216][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0912 (0.0912)	
0.9999962 3.7871993e-07
Epoch: [1216][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0285 (0.0614)	
0.99998343 3.519973e-07
Epoch: [1216][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0919 (0.0569)	
0.9999907 4.757157e-07
loss:  0.04135497741617855 0.038747089495286824
===========>   training    <===========
Epoch: [1217][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0475 (0.0475)	
0.99999046 1.8059683e-07
===========>   testing    <===========
Epoch: [1217][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0839 (0.0839)	
0.99999595 4.4958145e-07
Epoch: [1217][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0335 (0.0615)	
0.9999838 4.857919e-07
Epoch: [1217][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0739 (0.0569)	
0.99999 5.756412e-07
loss:  0.04176503037034729 0.038747089495286824
===========>   training    <===========
Epoch: [1218][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0396 (0.0396)	
0.9999931 3.6622805e-07
===========>   testing    <===========
Epoch: [1218][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0955 (0.0955)	
0.99999547 3.4810748e-07
Epoch: [1218][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0356 (0.0634)	
0.9999809 3.9786408e-07
Epoch: [1218][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0707 (0.0585)	
0.99998796 3.946102e-07
loss:  0.04210403624199954 0.038747089495286824
===========>   training    <===========
Epoch: [1219][0/23]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0369 (0.0369)	
0.9999876 1.9705925e-07
===========>   testing    <===========
Epoch: [1219][0/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.1073 (0.1073)	
0.99999547 3.8721623e-07
Epoch: [1219][100/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0358 (0.0631)	
0.99998176 3.8120862e-07
Epoch: [1219][200/289]	Lr-deconv: [0.0]	Lr-other: [4.6069798986951947e-05]	Loss 0.0817 (0.0582)	
0.99999034 4.9776617e-07
loss:  0.04221189552160998 0.038747089495286824
===========>   training    <===========
Epoch: [1220][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0339 (0.0339)	
0.99999595 2.5909029e-07
===========>   testing    <===========
Epoch: [1220][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.1162 (0.1162)	
0.9999963 4.1977518e-07
Epoch: [1220][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0831 (0.0636)	
0.99998796 5.5642465e-07
Epoch: [1220][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0721 (0.0578)	
0.9999918 5.2347394e-07
loss:  0.042215443758241045 0.038747089495286824
===========>   training    <===========
Epoch: [1221][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0457 (0.0457)	
0.9999894 7.748138e-08
===========>   testing    <===========
Epoch: [1221][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0886 (0.0886)	
0.99999607 3.0779142e-07
Epoch: [1221][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0524 (0.0626)	
0.99998593 3.5362513e-07
Epoch: [1221][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0865 (0.0571)	
0.99999213 3.6006983e-07
loss:  0.04136554187926733 0.038747089495286824
===========>   training    <===========
Epoch: [1222][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0402 (0.0402)	
0.99999213 8.8375025e-08
===========>   testing    <===========
Epoch: [1222][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.1233 (0.1233)	
0.99999535 2.4917443e-07
Epoch: [1222][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0437 (0.0618)	
0.9999826 3.921204e-07
Epoch: [1222][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0855 (0.0568)	
0.99999166 3.0529833e-07
loss:  0.041913462585471906 0.038747089495286824
===========>   training    <===========
Epoch: [1223][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0334 (0.0334)	
0.99999404 2.4805727e-06
===========>   testing    <===========
Epoch: [1223][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.1204 (0.1204)	
0.9999962 3.4622857e-07
Epoch: [1223][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0250 (0.0618)	
0.9999862 3.385144e-07
Epoch: [1223][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.1018 (0.0575)	
0.9999926 4.322486e-07
loss:  0.0419158054392591 0.038747089495286824
===========>   training    <===========
Epoch: [1224][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0324 (0.0324)	
0.9999951 7.9089624e-08
===========>   testing    <===========
Epoch: [1224][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0898 (0.0898)	
0.9999963 3.4055148e-07
Epoch: [1224][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0222 (0.0620)	
0.9999845 3.5042274e-07
Epoch: [1224][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.1081 (0.0572)	
0.9999931 3.485569e-07
loss:  0.04190792291424683 0.038747089495286824
===========>   training    <===========
Epoch: [1225][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0305 (0.0305)	
0.9999956 1.8219527e-07
===========>   testing    <===========
Epoch: [1225][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0747 (0.0747)	
0.9999958 3.7050086e-07
Epoch: [1225][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0232 (0.0629)	
0.99998546 4.970608e-07
Epoch: [1225][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0932 (0.0572)	
0.9999925 3.985701e-07
loss:  0.04206637818002357 0.038747089495286824
===========>   training    <===========
Epoch: [1226][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0313 (0.0313)	
0.9999951 9.5941886e-08
===========>   testing    <===========
Epoch: [1226][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0880 (0.0880)	
0.99999535 2.6655889e-07
Epoch: [1226][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0201 (0.0613)	
0.9999819 2.8204212e-07
Epoch: [1226][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.1019 (0.0568)	
0.9999912 2.6057705e-07
loss:  0.04114921670487426 0.038747089495286824
===========>   training    <===========
Epoch: [1227][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0388 (0.0388)	
0.9999883 1.0865293e-08
===========>   testing    <===========
Epoch: [1227][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0853 (0.0853)	
0.99999535 3.0170872e-07
Epoch: [1227][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0430 (0.0642)	
0.999982 3.9110046e-07
Epoch: [1227][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0993 (0.0584)	
0.9999919 2.9897333e-07
loss:  0.04225174943083754 0.038747089495286824
===========>   training    <===========
Epoch: [1228][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0352 (0.0352)	
0.9999845 1.3073613e-08
===========>   testing    <===========
Epoch: [1228][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0843 (0.0843)	
0.9999956 3.9686103e-07
Epoch: [1228][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0262 (0.0636)	
0.9999845 4.2490487e-07
Epoch: [1228][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0958 (0.0576)	
0.9999932 4.4107253e-07
loss:  0.04122546726655718 0.038747089495286824
===========>   training    <===========
Epoch: [1229][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0327 (0.0327)	
0.99998915 3.705782e-08
===========>   testing    <===========
Epoch: [1229][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0903 (0.0903)	
0.9999956 3.2906362e-07
Epoch: [1229][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0177 (0.0622)	
0.9999882 3.8547714e-07
Epoch: [1229][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0985 (0.0570)	
0.9999926 3.6950368e-07
loss:  0.041273237404584884 0.038747089495286824
===========>   training    <===========
Epoch: [1230][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0385 (0.0385)	
0.99999356 3.55083e-07
===========>   testing    <===========
Epoch: [1230][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.1027 (0.1027)	
0.999995 3.2467491e-07
Epoch: [1230][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0227 (0.0630)	
0.9999863 2.3148039e-07
Epoch: [1230][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0814 (0.0567)	
0.9999927 4.0219751e-07
loss:  0.04152211067112843 0.038747089495286824
===========>   training    <===========
Epoch: [1231][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0406 (0.0406)	
0.9999869 4.438928e-09
===========>   testing    <===========
Epoch: [1231][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0704 (0.0704)	
0.9999958 2.740059e-07
Epoch: [1231][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0250 (0.0614)	
0.99998784 3.433796e-07
Epoch: [1231][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0970 (0.0558)	
0.99999297 2.913061e-07
loss:  0.04080566101577354 0.038747089495286824
===========>   training    <===========
Epoch: [1232][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0418 (0.0418)	
0.99999166 1.7878953e-08
===========>   testing    <===========
Epoch: [1232][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0759 (0.0759)	
0.99999547 2.6083387e-07
Epoch: [1232][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0366 (0.0619)	
0.99998474 2.550158e-07
Epoch: [1232][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.1003 (0.0561)	
0.99999154 2.988673e-07
loss:  0.041112166492438096 0.038747089495286824
===========>   training    <===========
Epoch: [1233][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0366 (0.0366)	
0.99999034 8.021476e-08
===========>   testing    <===========
Epoch: [1233][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0947 (0.0947)	
0.999995 2.5981055e-07
Epoch: [1233][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0227 (0.0599)	
0.99998116 2.0061445e-07
Epoch: [1233][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.1060 (0.0552)	
0.99998975 2.1479605e-07
loss:  0.04049696999936414 0.038747089495286824
===========>   training    <===========
Epoch: [1234][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0360 (0.0360)	
0.99999523 3.780307e-08
===========>   testing    <===========
Epoch: [1234][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0848 (0.0848)	
0.99999535 2.0520703e-07
Epoch: [1234][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0202 (0.0588)	
0.99998224 1.5567264e-07
Epoch: [1234][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0934 (0.0540)	
0.99999046 1.9923823e-07
loss:  0.03987441692080895 0.038747089495286824
===========>   training    <===========
Epoch: [1235][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0378 (0.0378)	
0.99999523 5.27474e-07
===========>   testing    <===========
Epoch: [1235][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.1057 (0.1057)	
0.9999963 2.481618e-07
Epoch: [1235][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0224 (0.0599)	
0.9999862 2.955114e-07
Epoch: [1235][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0915 (0.0548)	
0.99999213 2.9014492e-07
loss:  0.04016685891393956 0.038747089495286824
===========>   training    <===========
Epoch: [1236][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0383 (0.0383)	
0.99999046 1.2126827e-07
===========>   testing    <===========
Epoch: [1236][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.1050 (0.1050)	
0.99999607 3.4231402e-07
Epoch: [1236][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0659 (0.0622)	
0.9999888 4.006081e-07
Epoch: [1236][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.1031 (0.0572)	
0.9999927 3.7913696e-07
loss:  0.040590228164460784 0.038747089495286824
===========>   training    <===========
Epoch: [1237][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0324 (0.0324)	
0.9999862 3.4395808e-07
===========>   testing    <===========
Epoch: [1237][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.1215 (0.1215)	
0.9999962 3.4506925e-07
Epoch: [1237][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0230 (0.0608)	
0.9999876 4.2626817e-07
Epoch: [1237][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.1047 (0.0565)	
0.9999939 4.0765593e-07
loss:  0.04069422485980845 0.038747089495286824
===========>   training    <===========
Epoch: [1238][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0409 (0.0409)	
0.9999758 3.062478e-08
===========>   testing    <===========
Epoch: [1238][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.1186 (0.1186)	
0.9999956 3.392461e-07
Epoch: [1238][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0343 (0.0612)	
0.999985 4.440006e-07
Epoch: [1238][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0964 (0.0564)	
0.9999913 3.9446198e-07
loss:  0.0405997390865962 0.038747089495286824
===========>   training    <===========
Epoch: [1239][0/23]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0389 (0.0389)	
0.99999 2.2653299e-07
===========>   testing    <===========
Epoch: [1239][0/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0911 (0.0911)	
0.99999547 3.7246318e-07
Epoch: [1239][100/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.0352 (0.0613)	
0.9999858 5.9708185e-07
Epoch: [1239][200/289]	Lr-deconv: [0.0]	Lr-other: [4.3766309037604346e-05]	Loss 0.1084 (0.0572)	
0.9999919 3.981203e-07
loss:  0.0410686654598762 0.038747089495286824
===========>   training    <===========
Epoch: [1240][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0417 (0.0417)	
0.9999862 6.969033e-08
===========>   testing    <===========
Epoch: [1240][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1233 (0.1233)	
0.99999607 2.6910567e-07
Epoch: [1240][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0908 (0.0624)	
0.99998784 4.1687335e-07
Epoch: [1240][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1221 (0.0582)	
0.9999926 2.938561e-07
loss:  0.04121056016854929 0.038747089495286824
===========>   training    <===========
Epoch: [1241][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0323 (0.0323)	
0.9999926 1.99461e-08
===========>   testing    <===========
Epoch: [1241][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1415 (0.1415)	
0.99999607 3.7733918e-07
Epoch: [1241][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0458 (0.0612)	
0.99998677 4.188898e-07
Epoch: [1241][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1229 (0.0570)	
0.9999924 4.8203805e-07
loss:  0.04126568903916661 0.038747089495286824
===========>   training    <===========
Epoch: [1242][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0317 (0.0317)	
0.9999864 6.9844947e-07
===========>   testing    <===========
Epoch: [1242][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1493 (0.1493)	
0.9999957 3.0076183e-07
Epoch: [1242][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0576 (0.0613)	
0.99998474 2.9904518e-07
Epoch: [1242][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0986 (0.0564)	
0.99999225 3.8265102e-07
loss:  0.041204702385216674 0.038747089495286824
===========>   training    <===========
Epoch: [1243][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0384 (0.0384)	
0.99999106 2.2313701e-08
===========>   testing    <===========
Epoch: [1243][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1511 (0.1511)	
0.99999654 2.1019521e-07
Epoch: [1243][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0237 (0.0626)	
0.99998724 2.153063e-07
Epoch: [1243][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1093 (0.0581)	
0.99999285 2.4447849e-07
loss:  0.0418263722089699 0.038747089495286824
===========>   training    <===========
Epoch: [1244][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0459 (0.0459)	
0.9999944 1.3071893e-08
===========>   testing    <===========
Epoch: [1244][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1230 (0.1230)	
0.999997 2.5775378e-07
Epoch: [1244][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0326 (0.0623)	
0.9999894 2.6228915e-07
Epoch: [1244][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1038 (0.0584)	
0.99999297 3.2747766e-07
loss:  0.04155969442035223 0.038747089495286824
===========>   training    <===========
Epoch: [1245][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0415 (0.0415)	
0.9999939 1.3907017e-07
===========>   testing    <===========
Epoch: [1245][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1162 (0.1162)	
0.999997 2.5605297e-07
Epoch: [1245][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0520 (0.0643)	
0.9999924 2.655607e-07
Epoch: [1245][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0900 (0.0593)	
0.99999344 3.1135394e-07
loss:  0.04139539682806759 0.038747089495286824
===========>   training    <===========
Epoch: [1246][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0371 (0.0371)	
0.99999714 1.2912633e-07
===========>   testing    <===========
Epoch: [1246][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1448 (0.1448)	
0.99999666 2.113226e-07
Epoch: [1246][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1247 (0.0615)	
0.99999046 2.3661345e-07
Epoch: [1246][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0966 (0.0570)	
0.9999933 2.7314726e-07
loss:  0.04109368350470333 0.038747089495286824
===========>   training    <===========
Epoch: [1247][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0326 (0.0326)	
0.9999871 7.846217e-08
===========>   testing    <===========
Epoch: [1247][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1401 (0.1401)	
0.9999963 1.8730645e-07
Epoch: [1247][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1426 (0.0612)	
0.99998784 3.3059422e-07
Epoch: [1247][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1089 (0.0565)	
0.99999285 3.030609e-07
loss:  0.04110696038948858 0.038747089495286824
===========>   training    <===========
Epoch: [1248][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0300 (0.0300)	
0.99999607 5.3526566e-08
===========>   testing    <===========
Epoch: [1248][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1413 (0.1413)	
0.9999969 2.9949413e-07
Epoch: [1248][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1094 (0.0611)	
0.9999894 2.9470675e-07
Epoch: [1248][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1083 (0.0569)	
0.9999931 3.3988115e-07
loss:  0.0414212787237771 0.038747089495286824
===========>   training    <===========
Epoch: [1249][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0424 (0.0424)	
0.9999963 1.5072347e-07
===========>   testing    <===========
Epoch: [1249][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1466 (0.1466)	
0.9999962 3.7932864e-07
Epoch: [1249][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0694 (0.0621)	
0.99998724 4.0845094e-07
Epoch: [1249][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1032 (0.0576)	
0.9999926 4.7380863e-07
loss:  0.042309362120679705 0.038747089495286824
===========>   training    <===========
Epoch: [1250][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0439 (0.0439)	
0.99999607 1.5887993e-07
===========>   testing    <===========
Epoch: [1250][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1198 (0.1198)	
0.99999607 3.0874278e-07
Epoch: [1250][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0378 (0.0622)	
0.9999869 3.205736e-07
Epoch: [1250][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1103 (0.0578)	
0.9999913 3.9116085e-07
loss:  0.04160806251193805 0.038747089495286824
===========>   training    <===========
Epoch: [1251][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0335 (0.0335)	
0.9999902 1.4245708e-07
===========>   testing    <===========
Epoch: [1251][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1167 (0.1167)	
0.99999595 2.1136069e-07
Epoch: [1251][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0387 (0.0622)	
0.99998736 2.4548734e-07
Epoch: [1251][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1134 (0.0574)	
0.9999914 2.9003095e-07
loss:  0.04011314329590654 0.038747089495286824
===========>   training    <===========
Epoch: [1252][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0372 (0.0372)	
0.9999927 3.110818e-07
===========>   testing    <===========
Epoch: [1252][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1286 (0.1286)	
0.9999962 2.1436425e-07
Epoch: [1252][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0389 (0.0614)	
0.9999869 2.5470615e-07
Epoch: [1252][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1111 (0.0560)	
0.9999919 2.9120721e-07
loss:  0.03992564260138087 0.038747089495286824
===========>   training    <===========
Epoch: [1253][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0337 (0.0337)	
0.9999857 3.640367e-07
===========>   testing    <===========
Epoch: [1253][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1446 (0.1446)	
0.99999666 1.786945e-07
Epoch: [1253][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0513 (0.0639)	
0.99999 1.727707e-07
Epoch: [1253][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1050 (0.0580)	
0.9999926 1.9205815e-07
loss:  0.04145002822147048 0.038747089495286824
===========>   training    <===========
Epoch: [1254][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0355 (0.0355)	
0.9999938 4.939078e-09
===========>   testing    <===========
Epoch: [1254][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1579 (0.1579)	
0.99999607 2.0288594e-07
Epoch: [1254][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0626 (0.0630)	
0.9999889 3.1864298e-07
Epoch: [1254][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1032 (0.0575)	
0.9999926 2.6122098e-07
loss:  0.041396992061953575 0.038747089495286824
===========>   training    <===========
Epoch: [1255][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0333 (0.0333)	
0.9999914 2.9480793e-07
===========>   testing    <===========
Epoch: [1255][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1425 (0.1425)	
0.99999607 1.820544e-07
Epoch: [1255][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0444 (0.0621)	
0.9999875 2.873834e-07
Epoch: [1255][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1088 (0.0569)	
0.9999924 2.4781156e-07
loss:  0.04047921599593718 0.038747089495286824
===========>   training    <===========
Epoch: [1256][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0420 (0.0420)	
0.99998546 1.5083246e-07
===========>   testing    <===========
Epoch: [1256][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1185 (0.1185)	
0.9999958 2.2026127e-07
Epoch: [1256][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0725 (0.0635)	
0.99998796 3.5686526e-07
Epoch: [1256][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1050 (0.0587)	
0.99999225 3.5207248e-07
loss:  0.04192589864763829 0.038747089495286824
===========>   training    <===========
Epoch: [1257][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0412 (0.0412)	
0.99998736 1.7410297e-06
===========>   testing    <===========
Epoch: [1257][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1275 (0.1275)	
0.99999654 3.9775296e-07
Epoch: [1257][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0616 (0.0649)	
0.9999906 4.3005213e-07
Epoch: [1257][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0912 (0.0601)	
0.9999932 4.638107e-07
loss:  0.04138598634309898 0.038747089495286824
===========>   training    <===========
Epoch: [1258][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0495 (0.0495)	
0.9999889 2.1345315e-08
===========>   testing    <===========
Epoch: [1258][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1301 (0.1301)	
0.99999607 6.068999e-07
Epoch: [1258][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0438 (0.0648)	
0.9999888 6.392339e-07
Epoch: [1258][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0859 (0.0589)	
0.9999924 7.2256677e-07
loss:  0.040605840075646604 0.038747089495286824
===========>   training    <===========
Epoch: [1259][0/23]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0372 (0.0372)	
0.9999913 4.815575e-07
===========>   testing    <===========
Epoch: [1259][0/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1343 (0.1343)	
0.9999962 2.3811016e-07
Epoch: [1259][100/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.0249 (0.0635)	
0.99999034 2.4995603e-07
Epoch: [1259][200/289]	Lr-deconv: [0.0]	Lr-other: [4.157799358572413e-05]	Loss 0.1102 (0.0593)	
0.9999933 2.8480613e-07
loss:  0.04082767193830639 0.038747089495286824
===========>   training    <===========
Epoch: [1260][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0380 (0.0380)	
0.9999846 7.482359e-08
===========>   testing    <===========
Epoch: [1260][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.1195 (0.1195)	
0.9999964 2.7728788e-07
Epoch: [1260][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0264 (0.0623)	
0.99999034 2.9049934e-07
Epoch: [1260][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0938 (0.0577)	
0.9999937 3.2922716e-07
loss:  0.04051735397367995 0.038747089495286824
===========>   training    <===========
Epoch: [1261][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0361 (0.0361)	
0.9999918 1.330579e-07
===========>   testing    <===========
Epoch: [1261][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.1239 (0.1239)	
0.9999962 3.1147184e-07
Epoch: [1261][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0323 (0.0640)	
0.99998975 3.2319699e-07
Epoch: [1261][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0897 (0.0585)	
0.9999931 3.8300627e-07
loss:  0.04106820690387447 0.038747089495286824
===========>   training    <===========
Epoch: [1262][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0421 (0.0421)	
0.9999918 7.2879817e-07
===========>   testing    <===========
Epoch: [1262][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.1210 (0.1210)	
0.9999964 2.709973e-07
Epoch: [1262][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0824 (0.0639)	
0.9999889 3.1697357e-07
Epoch: [1262][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.1101 (0.0588)	
0.9999932 3.447219e-07
loss:  0.041187640492553856 0.038747089495286824
===========>   training    <===========
Epoch: [1263][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0379 (0.0379)	
0.9999927 1.3179248e-07
===========>   testing    <===========
Epoch: [1263][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.1066 (0.1066)	
0.9999964 2.394569e-07
Epoch: [1263][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0746 (0.0636)	
0.99998987 2.5972136e-07
Epoch: [1263][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.1257 (0.0593)	
0.9999933 2.7208236e-07
loss:  0.04085873061313139 0.038747089495286824
===========>   training    <===========
Epoch: [1264][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0423 (0.0423)	
0.99999464 2.0273238e-07
===========>   testing    <===========
Epoch: [1264][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.1016 (0.1016)	
0.99999595 2.2848266e-07
Epoch: [1264][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0608 (0.0622)	
0.99998677 2.9465505e-07
Epoch: [1264][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0982 (0.0571)	
0.9999908 3.135641e-07
loss:  0.041122854106428575 0.038747089495286824
===========>   training    <===========
Epoch: [1265][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0347 (0.0347)	
0.99999213 3.3842113e-07
===========>   testing    <===========
Epoch: [1265][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.1015 (0.1015)	
0.9999962 2.002952e-07
Epoch: [1265][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0515 (0.0628)	
0.9999883 2.5061863e-07
Epoch: [1265][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0855 (0.0578)	
0.9999932 2.5098532e-07
loss:  0.0418648662240636 0.038747089495286824
===========>   training    <===========
Epoch: [1266][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0349 (0.0349)	
0.9999914 7.186319e-08
===========>   testing    <===========
Epoch: [1266][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.1085 (0.1085)	
0.9999962 2.3645103e-07
Epoch: [1266][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.1169 (0.0622)	
0.9999881 3.2480807e-07
Epoch: [1266][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.1042 (0.0576)	
0.9999938 3.0262362e-07
loss:  0.04106125987421283 0.038747089495286824
===========>   training    <===========
Epoch: [1267][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0446 (0.0446)	
0.9999927 1.9078611e-07
===========>   testing    <===========
Epoch: [1267][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0946 (0.0946)	
0.99999595 2.245657e-07
Epoch: [1267][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0631 (0.0610)	
0.9999864 3.6887553e-07
Epoch: [1267][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0932 (0.0562)	
0.99999154 2.662362e-07
loss:  0.04020748575872535 0.038747089495286824
===========>   training    <===========
Epoch: [1268][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0447 (0.0447)	
0.9999826 1.1598771e-06
===========>   testing    <===========
Epoch: [1268][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0606 (0.0606)	
0.9999963 2.9578743e-07
Epoch: [1268][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.1157 (0.0629)	
0.99999034 3.5441786e-07
Epoch: [1268][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0951 (0.0579)	
0.9999933 3.9228607e-07
loss:  0.041219765939864095 0.038747089495286824
===========>   training    <===========
Epoch: [1269][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0353 (0.0353)	
0.9999939 2.1092293e-07
===========>   testing    <===========
Epoch: [1269][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0841 (0.0841)	
0.9999945 1.8198568e-07
Epoch: [1269][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.1082 (0.0629)	
0.9999856 3.2624357e-07
Epoch: [1269][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0824 (0.0577)	
0.9999906 2.3137908e-07
loss:  0.04131798059380709 0.038747089495286824
===========>   training    <===========
Epoch: [1270][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0388 (0.0388)	
0.99998784 8.97621e-08
===========>   testing    <===========
Epoch: [1270][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.1027 (0.1027)	
0.99999547 2.4111827e-07
Epoch: [1270][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.1510 (0.0626)	
0.99998975 2.782094e-07
Epoch: [1270][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0833 (0.0574)	
0.999992 2.8379537e-07
loss:  0.04209322157423756 0.038747089495286824
===========>   training    <===========
Epoch: [1271][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0355 (0.0355)	
0.99999225 9.584587e-08
===========>   testing    <===========
Epoch: [1271][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.1079 (0.1079)	
0.99999607 3.036664e-07
Epoch: [1271][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.1575 (0.0634)	
0.9999908 3.0480376e-07
Epoch: [1271][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0858 (0.0573)	
0.9999926 3.1488563e-07
loss:  0.04194795621422098 0.038747089495286824
===========>   training    <===========
Epoch: [1272][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0318 (0.0318)	
0.9999908 5.540504e-08
===========>   testing    <===========
Epoch: [1272][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.1103 (0.1103)	
0.99999547 1.1870132e-07
Epoch: [1272][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.1119 (0.0626)	
0.9999889 1.9316285e-07
Epoch: [1272][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0918 (0.0565)	
0.99999213 1.4772647e-07
loss:  0.04096842592831551 0.038747089495286824
===========>   training    <===========
Epoch: [1273][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0409 (0.0409)	
0.999992 5.5970318e-08
===========>   testing    <===========
Epoch: [1273][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.1126 (0.1126)	
0.9999957 1.16011556e-07
Epoch: [1273][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.1255 (0.0635)	
0.99998987 1.7014925e-07
Epoch: [1273][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0832 (0.0573)	
0.99999166 1.6451186e-07
loss:  0.04134850364977749 0.038747089495286824
===========>   training    <===========
Epoch: [1274][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0350 (0.0350)	
0.9999931 1.1772514e-07
===========>   testing    <===========
Epoch: [1274][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.1188 (0.1188)	
0.9999956 1.5471741e-07
Epoch: [1274][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0538 (0.0612)	
0.9999887 2.3630157e-07
Epoch: [1274][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0724 (0.0557)	
0.99999154 2.0962848e-07
loss:  0.04017831744928524 0.038747089495286824
===========>   training    <===========
Epoch: [1275][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0343 (0.0343)	
0.9999951 1.6717362e-07
===========>   testing    <===========
Epoch: [1275][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0962 (0.0962)	
0.99999547 2.8728854e-07
Epoch: [1275][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0414 (0.0608)	
0.9999895 2.902966e-07
Epoch: [1275][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0833 (0.0559)	
0.9999918 3.2764413e-07
loss:  0.04073984152012344 0.038747089495286824
===========>   training    <===========
Epoch: [1276][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0305 (0.0305)	
0.9999825 8.009612e-08
===========>   testing    <===========
Epoch: [1276][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0885 (0.0885)	
0.9999958 2.949986e-07
Epoch: [1276][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0889 (0.0616)	
0.9999902 3.0679973e-07
Epoch: [1276][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0883 (0.0568)	
0.9999924 3.2822587e-07
loss:  0.04145034965277017 0.038747089495286824
===========>   training    <===========
Epoch: [1277][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0352 (0.0352)	
0.9999949 7.265095e-07
===========>   testing    <===========
Epoch: [1277][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0982 (0.0982)	
0.9999962 2.411008e-07
Epoch: [1277][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.1134 (0.0599)	
0.99998975 3.695294e-07
Epoch: [1277][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0889 (0.0552)	
0.99999225 3.9277572e-07
loss:  0.040507558193029314 0.038747089495286824
===========>   training    <===========
Epoch: [1278][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0364 (0.0364)	
0.9999871 2.0410664e-07
===========>   testing    <===========
Epoch: [1278][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0869 (0.0869)	
0.9999964 1.2238688e-07
Epoch: [1278][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0997 (0.0612)	
0.9999895 1.8614344e-07
Epoch: [1278][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0713 (0.0557)	
0.99999154 1.6140977e-07
loss:  0.04040874777054404 0.038747089495286824
===========>   training    <===========
Epoch: [1279][0/23]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0337 (0.0337)	
0.99999666 2.5841095e-07
===========>   testing    <===========
Epoch: [1279][0/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0987 (0.0987)	
0.99999714 1.7740977e-07
Epoch: [1279][100/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0564 (0.0617)	
0.9999901 1.7835347e-07
Epoch: [1279][200/289]	Lr-deconv: [0.0]	Lr-other: [3.949909390643792e-05]	Loss 0.0824 (0.0560)	
0.9999925 1.8014374e-07
loss:  0.04043573823615909 0.038747089495286824
===========>   training    <===========
Epoch: [1280][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0366 (0.0366)	
0.99999404 1.6952105e-08
===========>   testing    <===========
Epoch: [1280][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0805 (0.0805)	
0.99999714 2.8963072e-07
Epoch: [1280][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0566 (0.0612)	
0.99999046 2.9418555e-07
Epoch: [1280][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0787 (0.0562)	
0.9999927 3.1231153e-07
loss:  0.040114745828575105 0.038747089495286824
===========>   training    <===========
Epoch: [1281][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0378 (0.0378)	
0.9999902 1.4906384e-07
===========>   testing    <===========
Epoch: [1281][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0868 (0.0868)	
0.9999962 3.3245138e-07
Epoch: [1281][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0372 (0.0604)	
0.99998844 4.058146e-07
Epoch: [1281][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0714 (0.0564)	
0.9999908 3.900437e-07
loss:  0.04072694486267858 0.038747089495286824
===========>   training    <===========
Epoch: [1282][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0431 (0.0431)	
0.99999535 1.9461137e-07
===========>   testing    <===========
Epoch: [1282][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0793 (0.0793)	
0.99999607 2.6684322e-07
Epoch: [1282][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0775 (0.0616)	
0.999987 3.0162238e-07
Epoch: [1282][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0753 (0.0571)	
0.99999046 3.146971e-07
loss:  0.04104217099312779 0.038747089495286824
===========>   training    <===========
Epoch: [1283][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0378 (0.0378)	
0.9999925 8.994134e-07
===========>   testing    <===========
Epoch: [1283][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0730 (0.0730)	
0.99999666 2.8421138e-07
Epoch: [1283][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.1406 (0.0642)	
0.99998975 3.1176725e-07
Epoch: [1283][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0766 (0.0589)	
0.99999285 3.4970964e-07
loss:  0.04105789709413632 0.038747089495286824
===========>   training    <===========
Epoch: [1284][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0302 (0.0302)	
0.99999535 1.5884356e-06
===========>   testing    <===========
Epoch: [1284][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0976 (0.0976)	
0.9999968 2.8519207e-07
Epoch: [1284][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0319 (0.0609)	
0.99999046 2.9855164e-07
Epoch: [1284][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0652 (0.0559)	
0.99999213 3.3119537e-07
loss:  0.04018761520205161 0.038747089495286824
===========>   training    <===========
Epoch: [1285][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0346 (0.0346)	
0.9999895 2.6041832e-07
===========>   testing    <===========
Epoch: [1285][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.1058 (0.1058)	
0.9999968 2.7195708e-07
Epoch: [1285][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0413 (0.0612)	
0.99999106 2.8899117e-07
Epoch: [1285][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0870 (0.0561)	
0.9999925 3.166225e-07
loss:  0.03993276956598013 0.038747089495286824
===========>   training    <===========
Epoch: [1286][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0453 (0.0453)	
0.999998 5.908932e-07
===========>   testing    <===========
Epoch: [1286][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0856 (0.0856)	
0.9999968 3.778714e-07
Epoch: [1286][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0368 (0.0612)	
0.99999 3.9839605e-07
Epoch: [1286][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0932 (0.0569)	
0.99999297 4.435283e-07
loss:  0.04016849048791282 0.038747089495286824
===========>   training    <===========
Epoch: [1287][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0339 (0.0339)	
0.99999166 2.267193e-07
===========>   testing    <===========
Epoch: [1287][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.1096 (0.1096)	
0.9999956 3.0072368e-07
Epoch: [1287][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0262 (0.0621)	
0.9999863 3.8247114e-07
Epoch: [1287][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0822 (0.0567)	
0.9999912 3.5807412e-07
loss:  0.03930734791534263 0.038747089495286824
===========>   training    <===========
Epoch: [1288][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0375 (0.0375)	
0.99998665 2.0104533e-08
===========>   testing    <===========
Epoch: [1288][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.1109 (0.1109)	
0.9999958 2.0795312e-07
Epoch: [1288][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0271 (0.0623)	
0.9999856 2.8113766e-07
Epoch: [1288][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0870 (0.0569)	
0.9999914 2.3198515e-07
loss:  0.03984160647921586 0.038747089495286824
===========>   training    <===========
Epoch: [1289][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0353 (0.0353)	
0.99998784 2.2752324e-08
===========>   testing    <===========
Epoch: [1289][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.1096 (0.1096)	
0.99999607 2.4734712e-07
Epoch: [1289][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0418 (0.0606)	
0.99998677 2.7922397e-07
Epoch: [1289][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0801 (0.0558)	
0.9999926 3.083676e-07
loss:  0.040271154830826994 0.038747089495286824
===========>   training    <===========
Epoch: [1290][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0330 (0.0330)	
0.99999285 9.711301e-08
===========>   testing    <===========
Epoch: [1290][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.1008 (0.1008)	
0.99999654 3.9791988e-07
Epoch: [1290][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.1917 (0.0615)	
0.9999896 4.402232e-07
Epoch: [1290][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0808 (0.0564)	
0.9999931 4.7279212e-07
loss:  0.040743199517420337 0.038747089495286824
===========>   training    <===========
Epoch: [1291][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0322 (0.0322)	
0.99998856 2.2460083e-07
===========>   testing    <===========
Epoch: [1291][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0877 (0.0877)	
0.99999654 3.1656032e-07
Epoch: [1291][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0491 (0.0627)	
0.99998796 3.2918103e-07
Epoch: [1291][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0826 (0.0574)	
0.9999937 3.6248264e-07
loss:  0.04049502110931025 0.038747089495286824
===========>   training    <===========
Epoch: [1292][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0344 (0.0344)	
0.9999944 4.0714884e-08
===========>   testing    <===========
Epoch: [1292][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0771 (0.0771)	
0.9999964 3.0143548e-07
Epoch: [1292][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.1939 (0.0646)	
0.99998784 3.1365082e-07
Epoch: [1292][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0638 (0.0581)	
0.99999297 3.3636059e-07
loss:  0.04163403876010385 0.038747089495286824
===========>   training    <===========
Epoch: [1293][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0351 (0.0351)	
0.99999213 4.3308623e-07
===========>   testing    <===========
Epoch: [1293][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.1000 (0.1000)	
0.99999535 3.0037427e-07
Epoch: [1293][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.1009 (0.0614)	
0.9999864 4.0343988e-07
Epoch: [1293][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0700 (0.0563)	
0.999992 4.3488788e-07
loss:  0.04065282618475452 0.038747089495286824
===========>   training    <===========
Epoch: [1294][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0370 (0.0370)	
0.99998116 3.081812e-07
===========>   testing    <===========
Epoch: [1294][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0807 (0.0807)	
0.99999607 2.6152782e-07
Epoch: [1294][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.1034 (0.0621)	
0.99998796 2.703396e-07
Epoch: [1294][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0839 (0.0570)	
0.9999927 2.9617073e-07
loss:  0.040739606026436226 0.038747089495286824
===========>   training    <===========
Epoch: [1295][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0330 (0.0330)	
0.99999595 7.001021e-08
===========>   testing    <===========
Epoch: [1295][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0893 (0.0893)	
0.9999958 3.6299636e-07
Epoch: [1295][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0758 (0.0594)	
0.9999869 4.6627608e-07
Epoch: [1295][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0750 (0.0553)	
0.9999913 5.7716e-07
loss:  0.04035655063238475 0.038747089495286824
===========>   training    <===========
Epoch: [1296][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0481 (0.0481)	
0.9999808 1.7986976e-07
===========>   testing    <===========
Epoch: [1296][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0732 (0.0732)	
0.9999962 2.9604763e-07
Epoch: [1296][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0746 (0.0635)	
0.999987 3.7129567e-07
Epoch: [1296][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0833 (0.0577)	
0.9999926 4.7666936e-07
loss:  0.04174598547778363 0.038747089495286824
===========>   training    <===========
Epoch: [1297][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0342 (0.0342)	
0.99999166 3.1070403e-08
===========>   testing    <===========
Epoch: [1297][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0878 (0.0878)	
0.99999595 1.3988527e-07
Epoch: [1297][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0651 (0.0613)	
0.9999858 2.0482949e-07
Epoch: [1297][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0879 (0.0569)	
0.99999225 2.4136492e-07
loss:  0.04040236936176367 0.038747089495286824
===========>   training    <===========
Epoch: [1298][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0361 (0.0361)	
0.999992 1.7442616e-08
===========>   testing    <===========
Epoch: [1298][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0801 (0.0801)	
0.99999535 1.7999417e-07
Epoch: [1298][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0482 (0.0608)	
0.99998367 2.4748067e-07
Epoch: [1298][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0895 (0.0564)	
0.9999907 2.9742407e-07
loss:  0.04031806117673142 0.038747089495286824
===========>   training    <===========
Epoch: [1299][0/23]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0366 (0.0366)	
0.9999913 2.7416823e-07
===========>   testing    <===========
Epoch: [1299][0/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0953 (0.0953)	
0.9999958 3.958125e-07
Epoch: [1299][100/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0498 (0.0615)	
0.999987 4.654342e-07
Epoch: [1299][200/289]	Lr-deconv: [0.0]	Lr-other: [3.752413921111602e-05]	Loss 0.0902 (0.0567)	
0.99999285 5.1172435e-07
loss:  0.03972610237647056 0.038747089495286824
===========>   training    <===========
Epoch: [1300][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0330 (0.0330)	
0.9999938 4.0530242e-08
===========>   testing    <===========
Epoch: [1300][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0944 (0.0944)	
0.9999964 2.4453027e-07
Epoch: [1300][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0326 (0.0617)	
0.99998677 3.4743917e-07
Epoch: [1300][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0938 (0.0575)	
0.9999933 3.6549326e-07
loss:  0.04035311909525929 0.038747089495286824
===========>   training    <===========
Epoch: [1301][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0343 (0.0343)	
0.99999523 3.4096054e-08
===========>   testing    <===========
Epoch: [1301][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.1018 (0.1018)	
0.9999962 3.1756724e-07
Epoch: [1301][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0311 (0.0609)	
0.99998736 3.3277016e-07
Epoch: [1301][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.1000 (0.0570)	
0.9999933 3.6510863e-07
loss:  0.04015074317582312 0.038747089495286824
===========>   training    <===========
Epoch: [1302][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0365 (0.0365)	
0.9999802 1.5850611e-07
===========>   testing    <===========
Epoch: [1302][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.1034 (0.1034)	
0.9999956 2.582343e-07
Epoch: [1302][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0265 (0.0604)	
0.99998546 3.7260102e-07
Epoch: [1302][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0951 (0.0570)	
0.9999913 4.6170078e-07
loss:  0.040011299081265994 0.038747089495286824
===========>   training    <===========
Epoch: [1303][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0358 (0.0358)	
0.9999919 5.4366575e-07
===========>   testing    <===========
Epoch: [1303][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0957 (0.0957)	
0.9999956 2.3983768e-07
Epoch: [1303][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0383 (0.0616)	
0.99998736 3.0676432e-07
Epoch: [1303][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0763 (0.0574)	
0.99999166 3.5077616e-07
loss:  0.040177904732515146 0.038747089495286824
===========>   training    <===========
Epoch: [1304][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0363 (0.0363)	
0.9999969 1.0888097e-07
===========>   testing    <===========
Epoch: [1304][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0676 (0.0676)	
0.9999956 1.2394791e-07
Epoch: [1304][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0530 (0.0625)	
0.99998665 1.7169631e-07
Epoch: [1304][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0707 (0.0575)	
0.99999225 2.2071609e-07
loss:  0.04054391268816093 0.038747089495286824
===========>   training    <===========
Epoch: [1305][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0365 (0.0365)	
0.9999949 1.4433013e-07
===========>   testing    <===========
Epoch: [1305][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.1037 (0.1037)	
0.99999595 2.0249935e-07
Epoch: [1305][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0824 (0.0621)	
0.99998856 2.2253653e-07
Epoch: [1305][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0786 (0.0569)	
0.9999937 2.1993885e-07
loss:  0.04020037501840357 0.038747089495286824
===========>   training    <===========
Epoch: [1306][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0380 (0.0380)	
0.99999225 1.8395342e-07
===========>   testing    <===========
Epoch: [1306][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.1162 (0.1162)	
0.9999962 1.903129e-07
Epoch: [1306][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0563 (0.0620)	
0.9999894 2.0344861e-07
Epoch: [1306][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0805 (0.0569)	
0.9999943 2.0185978e-07
loss:  0.04045173693563742 0.038747089495286824
===========>   training    <===========
Epoch: [1307][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0300 (0.0300)	
0.99999106 9.6468895e-08
===========>   testing    <===========
Epoch: [1307][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.1068 (0.1068)	
0.99999607 3.17201e-07
Epoch: [1307][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0537 (0.0613)	
0.9999902 3.276082e-07
Epoch: [1307][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0816 (0.0561)	
0.99999356 3.2831414e-07
loss:  0.040270642081710495 0.038747089495286824
===========>   training    <===========
Epoch: [1308][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0402 (0.0402)	
0.99999404 7.12319e-08
===========>   testing    <===========
Epoch: [1308][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.1293 (0.1293)	
0.9999957 2.390918e-07
Epoch: [1308][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0483 (0.0622)	
0.9999883 2.814768e-07
Epoch: [1308][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0782 (0.0564)	
0.99999297 2.9219507e-07
loss:  0.04089776328201555 0.038747089495286824
===========>   training    <===========
Epoch: [1309][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0379 (0.0379)	
0.99999 1.09359256e-07
===========>   testing    <===========
Epoch: [1309][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.1228 (0.1228)	
0.9999957 2.6998123e-07
Epoch: [1309][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0382 (0.0632)	
0.9999876 2.830429e-07
Epoch: [1309][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0811 (0.0564)	
0.9999926 2.8594428e-07
loss:  0.040253402042269903 0.038747089495286824
===========>   training    <===========
Epoch: [1310][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0448 (0.0448)	
0.99999106 2.352557e-08
===========>   testing    <===========
Epoch: [1310][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.1249 (0.1249)	
0.9999956 2.9247246e-07
Epoch: [1310][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0426 (0.0619)	
0.99998856 2.9800043e-07
Epoch: [1310][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0827 (0.0557)	
0.9999918 3.0804105e-07
loss:  0.03954296276479252 0.038747089495286824
===========>   training    <===========
Epoch: [1311][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0363 (0.0363)	
0.9999949 9.374443e-08
===========>   testing    <===========
Epoch: [1311][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.1427 (0.1427)	
0.99999607 3.0717035e-07
Epoch: [1311][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0283 (0.0620)	
0.9999895 3.2826216e-07
Epoch: [1311][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0842 (0.0560)	
0.99999297 3.2882082e-07
loss:  0.0398010190086846 0.038747089495286824
===========>   training    <===========
Epoch: [1312][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0395 (0.0395)	
0.99999523 1.6037269e-06
===========>   testing    <===========
Epoch: [1312][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.1212 (0.1212)	
0.9999962 2.43107e-07
Epoch: [1312][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0299 (0.0606)	
0.99999034 2.465017e-07
Epoch: [1312][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0976 (0.0560)	
0.9999931 2.5838187e-07
loss:  0.03942561273028444 0.038747089495286824
===========>   training    <===========
Epoch: [1313][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0401 (0.0401)	
0.9999932 3.150292e-07
===========>   testing    <===========
Epoch: [1313][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.1189 (0.1189)	
0.99999595 1.6206717e-07
Epoch: [1313][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0403 (0.0605)	
0.99998784 2.0814062e-07
Epoch: [1313][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0801 (0.0553)	
0.9999914 2.2369959e-07
loss:  0.03973395295227544 0.038747089495286824
===========>   training    <===========
Epoch: [1314][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0353 (0.0353)	
0.9999895 1.2242236e-07
===========>   testing    <===========
Epoch: [1314][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.1126 (0.1126)	
0.99999535 2.2928026e-07
Epoch: [1314][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0528 (0.0618)	
0.9999875 2.3318559e-07
Epoch: [1314][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0826 (0.0560)	
0.9999912 2.5125712e-07
loss:  0.040953463069562934 0.038747089495286824
===========>   training    <===========
Epoch: [1315][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0401 (0.0401)	
0.99999213 1.689983e-07
===========>   testing    <===========
Epoch: [1315][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.1109 (0.1109)	
0.9999956 2.6302007e-07
Epoch: [1315][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0415 (0.0614)	
0.9999907 2.695683e-07
Epoch: [1315][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0975 (0.0563)	
0.9999924 2.8619857e-07
loss:  0.04061703936684291 0.038747089495286824
===========>   training    <===========
Epoch: [1316][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0384 (0.0384)	
0.99999774 1.3792085e-06
===========>   testing    <===========
Epoch: [1316][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.1065 (0.1065)	
0.9999964 2.3150422e-07
Epoch: [1316][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.1456 (0.0632)	
0.9999926 2.4614656e-07
Epoch: [1316][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0763 (0.0572)	
0.9999943 2.6631798e-07
loss:  0.04125641493619814 0.038747089495286824
===========>   training    <===========
Epoch: [1317][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0362 (0.0362)	
0.99999404 8.518825e-08
===========>   testing    <===========
Epoch: [1317][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.1137 (0.1137)	
0.99999595 2.8177544e-07
Epoch: [1317][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0607 (0.0620)	
0.99998903 2.701087e-07
Epoch: [1317][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0789 (0.0564)	
0.99999285 3.1455548e-07
loss:  0.04078138764853234 0.038747089495286824
===========>   training    <===========
Epoch: [1318][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0341 (0.0341)	
0.9999939 9.682356e-08
===========>   testing    <===========
Epoch: [1318][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.1242 (0.1242)	
0.99999654 2.4625078e-07
Epoch: [1318][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.1753 (0.0628)	
0.9999918 2.608548e-07
Epoch: [1318][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0711 (0.0565)	
0.99999404 2.74884e-07
loss:  0.04072013865209889 0.038747089495286824
===========>   training    <===========
Epoch: [1319][0/23]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0342 (0.0342)	
0.99999666 3.486477e-07
===========>   testing    <===========
Epoch: [1319][0/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.1112 (0.1112)	
0.99999654 2.1870565e-07
Epoch: [1319][100/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.2511 (0.0619)	
0.99999154 2.2529804e-07
Epoch: [1319][200/289]	Lr-deconv: [0.0]	Lr-other: [3.564793225056022e-05]	Loss 0.0789 (0.0556)	
0.99999416 2.2841752e-07
loss:  0.04046801584745341 0.038747089495286824
===========>   training    <===========
Epoch: [1320][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0353 (0.0353)	
0.9999951 2.6120222e-08
===========>   testing    <===========
Epoch: [1320][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.1068 (0.1068)	
0.99999607 3.298356e-07
Epoch: [1320][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0667 (0.0600)	
0.9999908 3.447446e-07
Epoch: [1320][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0774 (0.0550)	
0.9999931 3.660758e-07
loss:  0.0398807794371806 0.038747089495286824
===========>   training    <===========
Epoch: [1321][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0304 (0.0304)	
0.9999944 4.893056e-07
===========>   testing    <===========
Epoch: [1321][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.1249 (0.1249)	
0.9999956 3.5750907e-07
Epoch: [1321][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0357 (0.0609)	
0.99998915 3.8258753e-07
Epoch: [1321][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0785 (0.0556)	
0.9999926 4.0271337e-07
loss:  0.04015442529931745 0.038747089495286824
===========>   training    <===========
Epoch: [1322][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0327 (0.0327)	
0.9999771 4.926182e-07
===========>   testing    <===========
Epoch: [1322][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.1374 (0.1374)	
0.9999957 4.0817528e-07
Epoch: [1322][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0340 (0.0605)	
0.9999883 4.2025664e-07
Epoch: [1322][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0751 (0.0556)	
0.999992 4.4944258e-07
loss:  0.04049261540854876 0.038747089495286824
===========>   training    <===========
Epoch: [1323][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0298 (0.0298)	
0.9999957 3.220813e-07
===========>   testing    <===========
Epoch: [1323][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.1268 (0.1268)	
0.9999956 3.5215106e-07
Epoch: [1323][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0245 (0.0601)	
0.9999887 3.7284627e-07
Epoch: [1323][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0755 (0.0554)	
0.999992 3.8932276e-07
loss:  0.03971400337150477 0.038747089495286824
===========>   training    <===========
Epoch: [1324][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0317 (0.0317)	
0.9999926 3.6860367e-08
===========>   testing    <===========
Epoch: [1324][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.1165 (0.1165)	
0.99999654 2.4624984e-07
Epoch: [1324][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0239 (0.0614)	
0.99999 2.5629703e-07
Epoch: [1324][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0825 (0.0564)	
0.9999938 2.8223857e-07
loss:  0.040042609541028784 0.038747089495286824
===========>   training    <===========
Epoch: [1325][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0326 (0.0326)	
0.9999924 2.745916e-07
===========>   testing    <===========
Epoch: [1325][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.1301 (0.1301)	
0.99999607 3.2654796e-07
Epoch: [1325][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0247 (0.0616)	
0.9999869 3.7155425e-07
Epoch: [1325][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0756 (0.0561)	
0.99999225 3.8066585e-07
loss:  0.04005281997953769 0.038747089495286824
===========>   training    <===========
Epoch: [1326][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0343 (0.0343)	
0.9999908 3.024675e-08
===========>   testing    <===========
Epoch: [1326][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.1479 (0.1479)	
0.99999464 2.6875688e-07
Epoch: [1326][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0301 (0.0625)	
0.99998343 3.9670206e-07
Epoch: [1326][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0723 (0.0574)	
0.9999926 4.0127267e-07
loss:  0.04093659739660116 0.038747089495286824
===========>   training    <===========
Epoch: [1327][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0354 (0.0354)	
0.9999951 7.553809e-09
===========>   testing    <===========
Epoch: [1327][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.1159 (0.1159)	
0.99999595 2.0683306e-07
Epoch: [1327][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0634 (0.0630)	
0.9999871 3.085188e-07
Epoch: [1327][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0624 (0.0570)	
0.9999926 3.7945597e-07
loss:  0.04087770800365209 0.038747089495286824
===========>   training    <===========
Epoch: [1328][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0407 (0.0407)	
0.9999945 1.5948442e-07
===========>   testing    <===========
Epoch: [1328][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.1094 (0.1094)	
0.99999595 1.6609397e-07
Epoch: [1328][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0538 (0.0624)	
0.9999881 2.2054796e-07
Epoch: [1328][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0727 (0.0565)	
0.9999927 2.5965005e-07
loss:  0.03989847214147646 0.038747089495286824
===========>   training    <===========
Epoch: [1329][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0365 (0.0365)	
0.9999962 1.8697357e-08
===========>   testing    <===========
Epoch: [1329][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.1153 (0.1153)	
0.9999958 2.405939e-07
Epoch: [1329][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0527 (0.0624)	
0.9999877 2.455105e-07
Epoch: [1329][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0674 (0.0572)	
0.9999943 2.641593e-07
loss:  0.039951579144338445 0.038747089495286824
===========>   training    <===========
Epoch: [1330][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0381 (0.0381)	
0.99999714 1.6732133e-07
===========>   testing    <===========
Epoch: [1330][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.1180 (0.1180)	
0.9999951 1.4505375e-07
Epoch: [1330][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0259 (0.0604)	
0.99998164 1.7025184e-07
Epoch: [1330][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0787 (0.0559)	
0.9999924 1.9912957e-07
loss:  0.03949744877470074 0.038747089495286824
===========>   training    <===========
Epoch: [1331][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0354 (0.0354)	
0.99999666 7.16591e-07
===========>   testing    <===========
Epoch: [1331][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.1138 (0.1138)	
0.99999607 2.7250096e-07
Epoch: [1331][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0317 (0.0610)	
0.9999858 2.706133e-07
Epoch: [1331][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0759 (0.0557)	
0.99999285 2.933163e-07
loss:  0.03930960384768456 0.038747089495286824
===========>   training    <===========
Epoch: [1332][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0306 (0.0306)	
0.99998677 4.294652e-08
===========>   testing    <===========
Epoch: [1332][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.1110 (0.1110)	
0.9999962 2.1351894e-07
Epoch: [1332][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0278 (0.0614)	
0.9999871 2.0593694e-07
Epoch: [1332][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0777 (0.0559)	
0.99999344 2.3070199e-07
loss:  0.03930247913400364 0.038747089495286824
===========>   training    <===========
Epoch: [1333][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0332 (0.0332)	
0.9999956 3.8068617e-07
===========>   testing    <===========
Epoch: [1333][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.1029 (0.1029)	
0.99999607 2.901499e-07
Epoch: [1333][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0218 (0.0604)	
0.99998844 2.8809134e-07
Epoch: [1333][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0845 (0.0568)	
0.9999932 3.2583685e-07
loss:  0.03943859636208391 0.038747089495286824
===========>   training    <===========
Epoch: [1334][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0375 (0.0375)	
0.9999937 1.3935785e-07
===========>   testing    <===========
Epoch: [1334][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.1219 (0.1219)	
0.99999607 2.3253668e-07
Epoch: [1334][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0314 (0.0599)	
0.99998975 3.8331723e-07
Epoch: [1334][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0925 (0.0562)	
0.99999225 3.3767802e-07
loss:  0.03972201979124701 0.038747089495286824
===========>   training    <===========
Epoch: [1335][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0337 (0.0337)	
0.9999908 3.4581905e-07
===========>   testing    <===========
Epoch: [1335][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0958 (0.0958)	
0.99999607 2.7932145e-07
Epoch: [1335][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0358 (0.0597)	
0.99998915 3.0621422e-07
Epoch: [1335][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0869 (0.0560)	
0.9999924 3.4483733e-07
loss:  0.03916248721523308 0.038747089495286824
===========>   training    <===========
Epoch: [1336][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0362 (0.0362)	
0.99999356 5.616687e-07
===========>   testing    <===========
Epoch: [1336][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0945 (0.0945)	
0.99999654 2.4657697e-07
Epoch: [1336][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0305 (0.0581)	
0.99998975 2.4382166e-07
Epoch: [1336][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0949 (0.0555)	
0.9999932 2.76717e-07
loss:  0.03950861956775986 0.038747089495286824
===========>   training    <===========
Epoch: [1337][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0397 (0.0397)	
0.9999906 2.9079843e-07
===========>   testing    <===========
Epoch: [1337][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.1024 (0.1024)	
0.9999962 2.8546967e-07
Epoch: [1337][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0236 (0.0583)	
0.99998903 4.0055383e-07
Epoch: [1337][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0957 (0.0553)	
0.99999213 4.231813e-07
loss:  0.03930911296264383 0.038747089495286824
===========>   training    <===========
Epoch: [1338][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0336 (0.0336)	
0.9999896 7.985999e-08
===========>   testing    <===========
Epoch: [1338][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0983 (0.0983)	
0.99999595 2.739607e-07
Epoch: [1338][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0509 (0.0579)	
0.9999883 2.8124254e-07
Epoch: [1338][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0804 (0.0552)	
0.99999225 3.115188e-07
loss:  0.04033361607626229 0.038747089495286824
===========>   training    <===========
Epoch: [1339][0/23]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0334 (0.0334)	
0.99998903 9.399455e-08
===========>   testing    <===========
Epoch: [1339][0/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0886 (0.0886)	
0.99999595 2.9827618e-07
Epoch: [1339][100/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0302 (0.0599)	
0.99999 4.0858342e-07
Epoch: [1339][200/289]	Lr-deconv: [0.0]	Lr-other: [3.386553563803221e-05]	Loss 0.0903 (0.0564)	
0.99999297 3.6514416e-07
loss:  0.03971299315845145 0.038747089495286824
===========>   training    <===========
Epoch: [1340][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0365 (0.0365)	
0.99998426 1.3599444e-07
===========>   testing    <===========
Epoch: [1340][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0839 (0.0839)	
0.9999964 2.1394618e-07
Epoch: [1340][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0228 (0.0595)	
0.9999908 2.2248602e-07
Epoch: [1340][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0785 (0.0560)	
0.9999931 2.4807755e-07
loss:  0.03936871140482634 0.038747089495286824
===========>   training    <===========
Epoch: [1341][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0384 (0.0384)	
0.99999595 1.1301333e-07
===========>   testing    <===========
Epoch: [1341][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0950 (0.0950)	
0.99999595 2.0715484e-07
Epoch: [1341][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0245 (0.0593)	
0.9999887 2.067392e-07
Epoch: [1341][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0917 (0.0563)	
0.9999926 2.3628084e-07
loss:  0.03884195763953535 0.038747089495286824
===========>   training    <===========
Epoch: [1342][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0399 (0.0399)	
0.999997 7.83808e-08
===========>   testing    <===========
Epoch: [1342][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0885 (0.0885)	
0.9999964 2.4133544e-07
Epoch: [1342][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0592 (0.0608)	
0.9999919 2.4111185e-07
Epoch: [1342][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0924 (0.0568)	
0.99999344 2.6979023e-07
loss:  0.03912618253311695 0.038747089495286824
===========>   training    <===========
Epoch: [1343][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0353 (0.0353)	
0.9999974 5.8948107e-08
===========>   testing    <===========
Epoch: [1343][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.1150 (0.1150)	
0.99999607 2.984691e-07
Epoch: [1343][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0542 (0.0602)	
0.99998987 3.2986767e-07
Epoch: [1343][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0789 (0.0555)	
0.99999297 3.640454e-07
loss:  0.038861128114602295 0.038747089495286824
===========>   training    <===========
Epoch: [1344][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0319 (0.0319)	
0.9999932 4.2590247e-07
===========>   testing    <===========
Epoch: [1344][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.1189 (0.1189)	
0.9999962 2.5644104e-07
Epoch: [1344][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0557 (0.0591)	
0.9999882 2.582503e-07
Epoch: [1344][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0830 (0.0548)	
0.99999285 2.8059821e-07
loss:  0.038874400741666704 0.038747089495286824
===========>   training    <===========
Epoch: [1345][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0345 (0.0345)	
0.9999939 1.9145394e-07
===========>   testing    <===========
Epoch: [1345][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0846 (0.0846)	
0.999997 2.3395407e-07
Epoch: [1345][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0360 (0.0589)	
0.99998975 2.359433e-07
Epoch: [1345][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0969 (0.0554)	
0.99999404 2.5904112e-07
loss:  0.03875509629006613 0.038747089495286824
===========>   training    <===========
Epoch: [1346][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0395 (0.0395)	
0.9999901 5.393125e-07
===========>   testing    <===========
Epoch: [1346][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0763 (0.0763)	
0.9999964 2.6380434e-07
Epoch: [1346][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0280 (0.0604)	
0.99998903 3.0096095e-07
Epoch: [1346][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0963 (0.0561)	
0.99999213 3.3927068e-07
loss:  0.039188476919680304 0.038747089495286824
===========>   training    <===========
Epoch: [1347][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0370 (0.0370)	
0.9999927 5.1071754e-07
===========>   testing    <===========
Epoch: [1347][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0555 (0.0555)	
0.9999968 2.4815895e-07
Epoch: [1347][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0453 (0.0614)	
0.99999154 2.5466582e-07
Epoch: [1347][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0900 (0.0566)	
0.9999931 2.843285e-07
loss:  0.039891791748326244 0.038747089495286824
===========>   training    <===========
Epoch: [1348][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0379 (0.0379)	
0.999998 7.76339e-08
===========>   testing    <===========
Epoch: [1348][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0841 (0.0841)	
0.99999607 2.2755717e-07
Epoch: [1348][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0515 (0.0607)	
0.9999893 2.9194018e-07
Epoch: [1348][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0916 (0.0569)	
0.99999344 2.595297e-07
loss:  0.04046124178971511 0.038747089495286824
===========>   training    <===========
Epoch: [1349][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0333 (0.0333)	
0.99999475 1.2057497e-07
===========>   testing    <===========
Epoch: [1349][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0762 (0.0762)	
0.99999654 2.8236266e-07
Epoch: [1349][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0482 (0.0597)	
0.9999882 3.416572e-07
Epoch: [1349][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0924 (0.0557)	
0.9999932 3.5261348e-07
loss:  0.03965954594039045 0.038747089495286824
===========>   training    <===========
Epoch: [1350][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0317 (0.0317)	
0.9999913 1.7530427e-07
===========>   testing    <===========
Epoch: [1350][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0926 (0.0926)	
0.99999595 1.8102723e-07
Epoch: [1350][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0345 (0.0601)	
0.99998736 2.6264007e-07
Epoch: [1350][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.1050 (0.0562)	
0.9999933 2.321487e-07
loss:  0.03944840646203729 0.038747089495286824
===========>   training    <===========
Epoch: [1351][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0333 (0.0333)	
0.99999464 2.233772e-08
===========>   testing    <===========
Epoch: [1351][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0814 (0.0814)	
0.99999654 3.0705496e-07
Epoch: [1351][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0660 (0.0604)	
0.99999 3.03722e-07
Epoch: [1351][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.1014 (0.0562)	
0.99999464 3.3702847e-07
loss:  0.03982525421878236 0.038747089495286824
===========>   training    <===========
Epoch: [1352][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0379 (0.0379)	
0.9999888 4.0684188e-07
===========>   testing    <===========
Epoch: [1352][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0774 (0.0774)	
0.9999964 4.1305998e-07
Epoch: [1352][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0734 (0.0611)	
0.99998903 4.161405e-07
Epoch: [1352][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.1082 (0.0564)	
0.9999938 4.813444e-07
loss:  0.039816817875517385 0.038747089495286824
===========>   training    <===========
Epoch: [1353][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0319 (0.0319)	
0.9999893 1.4465877e-07
===========>   testing    <===========
Epoch: [1353][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0608 (0.0608)	
0.99999595 5.115643e-07
Epoch: [1353][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0643 (0.0614)	
0.9999887 5.4322834e-07
Epoch: [1353][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.1005 (0.0564)	
0.99999285 6.278584e-07
loss:  0.0407743426575683 0.038747089495286824
===========>   training    <===========
Epoch: [1354][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0394 (0.0394)	
0.9999819 2.8912623e-07
===========>   testing    <===========
Epoch: [1354][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0735 (0.0735)	
0.9999957 2.7937847e-07
Epoch: [1354][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0378 (0.0606)	
0.99998844 3.4468442e-07
Epoch: [1354][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.1035 (0.0563)	
0.9999926 3.5072867e-07
loss:  0.039820138069026956 0.038747089495286824
===========>   training    <===========
Epoch: [1355][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0393 (0.0393)	
0.99999404 1.6435841e-08
===========>   testing    <===========
Epoch: [1355][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.1005 (0.1005)	
0.9999957 4.1463431e-07
Epoch: [1355][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0527 (0.0592)	
0.9999887 2.7820647e-07
Epoch: [1355][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0938 (0.0556)	
0.99999285 5.143816e-07
loss:  0.03965452297082739 0.038747089495286824
===========>   training    <===========
Epoch: [1356][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0336 (0.0336)	
0.99999607 2.992723e-07
===========>   testing    <===========
Epoch: [1356][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0862 (0.0862)	
0.9999957 3.2786733e-07
Epoch: [1356][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0504 (0.0598)	
0.9999902 3.214933e-07
Epoch: [1356][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.1036 (0.0562)	
0.9999933 4.13337e-07
loss:  0.0403403502184605 0.038747089495286824
===========>   training    <===========
Epoch: [1357][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0394 (0.0394)	
0.9999827 3.726692e-08
===========>   testing    <===========
Epoch: [1357][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0905 (0.0905)	
0.99999654 3.9434835e-07
Epoch: [1357][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0706 (0.0600)	
0.99999285 4.830758e-07
Epoch: [1357][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0919 (0.0559)	
0.9999943 5.2847093e-07
loss:  0.040693593682252005 0.038747089495286824
===========>   training    <===========
Epoch: [1358][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0335 (0.0335)	
0.9999901 2.50034e-07
===========>   testing    <===========
Epoch: [1358][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0994 (0.0994)	
0.99999547 2.4387492e-07
Epoch: [1358][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0784 (0.0598)	
0.99999094 3.8599364e-07
Epoch: [1358][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0925 (0.0557)	
0.9999939 3.4307618e-07
loss:  0.04049315225934058 0.038747089495286824
===========>   training    <===========
Epoch: [1359][0/23]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0330 (0.0330)	
0.99998415 5.3845817e-09
===========>   testing    <===========
Epoch: [1359][0/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0977 (0.0977)	
0.9999963 4.2297555e-07
Epoch: [1359][100/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.1108 (0.0605)	
0.999992 4.9543604e-07
Epoch: [1359][200/289]	Lr-deconv: [0.0]	Lr-other: [3.217225885613059e-05]	Loss 0.0920 (0.0561)	
0.9999937 5.772426e-07
loss:  0.040487511199479465 0.038747089495286824
===========>   training    <===========
Epoch: [1360][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0356 (0.0356)	
0.99999475 1.573005e-07
===========>   testing    <===========
Epoch: [1360][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0969 (0.0969)	
0.9999957 1.5257463e-07
Epoch: [1360][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.1414 (0.0607)	
0.99999034 1.425367e-07
Epoch: [1360][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0808 (0.0564)	
0.9999919 2.2764573e-07
loss:  0.04079440164767545 0.038747089495286824
===========>   training    <===========
Epoch: [1361][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0304 (0.0304)	
0.9999896 4.82579e-08
===========>   testing    <===========
Epoch: [1361][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0676 (0.0676)	
0.99999654 2.551861e-07
Epoch: [1361][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.1495 (0.0611)	
0.9999912 2.8408863e-07
Epoch: [1361][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0791 (0.0568)	
0.9999938 2.9468202e-07
loss:  0.04110622603617675 0.038747089495286824
===========>   training    <===========
Epoch: [1362][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0327 (0.0327)	
0.9999914 8.6955126e-08
===========>   testing    <===========
Epoch: [1362][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0820 (0.0820)	
0.9999964 2.7856754e-07
Epoch: [1362][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.1006 (0.0607)	
0.9999907 3.0899494e-07
Epoch: [1362][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0829 (0.0563)	
0.99999356 3.1652772e-07
loss:  0.03964885290353071 0.038747089495286824
===========>   training    <===========
Epoch: [1363][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0417 (0.0417)	
0.99999607 3.4589487e-08
===========>   testing    <===========
Epoch: [1363][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0913 (0.0913)	
0.9999962 2.2763444e-07
Epoch: [1363][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0578 (0.0614)	
0.9999901 3.1216712e-07
Epoch: [1363][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0997 (0.0571)	
0.99999344 3.46474e-07
loss:  0.039673228794940174 0.038747089495286824
===========>   training    <===========
Epoch: [1364][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0335 (0.0335)	
0.99999034 1.2342368e-08
===========>   testing    <===========
Epoch: [1364][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.1119 (0.1119)	
0.99999607 2.602949e-07
Epoch: [1364][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0961 (0.0608)	
0.99999034 3.1848288e-07
Epoch: [1364][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0763 (0.0561)	
0.9999933 3.6128884e-07
loss:  0.04021359740960462 0.038747089495286824
===========>   training    <===========
Epoch: [1365][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0405 (0.0405)	
0.99999034 1.1554539e-07
===========>   testing    <===========
Epoch: [1365][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0925 (0.0925)	
0.99999607 2.63269e-07
Epoch: [1365][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0392 (0.0603)	
0.9999895 3.8807462e-07
Epoch: [1365][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0890 (0.0557)	
0.9999927 3.6343974e-07
loss:  0.03940390527900561 0.038747089495286824
===========>   training    <===========
Epoch: [1366][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0328 (0.0328)	
0.99999595 1.3299015e-07
===========>   testing    <===========
Epoch: [1366][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0917 (0.0917)	
0.99999547 1.2473505e-07
Epoch: [1366][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0343 (0.0609)	
0.9999888 2.0049796e-07
Epoch: [1366][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0829 (0.0557)	
0.99999213 1.7695406e-07
loss:  0.03973781741531979 0.038747089495286824
===========>   training    <===========
Epoch: [1367][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0320 (0.0320)	
0.9999956 7.335776e-08
===========>   testing    <===========
Epoch: [1367][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0951 (0.0951)	
0.99999607 2.1849299e-07
Epoch: [1367][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0366 (0.0590)	
0.99998987 2.3957386e-07
Epoch: [1367][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.1031 (0.0556)	
0.99999285 3.0770838e-07
loss:  0.03972306387460467 0.038747089495286824
===========>   training    <===========
Epoch: [1368][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0329 (0.0329)	
0.99999094 4.478445e-07
===========>   testing    <===========
Epoch: [1368][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0890 (0.0890)	
0.9999964 2.3056892e-07
Epoch: [1368][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0732 (0.0615)	
0.9999906 2.3317891e-07
Epoch: [1368][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0931 (0.0570)	
0.9999927 2.5351676e-07
loss:  0.040107440443986286 0.038747089495286824
===========>   training    <===========
Epoch: [1369][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0373 (0.0373)	
0.9999939 4.678172e-08
===========>   testing    <===========
Epoch: [1369][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0798 (0.0798)	
0.99999654 3.0759895e-07
Epoch: [1369][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0281 (0.0609)	
0.99999034 3.1482978e-07
Epoch: [1369][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.1128 (0.0569)	
0.9999932 3.3878766e-07
loss:  0.03942015754214789 0.038747089495286824
===========>   training    <===========
Epoch: [1370][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0329 (0.0329)	
0.99999106 5.777631e-08
===========>   testing    <===========
Epoch: [1370][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.1139 (0.1139)	
0.9999964 2.5216116e-07
Epoch: [1370][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0402 (0.0607)	
0.99999094 2.599424e-07
Epoch: [1370][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0994 (0.0568)	
0.9999931 2.7113433e-07
loss:  0.039802776160845155 0.038747089495286824
===========>   training    <===========
Epoch: [1371][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0277 (0.0277)	
0.9999949 8.100009e-08
===========>   testing    <===========
Epoch: [1371][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0930 (0.0930)	
0.9999963 2.2031652e-07
Epoch: [1371][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0293 (0.0601)	
0.9999908 2.1641094e-07
Epoch: [1371][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.1037 (0.0570)	
0.9999931 2.3376226e-07
loss:  0.03942994030586655 0.038747089495286824
===========>   training    <===========
Epoch: [1372][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0358 (0.0358)	
0.99999595 1.3499996e-07
===========>   testing    <===========
Epoch: [1372][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0818 (0.0818)	
0.9999963 3.0277806e-07
Epoch: [1372][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0331 (0.0605)	
0.99999094 3.035176e-07
Epoch: [1372][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.1053 (0.0573)	
0.9999926 3.2729187e-07
loss:  0.03986208862695928 0.038747089495286824
===========>   training    <===========
Epoch: [1373][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0276 (0.0276)	
0.9999908 7.0128095e-08
===========>   testing    <===========
Epoch: [1373][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0819 (0.0819)	
0.99999607 3.352212e-07
Epoch: [1373][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0358 (0.0604)	
0.9999918 3.422987e-07
Epoch: [1373][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0966 (0.0563)	
0.99999225 3.574293e-07
loss:  0.03924933226169147 0.038747089495286824
===========>   training    <===========
Epoch: [1374][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0351 (0.0351)	
0.99999046 2.2613409e-07
===========>   testing    <===========
Epoch: [1374][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0811 (0.0811)	
0.99999595 2.5129307e-07
Epoch: [1374][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0421 (0.0608)	
0.9999887 2.9973845e-07
Epoch: [1374][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0915 (0.0565)	
0.99999166 2.7223265e-07
loss:  0.039346909651512885 0.038747089495286824
===========>   training    <===========
Epoch: [1375][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0330 (0.0330)	
0.99999344 1.0023527e-07
===========>   testing    <===========
Epoch: [1375][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0822 (0.0822)	
0.9999958 3.0488897e-07
Epoch: [1375][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0339 (0.0608)	
0.9999883 3.575759e-07
Epoch: [1375][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0877 (0.0561)	
0.99999106 3.4634448e-07
loss:  0.03951776831562004 0.038747089495286824
===========>   training    <===========
Epoch: [1376][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0343 (0.0343)	
0.9999958 3.1399142e-07
===========>   testing    <===========
Epoch: [1376][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0865 (0.0865)	
0.99999535 3.0533968e-07
Epoch: [1376][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0232 (0.0596)	
0.9999865 3.322051e-07
Epoch: [1376][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0854 (0.0551)	
0.99999106 3.5302668e-07
loss:  0.039063732363709636 0.038747089495286824
===========>   training    <===========
Epoch: [1377][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0325 (0.0325)	
0.9999958 1.4481807e-07
===========>   testing    <===========
Epoch: [1377][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0980 (0.0980)	
0.9999963 3.253922e-07
Epoch: [1377][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0252 (0.0600)	
0.99998856 3.251651e-07
Epoch: [1377][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0860 (0.0558)	
0.9999918 3.7974633e-07
loss:  0.03946865903652075 0.038747089495286824
===========>   training    <===========
Epoch: [1378][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0340 (0.0340)	
0.9999944 3.115604e-07
===========>   testing    <===========
Epoch: [1378][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0942 (0.0942)	
0.9999964 4.3384358e-07
Epoch: [1378][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0202 (0.0591)	
0.9999887 4.3525839e-07
Epoch: [1378][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0854 (0.0555)	
0.9999924 4.843074e-07
loss:  0.0391793350268389 0.038747089495286824
===========>   training    <===========
Epoch: [1379][0/23]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0321 (0.0321)	
0.99999774 1.3200682e-07
===========>   testing    <===========
Epoch: [1379][0/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.1070 (0.1070)	
0.9999963 3.2017243e-07
Epoch: [1379][100/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0244 (0.0599)	
0.99998796 3.8300516e-07
Epoch: [1379][200/289]	Lr-deconv: [0.0]	Lr-other: [3.0563645913324066e-05]	Loss 0.0820 (0.0559)	
0.9999919 3.572119e-07
loss:  0.039158506506831725 0.038747089495286824
===========>   training    <===========
Epoch: [1380][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0316 (0.0316)	
0.99999106 1.6266827e-06
===========>   testing    <===========
Epoch: [1380][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1079 (0.1079)	
0.9999969 2.4703922e-07
Epoch: [1380][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0361 (0.0600)	
0.99999166 2.4613104e-07
Epoch: [1380][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0785 (0.0557)	
0.9999937 2.577523e-07
loss:  0.03862828731324508 0.038747089495286824
===========>   training    <===========
Epoch: [1381][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0355 (0.0355)	
0.99999404 1.8771615e-07
===========>   testing    <===========
Epoch: [1381][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0972 (0.0972)	
0.9999968 2.3796466e-07
Epoch: [1381][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0274 (0.0602)	
0.9999913 2.4050328e-07
Epoch: [1381][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0960 (0.0562)	
0.99999344 2.5581258e-07
loss:  0.03956831563510299 0.03862828731324508
===========>   training    <===========
Epoch: [1382][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0326 (0.0326)	
0.99999404 1.574461e-07
===========>   testing    <===========
Epoch: [1382][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1186 (0.1186)	
0.9999974 2.0774162e-07
Epoch: [1382][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0401 (0.0597)	
0.99999225 2.0821844e-07
Epoch: [1382][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0866 (0.0558)	
0.9999938 2.197028e-07
loss:  0.03997742728594733 0.03862828731324508
===========>   training    <===========
Epoch: [1383][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0339 (0.0339)	
0.9999949 2.7172607e-07
===========>   testing    <===========
Epoch: [1383][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1187 (0.1187)	
0.9999968 2.4097716e-07
Epoch: [1383][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0524 (0.0604)	
0.9999908 2.4068913e-07
Epoch: [1383][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0805 (0.0560)	
0.99999285 2.5851546e-07
loss:  0.03946401818154022 0.03862828731324508
===========>   training    <===========
Epoch: [1384][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0395 (0.0395)	
0.9999907 3.1628633e-07
===========>   testing    <===========
Epoch: [1384][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1240 (0.1240)	
0.99999666 2.0337781e-07
Epoch: [1384][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0471 (0.0603)	
0.9999908 2.0216939e-07
Epoch: [1384][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0937 (0.0557)	
0.9999931 2.2133348e-07
loss:  0.03951316202208177 0.03862828731324508
===========>   training    <===========
Epoch: [1385][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0309 (0.0309)	
0.99998987 1.19021664e-07
===========>   testing    <===========
Epoch: [1385][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1291 (0.1291)	
0.9999962 2.2945261e-07
Epoch: [1385][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0509 (0.0602)	
0.9999906 2.2852058e-07
Epoch: [1385][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0929 (0.0559)	
0.9999927 2.4642839e-07
loss:  0.03979905411318874 0.03862828731324508
===========>   training    <===========
Epoch: [1386][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0339 (0.0339)	
0.99999523 2.2582155e-08
===========>   testing    <===========
Epoch: [1386][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1102 (0.1102)	
0.9999968 2.3023318e-07
Epoch: [1386][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0349 (0.0609)	
0.9999912 2.2683392e-07
Epoch: [1386][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1029 (0.0566)	
0.99999404 2.3738914e-07
loss:  0.03953459636588397 0.03862828731324508
===========>   training    <===========
Epoch: [1387][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0405 (0.0405)	
0.9999968 5.70911e-07
===========>   testing    <===========
Epoch: [1387][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1087 (0.1087)	
0.9999969 2.519275e-07
Epoch: [1387][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0720 (0.0605)	
0.9999893 2.5353853e-07
Epoch: [1387][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1044 (0.0563)	
0.9999939 2.708428e-07
loss:  0.039568595670957274 0.03862828731324508
===========>   training    <===========
Epoch: [1388][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0357 (0.0357)	
0.99999666 9.1889145e-09
===========>   testing    <===========
Epoch: [1388][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1292 (0.1292)	
0.9999969 3.2044065e-07
Epoch: [1388][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0605 (0.0601)	
0.9999895 3.2577472e-07
Epoch: [1388][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0911 (0.0555)	
0.9999925 3.514958e-07
loss:  0.03890701725717083 0.03862828731324508
===========>   training    <===========
Epoch: [1389][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0378 (0.0378)	
0.99999285 4.230054e-08
===========>   testing    <===========
Epoch: [1389][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1287 (0.1287)	
0.99999654 1.947889e-07
Epoch: [1389][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0321 (0.0608)	
0.99998903 3.0468402e-07
Epoch: [1389][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0906 (0.0558)	
0.99999166 2.2653644e-07
loss:  0.039585198239236674 0.03862828731324508
===========>   training    <===========
Epoch: [1390][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0305 (0.0305)	
0.99999225 1.8215498e-07
===========>   testing    <===========
Epoch: [1390][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1148 (0.1148)	
0.9999964 2.0813091e-07
Epoch: [1390][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0309 (0.0606)	
0.99998903 2.3136738e-07
Epoch: [1390][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0969 (0.0556)	
0.99999166 2.5022743e-07
loss:  0.03937278363982477 0.03862828731324508
===========>   training    <===========
Epoch: [1391][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0363 (0.0363)	
0.99998856 1.083159e-07
===========>   testing    <===========
Epoch: [1391][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1138 (0.1138)	
0.9999974 2.394537e-07
Epoch: [1391][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0287 (0.0608)	
0.9999933 2.485038e-07
Epoch: [1391][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1019 (0.0556)	
0.99999416 2.660961e-07
loss:  0.038977120691708556 0.03862828731324508
===========>   training    <===========
Epoch: [1392][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0372 (0.0372)	
0.99999 8.49136e-08
===========>   testing    <===========
Epoch: [1392][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1026 (0.1026)	
0.99999714 2.643874e-07
Epoch: [1392][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0314 (0.0613)	
0.9999913 2.6970508e-07
Epoch: [1392][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0934 (0.0558)	
0.9999931 3.0503233e-07
loss:  0.03923339671474324 0.03862828731324508
===========>   training    <===========
Epoch: [1393][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0357 (0.0357)	
0.99998856 7.579921e-08
===========>   testing    <===========
Epoch: [1393][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1230 (0.1230)	
0.9999963 1.8106003e-07
Epoch: [1393][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0231 (0.0598)	
0.99998605 2.671531e-07
Epoch: [1393][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1062 (0.0556)	
0.99999106 2.1494317e-07
loss:  0.039419210971588514 0.03862828731324508
===========>   training    <===========
Epoch: [1394][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0312 (0.0312)	
0.99999356 3.0311316e-08
===========>   testing    <===========
Epoch: [1394][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1233 (0.1233)	
0.999997 2.041736e-07
Epoch: [1394][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0775 (0.0604)	
0.9999896 2.1335144e-07
Epoch: [1394][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1110 (0.0567)	
0.9999926 2.2465352e-07
loss:  0.04012301031565457 0.03862828731324508
===========>   training    <===========
Epoch: [1395][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0352 (0.0352)	
0.99999595 2.5063682e-07
===========>   testing    <===========
Epoch: [1395][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1172 (0.1172)	
0.9999968 1.8654615e-07
Epoch: [1395][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0519 (0.0613)	
0.9999908 2.2394207e-07
Epoch: [1395][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1145 (0.0571)	
0.99999285 2.2202711e-07
loss:  0.03991318981166303 0.03862828731324508
===========>   training    <===========
Epoch: [1396][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0397 (0.0397)	
0.9999968 3.4244005e-07
===========>   testing    <===========
Epoch: [1396][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1075 (0.1075)	
0.9999969 2.3395943e-07
Epoch: [1396][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0496 (0.0587)	
0.99998987 2.6408173e-07
Epoch: [1396][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1088 (0.0558)	
0.9999927 2.6887227e-07
loss:  0.03961697742534398 0.03862828731324508
===========>   training    <===========
Epoch: [1397][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0361 (0.0361)	
0.9999957 2.091614e-07
===========>   testing    <===========
Epoch: [1397][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1030 (0.1030)	
0.9999968 2.6099215e-07
Epoch: [1397][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0581 (0.0592)	
0.99999046 2.7108314e-07
Epoch: [1397][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0920 (0.0554)	
0.9999927 2.943837e-07
loss:  0.039650051996405034 0.03862828731324508
===========>   training    <===========
Epoch: [1398][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0349 (0.0349)	
0.99999464 5.7386035e-07
===========>   testing    <===========
Epoch: [1398][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1014 (0.1014)	
0.99999666 1.5680071e-07
Epoch: [1398][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0233 (0.0598)	
0.99998975 2.2551e-07
Epoch: [1398][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1036 (0.0560)	
0.999992 1.885233e-07
loss:  0.039503549159700224 0.03862828731324508
===========>   training    <===========
Epoch: [1399][0/23]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0348 (0.0348)	
0.9999931 4.588861e-08
===========>   testing    <===========
Epoch: [1399][0/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.1022 (0.1022)	
0.9999968 2.604526e-07
Epoch: [1399][100/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0399 (0.0606)	
0.9999918 2.6819387e-07
Epoch: [1399][200/289]	Lr-deconv: [0.0]	Lr-other: [2.903546361765786e-05]	Loss 0.0946 (0.0560)	
0.99999213 2.9710426e-07
loss:  0.039205286145501894 0.03862828731324508
===========>   training    <===========
Epoch: [1400][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0326 (0.0326)	
0.99999666 1.1580552e-07
===========>   testing    <===========
Epoch: [1400][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0951 (0.0951)	
0.9999968 2.1677883e-07
Epoch: [1400][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0264 (0.0600)	
0.99999154 2.305001e-07
Epoch: [1400][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1180 (0.0566)	
0.99999285 2.5850116e-07
loss:  0.03906594963769583 0.03862828731324508
===========>   training    <===========
Epoch: [1401][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0342 (0.0342)	
0.99999404 8.792007e-08
===========>   testing    <===========
Epoch: [1401][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1035 (0.1035)	
0.9999964 1.8160027e-07
Epoch: [1401][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0349 (0.0596)	
0.9999906 2.7325567e-07
Epoch: [1401][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1091 (0.0558)	
0.99999344 2.410916e-07
loss:  0.03921437644708525 0.03862828731324508
===========>   training    <===========
Epoch: [1402][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0370 (0.0370)	
0.9999943 3.3745525e-07
===========>   testing    <===========
Epoch: [1402][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0900 (0.0900)	
0.999997 2.4086708e-07
Epoch: [1402][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0415 (0.0592)	
0.999992 2.967959e-07
Epoch: [1402][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1093 (0.0561)	
0.9999943 3.2346063e-07
loss:  0.03946478892377259 0.03862828731324508
===========>   training    <===========
Epoch: [1403][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0412 (0.0412)	
0.99999404 4.5499206e-07
===========>   testing    <===========
Epoch: [1403][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1095 (0.1095)	
0.9999969 2.8031255e-07
Epoch: [1403][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0637 (0.0596)	
0.99999046 3.1475292e-07
Epoch: [1403][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1020 (0.0558)	
0.9999933 3.2116264e-07
loss:  0.03995424945128945 0.03862828731324508
===========>   training    <===========
Epoch: [1404][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0332 (0.0332)	
0.9999951 3.6860442e-07
===========>   testing    <===========
Epoch: [1404][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1167 (0.1167)	
0.99999654 1.8783506e-07
Epoch: [1404][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0630 (0.0599)	
0.9999895 2.7665712e-07
Epoch: [1404][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1106 (0.0565)	
0.9999924 2.3043066e-07
loss:  0.03976502791629899 0.03862828731324508
===========>   training    <===========
Epoch: [1405][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0382 (0.0382)	
0.9999956 3.4749982e-07
===========>   testing    <===========
Epoch: [1405][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0939 (0.0939)	
0.9999964 3.0966808e-07
Epoch: [1405][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0599 (0.0599)	
0.99998987 4.3524264e-07
Epoch: [1405][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1142 (0.0559)	
0.999992 3.422494e-07
loss:  0.03987200216767972 0.03862828731324508
===========>   training    <===========
Epoch: [1406][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0367 (0.0367)	
0.9999931 7.697466e-07
===========>   testing    <===========
Epoch: [1406][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0592 (0.0592)	
0.9999963 3.172391e-07
Epoch: [1406][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0488 (0.0608)	
0.9999894 3.4648986e-07
Epoch: [1406][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0993 (0.0565)	
0.9999913 4.661907e-07
loss:  0.04033749496799277 0.03862828731324508
===========>   training    <===========
Epoch: [1407][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0411 (0.0411)	
0.99999523 1.2102494e-07
===========>   testing    <===========
Epoch: [1407][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0555 (0.0555)	
0.9999963 2.9129163e-07
Epoch: [1407][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0672 (0.0615)	
0.99998915 3.1941275e-07
Epoch: [1407][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1148 (0.0572)	
0.9999907 3.5834364e-07
loss:  0.0403038639076958 0.03862828731324508
===========>   training    <===========
Epoch: [1408][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0343 (0.0343)	
0.99999166 3.9513665e-07
===========>   testing    <===========
Epoch: [1408][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0743 (0.0743)	
0.9999969 2.5411148e-07
Epoch: [1408][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0643 (0.0595)	
0.9999913 2.4175284e-07
Epoch: [1408][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1099 (0.0557)	
0.99999285 3.10138e-07
loss:  0.03977412823976745 0.03862828731324508
===========>   training    <===========
Epoch: [1409][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0324 (0.0324)	
0.99999547 2.413056e-06
===========>   testing    <===========
Epoch: [1409][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0739 (0.0739)	
0.999997 2.609324e-07
Epoch: [1409][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0412 (0.0590)	
0.9999919 2.5614972e-07
Epoch: [1409][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1104 (0.0554)	
0.9999937 3.277185e-07
loss:  0.039884462103221496 0.03862828731324508
===========>   training    <===========
Epoch: [1410][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0405 (0.0405)	
0.9999846 2.1360388e-07
===========>   testing    <===========
Epoch: [1410][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0628 (0.0628)	
0.999997 2.7389774e-07
Epoch: [1410][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0568 (0.0588)	
0.99999154 2.7617102e-07
Epoch: [1410][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1086 (0.0552)	
0.99999404 3.571969e-07
loss:  0.039591930283413235 0.03862828731324508
===========>   training    <===========
Epoch: [1411][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0370 (0.0370)	
0.99999154 5.6517205e-08
===========>   testing    <===========
Epoch: [1411][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0760 (0.0760)	
0.99999726 2.4602684e-07
Epoch: [1411][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0529 (0.0581)	
0.9999925 2.5365802e-07
Epoch: [1411][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1023 (0.0546)	
0.99999404 3.085432e-07
loss:  0.039641544332024825 0.03862828731324508
===========>   training    <===========
Epoch: [1412][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0377 (0.0377)	
0.99999154 1.5327392e-06
===========>   testing    <===========
Epoch: [1412][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0816 (0.0816)	
0.999997 2.686029e-07
Epoch: [1412][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0223 (0.0585)	
0.99999166 2.6867667e-07
Epoch: [1412][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1157 (0.0553)	
0.9999933 3.0569396e-07
loss:  0.0397277958398512 0.03862828731324508
===========>   training    <===========
Epoch: [1413][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0375 (0.0375)	
0.9999882 2.5598455e-08
===========>   testing    <===========
Epoch: [1413][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1001 (0.1001)	
0.99999726 2.6133483e-07
Epoch: [1413][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0337 (0.0583)	
0.99999285 2.646278e-07
Epoch: [1413][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0961 (0.0549)	
0.9999938 2.926041e-07
loss:  0.03990243294326101 0.03862828731324508
===========>   training    <===========
Epoch: [1414][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0351 (0.0351)	
0.99999094 1.0416441e-07
===========>   testing    <===========
Epoch: [1414][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0992 (0.0992)	
0.999997 2.586353e-07
Epoch: [1414][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0396 (0.0597)	
0.99999225 3.0200752e-07
Epoch: [1414][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0867 (0.0558)	
0.9999927 3.3923737e-07
loss:  0.0402342668805471 0.03862828731324508
===========>   training    <===========
Epoch: [1415][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0414 (0.0414)	
0.9999914 1.645263e-07
===========>   testing    <===========
Epoch: [1415][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0846 (0.0846)	
0.9999976 3.018693e-07
Epoch: [1415][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0358 (0.0600)	
0.99999404 3.0990918e-07
Epoch: [1415][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0917 (0.0558)	
0.9999945 3.4112713e-07
loss:  0.03976094662277263 0.03862828731324508
===========>   training    <===========
Epoch: [1416][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0329 (0.0329)	
0.99999464 7.551636e-07
===========>   testing    <===========
Epoch: [1416][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0728 (0.0728)	
0.999997 2.2176492e-07
Epoch: [1416][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0320 (0.0591)	
0.9999926 2.4953684e-07
Epoch: [1416][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0965 (0.0555)	
0.9999938 2.734882e-07
loss:  0.039663755947054846 0.03862828731324508
===========>   training    <===========
Epoch: [1417][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0287 (0.0287)	
0.9999902 4.6685452e-07
===========>   testing    <===========
Epoch: [1417][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0680 (0.0680)	
0.9999969 2.194557e-07
Epoch: [1417][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0667 (0.0599)	
0.99999154 2.2388782e-07
Epoch: [1417][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0999 (0.0558)	
0.99999356 2.458127e-07
loss:  0.040074441425516305 0.03862828731324508
===========>   training    <===========
Epoch: [1418][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0405 (0.0405)	
0.9999888 4.1914873e-08
===========>   testing    <===========
Epoch: [1418][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0670 (0.0670)	
0.99999714 3.3963036e-07
Epoch: [1418][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0587 (0.0593)	
0.9999926 3.434104e-07
Epoch: [1418][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.1020 (0.0557)	
0.9999945 3.6538555e-07
loss:  0.03961981038602469 0.03862828731324508
===========>   training    <===========
Epoch: [1419][0/23]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0379 (0.0379)	
0.9999945 1.7091655e-07
===========>   testing    <===========
Epoch: [1419][0/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0856 (0.0856)	
0.99999726 2.7916005e-07
Epoch: [1419][100/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0960 (0.0607)	
0.9999927 2.800715e-07
Epoch: [1419][200/289]	Lr-deconv: [0.0]	Lr-other: [2.7583690436774966e-05]	Loss 0.0872 (0.0560)	
0.9999945 2.9307722e-07
loss:  0.04054977888107125 0.03862828731324508
===========>   training    <===========
Epoch: [1420][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0361 (0.0361)	
0.99999 6.854435e-08
===========>   testing    <===========
Epoch: [1420][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0799 (0.0799)	
0.9999969 2.1622732e-07
Epoch: [1420][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0693 (0.0607)	
0.9999912 2.464566e-07
Epoch: [1420][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0855 (0.0560)	
0.9999931 2.652883e-07
loss:  0.04022498449715883 0.03862828731324508
===========>   training    <===========
Epoch: [1421][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0355 (0.0355)	
0.9999913 1.0180365e-07
===========>   testing    <===========
Epoch: [1421][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0788 (0.0788)	
0.99999654 2.3315378e-07
Epoch: [1421][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0406 (0.0589)	
0.9999888 2.4940363e-07
Epoch: [1421][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0866 (0.0550)	
0.9999926 2.7940806e-07
loss:  0.039340069118542154 0.03862828731324508
===========>   training    <===========
Epoch: [1422][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0333 (0.0333)	
0.99999523 1.4703004e-07
===========>   testing    <===========
Epoch: [1422][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0724 (0.0724)	
0.99999726 2.2040479e-07
Epoch: [1422][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0359 (0.0591)	
0.99999225 2.223405e-07
Epoch: [1422][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0848 (0.0552)	
0.9999944 2.4905043e-07
loss:  0.03937201347072394 0.03862828731324508
===========>   training    <===========
Epoch: [1423][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0332 (0.0332)	
0.99999344 5.5835752e-08
===========>   testing    <===========
Epoch: [1423][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0552 (0.0552)	
0.9999974 2.6791648e-07
Epoch: [1423][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0271 (0.0590)	
0.99999225 2.664661e-07
Epoch: [1423][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0911 (0.0552)	
0.9999938 3.0301118e-07
loss:  0.0395970166265317 0.03862828731324508
===========>   training    <===========
Epoch: [1424][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0290 (0.0290)	
0.9999938 6.062693e-08
===========>   testing    <===========
Epoch: [1424][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0842 (0.0842)	
0.9999969 2.4100103e-07
Epoch: [1424][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0340 (0.0598)	
0.9999912 2.431457e-07
Epoch: [1424][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0847 (0.0554)	
0.99999297 2.7728524e-07
loss:  0.03918663907845621 0.03862828731324508
===========>   training    <===========
Epoch: [1425][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0352 (0.0352)	
0.9999902 2.0757481e-08
===========>   testing    <===========
Epoch: [1425][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0860 (0.0860)	
0.99999666 2.7835563e-07
Epoch: [1425][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0456 (0.0596)	
0.99999034 2.8261186e-07
Epoch: [1425][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0789 (0.0550)	
0.9999924 3.1556263e-07
loss:  0.03968652686605301 0.03862828731324508
===========>   training    <===========
Epoch: [1426][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0305 (0.0305)	
0.9999784 8.324105e-08
===========>   testing    <===========
Epoch: [1426][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0905 (0.0905)	
0.9999968 1.6805824e-07
Epoch: [1426][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0287 (0.0596)	
0.9999914 1.6975571e-07
Epoch: [1426][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0926 (0.0554)	
0.9999931 2.0189232e-07
loss:  0.039835620909819736 0.03862828731324508
===========>   training    <===========
Epoch: [1427][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0329 (0.0329)	
0.9999912 9.2962935e-08
===========>   testing    <===========
Epoch: [1427][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.1029 (0.1029)	
0.9999969 2.6954e-07
Epoch: [1427][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0264 (0.0593)	
0.9999914 2.681023e-07
Epoch: [1427][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0790 (0.0551)	
0.99999344 3.0551215e-07
loss:  0.03928201688301691 0.03862828731324508
===========>   training    <===========
Epoch: [1428][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0398 (0.0398)	
0.9999939 1.0575336e-06
===========>   testing    <===========
Epoch: [1428][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0947 (0.0947)	
0.99999714 3.0167186e-07
Epoch: [1428][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0340 (0.0602)	
0.9999914 2.9831884e-07
Epoch: [1428][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0793 (0.0555)	
0.9999939 3.476145e-07
loss:  0.03988298977211957 0.03862828731324508
===========>   training    <===========
Epoch: [1429][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0302 (0.0302)	
0.99999416 9.7428966e-08
===========>   testing    <===========
Epoch: [1429][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.1087 (0.1087)	
0.999997 3.230817e-07
Epoch: [1429][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0294 (0.0598)	
0.9999912 3.2551822e-07
Epoch: [1429][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0754 (0.0552)	
0.9999932 3.7796582e-07
loss:  0.03953858279970446 0.03862828731324508
===========>   training    <===========
Epoch: [1430][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0409 (0.0409)	
0.99999547 1.09649356e-07
===========>   testing    <===========
Epoch: [1430][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.1013 (0.1013)	
0.99999666 3.0396544e-07
Epoch: [1430][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0249 (0.0591)	
0.99998975 3.2462904e-07
Epoch: [1430][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0796 (0.0550)	
0.9999932 3.897704e-07
loss:  0.03940949462876131 0.03862828731324508
===========>   training    <===========
Epoch: [1431][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0347 (0.0347)	
0.99998534 1.1676183e-06
===========>   testing    <===========
Epoch: [1431][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.1017 (0.1017)	
0.99999654 3.1478476e-07
Epoch: [1431][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0264 (0.0606)	
0.9999907 3.300414e-07
Epoch: [1431][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0816 (0.0559)	
0.9999927 3.8945083e-07
loss:  0.03952191058225041 0.03862828731324508
===========>   training    <===========
Epoch: [1432][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0309 (0.0309)	
0.99999464 1.8549964e-07
===========>   testing    <===========
Epoch: [1432][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0970 (0.0970)	
0.9999968 2.956921e-07
Epoch: [1432][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0214 (0.0593)	
0.99999106 3.0321556e-07
Epoch: [1432][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0880 (0.0551)	
0.9999932 3.5398278e-07
loss:  0.039488742824635215 0.03862828731324508
===========>   training    <===========
Epoch: [1433][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0344 (0.0344)	
0.99999094 5.260543e-08
===========>   testing    <===========
Epoch: [1433][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0910 (0.0910)	
0.99999666 2.4534503e-07
Epoch: [1433][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0193 (0.0588)	
0.99999106 2.4630762e-07
Epoch: [1433][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0964 (0.0551)	
0.9999925 2.9039407e-07
loss:  0.039444952712998416 0.03862828731324508
===========>   training    <===========
Epoch: [1434][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0399 (0.0399)	
0.99999535 1.5440581e-07
===========>   testing    <===========
Epoch: [1434][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.1003 (0.1003)	
0.9999964 2.8037243e-07
Epoch: [1434][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0247 (0.0600)	
0.9999914 2.961507e-07
Epoch: [1434][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0966 (0.0560)	
0.99999213 3.3168087e-07
loss:  0.03984018935145217 0.03862828731324508
===========>   training    <===========
Epoch: [1435][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0303 (0.0303)	
0.9999945 1.2895173e-07
===========>   testing    <===========
Epoch: [1435][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0938 (0.0938)	
0.9999962 2.660342e-07
Epoch: [1435][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0264 (0.0606)	
0.9999914 3.1646556e-07
Epoch: [1435][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0860 (0.0561)	
0.99999166 3.4749584e-07
loss:  0.03990008304709136 0.03862828731324508
===========>   training    <===========
Epoch: [1436][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0339 (0.0339)	
0.9999763 3.1839815e-07
===========>   testing    <===========
Epoch: [1436][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.1185 (0.1185)	
0.9999964 2.5281707e-07
Epoch: [1436][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0346 (0.0594)	
0.999992 2.706125e-07
Epoch: [1436][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0842 (0.0553)	
0.9999925 2.886053e-07
loss:  0.03992197733499614 0.03862828731324508
===========>   training    <===========
Epoch: [1437][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0381 (0.0381)	
0.9999938 3.6177707e-07
===========>   testing    <===========
Epoch: [1437][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.1237 (0.1237)	
0.9999958 2.4695913e-07
Epoch: [1437][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0244 (0.0604)	
0.99999 3.2658224e-07
Epoch: [1437][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0878 (0.0555)	
0.99999094 3.3966825e-07
loss:  0.03991179458848626 0.03862828731324508
===========>   training    <===========
Epoch: [1438][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0388 (0.0388)	
0.9999932 1.0431769e-07
===========>   testing    <===========
Epoch: [1438][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.1289 (0.1289)	
0.9999963 2.2114781e-07
Epoch: [1438][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0244 (0.0599)	
0.9999896 2.6482775e-07
Epoch: [1438][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0853 (0.0555)	
0.9999914 2.9656218e-07
loss:  0.04021545844415164 0.03862828731324508
===========>   training    <===========
Epoch: [1439][0/23]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0338 (0.0338)	
0.99999034 3.9889784e-08
===========>   testing    <===========
Epoch: [1439][0/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.1196 (0.1196)	
0.99999666 1.6603015e-07
Epoch: [1439][100/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0203 (0.0597)	
0.99999213 1.7256092e-07
Epoch: [1439][200/289]	Lr-deconv: [0.0]	Lr-other: [2.6204505914936218e-05]	Loss 0.0903 (0.0557)	
0.9999927 1.900791e-07
loss:  0.04027559704189543 0.03862828731324508
===========>   training    <===========
Epoch: [1440][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0345 (0.0345)	
0.999992 2.2980147e-07
===========>   testing    <===========
Epoch: [1440][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.1200 (0.1200)	
0.9999964 2.415793e-07
Epoch: [1440][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0194 (0.0598)	
0.9999906 2.525503e-07
Epoch: [1440][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0869 (0.0551)	
0.999992 2.8645033e-07
loss:  0.039415800235932164 0.03862828731324508
===========>   training    <===========
Epoch: [1441][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0342 (0.0342)	
0.9999906 1.6577587e-07
===========>   testing    <===========
Epoch: [1441][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.1121 (0.1121)	
0.99999654 1.7943698e-07
Epoch: [1441][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0217 (0.0608)	
0.999992 1.8874762e-07
Epoch: [1441][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0900 (0.0560)	
0.9999925 2.1045798e-07
loss:  0.03942549379641713 0.03862828731324508
===========>   training    <===========
Epoch: [1442][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0362 (0.0362)	
0.99998844 1.0079701e-07
===========>   testing    <===========
Epoch: [1442][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.1122 (0.1122)	
0.99999666 2.1304035e-07
Epoch: [1442][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0337 (0.0611)	
0.999992 2.2231676e-07
Epoch: [1442][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0832 (0.0559)	
0.9999925 2.448691e-07
loss:  0.03906510952584519 0.03862828731324508
===========>   training    <===========
Epoch: [1443][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0369 (0.0369)	
0.9999937 2.7001436e-08
===========>   testing    <===========
Epoch: [1443][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.1072 (0.1072)	
0.99999666 2.0694752e-07
Epoch: [1443][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0459 (0.0620)	
0.99998975 2.1333393e-07
Epoch: [1443][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0943 (0.0566)	
0.999992 2.2503993e-07
loss:  0.03970666188049299 0.03862828731324508
===========>   training    <===========
Epoch: [1444][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0435 (0.0435)	
0.9999933 1.06057115e-07
===========>   testing    <===========
Epoch: [1444][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0963 (0.0963)	
0.9999964 1.9408981e-07
Epoch: [1444][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0204 (0.0603)	
0.99998915 1.9364904e-07
Epoch: [1444][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.1084 (0.0567)	
0.999992 2.1002529e-07
loss:  0.03981304035057143 0.03862828731324508
===========>   training    <===========
Epoch: [1445][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0383 (0.0383)	
0.9999894 1.5901174e-08
===========>   testing    <===========
Epoch: [1445][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.1092 (0.1092)	
0.9999969 1.595039e-07
Epoch: [1445][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0261 (0.0595)	
0.99999213 1.5930672e-07
Epoch: [1445][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.1108 (0.0563)	
0.99999285 1.723139e-07
loss:  0.039714627918894796 0.03862828731324508
===========>   training    <===========
Epoch: [1446][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0300 (0.0300)	
0.9999908 1.06710885e-07
===========>   testing    <===========
Epoch: [1446][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.1140 (0.1140)	
0.999997 1.9015833e-07
Epoch: [1446][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0347 (0.0596)	
0.99999225 1.9197171e-07
Epoch: [1446][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.1104 (0.0561)	
0.99999356 2.0220061e-07
loss:  0.039527691236659 0.03862828731324508
===========>   training    <===========
Epoch: [1447][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0514 (0.0514)	
0.9999894 1.383016e-07
===========>   testing    <===========
Epoch: [1447][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.1094 (0.1094)	
0.9999962 2.4927093e-07
Epoch: [1447][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0549 (0.0594)	
0.9999914 2.529432e-07
Epoch: [1447][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.1081 (0.0558)	
0.9999927 2.7747836e-07
loss:  0.03975476609705286 0.03862828731324508
===========>   training    <===========
Epoch: [1448][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0307 (0.0307)	
0.9999964 9.5100894e-08
===========>   testing    <===========
Epoch: [1448][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0738 (0.0738)	
0.9999964 2.0215704e-07
Epoch: [1448][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0325 (0.0608)	
0.999992 2.0408348e-07
Epoch: [1448][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.1019 (0.0573)	
0.9999931 2.3113603e-07
loss:  0.0406644742553075 0.03862828731324508
===========>   training    <===========
Epoch: [1449][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0367 (0.0367)	
0.9999883 7.748019e-07
===========>   testing    <===========
Epoch: [1449][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0757 (0.0757)	
0.9999968 2.197355e-07
Epoch: [1449][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0291 (0.0604)	
0.99999285 2.249348e-07
Epoch: [1449][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0873 (0.0560)	
0.9999931 2.463997e-07
loss:  0.04000639441628773 0.03862828731324508
===========>   training    <===========
Epoch: [1450][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0355 (0.0355)	
0.9999962 1.3791609e-07
===========>   testing    <===========
Epoch: [1450][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0880 (0.0880)	
0.9999963 2.0829034e-07
Epoch: [1450][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0360 (0.0605)	
0.99999285 2.183172e-07
Epoch: [1450][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.1014 (0.0562)	
0.99999297 2.3465795e-07
loss:  0.04002711948614168 0.03862828731324508
===========>   training    <===========
Epoch: [1451][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0343 (0.0343)	
0.99999464 7.6792396e-08
===========>   testing    <===========
Epoch: [1451][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0625 (0.0625)	
0.9999964 1.9709854e-07
Epoch: [1451][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0357 (0.0609)	
0.9999925 2.015226e-07
Epoch: [1451][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.1171 (0.0572)	
0.9999925 2.1024152e-07
loss:  0.04032481314537706 0.03862828731324508
===========>   training    <===========
Epoch: [1452][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0301 (0.0301)	
0.99999344 2.2354901e-07
===========>   testing    <===========
Epoch: [1452][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0674 (0.0674)	
0.99999654 1.9399968e-07
Epoch: [1452][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0871 (0.0608)	
0.99999285 1.9856371e-07
Epoch: [1452][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.1102 (0.0567)	
0.9999926 2.0800252e-07
loss:  0.04126550283559216 0.03862828731324508
===========>   training    <===========
Epoch: [1453][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0358 (0.0358)	
0.999992 1.1173184e-07
===========>   testing    <===========
Epoch: [1453][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0757 (0.0757)	
0.9999962 1.857845e-07
Epoch: [1453][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0699 (0.0607)	
0.9999902 1.8934475e-07
Epoch: [1453][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.1062 (0.0567)	
0.9999914 2.0897937e-07
loss:  0.040942723856466245 0.03862828731324508
===========>   training    <===========
Epoch: [1454][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0297 (0.0297)	
0.9999932 3.7972387e-07
===========>   testing    <===========
Epoch: [1454][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0684 (0.0684)	
0.9999968 1.5180466e-07
Epoch: [1454][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0888 (0.0607)	
0.9999927 1.5295049e-07
Epoch: [1454][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.1023 (0.0567)	
0.9999932 1.5823454e-07
loss:  0.04056828792865019 0.03862828731324508
===========>   training    <===========
Epoch: [1455][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0326 (0.0326)	
0.99999213 7.536083e-08
===========>   testing    <===========
Epoch: [1455][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0908 (0.0908)	
0.9999968 2.5062795e-07
Epoch: [1455][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0587 (0.0613)	
0.9999927 2.5414565e-07
Epoch: [1455][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0918 (0.0571)	
0.9999927 2.6266085e-07
loss:  0.04092421985504724 0.03862828731324508
===========>   training    <===========
Epoch: [1456][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0332 (0.0332)	
0.9999927 1.617816e-08
===========>   testing    <===========
Epoch: [1456][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0760 (0.0760)	
0.99999714 2.4269164e-07
Epoch: [1456][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0368 (0.0612)	
0.9999926 2.4343436e-07
Epoch: [1456][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0879 (0.0572)	
0.9999933 2.6459853e-07
loss:  0.040819543020579 0.03862828731324508
===========>   training    <===========
Epoch: [1457][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0307 (0.0307)	
0.9999889 8.276768e-08
===========>   testing    <===========
Epoch: [1457][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0994 (0.0994)	
0.99999654 2.421571e-07
Epoch: [1457][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0567 (0.0601)	
0.99999154 2.4403127e-07
Epoch: [1457][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0825 (0.0562)	
0.9999925 2.542281e-07
loss:  0.040774805499330435 0.03862828731324508
===========>   training    <===========
Epoch: [1458][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0301 (0.0301)	
0.9999939 1.12393586e-07
===========>   testing    <===========
Epoch: [1458][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0852 (0.0852)	
0.99999666 2.785617e-07
Epoch: [1458][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0709 (0.0613)	
0.99999154 2.7805848e-07
Epoch: [1458][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0952 (0.0571)	
0.9999925 3.0582405e-07
loss:  0.04152782335397065 0.03862828731324508
===========>   training    <===========
Epoch: [1459][0/23]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0310 (0.0310)	
0.99998426 5.200952e-08
===========>   testing    <===========
Epoch: [1459][0/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.1056 (0.1056)	
0.9999968 2.8240547e-07
Epoch: [1459][100/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0698 (0.0604)	
0.9999914 2.8185121e-07
Epoch: [1459][200/289]	Lr-deconv: [0.0]	Lr-other: [2.4894280619189404e-05]	Loss 0.0956 (0.0566)	
0.9999926 3.1287973e-07
loss:  0.041007071465058775 0.03862828731324508
===========>   training    <===========
Epoch: [1460][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0371 (0.0371)	
0.9999902 6.117124e-08
===========>   testing    <===========
Epoch: [1460][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0739 (0.0739)	
0.99999607 2.5719933e-07
Epoch: [1460][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0351 (0.0603)	
0.9999906 2.6188772e-07
Epoch: [1460][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.1042 (0.0569)	
0.99999213 2.9590086e-07
loss:  0.040734700014055325 0.03862828731324508
===========>   training    <===========
Epoch: [1461][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0326 (0.0326)	
0.99999404 7.0042125e-07
===========>   testing    <===========
Epoch: [1461][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0644 (0.0644)	
0.9999974 1.8712953e-07
Epoch: [1461][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0394 (0.0601)	
0.99999356 1.8967872e-07
Epoch: [1461][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.1020 (0.0563)	
0.9999938 2.0236614e-07
loss:  0.04027744908720565 0.03862828731324508
===========>   training    <===========
Epoch: [1462][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0375 (0.0375)	
0.9999958 8.48592e-08
===========>   testing    <===========
Epoch: [1462][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0878 (0.0878)	
0.99999714 2.3142829e-07
Epoch: [1462][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0391 (0.0595)	
0.9999926 2.3612789e-07
Epoch: [1462][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0930 (0.0555)	
0.99999285 2.535175e-07
loss:  0.040062759289402505 0.03862828731324508
===========>   training    <===========
Epoch: [1463][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0293 (0.0293)	
0.9999907 2.8918185e-08
===========>   testing    <===========
Epoch: [1463][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0742 (0.0742)	
0.99999714 2.4525005e-07
Epoch: [1463][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0272 (0.0596)	
0.9999937 2.4584438e-07
Epoch: [1463][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.1103 (0.0561)	
0.9999939 2.6571166e-07
loss:  0.04009734682744637 0.03862828731324508
===========>   training    <===========
Epoch: [1464][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0399 (0.0399)	
0.99999535 1.8835202e-07
===========>   testing    <===========
Epoch: [1464][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0617 (0.0617)	
0.99999714 2.9505995e-07
Epoch: [1464][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0282 (0.0589)	
0.9999931 2.960157e-07
Epoch: [1464][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.1033 (0.0555)	
0.99999297 3.287324e-07
loss:  0.03990037953577308 0.03862828731324508
===========>   training    <===========
Epoch: [1465][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0433 (0.0433)	
0.999992 3.1503552e-07
===========>   testing    <===========
Epoch: [1465][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0762 (0.0762)	
0.9999968 3.013823e-07
Epoch: [1465][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0272 (0.0589)	
0.99999225 3.0663884e-07
Epoch: [1465][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0971 (0.0552)	
0.9999918 3.475389e-07
loss:  0.0396152155516577 0.03862828731324508
===========>   training    <===========
Epoch: [1466][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0281 (0.0281)	
0.99999285 1.2061925e-07
===========>   testing    <===========
Epoch: [1466][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0795 (0.0795)	
0.99999666 2.1624835e-07
Epoch: [1466][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0194 (0.0595)	
0.9999918 2.1784093e-07
Epoch: [1466][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.1036 (0.0558)	
0.9999926 2.3261076e-07
loss:  0.04011955373577736 0.03862828731324508
===========>   training    <===========
Epoch: [1467][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0366 (0.0366)	
0.9999732 1.10047864e-07
===========>   testing    <===========
Epoch: [1467][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0716 (0.0716)	
0.9999969 1.3759356e-07
Epoch: [1467][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0315 (0.0600)	
0.99999297 1.3573762e-07
Epoch: [1467][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0951 (0.0565)	
0.9999931 1.4460885e-07
loss:  0.03953138357919361 0.03862828731324508
===========>   training    <===========
Epoch: [1468][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0311 (0.0311)	
0.9999924 1.0700274e-07
===========>   testing    <===========
Epoch: [1468][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0795 (0.0795)	
0.9999969 2.1180986e-07
Epoch: [1468][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0499 (0.0589)	
0.9999937 2.1242766e-07
Epoch: [1468][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0983 (0.0559)	
0.9999933 2.24348e-07
loss:  0.039734714120644554 0.03862828731324508
===========>   training    <===========
Epoch: [1469][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0326 (0.0326)	
0.9999889 3.063202e-08
===========>   testing    <===========
Epoch: [1469][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0868 (0.0868)	
0.9999969 2.4792928e-07
Epoch: [1469][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0467 (0.0599)	
0.9999932 2.4840284e-07
Epoch: [1469][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.1032 (0.0563)	
0.999992 2.683013e-07
loss:  0.03942513627358901 0.03862828731324508
===========>   training    <===========
Epoch: [1470][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0331 (0.0331)	
0.99999404 4.3218515e-07
===========>   testing    <===========
Epoch: [1470][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0908 (0.0908)	
0.9999968 2.1641569e-07
Epoch: [1470][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0472 (0.0591)	
0.9999925 2.1623516e-07
Epoch: [1470][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.1149 (0.0562)	
0.9999924 2.2909185e-07
loss:  0.03949355120052367 0.03862828731324508
===========>   training    <===========
Epoch: [1471][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0348 (0.0348)	
0.9999944 1.9955005e-08
===========>   testing    <===========
Epoch: [1471][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0694 (0.0694)	
0.9999974 2.1056398e-07
Epoch: [1471][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0580 (0.0600)	
0.9999943 2.1148792e-07
Epoch: [1471][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.1108 (0.0567)	
0.9999932 2.2149734e-07
loss:  0.040197198343245866 0.03862828731324508
===========>   training    <===========
Epoch: [1472][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0302 (0.0302)	
0.9999918 3.9232567e-08
===========>   testing    <===========
Epoch: [1472][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0719 (0.0719)	
0.9999969 2.1229297e-07
Epoch: [1472][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0623 (0.0604)	
0.99999344 2.110356e-07
Epoch: [1472][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0944 (0.0566)	
0.9999925 2.2595432e-07
loss:  0.04043040264531805 0.03862828731324508
===========>   training    <===========
Epoch: [1473][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0370 (0.0370)	
0.99998546 5.9883706e-07
===========>   testing    <===========
Epoch: [1473][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0756 (0.0756)	
0.9999969 1.823218e-07
Epoch: [1473][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0467 (0.0597)	
0.99999285 1.8336596e-07
Epoch: [1473][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0887 (0.0564)	
0.9999926 1.993998e-07
loss:  0.040672880481892215 0.03862828731324508
===========>   training    <===========
Epoch: [1474][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0321 (0.0321)	
0.99999523 5.8834934e-07
===========>   testing    <===========
Epoch: [1474][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0879 (0.0879)	
0.9999968 2.3257438e-07
Epoch: [1474][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0396 (0.0606)	
0.99999285 2.3026544e-07
Epoch: [1474][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0980 (0.0569)	
0.9999925 2.5507904e-07
loss:  0.03993905200086434 0.03862828731324508
===========>   training    <===========
Epoch: [1475][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0327 (0.0327)	
0.9999931 8.922051e-08
===========>   testing    <===========
Epoch: [1475][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0855 (0.0855)	
0.9999969 2.0203927e-07
Epoch: [1475][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0741 (0.0602)	
0.9999927 1.9785053e-07
Epoch: [1475][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0984 (0.0570)	
0.9999926 2.2368764e-07
loss:  0.04033765755024632 0.03862828731324508
===========>   training    <===========
Epoch: [1476][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0393 (0.0393)	
0.99999535 1.0974414e-07
===========>   testing    <===========
Epoch: [1476][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0891 (0.0891)	
0.9999974 1.8499543e-07
Epoch: [1476][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0393 (0.0580)	
0.99999356 1.8173263e-07
Epoch: [1476][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0977 (0.0557)	
0.99999344 2.0674314e-07
loss:  0.03961532899947928 0.03862828731324508
===========>   training    <===========
Epoch: [1477][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0306 (0.0306)	
0.9999871 4.6285844e-08
===========>   testing    <===========
Epoch: [1477][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0789 (0.0789)	
0.9999976 2.448719e-07
Epoch: [1477][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0268 (0.0571)	
0.9999939 2.3383339e-07
Epoch: [1477][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0999 (0.0552)	
0.99999356 2.6525896e-07
loss:  0.039128095371783744 0.03862828731324508
===========>   training    <===========
Epoch: [1478][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0331 (0.0331)	
0.99999094 1.0975415e-06
===========>   testing    <===========
Epoch: [1478][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0917 (0.0917)	
0.9999968 2.4380864e-07
Epoch: [1478][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0252 (0.0570)	
0.99999166 2.419044e-07
Epoch: [1478][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.1041 (0.0551)	
0.9999908 2.8795017e-07
loss:  0.039292534575826155 0.03862828731324508
===========>   training    <===========
Epoch: [1479][0/23]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0377 (0.0377)	
0.9999932 4.7031065e-08
===========>   testing    <===========
Epoch: [1479][0/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0823 (0.0823)	
0.999997 2.3041703e-07
Epoch: [1479][100/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0245 (0.0574)	
0.9999912 2.2533759e-07
Epoch: [1479][200/289]	Lr-deconv: [0.0]	Lr-other: [2.3649566588229933e-05]	Loss 0.0927 (0.0549)	
0.9999918 2.586669e-07
loss:  0.039842409199102535 0.03862828731324508
===========>   training    <===========
Epoch: [1480][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0377 (0.0377)	
0.9999832 6.5008976e-08
===========>   testing    <===========
Epoch: [1480][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0719 (0.0719)	
0.99999726 2.3497189e-07
Epoch: [1480][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0367 (0.0574)	
0.99999297 2.3298774e-07
Epoch: [1480][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.1053 (0.0551)	
0.9999927 2.6107728e-07
loss:  0.039091388757904855 0.03862828731324508
===========>   training    <===========
Epoch: [1481][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0375 (0.0375)	
0.9999943 2.580641e-08
===========>   testing    <===========
Epoch: [1481][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0763 (0.0763)	
0.99999666 2.6088486e-07
Epoch: [1481][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0367 (0.0576)	
0.9999908 2.6449104e-07
Epoch: [1481][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0987 (0.0552)	
0.9999907 3.0616954e-07
loss:  0.039828538807686664 0.03862828731324508
===========>   training    <===========
Epoch: [1482][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0329 (0.0329)	
0.99999595 2.845477e-07
===========>   testing    <===========
Epoch: [1482][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0802 (0.0802)	
0.999997 2.5614725e-07
Epoch: [1482][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0371 (0.0579)	
0.99999285 2.5456094e-07
Epoch: [1482][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0958 (0.0556)	
0.9999925 2.9313927e-07
loss:  0.039619616535343516 0.03862828731324508
===========>   training    <===========
Epoch: [1483][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0289 (0.0289)	
0.9999938 5.894529e-07
===========>   testing    <===========
Epoch: [1483][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0674 (0.0674)	
0.999997 2.39727e-07
Epoch: [1483][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0642 (0.0584)	
0.9999927 2.3403372e-07
Epoch: [1483][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.1026 (0.0558)	
0.9999925 2.8169052e-07
loss:  0.04014749677410545 0.03862828731324508
===========>   training    <===========
Epoch: [1484][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0386 (0.0386)	
0.9999856 2.4508753e-07
===========>   testing    <===========
Epoch: [1484][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0733 (0.0733)	
0.999997 2.2906343e-07
Epoch: [1484][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0358 (0.0588)	
0.9999939 2.1904673e-07
Epoch: [1484][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.1165 (0.0559)	
0.9999927 2.6370648e-07
loss:  0.0397215554963638 0.03862828731324508
===========>   training    <===========
Epoch: [1485][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0326 (0.0326)	
0.9999937 2.61368e-07
===========>   testing    <===========
Epoch: [1485][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0753 (0.0753)	
0.9999976 1.9283523e-07
Epoch: [1485][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0729 (0.0611)	
0.99999416 1.8852634e-07
Epoch: [1485][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.1072 (0.0568)	
0.99999404 2.157941e-07
loss:  0.03976316295735671 0.03862828731324508
===========>   training    <===========
Epoch: [1486][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0368 (0.0368)	
0.9999881 2.1730438e-07
===========>   testing    <===========
Epoch: [1486][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.1001 (0.1001)	
0.99999654 2.1064673e-07
Epoch: [1486][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0894 (0.0604)	
0.99999213 2.0914605e-07
Epoch: [1486][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0911 (0.0563)	
0.99999166 2.6574688e-07
loss:  0.039973160725488954 0.03862828731324508
===========>   training    <===========
Epoch: [1487][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0376 (0.0376)	
0.99999034 1.9799832e-07
===========>   testing    <===========
Epoch: [1487][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0941 (0.0941)	
0.9999964 2.2210695e-07
Epoch: [1487][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0401 (0.0591)	
0.99999166 2.4874728e-07
Epoch: [1487][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0857 (0.0558)	
0.9999902 2.691696e-07
loss:  0.040020153262259384 0.03862828731324508
===========>   training    <===========
Epoch: [1488][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0304 (0.0304)	
0.9999943 7.494642e-08
===========>   testing    <===========
Epoch: [1488][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0900 (0.0900)	
0.99999714 1.8041712e-07
Epoch: [1488][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0334 (0.0588)	
0.9999932 1.8121585e-07
Epoch: [1488][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0850 (0.0556)	
0.9999918 2.1360755e-07
loss:  0.039769254826943046 0.03862828731324508
===========>   training    <===========
Epoch: [1489][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0345 (0.0345)	
0.9999894 1.3020385e-08
===========>   testing    <===========
Epoch: [1489][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0890 (0.0890)	
0.99999714 2.1179552e-07
Epoch: [1489][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0212 (0.0601)	
0.99999225 2.1155992e-07
Epoch: [1489][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0944 (0.0560)	
0.99999154 2.543149e-07
loss:  0.040050241381229035 0.03862828731324508
===========>   training    <===========
Epoch: [1490][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0362 (0.0362)	
0.9999927 6.769309e-08
===========>   testing    <===========
Epoch: [1490][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0771 (0.0771)	
0.99999726 2.001623e-07
Epoch: [1490][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0632 (0.0606)	
0.99999344 2.0052914e-07
Epoch: [1490][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0870 (0.0564)	
0.999992 2.3872863e-07
loss:  0.0401333923133369 0.03862828731324508
===========>   training    <===========
Epoch: [1491][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0359 (0.0359)	
0.99999106 4.099768e-08
===========>   testing    <===========
Epoch: [1491][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0736 (0.0736)	
0.99999726 1.7555539e-07
Epoch: [1491][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0583 (0.0611)	
0.9999927 1.7478226e-07
Epoch: [1491][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0915 (0.0566)	
0.99999154 2.0201887e-07
loss:  0.04015974050820448 0.03862828731324508
===========>   training    <===========
Epoch: [1492][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0406 (0.0406)	
0.9999914 2.1171608e-08
===========>   testing    <===========
Epoch: [1492][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0791 (0.0791)	
0.9999975 1.6563098e-07
Epoch: [1492][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.1083 (0.0614)	
0.99999404 1.6648981e-07
Epoch: [1492][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.1022 (0.0566)	
0.9999927 2.0199631e-07
loss:  0.040607975415128617 0.03862828731324508
===========>   training    <===========
Epoch: [1493][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0350 (0.0350)	
0.99998975 3.010957e-09
===========>   testing    <===========
Epoch: [1493][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0634 (0.0634)	
0.99999726 1.977662e-07
Epoch: [1493][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0418 (0.0608)	
0.99999297 1.9474987e-07
Epoch: [1493][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.1041 (0.0565)	
0.9999926 2.4450367e-07
loss:  0.04046097621897071 0.03862828731324508
===========>   training    <===========
Epoch: [1494][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0402 (0.0402)	
0.9999832 5.1996622e-08
===========>   testing    <===========
Epoch: [1494][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0754 (0.0754)	
0.9999976 2.129656e-07
Epoch: [1494][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0326 (0.0610)	
0.99999416 2.003294e-07
Epoch: [1494][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.1105 (0.0567)	
0.9999938 2.5876088e-07
loss:  0.04019322449168705 0.03862828731324508
===========>   training    <===========
Epoch: [1495][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0318 (0.0318)	
0.9999925 8.035637e-09
===========>   testing    <===========
Epoch: [1495][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0938 (0.0938)	
0.9999975 2.1895356e-07
Epoch: [1495][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0314 (0.0595)	
0.99999344 2.072485e-07
Epoch: [1495][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.1034 (0.0560)	
0.9999927 2.8170314e-07
loss:  0.03988118928164042 0.03862828731324508
===========>   training    <===========
Epoch: [1496][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0288 (0.0288)	
0.9999888 1.04184465e-07
===========>   testing    <===========
Epoch: [1496][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0979 (0.0979)	
0.9999974 2.0859011e-07
Epoch: [1496][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0543 (0.0590)	
0.9999937 2.0286777e-07
Epoch: [1496][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0953 (0.0554)	
0.9999925 2.6315203e-07
loss:  0.03980841774988053 0.03862828731324508
===========>   training    <===========
Epoch: [1497][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0315 (0.0315)	
0.9999888 6.2613985e-08
===========>   testing    <===========
Epoch: [1497][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0658 (0.0658)	
0.999997 2.1360877e-07
Epoch: [1497][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0687 (0.0601)	
0.99999213 2.1199578e-07
Epoch: [1497][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.1003 (0.0562)	
0.9999914 2.6740852e-07
loss:  0.04019590844880705 0.03862828731324508
===========>   training    <===========
Epoch: [1498][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0344 (0.0344)	
0.9999943 1.9717092e-07
===========>   testing    <===========
Epoch: [1498][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0701 (0.0701)	
0.9999968 1.6698816e-07
Epoch: [1498][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0617 (0.0604)	
0.9999919 1.6499217e-07
Epoch: [1498][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.1014 (0.0564)	
0.99999166 2.0126369e-07
loss:  0.03992491926224817 0.03862828731324508
===========>   training    <===========
Epoch: [1499][0/23]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0341 (0.0341)	
0.9999801 2.836578e-08
===========>   testing    <===========
Epoch: [1499][0/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.0796 (0.0796)	
0.9999974 1.9872057e-07
Epoch: [1499][100/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.1226 (0.0607)	
0.9999931 1.9596685e-07
Epoch: [1499][200/289]	Lr-deconv: [0.0]	Lr-other: [2.2467088258818436e-05]	Loss 0.1041 (0.0567)	
0.9999927 2.4034483e-07
loss:  0.04013075630715013 0.03862828731324508
===========>   training    <===========
Epoch: [1500][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0329 (0.0329)	
0.9999924 5.3590696e-09
===========>   testing    <===========
Epoch: [1500][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0655 (0.0655)	
0.99999726 1.9657031e-07
Epoch: [1500][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0647 (0.0596)	
0.9999925 1.9257205e-07
Epoch: [1500][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.1022 (0.0560)	
0.99999285 2.3399156e-07
loss:  0.03998170933788481 0.03862828731324508
===========>   training    <===========
Epoch: [1501][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0342 (0.0342)	
0.99999595 2.6489891e-08
===========>   testing    <===========
Epoch: [1501][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0762 (0.0762)	
0.99999726 1.4699148e-07
Epoch: [1501][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0630 (0.0598)	
0.9999925 1.4321513e-07
Epoch: [1501][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.1148 (0.0565)	
0.9999926 1.7616517e-07
loss:  0.040405302642035346 0.03862828731324508
===========>   training    <===========
Epoch: [1502][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0301 (0.0301)	
0.99999785 1.2604445e-07
===========>   testing    <===========
Epoch: [1502][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0727 (0.0727)	
0.9999976 1.4460389e-07
Epoch: [1502][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.1514 (0.0618)	
0.9999939 1.3992211e-07
Epoch: [1502][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.1042 (0.0575)	
0.9999933 1.5545308e-07
loss:  0.04092881773400481 0.03862828731324508
===========>   training    <===========
Epoch: [1503][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0312 (0.0312)	
0.99998844 2.0420399e-07
===========>   testing    <===========
Epoch: [1503][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0686 (0.0686)	
0.9999975 1.8967982e-07
Epoch: [1503][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0793 (0.0619)	
0.9999937 1.8534368e-07
Epoch: [1503][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.1010 (0.0574)	
0.9999931 2.1458105e-07
loss:  0.040065951455485194 0.03862828731324508
===========>   training    <===========
Epoch: [1504][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0329 (0.0329)	
0.9999856 2.9930824e-08
===========>   testing    <===========
Epoch: [1504][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0913 (0.0913)	
0.99999726 1.5990811e-07
Epoch: [1504][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0650 (0.0597)	
0.9999932 1.5518008e-07
Epoch: [1504][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.1041 (0.0561)	
0.9999933 1.7964244e-07
loss:  0.04020844789624711 0.03862828731324508
===========>   training    <===========
Epoch: [1505][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0349 (0.0349)	
0.9999951 1.7574902e-07
===========>   testing    <===========
Epoch: [1505][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0813 (0.0813)	
0.99999726 1.8219389e-07
Epoch: [1505][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.1276 (0.0605)	
0.9999933 1.7839483e-07
Epoch: [1505][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.1138 (0.0565)	
0.9999931 2.0930786e-07
loss:  0.04075048391073255 0.03862828731324508
===========>   training    <===========
Epoch: [1506][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0371 (0.0371)	
0.9999924 7.107271e-08
===========>   testing    <===========
Epoch: [1506][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0889 (0.0889)	
0.9999975 1.7241138e-07
Epoch: [1506][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.1657 (0.0613)	
0.9999939 1.688852e-07
Epoch: [1506][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0978 (0.0570)	
0.9999937 1.9465482e-07
loss:  0.04098213504327186 0.03862828731324508
===========>   training    <===========
Epoch: [1507][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0322 (0.0322)	
0.9999949 8.184554e-08
===========>   testing    <===========
Epoch: [1507][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.1059 (0.1059)	
0.9999975 2.0844496e-07
Epoch: [1507][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.1734 (0.0610)	
0.99999356 2.0347461e-07
Epoch: [1507][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0986 (0.0566)	
0.99999356 2.2945525e-07
loss:  0.04026916265186087 0.03862828731324508
===========>   training    <===========
Epoch: [1508][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0321 (0.0321)	
0.9999933 9.7956665e-08
===========>   testing    <===========
Epoch: [1508][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0930 (0.0930)	
0.99999714 2.0148494e-07
Epoch: [1508][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.1208 (0.0609)	
0.9999931 2.040068e-07
Epoch: [1508][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.1049 (0.0567)	
0.9999931 2.40865e-07
loss:  0.040506909087131726 0.03862828731324508
===========>   training    <===========
Epoch: [1509][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0362 (0.0362)	
0.99998665 5.3875198e-09
===========>   testing    <===========
Epoch: [1509][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0785 (0.0785)	
0.9999975 1.3849905e-07
Epoch: [1509][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.1311 (0.0607)	
0.99999356 1.3767495e-07
Epoch: [1509][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.1048 (0.0562)	
0.9999938 1.5833659e-07
loss:  0.04005383500357529 0.03862828731324508
===========>   training    <===========
Epoch: [1510][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0401 (0.0401)	
0.99998426 8.3369116e-08
===========>   testing    <===========
Epoch: [1510][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0669 (0.0669)	
0.9999974 1.531931e-07
Epoch: [1510][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.1475 (0.0613)	
0.9999931 1.5190878e-07
Epoch: [1510][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.1065 (0.0566)	
0.9999931 1.8130262e-07
loss:  0.04045166862840688 0.03862828731324508
===========>   training    <===========
Epoch: [1511][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0402 (0.0402)	
0.9999895 2.676915e-07
===========>   testing    <===========
Epoch: [1511][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0887 (0.0887)	
0.9999975 1.9173459e-07
Epoch: [1511][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0838 (0.0608)	
0.99999297 1.8774445e-07
Epoch: [1511][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0980 (0.0563)	
0.9999926 2.2215018e-07
loss:  0.04007282371166032 0.03862828731324508
===========>   training    <===========
Epoch: [1512][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0285 (0.0285)	
0.9999937 4.5600854e-07
===========>   testing    <===========
Epoch: [1512][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0969 (0.0969)	
0.9999974 2.1450536e-07
Epoch: [1512][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0512 (0.0608)	
0.9999926 2.1245664e-07
Epoch: [1512][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0823 (0.0562)	
0.9999924 2.4561567e-07
loss:  0.04011321425654879 0.03862828731324508
===========>   training    <===========
Epoch: [1513][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0277 (0.0277)	
0.9999957 2.30042e-07
===========>   testing    <===========
Epoch: [1513][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0948 (0.0948)	
0.9999974 2.090286e-07
Epoch: [1513][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0230 (0.0600)	
0.999992 2.070636e-07
Epoch: [1513][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0954 (0.0563)	
0.9999926 2.4274487e-07
loss:  0.039648987693060245 0.03862828731324508
===========>   training    <===========
Epoch: [1514][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0398 (0.0398)	
0.99998224 2.807598e-08
===========>   testing    <===========
Epoch: [1514][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.1141 (0.1141)	
0.9999974 1.6585021e-07
Epoch: [1514][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0351 (0.0600)	
0.9999933 1.6512644e-07
Epoch: [1514][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0863 (0.0563)	
0.9999933 1.9838049e-07
loss:  0.039393130628894935 0.03862828731324508
===========>   training    <===========
Epoch: [1515][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0285 (0.0285)	
0.9999943 2.1682865e-07
===========>   testing    <===========
Epoch: [1515][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.1018 (0.1018)	
0.99999714 1.6561724e-07
Epoch: [1515][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0357 (0.0598)	
0.9999926 1.6491038e-07
Epoch: [1515][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0934 (0.0562)	
0.9999933 1.9413831e-07
loss:  0.03939989157506307 0.03862828731324508
===========>   training    <===========
Epoch: [1516][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0305 (0.0305)	
0.9999975 2.0322523e-07
===========>   testing    <===========
Epoch: [1516][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.1120 (0.1120)	
0.99999726 1.4491367e-07
Epoch: [1516][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0936 (0.0611)	
0.9999926 1.457604e-07
Epoch: [1516][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0793 (0.0565)	
0.9999932 1.6438544e-07
loss:  0.040308347639524955 0.03862828731324508
===========>   training    <===========
Epoch: [1517][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0303 (0.0303)	
0.9999937 9.88297e-08
===========>   testing    <===========
Epoch: [1517][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.1167 (0.1167)	
0.999997 1.6798855e-07
Epoch: [1517][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0471 (0.0602)	
0.9999912 1.6861499e-07
Epoch: [1517][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0966 (0.0564)	
0.9999924 1.8937327e-07
loss:  0.03964873714107808 0.03862828731324508
===========>   training    <===========
Epoch: [1518][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0395 (0.0395)	
0.9999895 1.8966746e-08
===========>   testing    <===========
Epoch: [1518][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.1036 (0.1036)	
0.999997 2.0179742e-07
Epoch: [1518][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0478 (0.0602)	
0.9999913 2.0515401e-07
Epoch: [1518][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0932 (0.0568)	
0.99999225 2.2716472e-07
loss:  0.0396084828362373 0.03862828731324508
===========>   training    <===========
Epoch: [1519][0/23]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0394 (0.0394)	
0.9999801 4.151704e-08
===========>   testing    <===========
Epoch: [1519][0/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.1043 (0.1043)	
0.9999976 1.6280238e-07
Epoch: [1519][100/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0578 (0.0606)	
0.9999926 1.6509684e-07
Epoch: [1519][200/289]	Lr-deconv: [0.0]	Lr-other: [2.134373384587751e-05]	Loss 0.0877 (0.0570)	
0.9999938 1.840745e-07
loss:  0.03981376506424461 0.03862828731324508
===========>   training    <===========
Epoch: [1520][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0313 (0.0313)	
0.9999933 1.3524944e-07
===========>   testing    <===========
Epoch: [1520][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.1062 (0.1062)	
0.9999976 1.6309188e-07
Epoch: [1520][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.1000 (0.0611)	
0.9999924 1.6453963e-07
Epoch: [1520][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0831 (0.0572)	
0.9999933 1.8254764e-07
loss:  0.04074505630157221 0.03862828731324508
===========>   training    <===========
Epoch: [1521][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0307 (0.0307)	
0.99999654 1.6699963e-07
===========>   testing    <===========
Epoch: [1521][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.1029 (0.1029)	
0.99999726 2.2330269e-07
Epoch: [1521][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0692 (0.0615)	
0.9999907 2.2318136e-07
Epoch: [1521][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0924 (0.0572)	
0.99999213 2.527385e-07
loss:  0.04052232072642703 0.03862828731324508
===========>   training    <===========
Epoch: [1522][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0337 (0.0337)	
0.99999285 2.307033e-07
===========>   testing    <===========
Epoch: [1522][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.1145 (0.1145)	
0.99999774 1.8084984e-07
Epoch: [1522][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0739 (0.0613)	
0.9999925 1.8372059e-07
Epoch: [1522][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0879 (0.0572)	
0.99999356 2.1369435e-07
loss:  0.04009892972739093 0.03862828731324508
===========>   training    <===========
Epoch: [1523][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0349 (0.0349)	
0.9999821 1.06467134e-07
===========>   testing    <===========
Epoch: [1523][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.1181 (0.1181)	
0.99999774 1.7306886e-07
Epoch: [1523][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0918 (0.0623)	
0.9999931 1.7640222e-07
Epoch: [1523][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0776 (0.0574)	
0.99999344 2.0252348e-07
loss:  0.04022878261281826 0.03862828731324508
===========>   training    <===========
Epoch: [1524][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0358 (0.0358)	
0.99999523 3.56742e-08
===========>   testing    <===========
Epoch: [1524][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.1276 (0.1276)	
0.99999785 1.5146006e-07
Epoch: [1524][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0706 (0.0613)	
0.99999344 1.5449477e-07
Epoch: [1524][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0904 (0.0568)	
0.9999938 1.7433378e-07
loss:  0.039625242662619575 0.03862828731324508
===========>   training    <===========
Epoch: [1525][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0372 (0.0372)	
0.999979 2.1193104e-08
===========>   testing    <===========
Epoch: [1525][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.1045 (0.1045)	
0.99999774 1.5407073e-07
Epoch: [1525][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0658 (0.0602)	
0.9999939 1.5450759e-07
Epoch: [1525][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0791 (0.0561)	
0.9999938 1.7468393e-07
loss:  0.03921649600542476 0.03862828731324508
===========>   training    <===========
Epoch: [1526][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0410 (0.0410)	
0.9999864 5.973153e-08
===========>   testing    <===========
Epoch: [1526][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.1031 (0.1031)	
0.99999714 2.357566e-07
Epoch: [1526][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0479 (0.0604)	
0.99999106 2.333424e-07
Epoch: [1526][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0873 (0.0565)	
0.99999154 2.7007573e-07
loss:  0.0395699756624901 0.03862828731324508
===========>   training    <===========
Epoch: [1527][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0344 (0.0344)	
0.99999416 6.46028e-08
===========>   testing    <===========
Epoch: [1527][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.1126 (0.1126)	
0.99999726 2.456536e-07
Epoch: [1527][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0807 (0.0601)	
0.99999154 2.5092046e-07
Epoch: [1527][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0840 (0.0562)	
0.999992 2.877668e-07
loss:  0.04018852191758959 0.03862828731324508
===========>   training    <===========
Epoch: [1528][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0316 (0.0316)	
0.999982 2.650822e-07
===========>   testing    <===========
Epoch: [1528][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.1075 (0.1075)	
0.9999975 1.8246601e-07
Epoch: [1528][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.1460 (0.0613)	
0.99999285 1.877208e-07
Epoch: [1528][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0826 (0.0569)	
0.99999297 2.0364253e-07
loss:  0.04052376124662549 0.03862828731324508
===========>   training    <===========
Epoch: [1529][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0325 (0.0325)	
0.9999918 3.572677e-08
===========>   testing    <===========
Epoch: [1529][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0913 (0.0913)	
0.999997 1.9566302e-07
Epoch: [1529][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.1976 (0.0619)	
0.9999918 1.9952725e-07
Epoch: [1529][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0896 (0.0571)	
0.99999154 2.1695813e-07
loss:  0.04045560823698613 0.03862828731324508
===========>   training    <===========
Epoch: [1530][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0297 (0.0297)	
0.9999933 1.763743e-07
===========>   testing    <===========
Epoch: [1530][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0835 (0.0835)	
0.99999714 2.1561966e-07
Epoch: [1530][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.1315 (0.0610)	
0.9999924 2.1960392e-07
Epoch: [1530][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0842 (0.0567)	
0.99999225 2.4117094e-07
loss:  0.04088297105504901 0.03862828731324508
===========>   training    <===========
Epoch: [1531][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0445 (0.0445)	
0.9999838 2.8632297e-08
===========>   testing    <===========
Epoch: [1531][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0781 (0.0781)	
0.99999714 1.857133e-07
Epoch: [1531][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0825 (0.0594)	
0.9999925 1.924351e-07
Epoch: [1531][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0867 (0.0559)	
0.9999931 2.0720898e-07
loss:  0.0402032599460973 0.03862828731324508
===========>   training    <===========
Epoch: [1532][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0353 (0.0353)	
0.99999106 8.3404586e-08
===========>   testing    <===========
Epoch: [1532][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0725 (0.0725)	
0.9999969 2.2425859e-07
Epoch: [1532][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.1882 (0.0608)	
0.999992 2.2697154e-07
Epoch: [1532][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0817 (0.0565)	
0.99999166 2.6312193e-07
loss:  0.040350535969892354 0.03862828731324508
===========>   training    <===========
Epoch: [1533][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0288 (0.0288)	
0.999995 3.5705174e-08
===========>   testing    <===========
Epoch: [1533][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0905 (0.0905)	
0.9999974 2.1025134e-07
Epoch: [1533][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.1146 (0.0609)	
0.99999285 2.1456326e-07
Epoch: [1533][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0968 (0.0570)	
0.9999927 2.3546092e-07
loss:  0.040314345563634 0.03862828731324508
===========>   training    <===========
Epoch: [1534][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0319 (0.0319)	
0.9999901 2.4223357e-07
===========>   testing    <===========
Epoch: [1534][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0795 (0.0795)	
0.999997 2.1958905e-07
Epoch: [1534][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.1277 (0.0608)	
0.9999924 2.206439e-07
Epoch: [1534][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0898 (0.0566)	
0.9999925 2.4793897e-07
loss:  0.04077602701181127 0.03862828731324508
===========>   training    <===========
Epoch: [1535][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0370 (0.0370)	
0.9999845 1.4843809e-07
===========>   testing    <===========
Epoch: [1535][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0931 (0.0931)	
0.9999969 2.1597302e-07
Epoch: [1535][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.1322 (0.0616)	
0.99999225 2.16028e-07
Epoch: [1535][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0999 (0.0572)	
0.9999927 2.472028e-07
loss:  0.04106937269074762 0.03862828731324508
===========>   training    <===========
Epoch: [1536][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0411 (0.0411)	
0.9999913 6.012049e-08
===========>   testing    <===========
Epoch: [1536][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0969 (0.0969)	
0.99999714 2.1997829e-07
Epoch: [1536][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.1025 (0.0609)	
0.99999213 2.2048846e-07
Epoch: [1536][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0979 (0.0571)	
0.9999927 2.4770287e-07
loss:  0.04097061528596557 0.03862828731324508
===========>   training    <===========
Epoch: [1537][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0310 (0.0310)	
0.99999547 2.6291573e-07
===========>   testing    <===========
Epoch: [1537][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0929 (0.0929)	
0.9999974 1.8643091e-07
Epoch: [1537][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.1521 (0.0615)	
0.9999927 1.8700767e-07
Epoch: [1537][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.1019 (0.0574)	
0.99999297 2.0965587e-07
loss:  0.040814590590867894 0.03862828731324508
===========>   training    <===========
Epoch: [1538][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0425 (0.0425)	
0.9999912 8.890217e-08
===========>   testing    <===========
Epoch: [1538][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0833 (0.0833)	
0.9999976 2.4018195e-07
Epoch: [1538][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.1803 (0.0617)	
0.9999926 2.4067123e-07
Epoch: [1538][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.1009 (0.0576)	
0.9999938 2.5787082e-07
loss:  0.04074717848555742 0.03862828731324508
===========>   training    <===========
Epoch: [1539][0/23]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0363 (0.0363)	
0.99998224 1.0711874e-07
===========>   testing    <===========
Epoch: [1539][0/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.0855 (0.0855)	
0.99999785 2.0665445e-07
Epoch: [1539][100/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.1696 (0.0618)	
0.9999925 2.0899472e-07
Epoch: [1539][200/289]	Lr-deconv: [0.0]	Lr-other: [2.0276547153583635e-05]	Loss 0.1003 (0.0575)	
0.9999943 2.2559946e-07
loss:  0.040816807173199465 0.03862828731324508
===========>   training    <===========
Epoch: [1540][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0350 (0.0350)	
0.9999901 1.3308474e-08
===========>   testing    <===========
Epoch: [1540][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1006 (0.1006)	
0.99999726 2.1242644e-07
Epoch: [1540][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1764 (0.0623)	
0.9999912 2.1465392e-07
Epoch: [1540][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1020 (0.0575)	
0.99999344 2.3288645e-07
loss:  0.041077503425110184 0.03862828731324508
===========>   training    <===========
Epoch: [1541][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0320 (0.0320)	
0.9999939 1.7941748e-07
===========>   testing    <===========
Epoch: [1541][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0978 (0.0978)	
0.9999974 2.6604533e-07
Epoch: [1541][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1254 (0.0611)	
0.9999907 2.6859726e-07
Epoch: [1541][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1054 (0.0569)	
0.99999297 2.9236648e-07
loss:  0.040734723381170346 0.03862828731324508
===========>   training    <===========
Epoch: [1542][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0383 (0.0383)	
0.9999831 8.742777e-08
===========>   testing    <===========
Epoch: [1542][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1176 (0.1176)	
0.9999975 2.1878117e-07
Epoch: [1542][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1595 (0.0609)	
0.9999914 2.241087e-07
Epoch: [1542][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1025 (0.0566)	
0.9999932 2.3681075e-07
loss:  0.04055241823610001 0.03862828731324508
===========>   training    <===========
Epoch: [1543][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0369 (0.0369)	
0.9999852 1.7455605e-07
===========>   testing    <===========
Epoch: [1543][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1333 (0.1333)	
0.9999976 1.8105901e-07
Epoch: [1543][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.2334 (0.0614)	
0.9999926 1.8438742e-07
Epoch: [1543][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0981 (0.0571)	
0.9999943 1.9312158e-07
loss:  0.04069328338924183 0.03862828731324508
===========>   training    <===========
Epoch: [1544][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0380 (0.0380)	
0.9999864 4.2000423e-08
===========>   testing    <===========
Epoch: [1544][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1392 (0.1392)	
0.9999975 1.9582487e-07
Epoch: [1544][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1822 (0.0608)	
0.9999918 1.9877459e-07
Epoch: [1544][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0861 (0.0564)	
0.99999404 2.0992798e-07
loss:  0.04051189139980271 0.03862828731324508
===========>   training    <===========
Epoch: [1545][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0313 (0.0313)	
0.99999523 1.461252e-07
===========>   testing    <===========
Epoch: [1545][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1207 (0.1207)	
0.99999785 2.3719815e-07
Epoch: [1545][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.2332 (0.0626)	
0.99999344 2.3921564e-07
Epoch: [1545][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0948 (0.0581)	
0.99999464 2.5514086e-07
loss:  0.04052140232413337 0.03862828731324508
===========>   training    <===========
Epoch: [1546][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0371 (0.0371)	
0.9999975 3.2521783e-07
===========>   testing    <===========
Epoch: [1546][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1140 (0.1140)	
0.99999785 2.4878645e-07
Epoch: [1546][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1762 (0.0614)	
0.9999925 2.4883437e-07
Epoch: [1546][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0895 (0.0570)	
0.9999943 2.6853937e-07
loss:  0.04067301040293814 0.03862828731324508
===========>   training    <===========
Epoch: [1547][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0314 (0.0314)	
0.99999464 1.4939287e-07
===========>   testing    <===========
Epoch: [1547][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1150 (0.1150)	
0.9999975 2.5613235e-07
Epoch: [1547][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1426 (0.0597)	
0.99999106 2.57596e-07
Epoch: [1547][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0907 (0.0559)	
0.99999297 2.8369902e-07
loss:  0.040032910714287606 0.03862828731324508
===========>   training    <===========
Epoch: [1548][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0326 (0.0326)	
0.9999974 7.628131e-08
===========>   testing    <===========
Epoch: [1548][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1127 (0.1127)	
0.999998 2.1190401e-07
Epoch: [1548][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1540 (0.0602)	
0.9999937 2.1476204e-07
Epoch: [1548][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0944 (0.0564)	
0.9999943 2.3492754e-07
loss:  0.04004508069174251 0.03862828731324508
===========>   training    <===========
Epoch: [1549][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0394 (0.0394)	
0.9999933 1.9096852e-07
===========>   testing    <===========
Epoch: [1549][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1269 (0.1269)	
0.9999975 2.2841427e-07
Epoch: [1549][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1781 (0.0609)	
0.9999932 2.3104523e-07
Epoch: [1549][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0898 (0.0568)	
0.9999939 2.4970777e-07
loss:  0.04000354934050454 0.03862828731324508
===========>   training    <===========
Epoch: [1550][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0321 (0.0321)	
0.99999297 1.8548107e-07
===========>   testing    <===========
Epoch: [1550][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1173 (0.1173)	
0.9999976 2.5481842e-07
Epoch: [1550][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1889 (0.0606)	
0.99999297 2.5793085e-07
Epoch: [1550][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0966 (0.0566)	
0.99999404 2.8054257e-07
loss:  0.04004473639891393 0.03862828731324508
===========>   training    <===========
Epoch: [1551][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0318 (0.0318)	
0.9999926 8.038906e-08
===========>   testing    <===========
Epoch: [1551][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1175 (0.1175)	
0.9999974 2.297193e-07
Epoch: [1551][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1243 (0.0595)	
0.9999918 2.3301041e-07
Epoch: [1551][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0929 (0.0561)	
0.9999933 2.523772e-07
loss:  0.040185286849981794 0.03862828731324508
===========>   training    <===========
Epoch: [1552][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0388 (0.0388)	
0.99998987 3.3900193e-07
===========>   testing    <===========
Epoch: [1552][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1178 (0.1178)	
0.9999976 1.9687968e-07
Epoch: [1552][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1492 (0.0592)	
0.99999225 2.0214779e-07
Epoch: [1552][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0985 (0.0557)	
0.9999938 2.2422331e-07
loss:  0.040422993815481534 0.03862828731324508
===========>   training    <===========
Epoch: [1553][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0331 (0.0331)	
0.9999857 2.6524606e-07
===========>   testing    <===========
Epoch: [1553][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1303 (0.1303)	
0.9999974 2.6161388e-07
Epoch: [1553][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1474 (0.0598)	
0.99998987 2.6479518e-07
Epoch: [1553][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0870 (0.0559)	
0.9999927 2.8295923e-07
loss:  0.04042725751125209 0.03862828731324508
===========>   training    <===========
Epoch: [1554][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0339 (0.0339)	
0.9999943 3.1238392e-07
===========>   testing    <===========
Epoch: [1554][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1216 (0.1216)	
0.9999976 2.2147536e-07
Epoch: [1554][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1295 (0.0599)	
0.9999919 2.262247e-07
Epoch: [1554][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0921 (0.0563)	
0.9999939 2.4405452e-07
loss:  0.040219314160676256 0.03862828731324508
===========>   training    <===========
Epoch: [1555][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0305 (0.0305)	
0.99999654 3.2111978e-07
===========>   testing    <===========
Epoch: [1555][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1094 (0.1094)	
0.99999774 2.1307368e-07
Epoch: [1555][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1063 (0.0602)	
0.9999924 2.1492103e-07
Epoch: [1555][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1042 (0.0564)	
0.99999356 2.3040846e-07
loss:  0.04015024063961903 0.03862828731324508
===========>   training    <===========
Epoch: [1556][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0392 (0.0392)	
0.99999535 9.244345e-08
===========>   testing    <===========
Epoch: [1556][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1015 (0.1015)	
0.99999785 1.8270961e-07
Epoch: [1556][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1171 (0.0602)	
0.9999932 1.8275249e-07
Epoch: [1556][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1003 (0.0566)	
0.9999944 1.9553188e-07
loss:  0.040387704850075146 0.03862828731324508
===========>   training    <===========
Epoch: [1557][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0345 (0.0345)	
0.9999932 4.2284405e-08
===========>   testing    <===========
Epoch: [1557][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1075 (0.1075)	
0.99999714 1.7433494e-07
Epoch: [1557][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1086 (0.0611)	
0.9999908 1.710439e-07
Epoch: [1557][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1014 (0.0572)	
0.99999213 1.9324797e-07
loss:  0.04056267139364378 0.03862828731324508
===========>   training    <===========
Epoch: [1558][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0316 (0.0316)	
0.9999933 1.8950317e-07
===========>   testing    <===========
Epoch: [1558][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1145 (0.1145)	
0.9999975 2.0775073e-07
Epoch: [1558][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1003 (0.0600)	
0.9999914 2.0612615e-07
Epoch: [1558][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0962 (0.0562)	
0.9999927 2.2637016e-07
loss:  0.0402089373102098 0.03862828731324508
===========>   training    <===========
Epoch: [1559][0/23]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0306 (0.0306)	
0.9999888 3.3898542e-07
===========>   testing    <===========
Epoch: [1559][0/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.1176 (0.1176)	
0.9999976 2.0507714e-07
Epoch: [1559][100/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0329 (0.0590)	
0.99999154 2.0723111e-07
Epoch: [1559][200/289]	Lr-deconv: [0.0]	Lr-other: [1.9262719795904453e-05]	Loss 0.0988 (0.0559)	
0.9999933 2.2429943e-07
loss:  0.03926303397041653 0.03862828731324508
===========>   training    <===========
Epoch: [1560][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0302 (0.0302)	
0.99999654 1.8926585e-07
===========>   testing    <===========
Epoch: [1560][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.1143 (0.1143)	
0.9999975 2.9119053e-07
Epoch: [1560][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0251 (0.0593)	
0.99999106 2.9262088e-07
Epoch: [1560][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.1103 (0.0562)	
0.99999213 3.1141957e-07
loss:  0.03945531767509791 0.03862828731324508
===========>   training    <===========
Epoch: [1561][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0305 (0.0305)	
0.99999464 8.780227e-08
===========>   testing    <===========
Epoch: [1561][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.1163 (0.1163)	
0.99999714 2.3317757e-07
Epoch: [1561][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0249 (0.0588)	
0.9999901 2.3377787e-07
Epoch: [1561][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0989 (0.0556)	
0.999992 2.552852e-07
loss:  0.0390287748744409 0.03862828731324508
===========>   training    <===========
Epoch: [1562][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0383 (0.0383)	
0.99999094 2.77625e-07
===========>   testing    <===========
Epoch: [1562][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0998 (0.0998)	
0.9999974 2.1607458e-07
Epoch: [1562][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0288 (0.0600)	
0.9999912 2.1449716e-07
Epoch: [1562][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.1250 (0.0567)	
0.99999297 2.3706698e-07
loss:  0.039422433741116536 0.03862828731324508
===========>   training    <===========
Epoch: [1563][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0373 (0.0373)	
0.99999285 1.7710346e-07
===========>   testing    <===========
Epoch: [1563][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.1064 (0.1064)	
0.999997 2.3914106e-07
Epoch: [1563][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0361 (0.0588)	
0.99999 2.3714341e-07
Epoch: [1563][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.1011 (0.0558)	
0.99999213 2.6791574e-07
loss:  0.03966749691051985 0.03862828731324508
===========>   training    <===========
Epoch: [1564][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0281 (0.0281)	
0.99998987 6.727168e-08
===========>   testing    <===========
Epoch: [1564][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0981 (0.0981)	
0.9999974 2.4345618e-07
Epoch: [1564][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0419 (0.0592)	
0.9999907 2.4495552e-07
Epoch: [1564][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.1094 (0.0560)	
0.9999927 2.735889e-07
loss:  0.03998811897828258 0.03862828731324508
===========>   training    <===========
Epoch: [1565][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0341 (0.0341)	
0.9999943 1.5134917e-07
===========>   testing    <===========
Epoch: [1565][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0973 (0.0973)	
0.999997 2.4682683e-07
Epoch: [1565][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0560 (0.0598)	
0.9999902 2.6663614e-07
Epoch: [1565][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.1051 (0.0562)	
0.99999225 3.1030254e-07
loss:  0.04033751297726362 0.03862828731324508
===========>   training    <===========
Epoch: [1566][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0336 (0.0336)	
0.99999225 3.150247e-07
===========>   testing    <===========
Epoch: [1566][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0957 (0.0957)	
0.9999969 2.1405904e-07
Epoch: [1566][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0843 (0.0587)	
0.9999902 2.4802057e-07
Epoch: [1566][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0939 (0.0557)	
0.99999285 2.8364627e-07
loss:  0.04024645431044638 0.03862828731324508
===========>   training    <===========
Epoch: [1567][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0386 (0.0386)	
0.9999927 1.3702257e-08
===========>   testing    <===========
Epoch: [1567][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0856 (0.0856)	
0.9999964 2.0638657e-07
Epoch: [1567][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0984 (0.0594)	
0.99998975 2.0736e-07
Epoch: [1567][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0884 (0.0558)	
0.9999919 2.3331037e-07
loss:  0.04077283650216723 0.03862828731324508
===========>   training    <===========
Epoch: [1568][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0310 (0.0310)	
0.99998915 3.541887e-08
===========>   testing    <===========
Epoch: [1568][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0709 (0.0709)	
0.9999968 1.535579e-07
Epoch: [1568][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.1398 (0.0597)	
0.9999913 1.5266035e-07
Epoch: [1568][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0988 (0.0561)	
0.9999931 1.6764845e-07
loss:  0.04034055473859066 0.03862828731324508
===========>   training    <===========
Epoch: [1569][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0338 (0.0338)	
0.99999726 3.472109e-08
===========>   testing    <===========
Epoch: [1569][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0811 (0.0811)	
0.9999969 1.705593e-07
Epoch: [1569][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0627 (0.0595)	
0.9999919 1.708002e-07
Epoch: [1569][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.1101 (0.0563)	
0.99999344 1.9233015e-07
loss:  0.03973585255527112 0.03862828731324508
===========>   training    <===========
Epoch: [1570][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0345 (0.0345)	
0.99999154 1.8068054e-07
===========>   testing    <===========
Epoch: [1570][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0908 (0.0908)	
0.99999726 2.3273236e-07
Epoch: [1570][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0470 (0.0595)	
0.9999919 2.3737059e-07
Epoch: [1570][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.1002 (0.0564)	
0.99999344 2.6206786e-07
loss:  0.03966819463133686 0.03862828731324508
===========>   training    <===========
Epoch: [1571][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0293 (0.0293)	
0.9999944 1.6357444e-07
===========>   testing    <===========
Epoch: [1571][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.1009 (0.1009)	
0.9999969 1.8432254e-07
Epoch: [1571][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0413 (0.0583)	
0.9999907 1.8679323e-07
Epoch: [1571][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.1020 (0.0556)	
0.9999926 2.1104547e-07
loss:  0.03953078150527101 0.03862828731324508
===========>   training    <===========
Epoch: [1572][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0324 (0.0324)	
0.9999951 1.5287466e-07
===========>   testing    <===========
Epoch: [1572][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0872 (0.0872)	
0.99999666 2.1835801e-07
Epoch: [1572][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.1146 (0.0593)	
0.9999906 2.1966383e-07
Epoch: [1572][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.1043 (0.0559)	
0.9999925 2.4764688e-07
loss:  0.040331249717025064 0.03862828731324508
===========>   training    <===========
Epoch: [1573][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0351 (0.0351)	
0.99998915 3.300266e-07
===========>   testing    <===========
Epoch: [1573][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0810 (0.0810)	
0.9999969 2.4407524e-07
Epoch: [1573][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0560 (0.0590)	
0.9999908 2.4664257e-07
Epoch: [1573][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.1097 (0.0554)	
0.99999225 2.8440147e-07
loss:  0.03945152044611233 0.03862828731324508
===========>   training    <===========
Epoch: [1574][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0307 (0.0307)	
0.999992 1.0743445e-07
===========>   testing    <===========
Epoch: [1574][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.1054 (0.1054)	
0.999997 1.639721e-07
Epoch: [1574][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0957 (0.0592)	
0.99999154 2.8073873e-07
Epoch: [1574][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0986 (0.0551)	
0.9999925 2.486631e-07
loss:  0.03983473180587083 0.03862828731324508
===========>   training    <===========
Epoch: [1575][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0344 (0.0344)	
0.9999949 1.2127578e-07
===========>   testing    <===========
Epoch: [1575][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0915 (0.0915)	
0.9999974 1.5728311e-07
Epoch: [1575][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0732 (0.0589)	
0.99999225 1.5854602e-07
Epoch: [1575][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0989 (0.0554)	
0.9999933 1.7380655e-07
loss:  0.0392736255415852 0.03862828731324508
===========>   training    <===========
Epoch: [1576][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0339 (0.0339)	
0.9999956 1.5829794e-07
===========>   testing    <===========
Epoch: [1576][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0876 (0.0876)	
0.9999975 2.04301e-07
Epoch: [1576][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0465 (0.0587)	
0.99999344 2.2814778e-07
Epoch: [1576][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0968 (0.0555)	
0.99999404 2.414068e-07
loss:  0.03945555275224799 0.03862828731324508
===========>   training    <===========
Epoch: [1577][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0322 (0.0322)	
0.99999344 9.301774e-08
===========>   testing    <===========
Epoch: [1577][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0985 (0.0985)	
0.99999654 1.4186028e-07
Epoch: [1577][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0647 (0.0592)	
0.9999912 2.2168055e-07
Epoch: [1577][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0869 (0.0556)	
0.99999213 2.0693666e-07
loss:  0.03927426879547857 0.03862828731324508
===========>   training    <===========
Epoch: [1578][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0363 (0.0363)	
0.99999607 8.8298535e-08
===========>   testing    <===========
Epoch: [1578][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.1068 (0.1068)	
0.99999654 1.60273e-07
Epoch: [1578][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0667 (0.0591)	
0.9999913 2.3868878e-07
Epoch: [1578][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0855 (0.0553)	
0.9999925 2.2591423e-07
loss:  0.03897344752050069 0.03862828731324508
===========>   training    <===========
Epoch: [1579][0/23]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0324 (0.0324)	
0.99999213 5.7786227e-08
===========>   testing    <===========
Epoch: [1579][0/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.1106 (0.1106)	
0.9999962 1.3800594e-07
Epoch: [1579][100/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0660 (0.0594)	
0.9999907 2.2692004e-07
Epoch: [1579][200/289]	Lr-deconv: [0.0]	Lr-other: [1.8299583806109228e-05]	Loss 0.0730 (0.0550)	
0.99999166 2.1428535e-07
loss:  0.03922125128426057 0.03862828731324508
===========>   training    <===========
Epoch: [1580][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0331 (0.0331)	
0.99999475 7.135864e-08
===========>   testing    <===========
Epoch: [1580][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.1268 (0.1268)	
0.9999963 1.550644e-07
Epoch: [1580][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.1070 (0.0598)	
0.99999094 1.950523e-07
Epoch: [1580][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0752 (0.0553)	
0.9999927 2.1639856e-07
loss:  0.03974534675997088 0.03862828731324508
===========>   training    <===========
Epoch: [1581][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0298 (0.0298)	
0.9999901 1.5501989e-07
===========>   testing    <===========
Epoch: [1581][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.1195 (0.1195)	
0.9999968 1.9633255e-07
Epoch: [1581][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.1058 (0.0601)	
0.99999297 2.0711039e-07
Epoch: [1581][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0837 (0.0556)	
0.9999937 2.2102888e-07
loss:  0.039666448335040405 0.03862828731324508
===========>   training    <===========
Epoch: [1582][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0378 (0.0378)	
0.9999902 1.3711191e-07
===========>   testing    <===========
Epoch: [1582][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0849 (0.0849)	
0.99999714 1.8707973e-07
Epoch: [1582][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.1559 (0.0614)	
0.99999297 1.9683142e-07
Epoch: [1582][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0877 (0.0567)	
0.9999939 2.0860782e-07
loss:  0.04032187985547275 0.03862828731324508
===========>   training    <===========
Epoch: [1583][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0306 (0.0306)	
0.99999714 1.1317635e-06
===========>   testing    <===========
Epoch: [1583][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0944 (0.0944)	
0.999997 1.764273e-07
Epoch: [1583][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.1473 (0.0611)	
0.99999213 1.854144e-07
Epoch: [1583][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0828 (0.0564)	
0.99999356 1.9808785e-07
loss:  0.04035672035297211 0.03862828731324508
===========>   training    <===========
Epoch: [1584][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0360 (0.0360)	
0.9999968 6.712019e-08
===========>   testing    <===========
Epoch: [1584][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.1013 (0.1013)	
0.9999975 1.8033505e-07
Epoch: [1584][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.1359 (0.0611)	
0.99999356 1.8705921e-07
Epoch: [1584][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0857 (0.0564)	
0.9999951 1.9782355e-07
loss:  0.040102660135157286 0.03862828731324508
===========>   training    <===========
Epoch: [1585][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0371 (0.0371)	
0.9999975 4.7136407e-08
===========>   testing    <===========
Epoch: [1585][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.1170 (0.1170)	
0.99999714 2.3282915e-07
Epoch: [1585][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0929 (0.0613)	
0.99999225 2.4101965e-07
Epoch: [1585][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0762 (0.0561)	
0.99999404 2.6439898e-07
loss:  0.040327746690219435 0.03862828731324508
===========>   training    <===========
Epoch: [1586][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0435 (0.0435)	
0.9999871 1.7437402e-07
===========>   testing    <===========
Epoch: [1586][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.1114 (0.1114)	
0.99999714 1.7076128e-07
Epoch: [1586][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0926 (0.0616)	
0.9999919 1.764046e-07
Epoch: [1586][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0849 (0.0566)	
0.9999937 1.8881568e-07
loss:  0.040320931702268914 0.03862828731324508
===========>   training    <===========
Epoch: [1587][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0370 (0.0370)	
0.99997663 1.4400874e-08
===========>   testing    <===========
Epoch: [1587][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.1222 (0.1222)	
0.999997 1.7563946e-07
Epoch: [1587][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0611 (0.0603)	
0.99999225 1.7872551e-07
Epoch: [1587][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0867 (0.0559)	
0.9999939 1.9149594e-07
loss:  0.03940218276449259 0.03862828731324508
===========>   training    <===========
Epoch: [1588][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0353 (0.0353)	
0.99999356 9.415484e-07
===========>   testing    <===========
Epoch: [1588][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.1314 (0.1314)	
0.99999607 2.5416844e-07
Epoch: [1588][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0738 (0.0601)	
0.99998987 2.587409e-07
Epoch: [1588][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0870 (0.0557)	
0.99999225 2.9563458e-07
loss:  0.039926001853746285 0.03862828731324508
===========>   training    <===========
Epoch: [1589][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0324 (0.0324)	
0.999992 1.0172989e-07
===========>   testing    <===========
Epoch: [1589][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.1275 (0.1275)	
0.9999969 1.2852335e-07
Epoch: [1589][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0572 (0.0610)	
0.999992 1.212204e-07
Epoch: [1589][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0937 (0.0569)	
0.99999356 1.7192588e-07
loss:  0.04013775032922284 0.03862828731324508
===========>   training    <===========
Epoch: [1590][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0358 (0.0358)	
0.9999912 2.0362714e-08
===========>   testing    <===========
Epoch: [1590][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.1178 (0.1178)	
0.9999975 1.5993221e-07
Epoch: [1590][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0688 (0.0609)	
0.99999344 1.5266662e-07
Epoch: [1590][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0905 (0.0570)	
0.99999416 1.8474931e-07
loss:  0.04063388646630084 0.03862828731324508
===========>   training    <===========
Epoch: [1591][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0398 (0.0398)	
0.99999785 3.782052e-08
===========>   testing    <===========
Epoch: [1591][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.1259 (0.1259)	
0.9999968 1.9036555e-07
Epoch: [1591][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0808 (0.0614)	
0.999992 1.8847312e-07
Epoch: [1591][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0883 (0.0569)	
0.99999285 2.2799357e-07
loss:  0.040317740191014195 0.03862828731324508
===========>   training    <===========
Epoch: [1592][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0429 (0.0429)	
0.9999906 9.624724e-08
===========>   testing    <===========
Epoch: [1592][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.1194 (0.1194)	
0.999997 1.9963386e-07
Epoch: [1592][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0853 (0.0617)	
0.9999932 1.98034e-07
Epoch: [1592][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.1036 (0.0571)	
0.99999416 2.3814877e-07
loss:  0.040421512657593306 0.03862828731324508
===========>   training    <===========
Epoch: [1593][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0367 (0.0367)	
0.99999225 6.5251214e-08
===========>   testing    <===========
Epoch: [1593][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.1127 (0.1127)	
0.9999968 1.4661445e-07
Epoch: [1593][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.1374 (0.0614)	
0.9999924 1.4198089e-07
Epoch: [1593][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0893 (0.0566)	
0.99999356 1.6748673e-07
loss:  0.040651992316414476 0.03862828731324508
===========>   training    <===========
Epoch: [1594][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0480 (0.0480)	
0.99999297 7.6588194e-08
===========>   testing    <===========
Epoch: [1594][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.1051 (0.1051)	
0.9999968 1.5554517e-07
Epoch: [1594][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.1056 (0.0606)	
0.9999919 1.5579681e-07
Epoch: [1594][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0895 (0.0562)	
0.9999933 1.9353936e-07
loss:  0.0403884247565508 0.03862828731324508
===========>   training    <===========
Epoch: [1595][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0382 (0.0382)	
0.99999547 6.4558826e-08
===========>   testing    <===========
Epoch: [1595][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.1012 (0.1012)	
0.9999964 2.0426164e-07
Epoch: [1595][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.1233 (0.0612)	
0.99999213 1.9889879e-07
Epoch: [1595][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0876 (0.0564)	
0.99999285 2.3955127e-07
loss:  0.04065573379941301 0.03862828731324508
===========>   training    <===========
Epoch: [1596][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0365 (0.0365)	
0.99999285 1.5461313e-07
===========>   testing    <===========
Epoch: [1596][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.1172 (0.1172)	
0.9999958 2.0873179e-07
Epoch: [1596][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0799 (0.0609)	
0.9999906 2.0449592e-07
Epoch: [1596][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0782 (0.0563)	
0.99999225 2.5355837e-07
loss:  0.040629813907956724 0.03862828731324508
===========>   training    <===========
Epoch: [1597][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0300 (0.0300)	
0.9999931 1.3310714e-07
===========>   testing    <===========
Epoch: [1597][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.1124 (0.1124)	
0.9999964 1.8276748e-07
Epoch: [1597][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0701 (0.0610)	
0.99999213 1.8123434e-07
Epoch: [1597][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0873 (0.0564)	
0.9999932 2.1745777e-07
loss:  0.039915550151740975 0.03862828731324508
===========>   training    <===========
Epoch: [1598][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0385 (0.0385)	
0.99999475 1.5157681e-07
===========>   testing    <===========
Epoch: [1598][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.1043 (0.1043)	
0.9999963 1.7558217e-07
Epoch: [1598][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0824 (0.0613)	
0.99999225 1.7259465e-07
Epoch: [1598][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0806 (0.0563)	
0.9999931 2.0862352e-07
loss:  0.039657578479389 0.03862828731324508
===========>   training    <===========
Epoch: [1599][0/23]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0315 (0.0315)	
0.9999925 6.99344e-08
===========>   testing    <===========
Epoch: [1599][0/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.1041 (0.1041)	
0.9999975 1.5944322e-07
Epoch: [1599][100/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0984 (0.0605)	
0.9999924 1.5717784e-07
Epoch: [1599][200/289]	Lr-deconv: [0.0]	Lr-other: [1.7384604615803768e-05]	Loss 0.0825 (0.0562)	
0.99999356 1.9064734e-07
loss:  0.03941024052084585 0.03862828731324508
===========>   training    <===========
Epoch: [1600][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0288 (0.0288)	
0.99999106 9.088535e-08
===========>   testing    <===========
Epoch: [1600][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.1143 (0.1143)	
0.9999969 2.0998564e-07
Epoch: [1600][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0612 (0.0607)	
0.9999914 2.109334e-07
Epoch: [1600][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0822 (0.0565)	
0.9999925 2.521472e-07
loss:  0.0395209800477081 0.03862828731324508
===========>   training    <===========
Epoch: [1601][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0387 (0.0387)	
0.9999907 2.1698132e-07
===========>   testing    <===========
Epoch: [1601][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.1111 (0.1111)	
0.9999963 2.0338246e-07
Epoch: [1601][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0721 (0.0606)	
0.9999902 2.6182053e-07
Epoch: [1601][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0800 (0.0561)	
0.999992 3.0523836e-07
loss:  0.04003525510587358 0.03862828731324508
===========>   training    <===========
Epoch: [1602][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0375 (0.0375)	
0.9999902 1.3210177e-07
===========>   testing    <===========
Epoch: [1602][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.1024 (0.1024)	
0.99999666 2.3164071e-07
Epoch: [1602][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0832 (0.0601)	
0.9999913 2.6087767e-07
Epoch: [1602][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0833 (0.0557)	
0.99999213 3.1776628e-07
loss:  0.03981298975965186 0.03862828731324508
===========>   training    <===========
Epoch: [1603][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0327 (0.0327)	
0.9999943 2.1710633e-07
===========>   testing    <===========
Epoch: [1603][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0999 (0.0999)	
0.9999968 2.0526166e-07
Epoch: [1603][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0855 (0.0608)	
0.9999906 2.4580638e-07
Epoch: [1603][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0707 (0.0557)	
0.99999213 2.9753045e-07
loss:  0.04031380407112917 0.03862828731324508
===========>   training    <===========
Epoch: [1604][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0311 (0.0311)	
0.9999938 1.8851233e-07
===========>   testing    <===========
Epoch: [1604][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.1031 (0.1031)	
0.9999968 2.1972836e-07
Epoch: [1604][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0990 (0.0615)	
0.9999914 2.2001521e-07
Epoch: [1604][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0735 (0.0563)	
0.9999931 2.6001555e-07
loss:  0.040380929014800726 0.03862828731324508
===========>   training    <===========
Epoch: [1605][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0289 (0.0289)	
0.9999944 2.0307256e-07
===========>   testing    <===========
Epoch: [1605][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.1080 (0.1080)	
0.99999714 2.0052263e-07
Epoch: [1605][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0983 (0.0612)	
0.9999924 1.9890145e-07
Epoch: [1605][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0841 (0.0563)	
0.99999404 2.3641134e-07
loss:  0.040018997503349585 0.03862828731324508
===========>   training    <===========
Epoch: [1606][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0316 (0.0316)	
0.9999864 4.73459e-08
===========>   testing    <===========
Epoch: [1606][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.1133 (0.1133)	
0.99999726 2.128458e-07
Epoch: [1606][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0688 (0.0612)	
0.99999297 2.1398719e-07
Epoch: [1606][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0893 (0.0567)	
0.99999404 2.50875e-07
loss:  0.04003968214268927 0.03862828731324508
===========>   training    <===========
Epoch: [1607][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0392 (0.0392)	
0.9999871 2.3386796e-07
===========>   testing    <===========
Epoch: [1607][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.1169 (0.1169)	
0.9999969 1.7707475e-07
Epoch: [1607][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.1461 (0.0617)	
0.9999919 1.8091677e-07
Epoch: [1607][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0855 (0.0566)	
0.9999932 2.0780246e-07
loss:  0.04038613631994192 0.03862828731324508
===========>   training    <===========
Epoch: [1608][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0396 (0.0396)	
0.9999918 3.0538683e-08
===========>   testing    <===========
Epoch: [1608][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.1163 (0.1163)	
0.99999666 1.9456313e-07
Epoch: [1608][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.1202 (0.0619)	
0.99999225 1.9936863e-07
Epoch: [1608][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0819 (0.0564)	
0.9999933 2.2977277e-07
loss:  0.03986159737147266 0.03862828731324508
===========>   training    <===========
Epoch: [1609][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0332 (0.0332)	
0.9999956 1.4543744e-07
===========>   testing    <===========
Epoch: [1609][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.1273 (0.1273)	
0.99999607 2.616735e-07
Epoch: [1609][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0873 (0.0618)	
0.9999912 2.643032e-07
Epoch: [1609][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0806 (0.0565)	
0.99999297 3.148514e-07
loss:  0.0401949022003778 0.03862828731324508
===========>   training    <===========
Epoch: [1610][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0327 (0.0327)	
0.99999404 1.6375957e-07
===========>   testing    <===========
Epoch: [1610][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.1308 (0.1308)	
0.99999654 2.1447549e-07
Epoch: [1610][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0968 (0.0620)	
0.99999106 3.233024e-07
Epoch: [1610][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0840 (0.0569)	
0.99999297 2.9926488e-07
loss:  0.04047190197264272 0.03862828731324508
===========>   training    <===========
Epoch: [1611][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0296 (0.0296)	
0.9999938 2.8401512e-08
===========>   testing    <===========
Epoch: [1611][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.1435 (0.1435)	
0.99999714 2.870251e-07
Epoch: [1611][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0825 (0.0611)	
0.9999912 2.948445e-07
Epoch: [1611][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0871 (0.0566)	
0.9999932 3.5607454e-07
loss:  0.040440639421361224 0.03862828731324508
===========>   training    <===========
Epoch: [1612][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0346 (0.0346)	
0.9999895 1.709702e-07
===========>   testing    <===========
Epoch: [1612][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.1342 (0.1342)	
0.99999726 2.4204743e-07
Epoch: [1612][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0439 (0.0608)	
0.9999918 2.4928306e-07
Epoch: [1612][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0920 (0.0565)	
0.9999931 2.9971957e-07
loss:  0.04011114962294626 0.03862828731324508
===========>   training    <===========
Epoch: [1613][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0298 (0.0298)	
0.9999987 1.4526396e-08
===========>   testing    <===========
Epoch: [1613][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.1414 (0.1414)	
0.999997 2.5961464e-07
Epoch: [1613][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0583 (0.0614)	
0.99999166 2.642737e-07
Epoch: [1613][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0860 (0.0565)	
0.99999297 3.0869597e-07
loss:  0.04016031351724836 0.03862828731324508
===========>   training    <===========
Epoch: [1614][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0351 (0.0351)	
0.99999 1.0647911e-07
===========>   testing    <===========
Epoch: [1614][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.1371 (0.1371)	
0.9999969 2.0639368e-07
Epoch: [1614][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0560 (0.0615)	
0.999992 2.1045838e-07
Epoch: [1614][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0897 (0.0568)	
0.9999933 2.5279488e-07
loss:  0.039841833809024285 0.03862828731324508
===========>   training    <===========
Epoch: [1615][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0296 (0.0296)	
0.99999297 1.167895e-07
===========>   testing    <===========
Epoch: [1615][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.1383 (0.1383)	
0.9999962 2.5729895e-07
Epoch: [1615][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0944 (0.0613)	
0.99999106 2.8582105e-07
Epoch: [1615][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0861 (0.0565)	
0.9999925 3.5163762e-07
loss:  0.03999085257498103 0.03862828731324508
===========>   training    <===========
Epoch: [1616][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0328 (0.0328)	
0.9999945 4.953345e-08
===========>   testing    <===========
Epoch: [1616][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.1222 (0.1222)	
0.99999666 1.8929346e-07
Epoch: [1616][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.1037 (0.0612)	
0.99999166 3.1752242e-07
Epoch: [1616][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0876 (0.0566)	
0.9999932 2.9204324e-07
loss:  0.04013261799987211 0.03862828731324508
===========>   training    <===========
Epoch: [1617][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0351 (0.0351)	
0.9999958 3.011039e-07
===========>   testing    <===========
Epoch: [1617][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.1295 (0.1295)	
0.99999726 2.75475e-07
Epoch: [1617][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.1532 (0.0614)	
0.99999285 2.8330837e-07
Epoch: [1617][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0794 (0.0563)	
0.99999356 3.396365e-07
loss:  0.04037020137890224 0.03862828731324508
===========>   training    <===========
Epoch: [1618][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0338 (0.0338)	
0.9999938 7.9786595e-08
===========>   testing    <===========
Epoch: [1618][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.1261 (0.1261)	
0.9999969 2.756377e-07
Epoch: [1618][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.1076 (0.0611)	
0.9999927 2.7877775e-07
Epoch: [1618][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0747 (0.0560)	
0.9999937 3.208513e-07
loss:  0.04041871477149184 0.03862828731324508
===========>   training    <===========
Epoch: [1619][0/23]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0360 (0.0360)	
0.9999932 2.9259956e-08
===========>   testing    <===========
Epoch: [1619][0/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.1212 (0.1212)	
0.999997 2.1952164e-07
Epoch: [1619][100/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0925 (0.0611)	
0.999992 3.061059e-07
Epoch: [1619][200/289]	Lr-deconv: [0.0]	Lr-other: [1.651537438501358e-05]	Loss 0.0746 (0.0561)	
0.9999927 3.3834144e-07
loss:  0.04016444875796443 0.03862828731324508
===========>   training    <===========
Epoch: [1620][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0298 (0.0298)	
0.99998903 1.4439601e-08
===========>   testing    <===========
Epoch: [1620][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.1133 (0.1133)	
0.99999726 2.0571885e-07
Epoch: [1620][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0713 (0.0614)	
0.9999927 2.813686e-07
Epoch: [1620][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0778 (0.0565)	
0.9999932 3.3304445e-07
loss:  0.04006036319943751 0.03862828731324508
===========>   training    <===========
Epoch: [1621][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0277 (0.0277)	
0.9999901 4.1336105e-07
===========>   testing    <===========
Epoch: [1621][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.1215 (0.1215)	
0.9999968 1.7035545e-07
Epoch: [1621][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0494 (0.0603)	
0.99999154 2.3462168e-07
Epoch: [1621][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0781 (0.0559)	
0.99999225 2.7988142e-07
loss:  0.03990340696000072 0.03862828731324508
===========>   training    <===========
Epoch: [1622][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0334 (0.0334)	
0.99999607 4.1763368e-10
===========>   testing    <===========
Epoch: [1622][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.1246 (0.1246)	
0.9999974 2.2413629e-07
Epoch: [1622][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0453 (0.0599)	
0.9999939 2.2373564e-07
Epoch: [1622][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0745 (0.0556)	
0.9999943 2.5956066e-07
loss:  0.039570477757273737 0.03862828731324508
===========>   training    <===========
Epoch: [1623][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0343 (0.0343)	
0.99998534 1.7859229e-07
===========>   testing    <===========
Epoch: [1623][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.1219 (0.1219)	
0.9999968 2.1880496e-07
Epoch: [1623][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0566 (0.0608)	
0.9999925 2.1850174e-07
Epoch: [1623][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0805 (0.0562)	
0.9999932 2.5341137e-07
loss:  0.039903605281363164 0.03862828731324508
===========>   training    <===========
Epoch: [1624][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0310 (0.0310)	
0.9999968 1.1113604e-05
===========>   testing    <===========
Epoch: [1624][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.1416 (0.1416)	
0.9999968 2.0159217e-07
Epoch: [1624][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0604 (0.0608)	
0.9999925 1.9840148e-07
Epoch: [1624][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0752 (0.0559)	
0.9999933 2.3706788e-07
loss:  0.039844279460391485 0.03862828731324508
===========>   training    <===========
Epoch: [1625][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0361 (0.0361)	
0.99998367 2.7916423e-08
===========>   testing    <===========
Epoch: [1625][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.1355 (0.1355)	
0.9999968 2.3413261e-07
Epoch: [1625][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0420 (0.0609)	
0.9999914 2.5666614e-07
Epoch: [1625][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0837 (0.0562)	
0.9999925 2.989876e-07
loss:  0.03999418165891888 0.03862828731324508
===========>   training    <===========
Epoch: [1626][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0345 (0.0345)	
0.9999987 2.0249277e-07
===========>   testing    <===========
Epoch: [1626][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.1191 (0.1191)	
0.9999968 2.684057e-07
Epoch: [1626][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0464 (0.0606)	
0.9999925 2.6362125e-07
Epoch: [1626][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0861 (0.0562)	
0.99999297 3.133351e-07
loss:  0.03954179543997638 0.03862828731324508
===========>   training    <===========
Epoch: [1627][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0291 (0.0291)	
0.99999225 4.5571466e-07
===========>   testing    <===========
Epoch: [1627][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.1147 (0.1147)	
0.9999964 2.000497e-07
Epoch: [1627][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.1016 (0.0609)	
0.9999927 1.9868305e-07
Epoch: [1627][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0831 (0.0563)	
0.9999927 2.2470839e-07
loss:  0.04007085938569732 0.03862828731324508
===========>   training    <===========
Epoch: [1628][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0323 (0.0323)	
0.9999888 5.681497e-08
===========>   testing    <===========
Epoch: [1628][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.1203 (0.1203)	
0.9999968 1.8584758e-07
Epoch: [1628][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0765 (0.0613)	
0.9999931 1.8746765e-07
Epoch: [1628][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0855 (0.0562)	
0.99999356 2.1503523e-07
loss:  0.040098711087766414 0.03862828731324508
===========>   training    <===========
Epoch: [1629][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0401 (0.0401)	
0.9999956 8.737776e-08
===========>   testing    <===========
Epoch: [1629][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.1202 (0.1202)	
0.9999969 2.3401365e-07
Epoch: [1629][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0793 (0.0609)	
0.9999927 2.3357775e-07
Epoch: [1629][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0870 (0.0561)	
0.9999939 2.7247393e-07
loss:  0.039987924505869965 0.03862828731324508
===========>   training    <===========
Epoch: [1630][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0330 (0.0330)	
0.99999607 3.8653587e-07
===========>   testing    <===========
Epoch: [1630][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.1255 (0.1255)	
0.9999969 2.3309664e-07
Epoch: [1630][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0662 (0.0606)	
0.999992 2.7488767e-07
Epoch: [1630][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0854 (0.0559)	
0.9999931 3.2308358e-07
loss:  0.03998434525374406 0.03862828731324508
===========>   training    <===========
Epoch: [1631][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0304 (0.0304)	
0.9999937 1.5404459e-07
===========>   testing    <===========
Epoch: [1631][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.1192 (0.1192)	
0.9999974 1.8308377e-07
Epoch: [1631][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.1250 (0.0618)	
0.99999356 1.8062197e-07
Epoch: [1631][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0844 (0.0566)	
0.99999416 2.2040457e-07
loss:  0.040639256225636355 0.03862828731324508
===========>   training    <===========
Epoch: [1632][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0298 (0.0298)	
0.99999285 5.00666e-08
===========>   testing    <===========
Epoch: [1632][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.1200 (0.1200)	
0.99999714 2.5881246e-07
Epoch: [1632][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0817 (0.0616)	
0.9999924 2.5328575e-07
Epoch: [1632][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0870 (0.0568)	
0.9999933 3.1034514e-07
loss:  0.040227707825501224 0.03862828731324508
===========>   training    <===========
Epoch: [1633][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0354 (0.0354)	
0.99998546 4.493003e-08
===========>   testing    <===========
Epoch: [1633][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.1207 (0.1207)	
0.9999974 2.4639243e-07
Epoch: [1633][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0889 (0.0611)	
0.99999344 2.4840523e-07
Epoch: [1633][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0865 (0.0567)	
0.99999404 2.949086e-07
loss:  0.04009771388685057 0.03862828731324508
===========>   training    <===========
Epoch: [1634][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0326 (0.0326)	
0.99999833 5.0661794e-07
===========>   testing    <===========
Epoch: [1634][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.1319 (0.1319)	
0.9999969 2.3650153e-07
Epoch: [1634][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0739 (0.0604)	
0.9999926 2.3618463e-07
Epoch: [1634][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0782 (0.0561)	
0.99999297 2.7069848e-07
loss:  0.039496161986932954 0.03862828731324508
===========>   training    <===========
Epoch: [1635][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0292 (0.0292)	
0.99999785 3.9311292e-08
===========>   testing    <===========
Epoch: [1635][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.1259 (0.1259)	
0.99999666 1.5320568e-07
Epoch: [1635][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0518 (0.0606)	
0.99999046 1.2663897e-07
Epoch: [1635][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0783 (0.0563)	
0.99999154 2.2910037e-07
loss:  0.039891439910563875 0.03862828731324508
===========>   training    <===========
Epoch: [1636][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0337 (0.0337)	
0.9999956 2.2841033e-07
===========>   testing    <===========
Epoch: [1636][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.1178 (0.1178)	
0.9999968 2.713485e-07
Epoch: [1636][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.1102 (0.0604)	
0.999992 2.7477182e-07
Epoch: [1636][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0734 (0.0559)	
0.99999285 3.3066894e-07
loss:  0.04029788930301892 0.03862828731324508
===========>   training    <===========
Epoch: [1637][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0319 (0.0319)	
0.9999957 2.2793574e-07
===========>   testing    <===========
Epoch: [1637][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.1099 (0.1099)	
0.9999969 2.3075391e-07
Epoch: [1637][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0561 (0.0611)	
0.99999154 2.3815332e-07
Epoch: [1637][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0897 (0.0568)	
0.9999924 2.79257e-07
loss:  0.04050660561706676 0.03862828731324508
===========>   training    <===========
Epoch: [1638][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0351 (0.0351)	
0.9999926 1.18827494e-07
===========>   testing    <===========
Epoch: [1638][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.1254 (0.1254)	
0.999997 2.3334375e-07
Epoch: [1638][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0459 (0.0601)	
0.999992 2.3616595e-07
Epoch: [1638][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0911 (0.0560)	
0.9999927 2.6646913e-07
loss:  0.03972080101823694 0.03862828731324508
===========>   training    <===========
Epoch: [1639][0/23]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0322 (0.0322)	
0.99999034 1.9662124e-08
===========>   testing    <===========
Epoch: [1639][0/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.1351 (0.1351)	
0.99999714 2.1023811e-07
Epoch: [1639][100/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0782 (0.0610)	
0.9999913 2.1277538e-07
Epoch: [1639][200/289]	Lr-deconv: [0.0]	Lr-other: [1.56896056657629e-05]	Loss 0.0799 (0.0562)	
0.9999926 2.404331e-07
loss:  0.04005496855406199 0.03862828731324508
===========>   training    <===========
Epoch: [1640][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0264 (0.0264)	
0.99999666 3.7392805e-08
===========>   testing    <===========
Epoch: [1640][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.1339 (0.1339)	
0.99999726 2.1007978e-07
Epoch: [1640][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0707 (0.0615)	
0.99999154 2.121321e-07
Epoch: [1640][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0799 (0.0565)	
0.99999297 2.3879556e-07
loss:  0.04017442110129665 0.03862828731324508
===========>   training    <===========
Epoch: [1641][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0273 (0.0273)	
0.9999927 2.4835214e-07
===========>   testing    <===========
Epoch: [1641][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.1313 (0.1313)	
0.99999726 2.2260402e-07
Epoch: [1641][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0544 (0.0613)	
0.9999919 2.2777428e-07
Epoch: [1641][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0826 (0.0566)	
0.9999931 2.577592e-07
loss:  0.03999592269983532 0.03862828731324508
===========>   training    <===========
Epoch: [1642][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0333 (0.0333)	
0.999992 8.8698926e-08
===========>   testing    <===========
Epoch: [1642][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.1284 (0.1284)	
0.999997 1.706016e-07
Epoch: [1642][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0330 (0.0605)	
0.9999906 2.1952897e-07
Epoch: [1642][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0778 (0.0560)	
0.99999225 2.6451954e-07
loss:  0.040149008574157485 0.03862828731324508
===========>   training    <===========
Epoch: [1643][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0311 (0.0311)	
0.9999901 5.8584384e-08
===========>   testing    <===========
Epoch: [1643][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.1321 (0.1321)	
0.99999714 1.5642388e-07
Epoch: [1643][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0500 (0.0606)	
0.99999285 1.5800097e-07
Epoch: [1643][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0845 (0.0566)	
0.9999939 1.779532e-07
loss:  0.03989201984509283 0.03862828731324508
===========>   training    <===========
Epoch: [1644][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0269 (0.0269)	
0.9999945 1.31112e-07
===========>   testing    <===========
Epoch: [1644][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.1365 (0.1365)	
0.9999969 1.7766747e-07
Epoch: [1644][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0401 (0.0603)	
0.9999912 2.1413582e-07
Epoch: [1644][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0805 (0.0563)	
0.9999918 2.5193137e-07
loss:  0.04020899027837166 0.03862828731324508
===========>   training    <===========
Epoch: [1645][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0358 (0.0358)	
0.99999714 3.9729954e-07
===========>   testing    <===========
Epoch: [1645][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.1296 (0.1296)	
0.99999714 1.9573413e-07
Epoch: [1645][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0601 (0.0607)	
0.999992 1.9655361e-07
Epoch: [1645][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0760 (0.0566)	
0.9999933 2.2844563e-07
loss:  0.04028804795918273 0.03862828731324508
===========>   training    <===========
Epoch: [1646][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0497 (0.0497)	
0.99999785 7.787504e-08
===========>   testing    <===========
Epoch: [1646][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.1089 (0.1089)	
0.9999975 1.3238314e-07
Epoch: [1646][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0599 (0.0614)	
0.9999938 1.325217e-07
Epoch: [1646][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0761 (0.0570)	
0.99999404 1.4908814e-07
loss:  0.040235024862453006 0.03862828731324508
===========>   training    <===========
Epoch: [1647][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0308 (0.0308)	
0.99999666 1.5785564e-07
===========>   testing    <===========
Epoch: [1647][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.1122 (0.1122)	
0.999997 1.9007803e-07
Epoch: [1647][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0598 (0.0612)	
0.99999166 1.8990497e-07
Epoch: [1647][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0800 (0.0567)	
0.99999297 2.146666e-07
loss:  0.04030303832373672 0.03862828731324508
===========>   training    <===========
Epoch: [1648][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0386 (0.0386)	
0.99999285 2.9261585e-07
===========>   testing    <===========
Epoch: [1648][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.1085 (0.1085)	
0.9999969 1.600868e-07
Epoch: [1648][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0604 (0.0610)	
0.9999913 1.5962745e-07
Epoch: [1648][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0851 (0.0563)	
0.9999926 1.8072915e-07
loss:  0.03965847358749741 0.03862828731324508
===========>   training    <===========
Epoch: [1649][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0349 (0.0349)	
0.9999963 8.7009546e-08
===========>   testing    <===========
Epoch: [1649][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.1127 (0.1127)	
0.99999714 1.431956e-07
Epoch: [1649][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0414 (0.0605)	
0.99999225 1.4545172e-07
Epoch: [1649][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0768 (0.0560)	
0.9999933 1.6357693e-07
loss:  0.03934601550163419 0.03862828731324508
===========>   training    <===========
Epoch: [1650][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0318 (0.0318)	
0.9999926 1.1897105e-07
===========>   testing    <===========
Epoch: [1650][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.1125 (0.1125)	
0.99999726 2.1602163e-07
Epoch: [1650][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0448 (0.0600)	
0.9999931 2.2158905e-07
Epoch: [1650][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0829 (0.0561)	
0.99999356 2.5137507e-07
loss:  0.03931458536193977 0.03862828731324508
===========>   training    <===========
Epoch: [1651][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0312 (0.0312)	
0.99999475 3.827984e-08
===========>   testing    <===========
Epoch: [1651][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.1168 (0.1168)	
0.9999969 1.8036894e-07
Epoch: [1651][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0339 (0.0605)	
0.9999927 1.8171565e-07
Epoch: [1651][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0838 (0.0560)	
0.9999933 2.0504936e-07
loss:  0.03903415631301732 0.03862828731324508
===========>   training    <===========
Epoch: [1652][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0321 (0.0321)	
0.9999956 2.2708413e-07
===========>   testing    <===========
Epoch: [1652][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.1114 (0.1114)	
0.99999714 1.9116986e-07
Epoch: [1652][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0373 (0.0604)	
0.9999932 1.91921e-07
Epoch: [1652][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0875 (0.0560)	
0.99999404 2.1510844e-07
loss:  0.03922447586524236 0.03862828731324508
===========>   training    <===========
Epoch: [1653][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0312 (0.0312)	
0.99999404 1.3013587e-07
===========>   testing    <===========
Epoch: [1653][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.1190 (0.1190)	
0.99999726 1.6054531e-07
Epoch: [1653][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0313 (0.0611)	
0.99999225 1.6439219e-07
Epoch: [1653][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0841 (0.0561)	
0.99999356 1.805784e-07
loss:  0.03932797653609643 0.03862828731324508
===========>   training    <===========
Epoch: [1654][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0284 (0.0284)	
0.9999944 2.6361764e-08
===========>   testing    <===========
Epoch: [1654][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.1221 (0.1221)	
0.9999975 1.7348941e-07
Epoch: [1654][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0408 (0.0602)	
0.9999931 1.7675586e-07
Epoch: [1654][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0924 (0.0558)	
0.9999939 1.9399617e-07
loss:  0.039009011616758626 0.03862828731324508
===========>   training    <===========
Epoch: [1655][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0339 (0.0339)	
0.9999962 1.3156794e-07
===========>   testing    <===========
Epoch: [1655][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.1274 (0.1274)	
0.99999726 2.0388875e-07
Epoch: [1655][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0587 (0.0610)	
0.99999094 2.2143419e-07
Epoch: [1655][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0897 (0.0561)	
0.9999927 2.57323e-07
loss:  0.03931585168459917 0.03862828731324508
===========>   training    <===========
Epoch: [1656][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0433 (0.0433)	
0.99999106 2.01781e-08
===========>   testing    <===========
Epoch: [1656][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.1315 (0.1315)	
0.9999976 1.646927e-07
Epoch: [1656][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0429 (0.0606)	
0.9999925 1.6668012e-07
Epoch: [1656][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0841 (0.0557)	
0.9999944 1.8617577e-07
loss:  0.039040304032883166 0.03862828731324508
===========>   training    <===========
Epoch: [1657][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0440 (0.0440)	
0.9999939 7.082141e-07
===========>   testing    <===========
Epoch: [1657][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.1188 (0.1188)	
0.9999975 1.8802915e-07
Epoch: [1657][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0378 (0.0608)	
0.9999925 1.8870028e-07
Epoch: [1657][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0941 (0.0563)	
0.9999938 2.1946553e-07
loss:  0.039256667178871774 0.03862828731324508
===========>   training    <===========
Epoch: [1658][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0340 (0.0340)	
0.999997 6.7314296e-08
===========>   testing    <===========
Epoch: [1658][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.1226 (0.1226)	
0.99999726 1.6945891e-07
Epoch: [1658][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0327 (0.0605)	
0.999992 1.7156847e-07
Epoch: [1658][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0872 (0.0563)	
0.9999932 1.9445851e-07
loss:  0.03941007851788081 0.03862828731324508
===========>   training    <===========
Epoch: [1659][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0419 (0.0419)	
0.999998 2.1332458e-07
===========>   testing    <===========
Epoch: [1659][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.1341 (0.1341)	
0.9999974 2.1008799e-07
Epoch: [1659][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0444 (0.0602)	
0.99999154 2.702102e-07
Epoch: [1659][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4905125382474753e-05]	Loss 0.0811 (0.0556)	
0.99999285 3.103777e-07
loss:  0.039867773695706266 0.03862828731324508
===========>   training    <===========
Epoch: [1660][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0323 (0.0323)	
0.9999957 1.0908135e-07
===========>   testing    <===========
Epoch: [1660][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.1339 (0.1339)	
0.9999975 1.8471073e-07
Epoch: [1660][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0263 (0.0599)	
0.9999912 2.1935276e-07
Epoch: [1660][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0922 (0.0560)	
0.99999356 2.4688472e-07
loss:  0.039700627916208986 0.03862828731324508
===========>   training    <===========
Epoch: [1661][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0378 (0.0378)	
0.9999974 5.6199777e-08
===========>   testing    <===========
Epoch: [1661][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.1334 (0.1334)	
0.99999726 1.8379858e-07
Epoch: [1661][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0379 (0.0601)	
0.99999285 1.8694081e-07
Epoch: [1661][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0792 (0.0561)	
0.9999949 2.0994239e-07
loss:  0.03968905058517713 0.03862828731324508
===========>   training    <===========
Epoch: [1662][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0337 (0.0337)	
0.99999726 4.969565e-07
===========>   testing    <===========
Epoch: [1662][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.1374 (0.1374)	
0.99999714 1.7815084e-07
Epoch: [1662][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0482 (0.0600)	
0.99999213 1.8322682e-07
Epoch: [1662][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0803 (0.0560)	
0.99999416 2.0567725e-07
loss:  0.039351842262468906 0.03862828731324508
===========>   training    <===========
Epoch: [1663][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0325 (0.0325)	
0.9999907 2.0403172e-07
===========>   testing    <===========
Epoch: [1663][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.1329 (0.1329)	
0.999997 1.744126e-07
Epoch: [1663][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0392 (0.0598)	
0.99999166 1.7987492e-07
Epoch: [1663][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0746 (0.0559)	
0.9999938 2.049516e-07
loss:  0.039287244466231774 0.03862828731324508
===========>   training    <===========
Epoch: [1664][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0357 (0.0357)	
0.9999927 1.7363557e-07
===========>   testing    <===========
Epoch: [1664][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.1411 (0.1411)	
0.9999968 2.0034467e-07
Epoch: [1664][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0340 (0.0600)	
0.9999919 2.0775113e-07
Epoch: [1664][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0894 (0.0563)	
0.9999938 2.3394425e-07
loss:  0.039334163947065015 0.03862828731324508
===========>   training    <===========
Epoch: [1665][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0366 (0.0366)	
0.9999988 8.560077e-09
===========>   testing    <===========
Epoch: [1665][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.1473 (0.1473)	
0.99999654 1.7375501e-07
Epoch: [1665][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0455 (0.0600)	
0.9999912 2.1760091e-07
Epoch: [1665][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0703 (0.0558)	
0.9999933 2.4354674e-07
loss:  0.039589263269511954 0.03862828731324508
===========>   training    <===========
Epoch: [1666][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0299 (0.0299)	
0.99999 1.2901938e-07
===========>   testing    <===========
Epoch: [1666][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.1539 (0.1539)	
0.9999963 1.772045e-07
Epoch: [1666][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0779 (0.0603)	
0.9999918 1.8266432e-07
Epoch: [1666][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0709 (0.0561)	
0.9999937 2.0650374e-07
loss:  0.039605535747120224 0.03862828731324508
===========>   training    <===========
Epoch: [1667][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0290 (0.0290)	
0.9999949 1.6272058e-07
===========>   testing    <===========
Epoch: [1667][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.1495 (0.1495)	
0.99999666 1.9686352e-07
Epoch: [1667][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0396 (0.0599)	
0.9999924 2.0643343e-07
Epoch: [1667][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0767 (0.0559)	
0.99999416 2.232435e-07
loss:  0.03909355962291772 0.03862828731324508
===========>   training    <===========
Epoch: [1668][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0308 (0.0308)	
0.99999523 8.950787e-08
===========>   testing    <===========
Epoch: [1668][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.1477 (0.1477)	
0.999997 1.5622172e-07
Epoch: [1668][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0460 (0.0601)	
0.99999285 1.6135083e-07
Epoch: [1668][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0807 (0.0562)	
0.99999464 1.7765595e-07
loss:  0.03924696925856541 0.03862828731324508
===========>   training    <===========
Epoch: [1669][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0309 (0.0309)	
0.99999774 1.7977202e-07
===========>   testing    <===========
Epoch: [1669][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.1418 (0.1418)	
0.9999963 2.033551e-07
Epoch: [1669][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0621 (0.0606)	
0.9999906 2.0642989e-07
Epoch: [1669][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0712 (0.0561)	
0.99999297 2.3556784e-07
loss:  0.03937663736385422 0.03862828731324508
===========>   training    <===========
Epoch: [1670][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0327 (0.0327)	
0.9999882 2.839903e-07
===========>   testing    <===========
Epoch: [1670][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.1391 (0.1391)	
0.9999969 1.5256472e-07
Epoch: [1670][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0683 (0.0604)	
0.99999225 1.5426157e-07
Epoch: [1670][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0755 (0.0564)	
0.9999939 1.695192e-07
loss:  0.0393572663722116 0.03862828731324508
===========>   training    <===========
Epoch: [1671][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0339 (0.0339)	
0.99998426 1.2462674e-07
===========>   testing    <===========
Epoch: [1671][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.1337 (0.1337)	
0.9999968 1.6643837e-07
Epoch: [1671][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0574 (0.0608)	
0.9999925 1.6733026e-07
Epoch: [1671][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0774 (0.0566)	
0.9999938 1.8793683e-07
loss:  0.039282348914187804 0.03862828731324508
===========>   training    <===========
Epoch: [1672][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0284 (0.0284)	
0.9999901 8.091825e-08
===========>   testing    <===========
Epoch: [1672][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.1376 (0.1376)	
0.9999968 1.975142e-07
Epoch: [1672][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0408 (0.0607)	
0.99999356 2.0120957e-07
Epoch: [1672][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0823 (0.0571)	
0.9999945 2.2026127e-07
loss:  0.03941326065437667 0.03862828731324508
===========>   training    <===========
Epoch: [1673][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0359 (0.0359)	
0.99999714 2.88518e-08
===========>   testing    <===========
Epoch: [1673][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.1433 (0.1433)	
0.99999654 1.768648e-07
Epoch: [1673][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0444 (0.0614)	
0.9999926 1.7958729e-07
Epoch: [1673][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0765 (0.0572)	
0.9999939 1.9612277e-07
loss:  0.03969997488305166 0.03862828731324508
===========>   training    <===========
Epoch: [1674][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0346 (0.0346)	
0.99999154 8.340061e-08
===========>   testing    <===========
Epoch: [1674][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.1349 (0.1349)	
0.9999969 1.86158e-07
Epoch: [1674][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0558 (0.0611)	
0.9999926 1.9080667e-07
Epoch: [1674][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0804 (0.0569)	
0.9999937 2.0824069e-07
loss:  0.039725951369574575 0.03862828731324508
===========>   training    <===========
Epoch: [1675][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0251 (0.0251)	
0.9999951 5.6086908e-08
===========>   testing    <===========
Epoch: [1675][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.1292 (0.1292)	
0.999997 1.7264519e-07
Epoch: [1675][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0853 (0.0609)	
0.9999933 1.7644362e-07
Epoch: [1675][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0785 (0.0570)	
0.9999943 1.9449931e-07
loss:  0.039974679356799325 0.03862828731324508
===========>   training    <===========
Epoch: [1676][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0380 (0.0380)	
0.99998784 3.6611834e-08
===========>   testing    <===========
Epoch: [1676][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.1236 (0.1236)	
0.999997 1.9248941e-07
Epoch: [1676][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0888 (0.0610)	
0.99999285 1.947237e-07
Epoch: [1676][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0807 (0.0569)	
0.9999939 2.2042391e-07
loss:  0.040168747224356816 0.03862828731324508
===========>   training    <===========
Epoch: [1677][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0316 (0.0316)	
0.99999523 1.2148345e-07
===========>   testing    <===========
Epoch: [1677][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.1311 (0.1311)	
0.999997 1.8292319e-07
Epoch: [1677][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.1063 (0.0608)	
0.9999937 1.8317755e-07
Epoch: [1677][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0874 (0.0569)	
0.99999464 2.078544e-07
loss:  0.04034768884560258 0.03862828731324508
===========>   training    <===========
Epoch: [1678][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0375 (0.0375)	
0.9999877 6.273903e-08
===========>   testing    <===========
Epoch: [1678][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.1348 (0.1348)	
0.999997 1.9436098e-07
Epoch: [1678][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0705 (0.0602)	
0.99999297 1.9595974e-07
Epoch: [1678][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0885 (0.0564)	
0.9999943 2.2589808e-07
loss:  0.040004593770161856 0.03862828731324508
===========>   training    <===========
Epoch: [1679][0/23]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0340 (0.0340)	
0.99999535 2.91953e-07
===========>   testing    <===========
Epoch: [1679][0/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.1296 (0.1296)	
0.9999969 1.9283155e-07
Epoch: [1679][100/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0516 (0.0608)	
0.99999225 1.9461935e-07
Epoch: [1679][200/289]	Lr-deconv: [0.0]	Lr-other: [1.4159869113351015e-05]	Loss 0.0879 (0.0566)	
0.9999937 2.1948418e-07
loss:  0.03975550569358466 0.03862828731324508
===========>   training    <===========
Epoch: [1680][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0330 (0.0330)	
0.99999523 2.182493e-08
===========>   testing    <===========
Epoch: [1680][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.1399 (0.1399)	
0.9999964 1.774184e-07
Epoch: [1680][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0563 (0.0613)	
0.99999166 1.8066814e-07
Epoch: [1680][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0917 (0.0570)	
0.9999932 2.0259246e-07
loss:  0.0399817100908868 0.03862828731324508
===========>   training    <===========
Epoch: [1681][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0303 (0.0303)	
0.99999464 9.435991e-08
===========>   testing    <===========
Epoch: [1681][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.1336 (0.1336)	
0.99999654 2.2528859e-07
Epoch: [1681][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0566 (0.0605)	
0.99999213 2.2940361e-07
Epoch: [1681][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0816 (0.0565)	
0.99999344 2.5938672e-07
loss:  0.03977651828768125 0.03862828731324508
===========>   training    <===========
Epoch: [1682][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0310 (0.0310)	
0.99999356 1.4727661e-07
===========>   testing    <===========
Epoch: [1682][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.1409 (0.1409)	
0.99999654 1.9705418e-07
Epoch: [1682][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0481 (0.0608)	
0.99999166 1.9816096e-07
Epoch: [1682][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0946 (0.0571)	
0.9999931 2.2345182e-07
loss:  0.039868035457982676 0.03862828731324508
===========>   training    <===========
Epoch: [1683][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0280 (0.0280)	
0.999998 1.2177146e-07
===========>   testing    <===========
Epoch: [1683][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.1389 (0.1389)	
0.99999714 1.7218463e-07
Epoch: [1683][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.1010 (0.0614)	
0.9999932 1.7460732e-07
Epoch: [1683][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0857 (0.0571)	
0.9999939 1.9174429e-07
loss:  0.04044833589915897 0.03862828731324508
===========>   training    <===========
Epoch: [1684][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0290 (0.0290)	
0.99999404 1.3083067e-08
===========>   testing    <===========
Epoch: [1684][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.1337 (0.1337)	
0.9999968 1.6302408e-07
Epoch: [1684][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0976 (0.0608)	
0.99999213 1.6287707e-07
Epoch: [1684][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0794 (0.0569)	
0.9999938 1.7759292e-07
loss:  0.04023453172330815 0.03862828731324508
===========>   training    <===========
Epoch: [1685][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0400 (0.0400)	
0.99999475 1.0110471e-07
===========>   testing    <===========
Epoch: [1685][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.1372 (0.1372)	
0.9999964 1.8592877e-07
Epoch: [1685][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.1441 (0.0612)	
0.9999908 1.8848463e-07
Epoch: [1685][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0755 (0.0569)	
0.9999927 2.1131434e-07
loss:  0.040588582819425456 0.03862828731324508
===========>   training    <===========
Epoch: [1686][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0312 (0.0312)	
0.9999933 1.6160523e-07
===========>   testing    <===========
Epoch: [1686][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.1333 (0.1333)	
0.9999968 2.1959178e-07
Epoch: [1686][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0959 (0.0608)	
0.999992 2.1918422e-07
Epoch: [1686][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0779 (0.0567)	
0.9999937 2.423313e-07
loss:  0.040350874109883916 0.03862828731324508
===========>   training    <===========
Epoch: [1687][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0294 (0.0294)	
0.9999925 1.3458565e-07
===========>   testing    <===========
Epoch: [1687][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.1280 (0.1280)	
0.9999963 2.0538717e-07
Epoch: [1687][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0813 (0.0614)	
0.9999912 2.0701816e-07
Epoch: [1687][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0818 (0.0574)	
0.9999931 2.2141751e-07
loss:  0.04047704945525743 0.03862828731324508
===========>   training    <===========
Epoch: [1688][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0307 (0.0307)	
0.99998176 6.109766e-08
===========>   testing    <===========
Epoch: [1688][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.1322 (0.1322)	
0.99999654 1.9328851e-07
Epoch: [1688][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0469 (0.0620)	
0.99999166 2.0687253e-07
Epoch: [1688][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0832 (0.0575)	
0.9999932 2.229501e-07
loss:  0.040344024743567575 0.03862828731324508
===========>   training    <===========
Epoch: [1689][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0330 (0.0330)	
0.99999535 2.5921705e-07
===========>   testing    <===========
Epoch: [1689][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.1277 (0.1277)	
0.9999969 2.2850315e-07
Epoch: [1689][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0933 (0.0620)	
0.9999925 2.2440642e-07
Epoch: [1689][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0853 (0.0574)	
0.9999938 2.4293155e-07
loss:  0.04064133729396502 0.03862828731324508
===========>   training    <===========
Epoch: [1690][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0326 (0.0326)	
0.9999925 4.485177e-08
===========>   testing    <===========
Epoch: [1690][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.1213 (0.1213)	
0.99999666 1.5014845e-07
Epoch: [1690][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0660 (0.0613)	
0.9999927 1.48415e-07
Epoch: [1690][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0862 (0.0572)	
0.99999404 1.6012665e-07
loss:  0.04038912695701835 0.03862828731324508
===========>   training    <===========
Epoch: [1691][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0343 (0.0343)	
0.9999809 1.8284588e-08
===========>   testing    <===========
Epoch: [1691][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.1237 (0.1237)	
0.99999666 2.271725e-07
Epoch: [1691][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0830 (0.0611)	
0.99999297 2.2660191e-07
Epoch: [1691][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0863 (0.0566)	
0.9999938 2.464265e-07
loss:  0.0404505899110017 0.03862828731324508
===========>   training    <===========
Epoch: [1692][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0381 (0.0381)	
0.9999968 6.0570294e-08
===========>   testing    <===========
Epoch: [1692][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.1315 (0.1315)	
0.99999714 1.5987823e-07
Epoch: [1692][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.1544 (0.0617)	
0.9999932 1.592522e-07
Epoch: [1692][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0794 (0.0564)	
0.9999944 1.7315602e-07
loss:  0.0402448893305819 0.03862828731324508
===========>   training    <===========
Epoch: [1693][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0366 (0.0366)	
0.9999927 3.9558572e-07
===========>   testing    <===========
Epoch: [1693][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.1288 (0.1288)	
0.9999968 1.515667e-07
Epoch: [1693][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.1003 (0.0619)	
0.9999926 1.4887402e-07
Epoch: [1693][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0695 (0.0567)	
0.9999937 1.6851773e-07
loss:  0.04028968643597275 0.03862828731324508
===========>   training    <===========
Epoch: [1694][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0340 (0.0340)	
0.9999807 1.9901334e-08
===========>   testing    <===========
Epoch: [1694][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.1233 (0.1233)	
0.9999968 1.5207476e-07
Epoch: [1694][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.1351 (0.0623)	
0.99999297 1.4936266e-07
Epoch: [1694][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0715 (0.0569)	
0.9999939 1.6983944e-07
loss:  0.040762849274555424 0.03862828731324508
===========>   training    <===========
Epoch: [1695][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0408 (0.0408)	
0.99998987 8.682029e-07
===========>   testing    <===========
Epoch: [1695][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.1216 (0.1216)	
0.9999969 1.6108301e-07
Epoch: [1695][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0814 (0.0617)	
0.9999924 1.5938164e-07
Epoch: [1695][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0806 (0.0570)	
0.9999937 1.8003193e-07
loss:  0.04022836503612304 0.03862828731324508
===========>   training    <===========
Epoch: [1696][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0326 (0.0326)	
0.9999962 1.7332437e-07
===========>   testing    <===========
Epoch: [1696][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.1338 (0.1338)	
0.99999714 1.3022724e-07
Epoch: [1696][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.1295 (0.0625)	
0.99999297 1.3101202e-07
Epoch: [1696][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0761 (0.0575)	
0.9999939 1.4555079e-07
loss:  0.04091691088454308 0.03862828731324508
===========>   training    <===========
Epoch: [1697][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0414 (0.0414)	
0.99999475 1.3328459e-07
===========>   testing    <===========
Epoch: [1697][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.1391 (0.1391)	
0.9999968 1.8890249e-07
Epoch: [1697][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.1178 (0.0617)	
0.999992 1.919847e-07
Epoch: [1697][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0773 (0.0567)	
0.9999933 2.168001e-07
loss:  0.04063429450163869 0.03862828731324508
===========>   training    <===========
Epoch: [1698][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0304 (0.0304)	
0.9999926 2.6645517e-07
===========>   testing    <===========
Epoch: [1698][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.1321 (0.1321)	
0.9999968 1.9253055e-07
Epoch: [1698][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.1804 (0.0629)	
0.9999927 1.9561917e-07
Epoch: [1698][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0738 (0.0572)	
0.9999939 2.2404974e-07
loss:  0.040944730774018945 0.03862828731324508
===========>   training    <===========
Epoch: [1699][0/23]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0305 (0.0305)	
0.9999968 1.3967053e-07
===========>   testing    <===========
Epoch: [1699][0/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.1309 (0.1309)	
0.9999969 1.9130337e-07
Epoch: [1699][100/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.1281 (0.0619)	
0.99999225 1.9449338e-07
Epoch: [1699][200/289]	Lr-deconv: [0.0]	Lr-other: [1.3451875657683464e-05]	Loss 0.0799 (0.0570)	
0.99999404 2.1982311e-07
loss:  0.040933127676980874 0.03862828731324508
===========>   training    <===========
Epoch: [1700][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0302 (0.0302)	
0.99999523 4.123829e-08
===========>   testing    <===========
Epoch: [1700][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.1397 (0.1397)	
0.999997 1.9626498e-07
Epoch: [1700][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.1709 (0.0624)	
0.99999297 1.9501286e-07
Epoch: [1700][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0838 (0.0575)	
0.99999464 2.2188658e-07
loss:  0.040904088724026955 0.03862828731324508
===========>   training    <===========
Epoch: [1701][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0351 (0.0351)	
0.9999933 2.7322022e-07
===========>   testing    <===========
Epoch: [1701][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.1420 (0.1420)	
0.99999714 2.1258289e-07
Epoch: [1701][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.1616 (0.0630)	
0.99999106 2.170078e-07
Epoch: [1701][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0814 (0.0578)	
0.9999937 2.527115e-07
loss:  0.040883005302180586 0.03862828731324508
===========>   training    <===========
Epoch: [1702][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0374 (0.0374)	
0.99997914 6.914404e-08
===========>   testing    <===========
Epoch: [1702][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.1514 (0.1514)	
0.9999974 2.4284074e-07
Epoch: [1702][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.1670 (0.0630)	
0.99999154 2.424913e-07
Epoch: [1702][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0806 (0.0578)	
0.9999938 2.7876155e-07
loss:  0.041011051859569325 0.03862828731324508
===========>   training    <===========
Epoch: [1703][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0289 (0.0289)	
0.9999943 1.2681807e-07
===========>   testing    <===========
Epoch: [1703][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.1434 (0.1434)	
0.99999666 2.136259e-07
Epoch: [1703][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.2092 (0.0638)	
0.9999914 2.1489521e-07
Epoch: [1703][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0785 (0.0580)	
0.9999933 2.4284375e-07
loss:  0.041334966687028185 0.03862828731324508
===========>   training    <===========
Epoch: [1704][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0293 (0.0293)	
0.99999416 2.255865e-08
===========>   testing    <===========
Epoch: [1704][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.1384 (0.1384)	
0.999997 1.8657676e-07
Epoch: [1704][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.2035 (0.0638)	
0.9999918 1.887307e-07
Epoch: [1704][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0833 (0.0582)	
0.99999356 2.1144054e-07
loss:  0.04115303368528944 0.03862828731324508
===========>   training    <===========
Epoch: [1705][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0297 (0.0297)	
0.9999969 1.5434986e-07
===========>   testing    <===========
Epoch: [1705][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.1325 (0.1325)	
0.9999969 1.9696888e-07
Epoch: [1705][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.1537 (0.0636)	
0.9999925 2.0066803e-07
Epoch: [1705][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0828 (0.0581)	
0.99999404 2.2361769e-07
loss:  0.04106586543119373 0.03862828731324508
===========>   training    <===========
Epoch: [1706][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0300 (0.0300)	
0.99999 3.928491e-08
===========>   testing    <===========
Epoch: [1706][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.1391 (0.1391)	
0.9999963 2.329753e-07
Epoch: [1706][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0681 (0.0619)	
0.9999912 2.3799484e-07
Epoch: [1706][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0859 (0.0569)	
0.99999344 2.664933e-07
loss:  0.040243338626477554 0.03862828731324508
===========>   training    <===========
Epoch: [1707][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0309 (0.0309)	
0.9999956 3.068851e-08
===========>   testing    <===========
Epoch: [1707][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.1413 (0.1413)	
0.9999968 1.8578858e-07
Epoch: [1707][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0793 (0.0625)	
0.99999213 1.887082e-07
Epoch: [1707][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0826 (0.0572)	
0.99999404 2.062398e-07
loss:  0.040479554506116844 0.03862828731324508
===========>   training    <===========
Epoch: [1708][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0373 (0.0373)	
0.99999595 1.8618353e-08
===========>   testing    <===========
Epoch: [1708][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.1478 (0.1478)	
0.99999654 2.054914e-07
Epoch: [1708][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0999 (0.0625)	
0.99999166 2.0901584e-07
Epoch: [1708][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0836 (0.0573)	
0.9999937 2.3436473e-07
loss:  0.04063898529501564 0.03862828731324508
===========>   training    <===========
Epoch: [1709][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0347 (0.0347)	
0.9999862 1.3715965e-07
===========>   testing    <===========
Epoch: [1709][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.1336 (0.1336)	
0.9999969 1.5712688e-07
Epoch: [1709][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0783 (0.0620)	
0.9999925 1.586416e-07
Epoch: [1709][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0825 (0.0571)	
0.999995 1.8046599e-07
loss:  0.04006475722962799 0.03862828731324508
===========>   training    <===========
Epoch: [1710][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0355 (0.0355)	
0.9999956 1.5721578e-06
===========>   testing    <===========
Epoch: [1710][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.1178 (0.1178)	
0.99999654 2.0334852e-07
Epoch: [1710][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.1239 (0.0626)	
0.9999913 2.0521819e-07
Epoch: [1710][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0804 (0.0573)	
0.99999404 2.3351562e-07
loss:  0.040614925648079 0.03862828731324508
===========>   training    <===========
Epoch: [1711][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0365 (0.0365)	
0.9999958 6.725282e-08
===========>   testing    <===========
Epoch: [1711][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.1234 (0.1234)	
0.9999968 1.9677624e-07
Epoch: [1711][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0769 (0.0624)	
0.9999914 1.9775582e-07
Epoch: [1711][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0893 (0.0572)	
0.99999416 2.2077778e-07
loss:  0.040401771632019856 0.03862828731324508
===========>   training    <===========
Epoch: [1712][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0297 (0.0297)	
0.99999213 1.2837832e-07
===========>   testing    <===========
Epoch: [1712][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.1313 (0.1313)	
0.9999969 1.6764173e-07
Epoch: [1712][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.1534 (0.0629)	
0.99999213 1.6828182e-07
Epoch: [1712][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0780 (0.0573)	
0.99999404 1.9015289e-07
loss:  0.04023811818694867 0.03862828731324508
===========>   training    <===========
Epoch: [1713][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0290 (0.0290)	
0.9999902 1.339154e-07
===========>   testing    <===========
Epoch: [1713][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.1325 (0.1325)	
0.999997 1.7093122e-07
Epoch: [1713][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.2473 (0.0643)	
0.99999213 1.728353e-07
Epoch: [1713][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0736 (0.0576)	
0.9999938 1.9318274e-07
loss:  0.04053304283738879 0.03862828731324508
===========>   training    <===========
Epoch: [1714][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0305 (0.0305)	
0.9999888 1.25583e-07
===========>   testing    <===========
Epoch: [1714][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.1317 (0.1317)	
0.9999975 1.3042373e-07
Epoch: [1714][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.2798 (0.0652)	
0.9999937 1.3121158e-07
Epoch: [1714][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0773 (0.0582)	
0.999995 1.4243602e-07
loss:  0.040943930469682255 0.03862828731324508
===========>   training    <===========
Epoch: [1715][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0303 (0.0303)	
0.9999956 1.50927e-07
===========>   testing    <===========
Epoch: [1715][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.1225 (0.1225)	
0.9999976 1.5960157e-07
Epoch: [1715][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.1106 (0.0627)	
0.9999932 1.6139053e-07
Epoch: [1715][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0854 (0.0572)	
0.99999475 1.7705331e-07
loss:  0.040325146898569364 0.03862828731324508
===========>   training    <===========
Epoch: [1716][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0299 (0.0299)	
0.999995 5.5771892e-08
===========>   testing    <===========
Epoch: [1716][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.1311 (0.1311)	
0.99999726 2.1515257e-07
Epoch: [1716][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0727 (0.0615)	
0.9999925 2.1839655e-07
Epoch: [1716][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0751 (0.0563)	
0.9999938 2.3435959e-07
loss:  0.04013488590485248 0.03862828731324508
===========>   training    <===========
Epoch: [1717][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0300 (0.0300)	
0.9999956 6.415021e-08
===========>   testing    <===========
Epoch: [1717][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.1318 (0.1318)	
0.99999714 1.6886474e-07
Epoch: [1717][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0583 (0.0615)	
0.9999925 1.7043085e-07
Epoch: [1717][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0814 (0.0568)	
0.9999937 1.8717806e-07
loss:  0.03998357458388502 0.03862828731324508
===========>   training    <===========
Epoch: [1718][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0296 (0.0296)	
0.99998915 1.1420052e-08
===========>   testing    <===========
Epoch: [1718][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.1287 (0.1287)	
0.9999969 2.1644769e-07
Epoch: [1718][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0406 (0.0609)	
0.99999154 2.1823811e-07
Epoch: [1718][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0807 (0.0568)	
0.9999932 2.4169566e-07
loss:  0.040302870291288206 0.03862828731324508
===========>   training    <===========
Epoch: [1719][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0362 (0.0362)	
0.9999913 4.3423764e-08
===========>   testing    <===========
Epoch: [1719][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.1159 (0.1159)	
0.99999726 2.0264365e-07
Epoch: [1719][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0852 (0.0617)	
0.9999919 2.0476483e-07
Epoch: [1719][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2779281874799288e-05]	Loss 0.0804 (0.0575)	
0.9999937 2.2416343e-07
loss:  0.0409332919953066 0.03862828731324508
===========>   training    <===========
Epoch: [1720][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0286 (0.0286)	
0.99999654 9.420472e-08
===========>   testing    <===========
Epoch: [1720][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1114 (0.1114)	
0.99999726 1.8740455e-07
Epoch: [1720][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0858 (0.0620)	
0.9999924 1.8588766e-07
Epoch: [1720][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0820 (0.0577)	
0.9999938 2.0718882e-07
loss:  0.04089469720880279 0.03862828731324508
===========>   training    <===========
Epoch: [1721][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0330 (0.0330)	
0.99999595 1.42265595e-08
===========>   testing    <===========
Epoch: [1721][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1194 (0.1194)	
0.99999726 1.9259427e-07
Epoch: [1721][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0882 (0.0622)	
0.9999925 1.9294043e-07
Epoch: [1721][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0872 (0.0577)	
0.99999356 2.1569103e-07
loss:  0.04074052627020408 0.03862828731324508
===========>   training    <===========
Epoch: [1722][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0347 (0.0347)	
0.99999094 5.5460234e-08
===========>   testing    <===========
Epoch: [1722][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1162 (0.1162)	
0.9999975 2.1777323e-07
Epoch: [1722][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1504 (0.0626)	
0.9999933 2.21066e-07
Epoch: [1722][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0892 (0.0579)	
0.99999404 2.4683058e-07
loss:  0.04126795134133421 0.03862828731324508
===========>   training    <===========
Epoch: [1723][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0331 (0.0331)	
0.99999547 1.0147815e-07
===========>   testing    <===========
Epoch: [1723][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1036 (0.1036)	
0.9999976 2.2367782e-07
Epoch: [1723][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1113 (0.0622)	
0.9999932 2.288032e-07
Epoch: [1723][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0957 (0.0581)	
0.9999945 2.549273e-07
loss:  0.04122013229326105 0.03862828731324508
===========>   training    <===========
Epoch: [1724][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0298 (0.0298)	
0.99999416 2.316517e-08
===========>   testing    <===========
Epoch: [1724][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1091 (0.1091)	
0.9999974 1.8888916e-07
Epoch: [1724][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0598 (0.0617)	
0.99999344 1.9266095e-07
Epoch: [1724][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0917 (0.0577)	
0.99999404 2.1618175e-07
loss:  0.040561797760982454 0.03862828731324508
===========>   training    <===========
Epoch: [1725][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0340 (0.0340)	
0.99998236 2.8582587e-08
===========>   testing    <===========
Epoch: [1725][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1117 (0.1117)	
0.9999976 2.2727328e-07
Epoch: [1725][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0679 (0.0615)	
0.9999931 2.295231e-07
Epoch: [1725][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0902 (0.0575)	
0.99999416 2.5661228e-07
loss:  0.040544364689579115 0.03862828731324508
===========>   training    <===========
Epoch: [1726][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0342 (0.0342)	
0.9999908 2.3448658e-07
===========>   testing    <===========
Epoch: [1726][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1177 (0.1177)	
0.9999974 2.0560117e-07
Epoch: [1726][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1202 (0.0630)	
0.9999924 2.074684e-07
Epoch: [1726][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0909 (0.0582)	
0.9999937 2.2955463e-07
loss:  0.04172762003190522 0.03862828731324508
===========>   training    <===========
Epoch: [1727][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0311 (0.0311)	
0.99998236 1.1833804e-07
===========>   testing    <===========
Epoch: [1727][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1210 (0.1210)	
0.99999726 2.1385215e-07
Epoch: [1727][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1191 (0.0622)	
0.9999932 2.1596644e-07
Epoch: [1727][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0934 (0.0580)	
0.9999937 2.4235766e-07
loss:  0.04156053158880468 0.03862828731324508
===========>   training    <===========
Epoch: [1728][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0302 (0.0302)	
0.99998844 2.7736503e-08
===========>   testing    <===========
Epoch: [1728][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1192 (0.1192)	
0.9999974 2.2699665e-07
Epoch: [1728][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0681 (0.0618)	
0.99999285 2.3134619e-07
Epoch: [1728][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1005 (0.0576)	
0.99999416 2.621636e-07
loss:  0.04054226205220701 0.03862828731324508
===========>   training    <===========
Epoch: [1729][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0361 (0.0361)	
0.9999896 3.1988275e-08
===========>   testing    <===========
Epoch: [1729][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1211 (0.1211)	
0.9999969 2.7258778e-07
Epoch: [1729][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1050 (0.0625)	
0.99999213 2.8133132e-07
Epoch: [1729][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0951 (0.0580)	
0.9999937 3.206042e-07
loss:  0.040812914544085976 0.03862828731324508
===========>   training    <===========
Epoch: [1730][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0297 (0.0297)	
0.9999937 4.6374833e-08
===========>   testing    <===========
Epoch: [1730][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1201 (0.1201)	
0.9999969 2.5878728e-07
Epoch: [1730][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1544 (0.0626)	
0.99999225 2.691126e-07
Epoch: [1730][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0917 (0.0578)	
0.99999344 3.0638628e-07
loss:  0.04103367028916827 0.03862828731324508
===========>   training    <===========
Epoch: [1731][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0351 (0.0351)	
0.99999297 4.6354845e-08
===========>   testing    <===========
Epoch: [1731][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1181 (0.1181)	
0.9999968 2.5977337e-07
Epoch: [1731][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1857 (0.0629)	
0.99999166 2.6315905e-07
Epoch: [1731][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0878 (0.0577)	
0.99999285 3.0535134e-07
loss:  0.04096095648243625 0.03862828731324508
===========>   training    <===========
Epoch: [1732][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0308 (0.0308)	
0.99999356 6.489104e-08
===========>   testing    <===========
Epoch: [1732][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1155 (0.1155)	
0.99999654 2.0176144e-07
Epoch: [1732][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1764 (0.0622)	
0.9999913 2.710945e-07
Epoch: [1732][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0834 (0.0573)	
0.9999926 2.7001443e-07
loss:  0.04098208814417226 0.03862828731324508
===========>   training    <===========
Epoch: [1733][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0319 (0.0319)	
0.99999213 1.4911957e-07
===========>   testing    <===========
Epoch: [1733][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1214 (0.1214)	
0.999997 2.3726331e-07
Epoch: [1733][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1463 (0.0616)	
0.9999924 2.3421882e-07
Epoch: [1733][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0814 (0.0570)	
0.9999939 2.8476595e-07
loss:  0.04096997236000699 0.03862828731324508
===========>   training    <===========
Epoch: [1734][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0353 (0.0353)	
0.99999344 2.9699098e-07
===========>   testing    <===========
Epoch: [1734][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1067 (0.1067)	
0.9999975 2.3542769e-07
Epoch: [1734][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1709 (0.0627)	
0.9999931 2.3539445e-07
Epoch: [1734][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0805 (0.0576)	
0.9999938 2.8564094e-07
loss:  0.04087558500445576 0.03862828731324508
===========>   training    <===========
Epoch: [1735][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0312 (0.0312)	
0.9999944 1.3972621e-07
===========>   testing    <===========
Epoch: [1735][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1200 (0.1200)	
0.99999714 2.4619467e-07
Epoch: [1735][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1105 (0.0618)	
0.99999285 2.4349006e-07
Epoch: [1735][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0837 (0.0570)	
0.9999931 2.90639e-07
loss:  0.040324454731174186 0.03862828731324508
===========>   training    <===========
Epoch: [1736][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0353 (0.0353)	
0.9999931 3.485266e-08
===========>   testing    <===========
Epoch: [1736][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1290 (0.1290)	
0.99999714 2.4050328e-07
Epoch: [1736][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1266 (0.0616)	
0.9999925 2.3976884e-07
Epoch: [1736][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0805 (0.0569)	
0.99999285 2.7916485e-07
loss:  0.040441908746945976 0.03862828731324508
===========>   training    <===========
Epoch: [1737][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0271 (0.0271)	
0.99999475 1.5606001e-07
===========>   testing    <===========
Epoch: [1737][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1296 (0.1296)	
0.9999969 2.0839248e-07
Epoch: [1737][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.2290 (0.0632)	
0.9999931 2.0715405e-07
Epoch: [1737][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0788 (0.0576)	
0.9999931 2.4328395e-07
loss:  0.041094648022714564 0.03862828731324508
===========>   training    <===========
Epoch: [1738][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0307 (0.0307)	
0.99998903 8.45632e-08
===========>   testing    <===========
Epoch: [1738][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1253 (0.1253)	
0.9999969 2.315199e-07
Epoch: [1738][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.2194 (0.0641)	
0.9999932 2.3122136e-07
Epoch: [1738][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0800 (0.0582)	
0.9999931 2.751539e-07
loss:  0.041290459149419756 0.03862828731324508
===========>   training    <===========
Epoch: [1739][0/23]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0347 (0.0347)	
0.999997 5.1937747e-08
===========>   testing    <===========
Epoch: [1739][0/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.1307 (0.1307)	
0.99999714 2.1161541e-07
Epoch: [1739][100/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.2356 (0.0631)	
0.99999356 2.0826194e-07
Epoch: [1739][200/289]	Lr-deconv: [0.0]	Lr-other: [1.2140317781059324e-05]	Loss 0.0792 (0.0578)	
0.9999937 2.442452e-07
loss:  0.04114133442782242 0.03862828731324508
===========>   training    <===========
Epoch: [1740][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0391 (0.0391)	
0.9999945 1.683823e-07
===========>   testing    <===========
Epoch: [1740][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.1197 (0.1197)	
0.9999974 1.7286827e-07
Epoch: [1740][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.2377 (0.0628)	
0.9999939 1.7460033e-07
Epoch: [1740][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0862 (0.0576)	
0.9999943 1.9772018e-07
loss:  0.04067059239546689 0.03862828731324508
===========>   training    <===========
Epoch: [1741][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0291 (0.0291)	
0.9999944 1.8568426e-07
===========>   testing    <===========
Epoch: [1741][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.1298 (0.1298)	
0.999997 2.1376752e-07
Epoch: [1741][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.2639 (0.0635)	
0.99999213 2.1400108e-07
Epoch: [1741][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0744 (0.0578)	
0.9999926 2.4015492e-07
loss:  0.04081193886226109 0.03862828731324508
===========>   training    <===========
Epoch: [1742][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0370 (0.0370)	
0.9999857 3.0910922e-08
===========>   testing    <===========
Epoch: [1742][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.1257 (0.1257)	
0.99999714 2.2745519e-07
Epoch: [1742][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.2335 (0.0628)	
0.9999933 2.2688475e-07
Epoch: [1742][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0699 (0.0575)	
0.9999938 2.5570867e-07
loss:  0.04074547573459075 0.03862828731324508
===========>   training    <===========
Epoch: [1743][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0348 (0.0348)	
0.9999937 6.1615744e-08
===========>   testing    <===========
Epoch: [1743][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.1207 (0.1207)	
0.99999714 2.447827e-07
Epoch: [1743][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.3196 (0.0634)	
0.9999925 2.4649606e-07
Epoch: [1743][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0766 (0.0577)	
0.9999931 2.818542e-07
loss:  0.040459581475594475 0.03862828731324508
===========>   training    <===========
Epoch: [1744][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0277 (0.0277)	
0.99999106 8.196771e-08
===========>   testing    <===========
Epoch: [1744][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.1240 (0.1240)	
0.99999714 2.5762355e-07
Epoch: [1744][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.2867 (0.0631)	
0.9999927 2.8969316e-07
Epoch: [1744][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0772 (0.0576)	
0.99999297 3.2246822e-07
loss:  0.04091417553836063 0.03862828731324508
===========>   training    <===========
Epoch: [1745][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0279 (0.0279)	
0.99999654 2.1748633e-08
===========>   testing    <===========
Epoch: [1745][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.1273 (0.1273)	
0.999997 2.2886474e-07
Epoch: [1745][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.2661 (0.0628)	
0.99999297 2.3129854e-07
Epoch: [1745][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0769 (0.0574)	
0.99999356 2.574074e-07
loss:  0.0409730501070934 0.03862828731324508
===========>   training    <===========
Epoch: [1746][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0304 (0.0304)	
0.99999225 2.4849479e-07
===========>   testing    <===========
Epoch: [1746][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.1375 (0.1375)	
0.9999974 1.9385784e-07
Epoch: [1746][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.3076 (0.0635)	
0.99999344 1.9835437e-07
Epoch: [1746][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0794 (0.0579)	
0.9999938 2.1925864e-07
loss:  0.041112183167841265 0.03862828731324508
===========>   training    <===========
Epoch: [1747][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0348 (0.0348)	
0.99998796 3.4907754e-07
===========>   testing    <===========
Epoch: [1747][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.1346 (0.1346)	
0.999997 1.7194817e-07
Epoch: [1747][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.2582 (0.0631)	
0.9999939 1.7719199e-07
Epoch: [1747][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0820 (0.0579)	
0.9999944 1.9245272e-07
loss:  0.04098513771519652 0.03862828731324508
===========>   training    <===========
Epoch: [1748][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0392 (0.0392)	
0.9999989 1.5798847e-07
===========>   testing    <===========
Epoch: [1748][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.1366 (0.1366)	
0.999997 2.396465e-07
Epoch: [1748][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.2272 (0.0630)	
0.99999297 2.5096784e-07
Epoch: [1748][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0790 (0.0577)	
0.9999939 2.7723075e-07
loss:  0.040889794668940826 0.03862828731324508
===========>   training    <===========
Epoch: [1749][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0324 (0.0324)	
0.9999968 2.1817353e-08
===========>   testing    <===========
Epoch: [1749][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.1409 (0.1409)	
0.99999726 1.9002383e-07
Epoch: [1749][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.1603 (0.0624)	
0.99999356 1.9684983e-07
Epoch: [1749][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0799 (0.0576)	
0.9999945 2.1119023e-07
loss:  0.04080393776466473 0.03862828731324508
===========>   training    <===========
Epoch: [1750][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0315 (0.0315)	
0.9999927 4.719907e-07
===========>   testing    <===========
Epoch: [1750][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.1390 (0.1390)	
0.99999666 1.865031e-07
Epoch: [1750][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0935 (0.0613)	
0.99999213 2.5378236e-07
Epoch: [1750][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0806 (0.0570)	
0.9999925 2.52203e-07
loss:  0.040610474097254046 0.03862828731324508
===========>   training    <===========
Epoch: [1751][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0320 (0.0320)	
0.99999475 2.5049488e-07
===========>   testing    <===========
Epoch: [1751][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.1443 (0.1443)	
0.99999654 1.9137671e-07
Epoch: [1751][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.1389 (0.0618)	
0.9999919 1.9400987e-07
Epoch: [1751][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0664 (0.0570)	
0.9999931 2.1757455e-07
loss:  0.04117094120394216 0.03862828731324508
===========>   training    <===========
Epoch: [1752][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0362 (0.0362)	
0.9999857 6.300645e-08
===========>   testing    <===========
Epoch: [1752][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.1369 (0.1369)	
0.9999969 2.2353323e-07
Epoch: [1752][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.1780 (0.0624)	
0.9999925 2.2874691e-07
Epoch: [1752][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0746 (0.0572)	
0.99999344 2.542145e-07
loss:  0.04101807235760535 0.03862828731324508
===========>   training    <===========
Epoch: [1753][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0344 (0.0344)	
0.9999833 5.1138183e-08
===========>   testing    <===========
Epoch: [1753][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.1375 (0.1375)	
0.999997 1.860831e-07
Epoch: [1753][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.2245 (0.0635)	
0.99999297 1.9162363e-07
Epoch: [1753][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0800 (0.0579)	
0.9999933 2.1255066e-07
loss:  0.04101778574085024 0.03862828731324508
===========>   training    <===========
Epoch: [1754][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0297 (0.0297)	
0.99998987 1.4630967e-07
===========>   testing    <===========
Epoch: [1754][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.1391 (0.1391)	
0.9999969 1.9990381e-07
Epoch: [1754][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.2328 (0.0631)	
0.9999925 2.0618475e-07
Epoch: [1754][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0771 (0.0576)	
0.9999927 2.2964352e-07
loss:  0.04090995903046557 0.03862828731324508
===========>   training    <===========
Epoch: [1755][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0328 (0.0328)	
0.99999046 1.090905e-07
===========>   testing    <===========
Epoch: [1755][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.1329 (0.1329)	
0.9999969 2.1823436e-07
Epoch: [1755][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.2204 (0.0638)	
0.9999931 2.2446358e-07
Epoch: [1755][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0822 (0.0580)	
0.99999285 2.4875845e-07
loss:  0.04088310716097421 0.03862828731324508
===========>   training    <===========
Epoch: [1756][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0321 (0.0321)	
0.9999937 8.953725e-08
===========>   testing    <===========
Epoch: [1756][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.1251 (0.1251)	
0.9999968 2.2492922e-07
Epoch: [1756][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.2353 (0.0636)	
0.9999926 2.2915695e-07
Epoch: [1756][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0847 (0.0579)	
0.9999927 2.5612772e-07
loss:  0.04113575380915002 0.03862828731324508
===========>   training    <===========
Epoch: [1757][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0357 (0.0357)	
0.9999938 4.793599e-07
===========>   testing    <===========
Epoch: [1757][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.1175 (0.1175)	
0.99999714 1.7331496e-07
Epoch: [1757][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.2050 (0.0636)	
0.99999404 1.7944726e-07
Epoch: [1757][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0884 (0.0579)	
0.99999416 1.9636813e-07
loss:  0.04118597862788531 0.03862828731324508
===========>   training    <===========
Epoch: [1758][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0320 (0.0320)	
0.99999666 9.109916e-08
===========>   testing    <===========
Epoch: [1758][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.1180 (0.1180)	
0.99999726 2.0136045e-07
Epoch: [1758][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.1523 (0.0624)	
0.99999404 2.0533761e-07
Epoch: [1758][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0910 (0.0575)	
0.99999416 2.2680105e-07
loss:  0.041096945770987325 0.03862828731324508
===========>   training    <===========
Epoch: [1759][0/23]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0337 (0.0337)	
0.9999907 4.1707216e-07
===========>   testing    <===========
Epoch: [1759][0/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.1158 (0.1158)	
0.999997 2.478137e-07
Epoch: [1759][100/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.1933 (0.0627)	
0.9999933 2.5224315e-07
Epoch: [1759][200/289]	Lr-deconv: [0.0]	Lr-other: [1.1533301892006358e-05]	Loss 0.0927 (0.0577)	
0.99999344 2.807647e-07
loss:  0.04131829673511778 0.03862828731324508
===========>   training    <===========
Epoch: [1760][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0338 (0.0338)	
0.99998987 1.3214009e-07
===========>   testing    <===========
Epoch: [1760][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.1226 (0.1226)	
0.9999968 2.5573183e-07
Epoch: [1760][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.1773 (0.0624)	
0.99999297 2.5856968e-07
Epoch: [1760][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0977 (0.0576)	
0.99999297 2.8940045e-07
loss:  0.041304856494049025 0.03862828731324508
===========>   training    <===========
Epoch: [1761][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0321 (0.0321)	
0.99999344 2.0070209e-07
===========>   testing    <===========
Epoch: [1761][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.1358 (0.1358)	
0.9999969 1.9113651e-07
Epoch: [1761][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.2331 (0.0630)	
0.9999927 1.968211e-07
Epoch: [1761][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0863 (0.0575)	
0.9999933 2.1985224e-07
loss:  0.04131286067024531 0.03862828731324508
===========>   training    <===========
Epoch: [1762][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0363 (0.0363)	
0.9999927 9.749626e-08
===========>   testing    <===========
Epoch: [1762][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.1340 (0.1340)	
0.999997 1.7709552e-07
Epoch: [1762][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.2320 (0.0628)	
0.99999285 1.8157603e-07
Epoch: [1762][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0819 (0.0574)	
0.9999939 2.0060851e-07
loss:  0.04141430496123333 0.03862828731324508
===========>   training    <===========
Epoch: [1763][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0335 (0.0335)	
0.99999607 1.8105658e-07
===========>   testing    <===========
Epoch: [1763][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.1305 (0.1305)	
0.99999726 1.5428952e-07
Epoch: [1763][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.2826 (0.0639)	
0.99999344 1.5858308e-07
Epoch: [1763][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0836 (0.0579)	
0.9999943 1.7212798e-07
loss:  0.04138697496187038 0.03862828731324508
===========>   training    <===========
Epoch: [1764][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0319 (0.0319)	
0.99999535 2.6973697e-07
===========>   testing    <===========
Epoch: [1764][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.1312 (0.1312)	
0.99999666 2.1080147e-07
Epoch: [1764][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.3231 (0.0635)	
0.99999166 2.1457164e-07
Epoch: [1764][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0807 (0.0576)	
0.9999926 2.3909956e-07
loss:  0.04105537512110924 0.03862828731324508
===========>   training    <===========
Epoch: [1765][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0343 (0.0343)	
0.99998903 1.7517725e-07
===========>   testing    <===========
Epoch: [1765][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.1306 (0.1306)	
0.99999714 2.4496813e-07
Epoch: [1765][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.3035 (0.0638)	
0.9999927 2.4710428e-07
Epoch: [1765][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0862 (0.0577)	
0.9999937 2.7417084e-07
loss:  0.041453024101515634 0.03862828731324508
===========>   training    <===========
Epoch: [1766][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0344 (0.0344)	
0.9999963 1.5201532e-07
===========>   testing    <===========
Epoch: [1766][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.1314 (0.1314)	
0.9999968 1.9320485e-07
Epoch: [1766][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.1975 (0.0626)	
0.99999225 1.9373698e-07
Epoch: [1766][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0857 (0.0570)	
0.9999931 2.1760547e-07
loss:  0.04106470549069008 0.03862828731324508
===========>   training    <===========
Epoch: [1767][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0329 (0.0329)	
0.9999931 1.2914082e-08
===========>   testing    <===========
Epoch: [1767][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.1207 (0.1207)	
0.999997 2.3222331e-07
Epoch: [1767][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.1499 (0.0624)	
0.99999344 2.3684099e-07
Epoch: [1767][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0863 (0.0569)	
0.9999939 2.6103893e-07
loss:  0.040837436094172785 0.03862828731324508
===========>   training    <===========
Epoch: [1768][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0344 (0.0344)	
0.9999969 1.6290565e-07
===========>   testing    <===========
Epoch: [1768][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.1209 (0.1209)	
0.99999666 2.608115e-07
Epoch: [1768][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.2267 (0.0631)	
0.99999225 2.9734693e-07
Epoch: [1768][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0776 (0.0572)	
0.9999937 3.387896e-07
loss:  0.04116346868302634 0.03862828731324508
===========>   training    <===========
Epoch: [1769][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0319 (0.0319)	
0.9999894 6.59582e-08
===========>   testing    <===========
Epoch: [1769][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.1157 (0.1157)	
0.9999964 2.2663932e-07
Epoch: [1769][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.2441 (0.0635)	
0.999992 2.3277808e-07
Epoch: [1769][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0762 (0.0575)	
0.99999356 2.6233016e-07
loss:  0.04128696446343383 0.03862828731324508
===========>   training    <===========
Epoch: [1770][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0304 (0.0304)	
0.9999926 2.0037602e-07
===========>   testing    <===========
Epoch: [1770][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.1012 (0.1012)	
0.99999654 2.2417157e-07
Epoch: [1770][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.2222 (0.0629)	
0.9999919 2.3266578e-07
Epoch: [1770][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0828 (0.0571)	
0.9999933 2.6587946e-07
loss:  0.04123563870724112 0.03862828731324508
===========>   training    <===========
Epoch: [1771][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0356 (0.0356)	
0.9999945 1.7300219e-07
===========>   testing    <===========
Epoch: [1771][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.1180 (0.1180)	
0.9999968 2.3561321e-07
Epoch: [1771][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.2024 (0.0631)	
0.99999225 2.7661594e-07
Epoch: [1771][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0818 (0.0574)	
0.9999932 2.966377e-07
loss:  0.04124329031460028 0.03862828731324508
===========>   training    <===========
Epoch: [1772][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0335 (0.0335)	
0.99999523 6.3710864e-08
===========>   testing    <===========
Epoch: [1772][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.1089 (0.1089)	
0.9999968 2.3154155e-07
Epoch: [1772][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.1716 (0.0623)	
0.99999285 2.4213426e-07
Epoch: [1772][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0792 (0.0569)	
0.9999937 2.704461e-07
loss:  0.04119462390402118 0.03862828731324508
===========>   training    <===========
Epoch: [1773][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0366 (0.0366)	
0.99999166 1.18010774e-07
===========>   testing    <===========
Epoch: [1773][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.1041 (0.1041)	
0.99999654 2.3875003e-07
Epoch: [1773][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.1795 (0.0619)	
0.9999919 2.744743e-07
Epoch: [1773][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0833 (0.0565)	
0.9999927 3.0955295e-07
loss:  0.041042328502043035 0.03862828731324508
===========>   training    <===========
Epoch: [1774][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0349 (0.0349)	
0.99999523 1.1778343e-07
===========>   testing    <===========
Epoch: [1774][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.1095 (0.1095)	
0.9999969 2.364224e-07
Epoch: [1774][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.1683 (0.0619)	
0.9999937 2.4562527e-07
Epoch: [1774][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0818 (0.0566)	
0.9999944 2.7720537e-07
loss:  0.04099165378394831 0.03862828731324508
===========>   training    <===========
Epoch: [1775][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0347 (0.0347)	
0.99999404 2.2829795e-07
===========>   testing    <===========
Epoch: [1775][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0970 (0.0970)	
0.9999968 2.922533e-07
Epoch: [1775][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.1384 (0.0617)	
0.99999285 3.0612574e-07
Epoch: [1775][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0790 (0.0564)	
0.9999939 3.4508307e-07
loss:  0.04095406415743352 0.03862828731324508
===========>   training    <===========
Epoch: [1776][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0292 (0.0292)	
0.999995 1.1462124e-08
===========>   testing    <===========
Epoch: [1776][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0942 (0.0942)	
0.9999974 2.0744051e-07
Epoch: [1776][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.1329 (0.0618)	
0.99999356 2.1206209e-07
Epoch: [1776][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0794 (0.0566)	
0.99999464 2.4086916e-07
loss:  0.04098066534174882 0.03862828731324508
===========>   training    <===========
Epoch: [1777][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0309 (0.0309)	
0.9999918 5.3543694e-09
===========>   testing    <===========
Epoch: [1777][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.1129 (0.1129)	
0.9999968 2.2633822e-07
Epoch: [1777][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0941 (0.0610)	
0.9999924 2.3355146e-07
Epoch: [1777][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0800 (0.0564)	
0.9999931 2.6020234e-07
loss:  0.04056391207782961 0.03862828731324508
===========>   training    <===========
Epoch: [1778][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0359 (0.0359)	
0.9999932 1.6323527e-08
===========>   testing    <===========
Epoch: [1778][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.1052 (0.1052)	
0.9999968 2.3352474e-07
Epoch: [1778][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.1306 (0.0609)	
0.99999297 2.4418884e-07
Epoch: [1778][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0831 (0.0564)	
0.99999356 2.7813698e-07
loss:  0.04081676460500727 0.03862828731324508
===========>   training    <===========
Epoch: [1779][0/23]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0443 (0.0443)	
0.9999901 9.617529e-07
===========>   testing    <===========
Epoch: [1779][0/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.1111 (0.1111)	
0.99999666 2.2579705e-07
Epoch: [1779][100/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.1788 (0.0612)	
0.99999285 2.3464183e-07
Epoch: [1779][200/289]	Lr-deconv: [0.0]	Lr-other: [1.095663679740604e-05]	Loss 0.0799 (0.0564)	
0.99999356 2.6629664e-07
loss:  0.04099958264299497 0.03862828731324508
===========>   training    <===========
Epoch: [1780][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0288 (0.0288)	
0.9999889 3.413517e-07
===========>   testing    <===========
Epoch: [1780][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1118 (0.1118)	
0.9999968 2.5091566e-07
Epoch: [1780][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0868 (0.0594)	
0.9999931 2.5742852e-07
Epoch: [1780][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0870 (0.0555)	
0.9999938 2.919235e-07
loss:  0.040389757492787504 0.03862828731324508
===========>   training    <===========
Epoch: [1781][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0353 (0.0353)	
0.9999887 3.634577e-08
===========>   testing    <===========
Epoch: [1781][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1201 (0.1201)	
0.9999962 2.0427372e-07
Epoch: [1781][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0696 (0.0592)	
0.9999896 2.8937203e-07
Epoch: [1781][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0885 (0.0555)	
0.99999154 2.8088763e-07
loss:  0.04044191166163469 0.03862828731324508
===========>   training    <===========
Epoch: [1782][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0327 (0.0327)	
0.999995 1.6209329e-07
===========>   testing    <===========
Epoch: [1782][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1157 (0.1157)	
0.99999654 2.3073235e-07
Epoch: [1782][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1418 (0.0601)	
0.9999914 2.4341693e-07
Epoch: [1782][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0896 (0.0557)	
0.9999926 2.6617934e-07
loss:  0.04059405068074462 0.03862828731324508
===========>   training    <===========
Epoch: [1783][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0331 (0.0331)	
0.9999807 2.0319285e-07
===========>   testing    <===========
Epoch: [1783][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1230 (0.1230)	
0.99999726 1.8094042e-07
Epoch: [1783][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.2245 (0.0619)	
0.9999938 1.8925122e-07
Epoch: [1783][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0847 (0.0568)	
0.9999944 2.026825e-07
loss:  0.04101029304561177 0.03862828731324508
===========>   training    <===========
Epoch: [1784][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0309 (0.0309)	
0.9999895 1.2813894e-07
===========>   testing    <===========
Epoch: [1784][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1208 (0.1208)	
0.9999964 1.8977879e-07
Epoch: [1784][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1665 (0.0620)	
0.99999094 2.4865076e-07
Epoch: [1784][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0821 (0.0567)	
0.99999225 2.4876937e-07
loss:  0.04089393101146932 0.03862828731324508
===========>   training    <===========
Epoch: [1785][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0325 (0.0325)	
0.99999523 7.731442e-08
===========>   testing    <===========
Epoch: [1785][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1017 (0.1017)	
0.9999963 2.2035667e-07
Epoch: [1785][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1105 (0.0603)	
0.9999925 2.2824354e-07
Epoch: [1785][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0845 (0.0559)	
0.9999933 2.528552e-07
loss:  0.04054338589641138 0.03862828731324508
===========>   training    <===========
Epoch: [1786][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0343 (0.0343)	
0.99999523 4.451886e-08
===========>   testing    <===========
Epoch: [1786][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1139 (0.1139)	
0.999997 1.6153096e-07
Epoch: [1786][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1668 (0.0613)	
0.9999931 1.6905972e-07
Epoch: [1786][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0830 (0.0565)	
0.9999943 1.8342438e-07
loss:  0.040853110447841456 0.03862828731324508
===========>   training    <===========
Epoch: [1787][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0388 (0.0388)	
0.9999969 1.05708935e-07
===========>   testing    <===========
Epoch: [1787][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1152 (0.1152)	
0.999997 2.0606011e-07
Epoch: [1787][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1350 (0.0607)	
0.9999924 2.173199e-07
Epoch: [1787][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0875 (0.0564)	
0.99999404 2.3352675e-07
loss:  0.04073695233911767 0.03862828731324508
===========>   training    <===========
Epoch: [1788][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0341 (0.0341)	
0.9999931 5.3303044e-08
===========>   testing    <===========
Epoch: [1788][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1185 (0.1185)	
0.9999969 2.481779e-07
Epoch: [1788][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1142 (0.0607)	
0.9999919 2.5944112e-07
Epoch: [1788][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0786 (0.0559)	
0.9999937 2.9177153e-07
loss:  0.040714717854334226 0.03862828731324508
===========>   training    <===========
Epoch: [1789][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0315 (0.0315)	
0.99999857 1.11723956e-07
===========>   testing    <===========
Epoch: [1789][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1129 (0.1129)	
0.9999968 2.119889e-07
Epoch: [1789][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0944 (0.0610)	
0.99999213 2.196741e-07
Epoch: [1789][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0795 (0.0564)	
0.9999939 2.3782603e-07
loss:  0.04061359305388201 0.03862828731324508
===========>   training    <===========
Epoch: [1790][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0314 (0.0314)	
0.999992 5.9234157e-08
===========>   testing    <===========
Epoch: [1790][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1094 (0.1094)	
0.9999964 2.418504e-07
Epoch: [1790][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1079 (0.0617)	
0.9999907 2.613331e-07
Epoch: [1790][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0699 (0.0564)	
0.9999926 2.7856277e-07
loss:  0.0411245117234984 0.03862828731324508
===========>   training    <===========
Epoch: [1791][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0454 (0.0454)	
0.999995 3.7223586e-08
===========>   testing    <===========
Epoch: [1791][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1147 (0.1147)	
0.9999969 2.0699447e-07
Epoch: [1791][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0817 (0.0612)	
0.99999166 2.193239e-07
Epoch: [1791][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0762 (0.0562)	
0.9999937 2.3266334e-07
loss:  0.04061315707494384 0.03862828731324508
===========>   training    <===========
Epoch: [1792][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0374 (0.0374)	
0.99999 8.3167855e-09
===========>   testing    <===========
Epoch: [1792][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1158 (0.1158)	
0.999997 2.0387357e-07
Epoch: [1792][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1416 (0.0621)	
0.9999926 2.1330261e-07
Epoch: [1792][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0733 (0.0566)	
0.99999416 2.2927632e-07
loss:  0.04091797627783755 0.03862828731324508
===========>   training    <===========
Epoch: [1793][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0377 (0.0377)	
0.99999464 1.26145e-07
===========>   testing    <===========
Epoch: [1793][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1060 (0.1060)	
0.9999969 2.230341e-07
Epoch: [1793][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1139 (0.0615)	
0.9999913 2.2720761e-07
Epoch: [1793][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0776 (0.0561)	
0.99999344 2.5141964e-07
loss:  0.040616939396842744 0.03862828731324508
===========>   training    <===========
Epoch: [1794][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0306 (0.0306)	
0.99998593 4.9739174e-07
===========>   testing    <===========
Epoch: [1794][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1078 (0.1078)	
0.99999666 1.7545564e-07
Epoch: [1794][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0835 (0.0610)	
0.9999913 1.8118509e-07
Epoch: [1794][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0805 (0.0560)	
0.99999344 1.9681379e-07
loss:  0.04045992100459406 0.03862828731324508
===========>   training    <===========
Epoch: [1795][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0293 (0.0293)	
0.9999925 2.0544769e-07
===========>   testing    <===========
Epoch: [1795][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1023 (0.1023)	
0.99999726 1.763506e-07
Epoch: [1795][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0787 (0.0611)	
0.9999931 1.8623898e-07
Epoch: [1795][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0829 (0.0562)	
0.99999464 2.0147877e-07
loss:  0.0401916577970568 0.03862828731324508
===========>   training    <===========
Epoch: [1796][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0335 (0.0335)	
0.99999464 1.14164834e-07
===========>   testing    <===========
Epoch: [1796][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1056 (0.1056)	
0.99999595 2.0562666e-07
Epoch: [1796][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0813 (0.0613)	
0.9999895 2.4611532e-07
Epoch: [1796][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0822 (0.0562)	
0.9999924 2.684477e-07
loss:  0.04028452526188564 0.03862828731324508
===========>   training    <===========
Epoch: [1797][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0303 (0.0303)	
0.9999908 3.237078e-07
===========>   testing    <===========
Epoch: [1797][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1048 (0.1048)	
0.9999976 2.1138891e-07
Epoch: [1797][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1192 (0.0614)	
0.99999356 2.1912193e-07
Epoch: [1797][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0801 (0.0565)	
0.9999951 2.3605179e-07
loss:  0.04008274356129882 0.03862828731324508
===========>   training    <===========
Epoch: [1798][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0294 (0.0294)	
0.99999523 1.5496727e-07
===========>   testing    <===========
Epoch: [1798][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1055 (0.1055)	
0.999997 1.8469258e-07
Epoch: [1798][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1906 (0.0631)	
0.9999926 1.8827015e-07
Epoch: [1798][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0720 (0.0573)	
0.9999944 2.018777e-07
loss:  0.041150249999076904 0.03862828731324508
===========>   training    <===========
Epoch: [1799][0/23]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0273 (0.0273)	
0.99999034 1.2901015e-07
===========>   testing    <===========
Epoch: [1799][0/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1086 (0.1086)	
0.9999976 1.9706734e-07
Epoch: [1799][100/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.1878 (0.0624)	
0.9999932 1.9979841e-07
Epoch: [1799][200/289]	Lr-deconv: [0.0]	Lr-other: [1.0408804957535738e-05]	Loss 0.0751 (0.0569)	
0.9999949 2.2314474e-07
loss:  0.04067739594446085 0.03862828731324508
===========>   training    <===========
Epoch: [1800][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0330 (0.0330)	
0.99999213 2.1610076e-07
===========>   testing    <===========
Epoch: [1800][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0997 (0.0997)	
0.9999975 2.3560827e-07
Epoch: [1800][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1721 (0.0628)	
0.99999285 2.3907583e-07
Epoch: [1800][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0799 (0.0573)	
0.9999945 2.626789e-07
loss:  0.04076278403100264 0.03862828731324508
===========>   training    <===========
Epoch: [1801][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0374 (0.0374)	
0.99999 6.680574e-08
===========>   testing    <===========
Epoch: [1801][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1121 (0.1121)	
0.9999976 2.1124885e-07
Epoch: [1801][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.2124 (0.0627)	
0.9999926 2.1576098e-07
Epoch: [1801][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0767 (0.0569)	
0.9999943 2.4066685e-07
loss:  0.0407136197527983 0.03862828731324508
===========>   training    <===========
Epoch: [1802][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0313 (0.0313)	
0.9999969 4.0277783e-08
===========>   testing    <===========
Epoch: [1802][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1221 (0.1221)	
0.9999975 1.9974603e-07
Epoch: [1802][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.2271 (0.0622)	
0.9999925 2.0354817e-07
Epoch: [1802][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0776 (0.0567)	
0.9999945 2.2531653e-07
loss:  0.040588045254970284 0.03862828731324508
===========>   training    <===========
Epoch: [1803][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0413 (0.0413)	
0.9999974 1.7792499e-06
===========>   testing    <===========
Epoch: [1803][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1154 (0.1154)	
0.9999975 1.7693128e-07
Epoch: [1803][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1885 (0.0620)	
0.99999285 1.8119495e-07
Epoch: [1803][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0780 (0.0569)	
0.99999475 1.9933859e-07
loss:  0.04078589436584934 0.03862828731324508
===========>   training    <===========
Epoch: [1804][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0312 (0.0312)	
0.9999852 5.1347925e-08
===========>   testing    <===========
Epoch: [1804][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1122 (0.1122)	
0.9999975 2.1419055e-07
Epoch: [1804][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1799 (0.0625)	
0.99999297 2.189993e-07
Epoch: [1804][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0761 (0.0570)	
0.9999943 2.378537e-07
loss:  0.040959725519947754 0.03862828731324508
===========>   training    <===========
Epoch: [1805][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0330 (0.0330)	
0.9999976 3.0269476e-09
===========>   testing    <===========
Epoch: [1805][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1212 (0.1212)	
0.999997 2.2931874e-07
Epoch: [1805][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1279 (0.0619)	
0.9999912 2.3103796e-07
Epoch: [1805][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0758 (0.0567)	
0.9999932 2.55135e-07
loss:  0.04086567815446163 0.03862828731324508
===========>   training    <===========
Epoch: [1806][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0310 (0.0310)	
0.99999285 1.5813612e-08
===========>   testing    <===========
Epoch: [1806][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1168 (0.1168)	
0.99999726 2.1094787e-07
Epoch: [1806][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.2075 (0.0634)	
0.99999166 2.1313343e-07
Epoch: [1806][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0680 (0.0575)	
0.99999356 2.3873181e-07
loss:  0.04096490150708809 0.03862828731324508
===========>   training    <===========
Epoch: [1807][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0294 (0.0294)	
0.99999344 2.6702472e-07
===========>   testing    <===========
Epoch: [1807][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1260 (0.1260)	
0.9999969 1.9921944e-07
Epoch: [1807][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1507 (0.0628)	
0.99999046 2.0227391e-07
Epoch: [1807][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0694 (0.0569)	
0.99999297 2.2776169e-07
loss:  0.04060825012750169 0.03862828731324508
===========>   training    <===========
Epoch: [1808][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0346 (0.0346)	
0.9999914 5.198076e-07
===========>   testing    <===========
Epoch: [1808][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1214 (0.1214)	
0.999997 2.0638501e-07
Epoch: [1808][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1255 (0.0625)	
0.99999094 2.0921146e-07
Epoch: [1808][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0750 (0.0572)	
0.9999933 2.3677416e-07
loss:  0.0406515770425413 0.03862828731324508
===========>   training    <===========
Epoch: [1809][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0309 (0.0309)	
0.99998283 5.18195e-08
===========>   testing    <===========
Epoch: [1809][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1161 (0.1161)	
0.9999969 1.8971093e-07
Epoch: [1809][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0801 (0.0617)	
0.99999094 1.9238188e-07
Epoch: [1809][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0754 (0.0567)	
0.9999937 2.1481816e-07
loss:  0.04037555304261786 0.03862828731324508
===========>   training    <===========
Epoch: [1810][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0344 (0.0344)	
0.99998987 2.532988e-07
===========>   testing    <===========
Epoch: [1810][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1103 (0.1103)	
0.999997 1.7174871e-07
Epoch: [1810][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1378 (0.0627)	
0.999992 1.7406798e-07
Epoch: [1810][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0736 (0.0572)	
0.99999404 1.9420126e-07
loss:  0.04074794690220207 0.03862828731324508
===========>   training    <===========
Epoch: [1811][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0279 (0.0279)	
0.99998784 1.608733e-07
===========>   testing    <===========
Epoch: [1811][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1024 (0.1024)	
0.9999974 1.5547604e-07
Epoch: [1811][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1662 (0.0632)	
0.99999225 1.5612268e-07
Epoch: [1811][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0718 (0.0570)	
0.99999416 1.7326256e-07
loss:  0.040660918463538476 0.03862828731324508
===========>   training    <===========
Epoch: [1812][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0363 (0.0363)	
0.99999404 4.5813488e-07
===========>   testing    <===========
Epoch: [1812][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1176 (0.1176)	
0.9999969 2.2479797e-07
Epoch: [1812][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1877 (0.0634)	
0.99999034 2.2562486e-07
Epoch: [1812][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0658 (0.0571)	
0.99999285 2.5543665e-07
loss:  0.04055876900491717 0.03862828731324508
===========>   training    <===========
Epoch: [1813][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0385 (0.0385)	
0.99998283 1.17006664e-07
===========>   testing    <===========
Epoch: [1813][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1192 (0.1192)	
0.99999726 2.044733e-07
Epoch: [1813][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1948 (0.0633)	
0.99999225 2.0846284e-07
Epoch: [1813][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0733 (0.0571)	
0.99999416 2.2734784e-07
loss:  0.040290675934678055 0.03862828731324508
===========>   training    <===========
Epoch: [1814][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0318 (0.0318)	
0.9999821 3.7667682e-08
===========>   testing    <===========
Epoch: [1814][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1167 (0.1167)	
0.9999974 1.9357094e-07
Epoch: [1814][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1952 (0.0635)	
0.9999926 1.9668693e-07
Epoch: [1814][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0776 (0.0575)	
0.9999943 2.1737608e-07
loss:  0.04035342473296677 0.03862828731324508
===========>   training    <===========
Epoch: [1815][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0272 (0.0272)	
0.9999982 2.0445478e-07
===========>   testing    <===========
Epoch: [1815][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1129 (0.1129)	
0.9999975 1.9412201e-07
Epoch: [1815][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1222 (0.0625)	
0.9999924 1.9475843e-07
Epoch: [1815][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0803 (0.0570)	
0.99999404 2.1589435e-07
loss:  0.04018173554589488 0.03862828731324508
===========>   training    <===========
Epoch: [1816][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0370 (0.0370)	
0.9999871 3.1106578e-07
===========>   testing    <===========
Epoch: [1816][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1151 (0.1151)	
0.9999975 1.7017797e-07
Epoch: [1816][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1341 (0.0628)	
0.9999933 1.718226e-07
Epoch: [1816][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0731 (0.0572)	
0.9999945 1.8603929e-07
loss:  0.040787550017454266 0.03862828731324508
===========>   training    <===========
Epoch: [1817][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0412 (0.0412)	
0.9999877 3.539564e-08
===========>   testing    <===========
Epoch: [1817][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1242 (0.1242)	
0.9999974 1.8754544e-07
Epoch: [1817][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1637 (0.0629)	
0.99999225 1.9140136e-07
Epoch: [1817][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0684 (0.0570)	
0.9999939 2.0722103e-07
loss:  0.04067556081315815 0.03862828731324508
===========>   training    <===========
Epoch: [1818][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0287 (0.0287)	
0.999997 1.0810765e-07
===========>   testing    <===========
Epoch: [1818][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1219 (0.1219)	
0.99999666 2.2197524e-07
Epoch: [1818][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0879 (0.0617)	
0.9999908 2.2510174e-07
Epoch: [1818][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0676 (0.0564)	
0.9999925 2.4966394e-07
loss:  0.04068829388715545 0.03862828731324508
===========>   training    <===========
Epoch: [1819][0/23]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0331 (0.0331)	
0.9999987 1.07960485e-08
===========>   testing    <===========
Epoch: [1819][0/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1181 (0.1181)	
0.999997 1.811977e-07
Epoch: [1819][100/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.1915 (0.0628)	
0.9999927 1.8607051e-07
Epoch: [1819][200/289]	Lr-deconv: [0.0]	Lr-other: [9.88836470965895e-06]	Loss 0.0715 (0.0570)	
0.99999416 1.9850104e-07
loss:  0.04105590549048943 0.03862828731324508
===========>   training    <===========
Epoch: [1820][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0288 (0.0288)	
0.9999939 1.1951623e-07
===========>   testing    <===========
Epoch: [1820][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1153 (0.1153)	
0.9999969 1.7298899e-07
Epoch: [1820][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1579 (0.0624)	
0.9999924 1.7774576e-07
Epoch: [1820][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0710 (0.0566)	
0.99999356 1.9582917e-07
loss:  0.040879134614056345 0.03862828731324508
===========>   training    <===========
Epoch: [1821][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0362 (0.0362)	
0.9999976 1.250693e-07
===========>   testing    <===========
Epoch: [1821][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1185 (0.1185)	
0.999997 1.8650417e-07
Epoch: [1821][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1359 (0.0624)	
0.9999927 1.9133601e-07
Epoch: [1821][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0707 (0.0569)	
0.99999356 2.122106e-07
loss:  0.0409588718234285 0.03862828731324508
===========>   training    <===========
Epoch: [1822][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0329 (0.0329)	
0.9999962 2.7841827e-07
===========>   testing    <===========
Epoch: [1822][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1209 (0.1209)	
0.9999974 1.8043777e-07
Epoch: [1822][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1465 (0.0626)	
0.9999937 1.8481576e-07
Epoch: [1822][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0734 (0.0573)	
0.99999416 2.090593e-07
loss:  0.040805606977190156 0.03862828731324508
===========>   training    <===========
Epoch: [1823][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0331 (0.0331)	
0.99998987 9.665786e-08
===========>   testing    <===========
Epoch: [1823][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1155 (0.1155)	
0.99999714 2.073865e-07
Epoch: [1823][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1404 (0.0624)	
0.999992 2.1421916e-07
Epoch: [1823][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0754 (0.0571)	
0.9999932 2.4418864e-07
loss:  0.04065174683674233 0.03862828731324508
===========>   training    <===========
Epoch: [1824][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0313 (0.0313)	
0.99999166 1.2023095e-07
===========>   testing    <===========
Epoch: [1824][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1215 (0.1215)	
0.99999726 2.275511e-07
Epoch: [1824][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1519 (0.0624)	
0.99999225 2.3438015e-07
Epoch: [1824][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0708 (0.0568)	
0.9999938 2.67265e-07
loss:  0.0406237081688382 0.03862828731324508
===========>   training    <===========
Epoch: [1825][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0291 (0.0291)	
0.9999963 1.00271414e-07
===========>   testing    <===========
Epoch: [1825][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1197 (0.1197)	
0.99999714 1.9641551e-07
Epoch: [1825][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1414 (0.0629)	
0.9999926 2.0218867e-07
Epoch: [1825][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0714 (0.0573)	
0.9999938 2.275051e-07
loss:  0.04096225245904905 0.03862828731324508
===========>   training    <===========
Epoch: [1826][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0273 (0.0273)	
0.99999726 1.5502552e-07
===========>   testing    <===========
Epoch: [1826][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1210 (0.1210)	
0.9999968 2.4831215e-07
Epoch: [1826][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0909 (0.0620)	
0.9999908 2.5932437e-07
Epoch: [1826][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0674 (0.0568)	
0.9999925 2.9121193e-07
loss:  0.040862476722638985 0.03862828731324508
===========>   training    <===========
Epoch: [1827][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0296 (0.0296)	
0.9999862 3.7054858e-07
===========>   testing    <===========
Epoch: [1827][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1122 (0.1122)	
0.9999968 1.8877535e-07
Epoch: [1827][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1128 (0.0618)	
0.9999912 1.9849062e-07
Epoch: [1827][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0742 (0.0567)	
0.9999931 2.1656786e-07
loss:  0.041028826297897725 0.03862828731324508
===========>   training    <===========
Epoch: [1828][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0327 (0.0327)	
0.9999981 1.6033654e-08
===========>   testing    <===========
Epoch: [1828][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1113 (0.1113)	
0.999997 1.7157518e-07
Epoch: [1828][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0786 (0.0615)	
0.999992 1.8352655e-07
Epoch: [1828][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0805 (0.0567)	
0.9999937 1.9815586e-07
loss:  0.04076077608274897 0.03862828731324508
===========>   training    <===========
Epoch: [1829][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0359 (0.0359)	
0.99999094 1.0813074e-07
===========>   testing    <===========
Epoch: [1829][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1195 (0.1195)	
0.9999968 1.532634e-07
Epoch: [1829][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0967 (0.0612)	
0.99999166 1.6056951e-07
Epoch: [1829][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0826 (0.0565)	
0.9999938 1.7339728e-07
loss:  0.040628020751566685 0.03862828731324508
===========>   training    <===========
Epoch: [1830][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0326 (0.0326)	
0.99999106 2.7771387e-08
===========>   testing    <===========
Epoch: [1830][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1126 (0.1126)	
0.9999968 1.8252535e-07
Epoch: [1830][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0798 (0.0612)	
0.9999924 1.9094193e-07
Epoch: [1830][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0804 (0.0566)	
0.9999943 2.1032034e-07
loss:  0.04064886321022121 0.03862828731324508
===========>   training    <===========
Epoch: [1831][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0327 (0.0327)	
0.99999547 1.501473e-07
===========>   testing    <===========
Epoch: [1831][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1242 (0.1242)	
0.99999654 2.0725642e-07
Epoch: [1831][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0744 (0.0610)	
0.9999918 2.1501207e-07
Epoch: [1831][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0799 (0.0563)	
0.9999937 2.3746477e-07
loss:  0.04047625680896494 0.03862828731324508
===========>   training    <===========
Epoch: [1832][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0304 (0.0304)	
0.99999475 1.2444242e-07
===========>   testing    <===========
Epoch: [1832][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1264 (0.1264)	
0.9999963 2.5408315e-07
Epoch: [1832][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1010 (0.0617)	
0.99999106 2.6440884e-07
Epoch: [1832][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0809 (0.0564)	
0.99999297 2.9301435e-07
loss:  0.04082876262352597 0.03862828731324508
===========>   training    <===========
Epoch: [1833][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0308 (0.0308)	
0.9999949 1.9203691e-07
===========>   testing    <===========
Epoch: [1833][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1247 (0.1247)	
0.99999607 1.9473428e-07
Epoch: [1833][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1410 (0.0624)	
0.9999912 2.016214e-07
Epoch: [1833][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0745 (0.0568)	
0.9999933 2.2777081e-07
loss:  0.04100053494239486 0.03862828731324508
===========>   training    <===========
Epoch: [1834][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0372 (0.0372)	
0.9999943 2.1011902e-08
===========>   testing    <===========
Epoch: [1834][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1250 (0.1250)	
0.99999654 1.8581852e-07
Epoch: [1834][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1422 (0.0625)	
0.9999919 1.925963e-07
Epoch: [1834][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0754 (0.0569)	
0.99999356 2.181274e-07
loss:  0.04104682545982696 0.03862828731324508
===========>   training    <===========
Epoch: [1835][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0417 (0.0417)	
0.9999937 1.6455249e-06
===========>   testing    <===========
Epoch: [1835][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1057 (0.1057)	
0.99999714 1.7828053e-07
Epoch: [1835][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1131 (0.0626)	
0.9999937 1.8373548e-07
Epoch: [1835][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0844 (0.0572)	
0.99999464 2.104389e-07
loss:  0.04124519408909999 0.03862828731324508
===========>   training    <===========
Epoch: [1836][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0354 (0.0354)	
0.9999876 2.729472e-08
===========>   testing    <===========
Epoch: [1836][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1069 (0.1069)	
0.9999964 1.9412313e-07
Epoch: [1836][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1960 (0.0630)	
0.9999925 1.9918296e-07
Epoch: [1836][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0799 (0.0571)	
0.9999939 2.2611147e-07
loss:  0.04111027537414924 0.03862828731324508
===========>   training    <===========
Epoch: [1837][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0388 (0.0388)	
0.9999864 1.2131036e-07
===========>   testing    <===========
Epoch: [1837][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1056 (0.1056)	
0.9999964 1.6211108e-07
Epoch: [1837][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1873 (0.0629)	
0.999992 1.6720041e-07
Epoch: [1837][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0772 (0.0569)	
0.9999938 1.8884052e-07
loss:  0.04080050737611196 0.03862828731324508
===========>   training    <===========
Epoch: [1838][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0352 (0.0352)	
0.9999882 7.1759644e-08
===========>   testing    <===========
Epoch: [1838][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1096 (0.1096)	
0.9999964 1.8880955e-07
Epoch: [1838][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1663 (0.0624)	
0.9999919 1.9531123e-07
Epoch: [1838][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0829 (0.0565)	
0.9999937 2.2026211e-07
loss:  0.040651117220560695 0.03862828731324508
===========>   training    <===========
Epoch: [1839][0/23]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0305 (0.0305)	
0.9999894 2.418926e-07
===========>   testing    <===========
Epoch: [1839][0/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0997 (0.0997)	
0.99999654 1.5834536e-07
Epoch: [1839][100/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.1387 (0.0623)	
0.9999927 1.6457744e-07
Epoch: [1839][200/289]	Lr-deconv: [0.0]	Lr-other: [9.393946474176e-06]	Loss 0.0826 (0.0565)	
0.9999939 1.839685e-07
loss:  0.040887849401943566 0.03862828731324508
===========>   training    <===========
Epoch: [1840][0/23]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0290 (0.0290)	
0.99999714 1.7656618e-07
===========>   testing    <===========
Epoch: [1840][0/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.1044 (0.1044)	
0.99999666 1.7064929e-07
Epoch: [1840][100/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0986 (0.0621)	
0.9999924 1.7499241e-07
Epoch: [1840][200/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0742 (0.0565)	
0.99999356 1.9627957e-07
loss:  0.040883253209094805 0.03862828731324508
===========>   training    <===========
Epoch: [1841][0/23]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0405 (0.0405)	
0.99997616 1.6975167e-07
===========>   testing    <===========
Epoch: [1841][0/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.1058 (0.1058)	
0.9999969 1.8506603e-07
Epoch: [1841][100/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0903 (0.0628)	
0.9999926 1.9400211e-07
Epoch: [1841][200/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0748 (0.0571)	
0.9999938 2.1941908e-07
loss:  0.040831841230788646 0.03862828731324508
===========>   training    <===========
Epoch: [1842][0/23]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0328 (0.0328)	
0.9999933 3.095385e-07
===========>   testing    <===========
Epoch: [1842][0/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.1142 (0.1142)	
0.9999963 2.0366797e-07
Epoch: [1842][100/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0436 (0.0615)	
0.99999106 2.1194403e-07
Epoch: [1842][200/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0706 (0.0563)	
0.99999285 2.3757305e-07
loss:  0.04001393299536471 0.03862828731324508
===========>   training    <===========
Epoch: [1843][0/23]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0357 (0.0357)	
0.9999957 4.3830752e-07
===========>   testing    <===========
Epoch: [1843][0/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.1199 (0.1199)	
0.9999969 1.9032163e-07
Epoch: [1843][100/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0591 (0.0615)	
0.9999926 1.9770397e-07
Epoch: [1843][200/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0734 (0.0564)	
0.99999404 2.1552138e-07
loss:  0.04000463352271344 0.03862828731324508
===========>   training    <===========
Epoch: [1844][0/23]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0364 (0.0364)	
0.99999166 6.8842034e-08
===========>   testing    <===========
Epoch: [1844][0/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.1204 (0.1204)	
0.9999964 2.3143183e-07
Epoch: [1844][100/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0558 (0.0608)	
0.9999901 2.3785893e-07
Epoch: [1844][200/289]	Lr-deconv: [0.0]	Lr-other: [8.924249150467201e-06]	Loss 0.0733 (0.0559)	
0.99999225 2.749126e-07
loss:  0.04009385576493596 0.03862828731324508
===========>   training    <===========
